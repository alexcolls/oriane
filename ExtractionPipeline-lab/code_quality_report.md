# Code Quality Report

Generated on: $(date)

## Summary

This report provides a comprehensive analysis of code quality metrics, including:
- Linting and code style checks
- Type checking results
- Test coverage analysis
- Technical debt indicators

---

## Technical Debt Analysis

![TODO Count](https://img.shields.io/badge/TODO-22198-red)
![FIXME Count](https://img.shields.io/badge/FIXME-2716-red)
![Total Debt](https://img.shields.io/badge/Total_Debt-24914-red)

**TODO tags:** 22198  
**FIXME tags:** 2716  
**Total technical debt items:** 24914

### TODO Items

```
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:554:        # TODO should we eliminate the recursion?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:558:                    # TODO check whether we need to call `list_hook`
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:566:            # TODO is the interaction between `list_hook` and `use_list` ok?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:571:                    # TODO check whether we need to call hooks
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/formatters/terminal256.py:17:# TODO:
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/formatters/latex.py:337:        # TODO: add support for background colors
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/formatters/img.py:511:            # TODO: make sure tab expansion happens earlier in the chain.  It
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:711:        # different tokens.  TODO: DelegatingLexer should support this
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:843:    TODO: clean up the code here.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:482:                # TODO: Not sure if we need the SecTrustResultType for anything?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:95:    # TODO: Can we test whether something is contained within a requirement?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:98:    # TODO: Can we normalize the name and extra name?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:326:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:852:            # TODO version verification
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:766:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:931:                # TODO SHA256 digest
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:413:        # TODO check k, v for valid values
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:255:    # TODO document the mapping API and UNKNOWN default key
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:585:    # TODO could add iter* variants
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:1018:        # TODO: any other fields wanted
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/resultdict.py:6:    # TODO: Remove the else block and TYPE_CHECKING check when dropping support
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/sbcsgroupprober.py:57:        # TODO: See if using ISO-8859-8 Hebrew model works better here, since
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/sbcsgroupprober.py:63:        # TODO: ORDER MATTERS HERE. I changed the order vs what was in master
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/sbcsgroupprober.py:78:            # TODO: Restore Hungarian encodings (iso-8859-2 and windows-1250)
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/codingstatemachinedict.py:6:    # TODO: Remove the else block and TYPE_CHECKING check when dropping support
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/universaldetector.py:194:                    # TODO: This encoding is not supported by Python. Should remove?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/universaldetector.py:202:                    # TODO: This encoding is not supported by Python. Should remove?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/metadata/languages.py:11:# TODO: Add Ukrainian (KOI8-U)
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/chardet/sbcharsetprober.py:95:        # TODO: Make filter_international_words keep things in self.alphabet
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:520:        # TODO: Add optional support for socket.gethostbyname checking.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:660:        # TODO: should I do clean shutdown here? Do I have to?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:820:        # TODO: Well, crap.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:830:        # TODO: Update in line with above.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:505:                # TODO: Remove this in 3.0.0: see #2811
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3051:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/rich/cells.py:122:# TODO: This is inefficient
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/rich/cells.py:123:# TODO: This might not work with CWJ type characters
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/rich/text.py:542:        # TODO: This is a little inefficient, it is only used by full justify
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:220:        # TODO: There is an assumption that the result will be a
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/utils/subprocess.py:26:    # TODO: Remove `if TYPE_CHECKING` when dropping support for Python 3.7.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/cache.py:279:                # TODO: use DirectUrl.equivalent when
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py:33:    # TODO: Remove this block after dropping Python 3.8 support.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:346:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:442:        # TODO: Remove this attribute when packaging is upgraded to support the
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:196:        # TODO: Check already installed candidate, and use it if the link and
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:611:        # TODO: Are there more cases this needs to return True? Editable?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/index/collector.py:356:        # TODO: In the future, it would be nice if pip supported PEP 691
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/vcs/versioncontrol.py:45:    # TODO: Remove `if TYPE_CHECKING` when dropping support for Python 3.7.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:145:        # TODO: Try to get these passing down from the command?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/req_install.py:287:                # TODO: Remove these two variants when packaging is upgraded to
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/req_file.py:491:    # TODO: handle space after '\'.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/constructors.py:290:        # TODO: The is_installable_dir test here might not be necessary
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/req_set.py:78:        TODO remove this property together with the legacy resolver, since the new
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/metadata/base.py:174:        # TODO: this property is relatively costly to compute, memoize it ?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/metadata/base.py:184:                # TODO: get project location from second line of egg_link file
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:550:        # TODO: separate this part out from RequirementPreparer when the v1
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1024:/* TODO: remove */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1029:/* TODO: move these enums out to the appropriate submodule */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1073:/* TODO: remove */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1024:/* TODO: remove */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1029:/* TODO: move these enums out to the appropriate submodule */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1073:/* TODO: remove */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:81:/* TODO */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:88:/* TODO: Detect UWP, a.k.a. Windows Store app, and set this to 0. */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cuda_runtime.h:1391: * TODO detail
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cooperative_groups.h:1173:// TODO: Use a static dispatch to determine appropriate return type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:594:        # TODO: Add logic that removes the TransferState if the transfer is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:644:        # TODO: Not all exceptions are pickleable so if we are running
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:899:    # TODO: It may make sense to expose these class variables as configuration
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/s3transfer/__init__.py:857:                # TODO: we need a way to reset the callback if the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psycopg2/tz.py:158:# TODO: pre-generate some interesting time zones?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psycopg2/_range.py:526:# TODO: probably won't work with infs, nans and other tricky cases.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/cv2/__init__.py:19:# TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PdfParser.py:616:            # TODO: support reuse of deleted objects
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:2280:                    raise RuntimeError(msg)  # XXX TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/IcoImagePlugin.py:75:            # TODO: invent a more convenient method for proportional scalings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:134:    #TODO: Add support for sets provided by the user
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1323:        # TODO : Remove when lambdify accepts 'pymc' as module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1340:                # TODO: Replace the try-except block with only given_fn(*args)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1366:                    # TODO: Replace the try-except block with only given_fn(*args)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1383:            # TODO: Replace the try-except block with only fn(*args)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1610:            # TODO: do this for drv.py and frv.py if necessary.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1611:            # TODO: add more distributions here if there are more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:114:    ### TODO: Add tests after adding matrix distributions in numpy_rv_map
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/frv.py:460:            #TODO: Implement the mechanism for handling queries for symbolic sized distributions.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/drv.py:152:        # TODO: support discrete sets with non integer stepsizes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:415:            #TODO: Modify to support integration
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1694:    .. TODO - What is the difference between these degrees of freedom?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2986:    .. TODO - what does the parameter mean?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:77:        with ignore_warnings(UserWarning):  # TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:109:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:408:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:677:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1348:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1358:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_compound_rv.py:90:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_finite_rv.py:68:    # TODO: Make iid method!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_mix.py:80:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/random_matrix_models.py:249:        # TODO : Add support for Lie groups(as extensions of sympy.diffgeom)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:10:# TODO: The code below could be made more granular with something like:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:74:    # TODO: How can we test that the output of a SyntaxError is the original
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:732:                    # TODO: Implement this case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:868:                # TODO: support for singular initial condition
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:103:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/trigonometry.py:5:# TODO sin(a*x)*cos(b*x) -> sin((a+b)x) + sin((a-b)x) ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:38:# TODO: Add messages to NonElementaryIntegralException errors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:205:    # TODO: finish writing this and write tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:286:    # TODO: finish writing this and write tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:510:# TODO: better name for this function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:653:            # TODO: Write a dummy function that does this idiom
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:713:        # TODO: Is this check necessary, and if so, what should it do if it fails?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:772:        # check for regularity conditions (TODO), see issue 4215
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:201:        # TODO handle derivatives etc
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:745:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:119:    # TODO this needs more polar_lift (c/f entry for exp)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:164:    # TODO can do sin^n, sinh^n by expansion ... where?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:170:    # TODO can do t + a. but can also do by expansion... (XXX not really)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:187:    # TODO these only hold for positive p, and can be made more general
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:189:    # TODO also it would be nice to derive them recursively ...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:202:    # TODO log(x)/(x+a) and log(x)/(x-1) can also be done. should they
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:204:    # TODO further formulae in this section seem obscure
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:207:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:230:    # TODO exp(-x)*erf(I*x) does not work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:256:    # TODO all of the following should be derivable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:282:    # TODO many more formulas. should all be derivable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:286:    # TODO many more formulas. should all be derivable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:524:    # TODO should this be a method of meijerg?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:852:    # TODO altered cases 4-7
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:876:    # TODO This leaves only one case from the three listed by Prudnikov.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:900:    # XXX TODO we should reduce order first
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:972:    # TODO should we try both?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:988:    # XXX TODO this is a testing *nightmare*
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1445:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:2040:            # TODO: This is for future development, as currently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:333:        # TODO: This probably doesn't need to be completely recomputed at
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:366:                    # TODO: Would there ever be any benefit from just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:395:            # TODO: Just put it in self.Tfuncs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:497:                    # TODO: Add something to backsubs to put exp(const*p)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:530:                        # TODO: give algebraic dependence in error string
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:779:    # TODO: Rewrite algorithms below to use this (?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:781:    # TODO: Pass through information about why the integral was nonelementary,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:798:    # TODO: This should go in densetools.py.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:855:    # TODO: Use this on the final result.  That way, we can avoid answers like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1006:    # TODO: This algorithm appears to be faster in every case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1007:    # TODO: Verify this and splitfactor() for multiple extensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1250:        # TODO also consider the complex roots which should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1280:    # TODO: Use log_to_atan() from rationaltools.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1350:    # TODO: check what Lambda does with RootOf
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1365:    # TODO: verify that this is correct for multiple extensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1458:        # TODO: This does not do the right thing when b is False
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1621:    # TODO: Integral from k?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1622:    # TODO: split out nonelementary integral
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1691:    # TODO: This is useful in and of itself, because isinstance(result,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:114:    # TODO: Merge this with the very similar special_denom() in rde.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:158:                        # TODO: Add test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:822:        # TODO: implement this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:878:    # TODO: finish writing this and write tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:921:        # TODO: We treat this as 'no solution', until the structure
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:952:    # TODO: Write the full algorithm using the structure theorems.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:957:        # TODO: This could be implemented more efficiently.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1035:        # TODO: What should really be done in this case?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1160:        # TODO: What should really be done in this case?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1185:            # TODO: But maybe we can tell if they're not rational, like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1266:    # TODO: finish writing this and write tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1301:        # TODO: we can use more efficient residue reduction from ratint()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:400:        # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:466:        # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:875:        # TODO not implemented yet, but also not important
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:977:        #  TODO : This part is quite hacky. Should be made more robust with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:978:        #  TODO : respect to symbol names and scalable w.r.t higher dimensions.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:235:    # TODO: Skip or make faster
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:250:    # TODO: Add tests for integrate_hyperexponential() from the book
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:374:    # TODO: Add a test where two different parts of the extension use a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:110:    # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:698:    # TODO sinh/cosh shifted come out a mess. also delayed trig is a mess
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:699:    # TODO should this simplify further?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:714:    # TODO can we make erf(t) work?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:756:    # TODO LT of Si, Shi, Chi is a mess ...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_trigonometry.py:32:    # TODO: remove conds='none' below. For this to work we would have to rule
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:328:    # TODO: Remove conds='none' below, let the assumption take care of it.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1140:    # TODO: Remove conds='none' below, let the assumption take care of it.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1329:    # TODO: How to test risch=False?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:149:    # TODO what simplifications should be done automatically?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:165:    # TODO it would be nice to test the condition
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:245:    # TODO more orthogonality integrals
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:257:    # TODO can do higher powers, but come out as high order ... should they be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:262:    # TODO more besseli when tables are extended or recursive mellin works
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:273:    # TODO how does besselj(0, a*x)*besselj(0, b*x) work?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:274:    # TODO how does besselj(0, x)**2*besselj(1, x)**2 work?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:275:    # TODO sin(x)*besselj(0, x) etc come out a mess
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:276:    # TODO can x*log(x)*besselj(0, x) be done?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:277:    # TODO how does besselj(1, x)*besselj(0, x+a) work?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:278:    # TODO more indefinite integrals when struve functions etc are implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:374:    # TODO gammasimp cannot prove that the factor is unity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:517:    # TODO conditions are a mess
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:523:    # TODO gamma, rayleigh
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:579:    # TODO are there other distributions supported on (-oo, oo) that we can do?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:658:    # TODO maybe simplify the inequalities? when the simplification
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:668:    # TODO FT(besselj(0,x)) - conditions are messy (but for acceptable reasons)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:105:    # TODO: when bound_degree() can handle this, test degree bound from that too
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:147:    # TODO: Add test for deg(b) <= 0 with b small
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:262:    # TODO: Add more tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:280:    # TODO: Add more tests, including ones with exponentials
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:80:    # TODO does not work with bneg, argument wrong. Needs changes to matching.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:164:    # TODO we cannot currently do these (needs summation of 3F2(-1))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:244:    # TODO we can't do any of these (delicate cancellation)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:253:    # TODO bessely(a, x)*besselk(a, x) is a mess
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:264:    # TODO products of besselk are a mess
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:271:    # TODO exp(x/2)*besselk(a, x/2) [etc] cannot currently be done
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:272:    # TODO various strange products of special orders
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:386:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:420:    # TODO this comes out as an amazing mess, but simplifies nicely
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:436:    # TODO this can be further simplified!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:444:    # TODO more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:466:    # TODO for this to work with real a, need to expand abs(a*x) to abs(a)*abs(x)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:479:    # TODO IFT is a *mess*
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:481:    # TODO IFT
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:492:    # TODO IFT without factoring comes out as meijer g
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:502:    # TODO IFT (comes out as meijer G)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:504:    # TODO besselj(n, x), n an integer > 0 actually can be done...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:506:    # TODO are there other common transforms (no distributions!)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:221:    # TODO: it looks like this used to work just by coincindence and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:254:    # TODO: heurisch() is off by a constant: -3/4. Possibly different permutation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:343:# TODO: convert the rest of PMINT tests:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:71:    # TODO: add more tests here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:114:    # TODO: Add test for when the degree bound becomes larger after limited_integrate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:115:    # TODO: Add test for db == da - 1 case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:118:    # TODO: Add tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:119:    # TODO: Add test for when the degree becomes larger after parametric_log_deriv()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:179:    # TODO: Add more exp tests, including tests that require is_deriv_in_field()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:193:    # TODO: Add more primitive tests, including tests that require is_deriv_in_field()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:197:    # TODO: Add more tests for rischDE, including ones from the text
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:495:    # TODO: caching is significant factor for why permutations work at all. Change this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:700:        # TODO: Currently it's better to use symbolic expressions here instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:726:                # TODO: Non-polynomial expression. This should have been
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/exprtools.py:1551:            # XXX TODO there should be a way to inspect what order the terms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/facts.py:139:       TODO: write about
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/facts.py:310:        """process a -> b rule"""   # TODO write more?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/facts.py:398:       # TODO b | c
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:180:# TODO: we should use the warnings module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:278:# TODO caching with decorator, but not to degrade performance
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1456:                #TODO: this can probably be optimized more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1885:    # TODO make it decorator + bytecodehacks?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/expr.py:3692:        # TODO: Smarter heuristics
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/add.py:292:                seq.extend(o_args)  # TODO zerocopy?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/function.py:212:        # TODO: Look at nargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/function.py:1416:            #TODO: check if assumption of discontinuous derivatives exist
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/function.py:1673:        # TODO: deprecate?  YES, make this 'enumerated_variables' and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/function.py:1675:        # TODO: support for `d^n`?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/symbol.py:637:    # TODO add check against another Wild
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1447:    # TODO: Disable string inputs (https://github.com/sympy/sympy/issues/11003)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_assumptions.py:410:    # TODO Change to x.is_nonzero is None
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_diff.py:138:    # TODO: assert diff(x**2, (x, n)) == x**(2-n)*ff(2, n)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3958:@SKIP("TODO: sympy.physics.quantum.shor: Cmod Not Implemented")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:208:    # TODO UndefinedFunction does not subclass Expr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_facts.py:70:# TODO move me to appropriate place
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:917:    # TODO UndefinedFunction does not subclass Expr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/mul.py:435:            # TODO: Make non-commutative exponents not combine automatically
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1049:        # TODO: Should these be self.func?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1190:        # TODO: Should this be self.func?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:2758:    # TODO: make this a class like bell()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:423:        # TODO: extend this to complex numbers?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:283:        if arg.is_Add: # TODO, implement more if deep stuff here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:480:        if arg.is_Add: # TODO, implement more if deep stuff here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/_trigonometric_special.py:3:TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:985:        # TODO new and probably slow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:578:                # TODO simplify hi <= upto
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:498:        if arg.is_Add:  # TODO, implement more if deep stuff here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:499:            # TODO: Do this more efficiently for more than two terms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:867:        if arg.is_Add:  # TODO: Do this more efficiently for more than two terms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1579:    # TODO refactor into TrigonometricFunction common parts of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1223:    # TODO raise error if function is discontinuous at limit of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_complexes.py:938:    # TODO XXX why does abs(x)._eval_evalf() not fall back to global evalf?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/gamma_functions.py:687:                # TODO n == 1 also can do some rational z
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:25:# TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:47:# TODO should __new__ accept **options?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:48:# TODO should constructors should check if parameters are sensible?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:210:        # TODO should we check convergence conditions?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:543:        # TODO should we check convergence conditions?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:980:    # TODO this can be nicer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:656:            # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:24:# TODO series expansions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:25:# TODO see the "Note:" in Ei
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:1220:        # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:2738:            # TODO: is the series really correct?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:150:        # TODO Add more simplififcation here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:179:        # TODO: Make sure n \in N
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:180:        # TODO: Assert |m| <= n ortherwise we should return 0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:189:        # TODO: Make sure n \in N
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:190:        # TODO: Assert |m| <= n ortherwise we should return 0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:197:        # TODO: Make sure theta \in R and phi \in R
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:202:        # TODO: Handle deep and hints
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:150:            # TODO should something be polarified here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:179:        # TODO use minpoly instead of ad-hoc methods when issue 5888 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:181:            # TODO reference?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/setexpr.py:84:        # TODO: this could be implemented straight into `imageset`:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2486:                    know its dimensions. TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2555:    # TODO: check subsets (`func` in `setv`)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2558:    # TODO: support more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:46:        # TODO: handle unevaluated condition.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:49:        # TODO: `s2 > s1` could be unevaluated.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:85:    # TODO: add logic for open intervals?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:34:    # TODO: some intervals containing 0 and oo will fail as 0*oo returns nan.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:41:    # TODO: handle symbolic intervals
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:38:    # TODO: handle functions with infinitely many solutions (eg, sin, tan)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:39:    # TODO: handle multivariate functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:371:            # TODO: Design a technique to handle multiple-inverse
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:29:    # TODO: add support for more functions in the future:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:206:    # TODO: some expressions cannot be calculated due to bugs (currently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:124:                # TODO: is this break necessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:297:        # TODO: this assumes that all arguments are matrices, it may not be the case:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:448:    # TODO: check if subremoved should be permuted as well...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:542:        # TODO: move this to ElementwiseApplyFunction
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py:189:    # TODO: this is returning a wrong result:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:50:    # TODO: not yet supported:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:54:    # TODO: not yet supported:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:445:    # TODO: reverse operation starting with `PermuteDims` and getting down to `bb`...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:113:        # TODO: check that Kronecker delta is only contracted to one other element:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:605:        # TODO: swap args positions in order to simplify the expression:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:606:        # TODO: this should be in a function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:641:        # TODO: function in order to permute the args:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:842:        # TODO: add API for total rank and cumulative rank:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1263:        # TODO: add API for total rank and cumulative rank:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1390:        # TODO: check that `expr` has `.subranks`:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/array_derivatives.py:91:        # TODO: this could be done with multiple-dispatching:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:567:        # TODO: add checks for dimensions for `value`?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2208:        # TODO: add possibility of metric after (spinors)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2590:            # TODO: what is the part which is not a coeff?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3064:        # TODO: this could be optimized by only swapping the indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3203:    # TODO: put this into TensExpr?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3209:    # TODO: put this into TensExpr?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3225:        # TODO: inefficient, this should be done at root level only:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3268:        # TODO: check data compatibility with properties of tensor.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3344:        # TODO: replace .args[0] with .name:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3359:            # TODO: if there is no metric present, the derivative should be zero?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3661:    # TODO: this method should be private
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3662:    # TODO: should this method be renamed _from_components_free_dum ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4540:        # TODO: inherit dummies from expr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4563:        # TODO: can be improved:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5136:    # TODO: add a dum_to_components_map ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:89:#   TODO:  (some ideas for improvement)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:375:         broadcasting.  (TODO)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:497:    # TODO: add check for *get_symmetric_group_sgs(0)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/_compilation/__init__.py:9:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:920:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:956:    # TODO: Replace solve with solveset when it gives Lambert solution
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:966:    # TODO: x = [-1, 2*(+/-asinh(1)*I + n*pi}, 3*(pi/6 + n*pi/3)]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:967:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1014:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1032:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1038:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1047:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1052:    # TODO: Replace solve with solveset, as of now test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1059:    # TODO: Replace solve with solveset which gives both [+/- current answer]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1077:    # TODO: Replace solve with solveset, as of now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1084:    # TODO: Replace solve with solveset, as of now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1092:    # TODO: Replace solve with solveset, as of now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1099:    # TODO: Replace solve with solveset, as of now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1118:    # TODO: Replace solve with solveset, as of now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1194:    # TODO: Replace solve with solveset, as of now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2252:    # TODO: Replace solve with solveset, current test fails for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3082:    # TODO: Replace solve with solveset, when it works for solveset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:382:    # TODO: fix pickling of Options class (see GroebnerBasis._options)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:409:        check(c, exclude=[0, 1], check_attr=False) # TODO: Py3k
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:420:    # TODO: AssertionError: assert id(obj) not in self.memo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:424:    # TODO: AssertionError: assert id(obj) not in self.memo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:438:    # TODO: fix pickling of ModularInteger
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:444:    # TODO: fix pickling of RealElement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:448:    # TODO: fix pickling of ComplexElement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:457:    # TODO: fix pickling of ModularInteger
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:472:        # TODO: fix pickling of ModularInteger
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:489:    # TODO: fix pickling of RealElement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:493:    # TODO: fix pickling of ComplexElement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:500:    # TODO: AssertionError
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:504:    # TODO: AttributeError: 'PolyElement' object has no attribute 'ring'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:526:    # TODO: Argh, Python is so naive. No lambdas nor inner function support in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:559:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:563:    # TODO: TypeError: can't pickle instancemethod objects
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:612:    # TODO: PicklingError: Can't pickle <function <lambda> at 0x38578c0>: it's not found as __main__.<lambda>
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:622:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:635:    # TODO: fix pickling of `symbols' flag
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:639:# TODO: def test_pickling_polys_rootisolation():
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2494:                # prop is a Symbol.  TODO: Find out why.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:34:    # TODO it would be good to pick the smallest divisible power
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:798:    # TODO: Use solveset here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1072:            # TODO: Hint first order series should match only if d/e is analytic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1783:    # TODO: if two solutions are solved for f(x), we still want to be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:204:    # TODO: Add methods that can be used by many ODE solvers:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:359:    # TODO: improve solution testing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2902:# TODO: option for calculating J numerically
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:2566:    # TODO: pre-simplification: Not necessary but may simplify
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:3893:        # TODO: Fall back to diop_DN when k = 2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:175:        # TODO : 'best' hint should be implemented when adequate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:284:    # TODO : For now pde.py uses support offered by the ode_order function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:521:    # TODO : For now homogeneous first order linear PDE's having
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:611:    # TODO : For now homogeneous first order linear PDE's having
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:323:    # TODO: Is the above solution set definitely complete?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1862:    # TODO: add more simple testcases when solveset returns
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1727:    # TODO: Investigate why currently solution [0] is preferred over [1].
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:185:    # TODO: does this really have to be so complicated?!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:694:        # TODO : We should not blindly recurse through all args of arbitrary expressions like this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1662:        # TODO Case: A-> function of symbol, can be extended here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:353:        # TODO: use |G:H| = |G|/|H| (currently H can't be made into a group)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:870:    # TODO:: Sims points out in [Sim94] that performance can be improved by
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:903:            # TODO: this should support input of a list of general words
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/combinatorics/coset_table.py:985:    # TODO: complete the docstring
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/combinatorics/tensor_can.py:1015:    TODO: use baseswap in the case in which if it fails in finding a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:666:        # TODO: Replace solve with nonlinsolve, when nonlinsolve will be able to solve in real domain
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:919:        # TODO: Replace solve with solveset, when this line is tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:927:                # TODO: Replace solve with solveset, when these lines are tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1290:            # TODO: Replace solve with solveset, when this line is tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/geometry/plane.py:412:                # TODO: Replace solve with solveset, when this line is tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/concrete/summations.py:607:        # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1043:    # TODO Implement matrix geometric series summation.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:78:#TODO debugging output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:403:    #TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:240:        # TODO The 3D stuff
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:304:        #TODO after fixing https://github.com/ipython/ipython/issues/1255
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/utils.py:159:    # TODO: prange check goes here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:128:        # TODO: _process_piecewise check goes here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:204:# TODO: Add color arrays for plots.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:205:# TODO: Add more plotting options for 3d plots.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:206:# TODO: Adaptive sampling for 3D plots.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:381:                # TODO: set cse=True once this issue is solved:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1146:        # TODO: for now, I assume that numpy functions are going to succeed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1156:                # TODO: what if points[k][idx]==e or points[k][idx+1]==e?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1774:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1790:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1871:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1972:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:2094:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:32:# TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1281:        # TODO this can be done more efficiently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:102:    # TODO more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/polyroots.py:761:    # TODO: This is fragile. Figure out how to make this independent of construct_domain().
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1977:    # TODO Use _parallel_dict_from_expr instead of sring as sring is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:515:        # TODO better data structure!!!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:675:        # TODO apply the product criterion?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:683:        # TODO mergesort?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:726:    # (TODO again, better data structures)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:450:        # TODO: implement this in from_ methods
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:459:        else: # TODO: remove this branch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:9:# TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:142:        # TODO optionally disable reduction?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/domains/polynomialring.py:40:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/domains/fractionfield.py:34:        # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:796:    # TODO: to improve performance, choose the main variable here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:2129:# TODO: add support for algebraic function fields
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:163:    # TODO: rewrite this so that it doesn't use expand() (see poly()).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:467:        # TODO: should AlgebraicField be a Composite domain?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:1251:        elif len(self) <= 5: # TODO: use an actual density measure
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:2275:        else: # TODO: don't use dense representation (port PRS algorithms)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:3044:    # TODO: following methods should point to polynomial
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:173:    # TODO: Use a nontrivial pivoting strategy to control intermediate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:321:    # TODO: Use a non-trivial pivoting strategy. Even just row swapping makes a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/matrices/normalforms.py:11:# TODO (future work):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:23:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:660:        # TODO: Implement similar algorithms for DDM and SDM.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/matrices/rref.py:256:            # TODO: Add partial pivot support to the sparse implementations.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_distributedmodules.py:50:# TODO test to_dict?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_heuristicgcd.py:53:    # TODO: assert heugcd(f, f.diff(x))[0] == g
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/heuristicgcd.py:124:    # TODO: don't expose poly repr implementation details
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:378:        # TODO: Integrate this into expand() itself
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:216:        # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1839:        # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/primes.py:678:    # TODO (future work):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:327:    # TODO: handle piecewise defined functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:328:    # TODO: handle transcendental functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:329:    # TODO: handle multivariate functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/calculus/accumulationbounds.py:688:        # TODO : Devise a better method for Union of AccumBounds
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:702:            # TODO: trigsimp is needed here so that the matrix becomes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/vector/operators.py:214:        # TODO: is case of many coord systems, this gets a random one:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:158:        # TODO: This gets a random coordinate system in case of multiple ones:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:503:        # TODO : The following line introduces a performance issue
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:330:    # TODO: We should be able to support more than 2 elements
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:410:def test_optims_numpy_TODO():
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:442:    NUMBER_OF_DIGITS = 25   # TODO: this should ideally be automatically handled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:526:    #TODO A class Complex may be implemented. The BeamParameter may
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:885:    #TODO add the other possible arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:906:#TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:911:#TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/vector/vector.py:735:        # TODO : Circular dependency if imported at top. Should move
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:47:    # TODO : The unit vectors should print with subscripts but they just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:50:    # TODO : The pretty print division does not print correctly here:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:35:    TODO: Handle condition such as symbols have subscripts/superscripts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:94:    # TODO: Need to handle printing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:172:        #TODO: Current version ignores the indices set for partial trace.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:189:        # TODO : improve this implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:192:    #TODO: Review if the permute method is needed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:3:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:428:            # TODO: make sure the hilbert spaces of the bra and ket are
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:491:        # TODO if operands are tensorproducts this may be will be handled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:36:    TODO: implement a decompose property that returns how to do this in terms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:3:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:417:            #TODO: Add support for sets of operators
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:451:    TODO (?): Support for Muls and other types of expressions?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cartesian.py:3:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:141:# TODO: Move this into sympy.matrices.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:242:            # TODO: This can be optimized to reduce the number of Qubit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:104:    # TODO: don't expand the scalars in front of each Mul.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:251:    # TODO: I may need to expand before returning the final result.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:78:        # TODO: explore different sparse formats. But sparse.kron will use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tensorproduct.py:151:        # TODO: disallow nested TensorProducts.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:145:        # TODO: add methods for uncoupling operators
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:157:    # TODO: move this to qapply_Mul
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:165:        #TODO: use options to use different j values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:616:        # TODO: move evaluation up to represent function/implement elsewhere
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1017:            # TODO: better way to get angles of rotation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1487:            # TODO: Need hilbert space fix, see issue 5732
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:1:#TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:486:    #TODO: Improve simplification method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:675:    # TODO: Check for symmetries
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_trace.py:82:    #TODO: needed while testing reduced density operations, etc.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_density.py:269:    #TODO: test for invalid arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:3:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:678:    # TODO: Fix non-unicode pretty printing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_cartesian.py:113:    # TODO: Add tests for representations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:13:TODO List:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/quantum/density.py:21:    TODO: Density operator support for Qubits
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:351:                # TODO: should this raise a warning?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:522:        #TODO: the inversion will fail if the system is inconsistent, for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:206:    # TODO: decide whether to allow such expression in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:227:    # TODO: Pow only support structural equality:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:244:    # TODO: need better simplification routine:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:249:    # TODO: need a better way to simplify expressions containing units:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:253:    # TODO: fix this, it should give `m` without `Abs`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/kane.py:630:    # TODO : Remove `new_method` after 1.1 has been released.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_particle.py:55:    # TODO make the result not be system-dependent
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/series/gruntz.py:633:    # TODO this should not be necessary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/series/series_class.py:70:        TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:441:    f = x*exp(x)*sin(2*x)  # TODO: rsolve needs improvement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:162:    # TODO : A better output for Order(log(x) + 1/log(x))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:148:    # TODO zeta function series
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:152:    # TODO 8.35 - 8.37 (bessel, max-min)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:655:        TODO: Implement algorithm for sparse matrices (SFF),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/hadamard.py:165:# TODO Implement algorithm for rewriting Hadamard product as diagonal matrix
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:52:    # TODO: this is commented because it slows down the tests.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:105:    # TODO: find a way to represent a four-dimensional zero-array:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:225:    # TODO: TensorProduct is not supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:292:    # TODO: no support for TensorProduct.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:407:    # TODO: restore this result (currently returning the transpose):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:416:    # TODO: restore (currently returning the transpose):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:435:    # TODO: not implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:444:    # TODO: wrong
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:448:    # TODO: wrong
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:731:    TODO: Implement algorithm for sparse matrices (SFF),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:1167:    # TODO: currently not working as ``_MinimalMatrix`` cannot be sympified:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3614:        TODO: Implement algorithm for sparse matrices (SFF),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/matrices.py:70:    # TODO: Add handlers to make these keys work with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/common.py:17:    # TODO: Add examples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:238:    # TODO: Add examples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:337:    # TODO: Add examples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:394:    # TODO: Add examples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/calculus.py:57:    # TODO: Add examples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/refine.py:53:        # TODO: this will probably not work with Integral or Polynomial
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:47:    # TODO: implement sathandlers system for the matrices.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:77:    # TODO: implement sathandlers system for the matrices.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:94:    # TODO: implement sathandlers system for the matrices.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:218:    # TODO: This should be deducible from the nonzero handler
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:103:        # TODO: Run additional checks to see which combination of the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:660:            # TODO: ANTLR refers to ISO 80000-2:2019. should we keep base 10 or base 2?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:520:            #TODO: No string type in AST
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:102:            # TODO: Arithmetic Assignment
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:151:            # TODO: Integer Binary Operations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:239:            # TODO:Numbers when the LFortran ASR is updated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:257:            # TODO: Return statement, variable declaration
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:796:            # TODO: Currently only works with symbols. Make it work for dynamicsymbols.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1269:            # TODO** Parse block matrices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1936:        # TODO parse integers as well ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2023:        # TODO: Should these be protected?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:26:# TODO you are a bit excessive in the use of Dummies
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:27:# TODO dummy point, literal field
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:28:# TODO too often one needs to call doit or simplify on the output, check the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1101:        # TODO: you need a real dummy function for the next line
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1309:                    if c:  # TODO this is ugly - the Commutator can be Zero and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1438:    # TODO the calculation of signatures is slow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1439:    # TODO you do not need all these permutations (neither the prefactor)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1594:        # TODO: you need a real dummy function for the next line
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1892:    # TODO Is this a good idea?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1919:    # TODO move some of this to class methods.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1920:    # TODO rewrite using the .as_blah_blah methods
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1965:    # TODO move some of this to class methods.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1966:    # TODO rewrite using the .as_blah_blah methods
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_hyperbolic_space.py:86:    #TODO - it would be nice to have index contraction built-in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:103:    #TODO assert m == R2_r.transform(R2_p, R2_p.transform(R2_r, [a, b])).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:117:    #TODO assert m == R3_r.transform(R3_c, R3_c.transform(R3_r, m)).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:120:    #TODO assert m == R3_r.transform(R3_s, R3_s.transform(R3_r, m)).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:123:    #TODO assert m == R3_c.transform(R3_s, R3_s.transform(R3_c, m)).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:128:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_c, R3_c.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:131:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:134:        #TODO assert m == R3_c.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_c, m)).applyfunc(simplify)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:19:    #TODO assert point.subs(x, 2) == Point(cs, [2, y])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:20:    #TODO assert point.free_symbols == set([x, y])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/str.py:962:        #TODO : Handle indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:107:    # TODO: a better class structure would avoid this mess:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:202:        # TODO: is this necessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:95:    # TODO - assumes all called functions take one double precision argument.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:200:# TODO: Make brackets adjust to height of contents
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:333:    # TODO robustify when no unicodedat available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1574:        # TODO should exp_polar be printed differently?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1910:            #TODO: Move this code to prettyForm
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2239:        # TODO: the stuff to the left of the | and the stuff to the right of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2602:        # TODO: copy-pasted from _print_Function: can we do better?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2671:                # TODO incorporate order
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2808:        #TODO: Handle indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:10:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4575:    # TODO: The "x in N" parts below should be centered independently of the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7256:    # TODO: add support for ASCII pretty.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7620:    # TODO: TBD polylog(s - 1, z)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:238:    # TODO: merge this with the above, which requires a lot of test changes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:1176:        # TODO should exp_polar be printed differently?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2585:                # TODO incorporate order
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2777:        # TODO: This expression is potentially confusing,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2785:        # TODO nicer fractions for few generators...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2802:        # TODO nicer fractions for few generators...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2850:        # TODO: Handle indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:182:@SKIP  # TODO - this is currently not checked but should be implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:236:    # TODO - matrix broadcasting?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:611:    # assert theq(aesara_code_(sy.Ne(x, y)), aet.neq(xt, yt))  # TODO - implement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:2079:    #TODO: Handle indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:172:@SKIP  # TODO - this is currently not checked but should be implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:226:    # TODO - matrix broadcasting?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:599:    # assert theq(theano_code_(sy.Ne(x, y)), tt.neq(xt, yt))  # TODO - implement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:93:    # TODO more tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:646:    # TODO: Apply different strategies, considering expression pattern:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1087:        # TODO: see if x*log(a)+x*log(a)*log(b) -> x*log(a)*(1+log(b))?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1247:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:50:#   TODO work this out in detail.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:86:    # TODO see if this can work as Mod(x, 1); this will require
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:253:    # TODO branching
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:736:        # TODO with symbolic parameters, it could be advantageous
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1947:    # TODO tons of more formulae
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1991:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2116:    # TODO for now, we use the following simple heuristic: inverse-shift
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2245:    # TODO the following would be possible:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2250:    # TODO Also, we tend to create combinations of gamma functions that can be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2443:    # TODO it would be helpful to give conditions under which the integral
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:121:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:116:    # TODO [a+1, aRational(-1, 2)], [2*a]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:130:    # TODO hyperexpand(hyper([a], [2*a + 1], z))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:131:    # TODO [S.Half, a], [Rational(3, 2), a+1]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:135:    # TODO [a], [a - S.Half, 2*a]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:949:    # TODO polys
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1011:    # TODO LOTS more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1039:    # TODO LOTS more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:393:                    # TODO is there a better heuristic?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/gui.py:26:    # TODO: @classmethod: write() on GUI?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/utils.py:9:# TODO consider using wcswidth third-party package for 0-width characters
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/cli.py:117:# TODO: add custom support for some of the following?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/cli.py:125:        TODO: find out why this is needed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/rich.py:74:    # TODO: @classmethod: write()?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/std.py:1442:        # TODO: private method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/__init__.py:3:from .cli import main  # TODO: remove in v5.0.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/__init__.py:4:from .gui import tqdm as tqdm_gui  # TODO: remove in v5.0.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/__init__.py:5:from .gui import trange as tgrange  # TODO: remove in v5.0.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tqdm/tk.py:31:    # TODO: @classmethod: write()?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/anyio/_core/_fileio.py:416:        def info(self) -> Any:  # TODO: add return type annotation when Typeshed gets it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sentence_transformers/backend.py:367:# TODO: Fill in the PR number
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py:378:        # TODO: Ensure this primary_metric works as expected, also with bolding the right thing in the model card
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:253:        # TODO: This is rather inefficient, as we load all data into memory. We might benefit from a more efficient solution
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:323:            # load_best_model_at_end=save_best_model, # <- TODO: Look into a good solution for save_best_model
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1405:# TODO: Fill in the PR number
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:118:                # TODO: Consider following these steps automatically so we can load PEFT models with other backends
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1600:        # TODO: use search_filter once with have an HasVector like condition
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:238:                # TODO is this the right name for the data attribute ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:305:        # TODO I think there is an edge case here where an annotation's span might not close
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/_utils.py:14:            # TODO: use `add_suggestion` from torchvision.prototype.utils._internal to improve the error message as
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/utils.py:315:    # TODO: There might be a way to vectorize this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/ops/_utils.py:11:    # TODO add back the assert
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/ops/poolers.py:36:# TODO: (eellison) T54974082 https://github.com/pytorch/pytorch/issues/26744/pytorch/issues/26744
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:45:    # TODO: It's possible the masking here is unnecessary if y and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:80:# TODO: this doesn't actually cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:81:# TODO: main library should make this easier to do
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video.py:155:        # TODO: we should change all of this from ground up to simply take
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video.py:190:        # TODO check if stream needs to always be the video stream here or not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video.py:193:        # TODO add some warnings in this case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video.py:206:        # TODO add a warning
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video.py:321:            # TODO raise a warning?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:160:            # TODO: load metadata
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:166:            # TODO: add extradata exception
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/datasets/kinetics.py:115:        # TODO: support test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/datasets/video_utils.py:388:            # TODO: Revert it once the bug is fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:267:# TODO: specify the return type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/datasets/celeba.py:173:                # TODO: refactor with utils.verify_str_arg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:39:# TODO: Once torchscript supports Enums with staticmethod
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:1564:    # TODO: if image shape is [N1, N2, ..., C, H, W] and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:70:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:94:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:392:        # TODO: Jit is failing on loading this op when scripted and saved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:862:    # TODO: we should expect bincount to always be faster than histc, but this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_color.py:36:    # TODO: Maybe move the validation that num_output_channels is 1 or 3 to this function instead of callers.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/__init__.py:93:    hflip,  # TODO: Consider moving all pure alias definitions at the bottom of the file
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:186:    # TODO: Add _xywh_to_cxcywh and _cxcywh_to_xywh to improve performance
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:242:    # TODO: Investigate if it makes sense from a performance perspective to have an implementation for every
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:250:            # TODO: when https://github.com/pytorch/pytorch/issues/68430 is fixed (possibly by https://github.com/pytorch/pytorch/pull/100373),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1239:        # TODO: See https://github.com/pytorch/pytorch/issues/40763
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1259:# TODO: This should be removed once torch_pad supports non-scalar padding values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1326:        # TODO: add support of other padding modes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1591:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1846:    # TODO: add in docstring about approximation we are doing for grid inversion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1854:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:107:    # TODO: consider deprecating integers from sigma on the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:221:        # TODO: remove this branch as soon as `dtype.is_floating_point` is supported by JIT
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:360:    # TODO: Do we really need to check for out of bounds here? All
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_utils.py:91:# TODO: let's use torchvision._utils.StrEnum to have the best of both worlds (strings and enums)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:15:# TODO: do we want/need to expose this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:377:                        # TODO: we don't need to enforce tensors, just that entries are indexable as t[bool_mask]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/_presets.py:113:        # TODO: we could re-train the video models with antialias=True?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/__init__.py:74:        # TODO: better messages
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/__init__.py:78:        # TODO: better messages
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/mobilenetv3.py:84:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/utils.py:38:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/shufflenetv2.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:51:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:42:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:64:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:86:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:120:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:202:    # TODO: simplify when indexing without rank will be supported by ONNX
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:451:    # TODO : replace below with a dynamic padding when support is added in ONNX
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:744:                # TODO: https://github.com/pytorch/pytorch/issues/26731
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/generalized_rcnn.py:86:        # TODO: Move this to a function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:43:            # TODO change this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:54:    # TODO: https://github.com/pytorch/pytorch/issues/26792
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:609:        # TODO: Move this to a function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:629:        # TODO: Do we want a list or a dict?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/_api.py:177:        # TODO: Replace ann.__args__ with typing.get_args(ann) after python >= 3.8
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/__init__.py:21:# TODO: we could / should document them publicly, but it's not clear where, as
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:154:                # TODO: If we have documentation on how to do that, put a link in the error message.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:200:    # TODO: maybe we should use __getstate__ and __setstate__ instead of __reduce__, as recommended in the docs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/__init__.py:11:# TODO: Fix this. We skip this method as it leads to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:274:            # TODO: we don't go through the rebuild logic here directly because we don't want
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/fields.py:55:    # TODO PEP 747: use TypeForm:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/fields.py:333:        # TODO check for classvar and error?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/fields.py:411:        # TODO check for classvar and error?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/fields.py:413:        # TODO infer from the default, this can be done in v3 once we treat final fields with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/fields.py:720:            # TODO: properly make use of the protocol (https://rich.readthedocs.io/en/stable/pretty.html#rich-repr-protocol)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/fields.py:797:    default: ellipsis,  # noqa: F821  # TODO: use `_typing_extra.EllipsisType` when we drop Py3.9
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/deprecated/json.py:112:# TODO: Add a suggested migration path once there is a way to use custom encoders
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/alias_generators.py:7:# TODO: in V3, change the argument names to be more descriptive
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/functional_validators.py:213:            # TODO if `schema['serialization']` is one of `'include-exclude-dict/sequence',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:124:# TODO: ultimately, make this public, see https://github.com/pydantic/pydantic/pull/9459#discussion_r1628197626
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:592:            # TODO: is there a better way? should we just not do this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/dataclasses.py:277:        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:303:        # TODO: in theory we should check that the schema accepts a serialization key
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:407:            # TODO this is an ugly hack, how do we trigger an Any schema for serialization?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:613:        # TODO: note, this is a fairly common pattern, re lax / strict for attempted type coercion,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1724:        # TODO: do we really need to resolve type vars here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1743:                # TODO: something like https://github.com/pydantic/pydantic/issues/5952
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2005:        TODO support functional validators once we support them in Config
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2511:# TODO V3: this function is only used for deprecated decorators. It should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:235:    # TODO: This could be unified with `get_standard_typevars_map` if we stored the generic metadata
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:276:        # TODO remove parentheses when we drop support for Python 3.10:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:91:    # TODO When we drop 3.9, use a match statement to get better type checking and remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:170:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:176:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py:83:    # TODO: this is a bit redundant, we could probably avoid some of these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_validators.py:44:    # TODO: refactor sequence validation to validate with either a list or a tuple
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:139:# TODO implement `is_finalvar_annotation` as Final can be wrapped with other special forms:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:186:# TODO In 2.12, delete this export. It is currently defined only to not break
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:195:# TODO: Ideally, we should avoid relying on the private `typing` constructs:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:445:        # TODO ideally recursion errors should be checked in `eval_type` above, but `eval_type_backport`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:230:                # TODO we can also stop there if `__pydantic_fields_complete__` is False.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:29:    TODO: Perhaps we should move this structure to pydantic-core. At the moment, though,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:32:    TODO: It's unfortunate how functionally oriented JSON schema generation is, especially that which occurs during
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:236:            # TODO: should we merge the parent namespace here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:263:        # TODO `typ.__type_params__` when we drop support for Python 3.11:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:394:                    # TODO: We should probably do something with this so that validate_assignment behaves properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:406:                        # TODO: same note as above re validate_assignment
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:433:            # was already evaluated. TODO: is this method relevant?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:436:        TODO: the nested function definitions here seem like bad practice, I'd like to unpack these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:505:        # TODO: I dislike that we have to wrap these basic dict updates in callables, is there any way around this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:713:            # TODO: should we add regex flags to the pattern?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1117:        # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1240:        # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1281:                        # TODO: fixme - this is a workaround for the fact that we can't always resolve refs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1320:        # TODO: Need to read the default value off of model config or whatever
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1321:        use_strict = schema.get('strict', False)  # TODO: replace this default False
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/v1/utils.py:270:            # TODO: replace annotation with actual expected types once #1055 solved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/v1/networks.py:535:    # TODO: Needed to generic "Parts" for "Replica Set", "Sharded Cluster", and other mongodb deployment modes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/mypy.py:513:                    # TODO: Only do this if the first argument of the decorated function is `cls`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/mypy.py:622:                # TODO: We shouldn't be performing type operations during the main
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/mypy.py:785:            # TODO this path should be removed (see https://github.com/pydantic/pydantic/issues/11119)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/main.py:4:# TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/main.py:1043:                    # TODO - matching error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/main.py:1689:    # TODO PEP 747: replace `Any` by the TypeForm:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/formatters/terminal256.py:17:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/formatters/latex.py:334:        # TODO: add support for background colors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/formatters/img.py:548:            # TODO: make sure tab expansion happens earlier in the chain.  It
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:445:            # TODO: these don't match the comments in docs, remove.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:130:                # TODO unsure if ellipses are allowed elsewhere, see
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/textfmts.py:240:    # TODO: Make date regex more ISO 8601 compliant
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:755:            # TODO support other Python syntax like $foo['bar']
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:123:            # TODO: we should probably escape also here ''${ \${
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:135:        # TODO: let/in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/ada.py:116:            # TODO: use Name.Namespace if appropriate.  This needs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:150:            # TODO: better logging
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:347:                # TODO: better handle multiline comments at the end with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:588:            # TODO: Backslash escapes?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/mips.py:28:    # TODO: add '*.s' and '*.asm', which will require designing an analyse_text
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:886:    # TODO / should divide keywords/symbols into namespace/rest
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:1341:            (r'\S+\s+', Text)   # TODO: make tests pass without \s+
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:390:            # TODO: Treat context-depedendent names specially
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:396:            # TODO: templates start and end tokens.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/urbi.py:34:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/dns.py:53:            # TODO, $GENERATE https://bind9.readthedocs.io/en/v9.18.14/chapter3.html#soa-rr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:27:    # TODO String interpolation @VARNAME@ inner matches
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:28:    # TODO keyword_arg: value inner matches
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/perl.py:35:    # TODO: give this to a perl guy who knows how to parse perl...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/_asy_builtins.py:9:    TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:140:            # TODO: regexes can have other delims
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:191:        # TODO: builtins are only subsequent tokens on lines
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:648:            (r'^(\* )(TODO)( .*)',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:650:            (r'^(\*\*+ )(TODO)( .*)',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:656:            # Unordered lists items, including TODO items and description items
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:672:            # TODO: language-dependent syntax highlighting (see Markdown lexer)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:701:            (_inline(r'=', r'='), String), # TODO token
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/javascript.py:133:            # TODO: should this include single-line comments and allow nesting strings?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/testing.py:200:            (r'(?i)\bTODO\b', Comment.Preproc),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:49:            # TODO: highlight references in fandocs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:85:        'insideUri': [  # TODO: remove copy/paste str/uri
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/c_like.py:212:            # TODO: "correctly" parse complex code attributes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/modula2.py:474:        'TODO', 'FFI', 'ADDR', 'VARGLIST', 'VARGC',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:24:    TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:85:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:123:                "varname",  # TODO varname the right fit?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:273:                        "async for",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:274:                        "async with",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:702:        # TODO supported?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/parsers.py:396:            # TODO finish implementing other possibilities for scope
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/css.py:555:            # TODO: broken, and prone to infinite loops.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/rnc.py:36:            # TODO single quoted strings and escape sequences outside of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/scripting.py:1502:            # TODO: JES3 statement
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/oberon.py:50:            # TODO: nested comments (* (* ... *) ... (* ... *) *) not supported!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/dotnet.py:558:# TODO support multiple languages within the same source file
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexer.py:861:    TODO: clean up the code here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/auto_augment.py:905:        # TODO the results appear in the right ballpark but they differ by more than rounding.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/naflex_dataset.py:5:TODO: 2. NaFlexIterableDatasetWrapper - Iterable dataset that yields batches with variable sequence lengths
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:373:        # TODO: use foreach_pow if/when foreach_pow is added
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:342:        # TODO: use foreach_pow if/when foreach_pow is added
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/norm_act.py:99:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:104:        ValueError: if the string def not properly specified (TODO)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/tiny_vit.py:626:            # TODO: whether move this func into model for dynamic input resolution? (high risk)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/regnet.py:128:    # TODO dWr scaling?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:993:        block_fn = cfg.block_fn or Block  # TODO: Support configurable block_fn via string lookup
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:994:        mlp_layer = cfg.mlp_layer or Mlp   # TODO: Support configurable mlp_layer via string lookup
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/davit.py:813:# TODO contact authors to get larger pretrained models
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/resnest.py:49:        assert aa_layer is None  # TODO not yet supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/resnest.py:50:        assert drop_path is None  # TODO not yet supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9:# TODO: remove this check when dropping Python 3.7 support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:167:    TODO: handle base64 as input
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:173:            yield get_session().get(content).content  # TODO: retrieve as stream and pipe to post request ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:25:# Some TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:259:        # TODO: this should be handled in provider helpers directly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:257:        # TODO: this should be handled in provider helpers directly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/mcp_client.py:192:            # ^ TODO: should be handle `get_session_id_callback`? (function to retrieve the current session ID)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:51:TODO: add support for `huggingface-cli delete-cache aaaaaa bbbbbb cccccc (...)` ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:52:TODO: add "--keep-last" arg to delete revisions that are not on `main` ref
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:53:TODO: add "--filter" arg to filter repositories by name ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:54:TODO: add "--limit" arg to limit to X repos ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:55:TODO: add "-y" arg for immediate deletion ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:85:    # TODO: refactor this + imports in a unified pattern across codebase
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:25:    # TODO: deprecate when adapted in transformers/datasets/gradio
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:43:    # TODO: deprecate when adapted in transformers/datasets/gradio
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:58:    # TODO: deprecate when adapted in transformers/datasets/gradio
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:60:    TODO: could be useful to be able to set a custom error message.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:91:    # TODO: add an argument to opt-out validation for specific argument?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4726:            # TODO: remove this in v1.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4999:            # TODO: remove this in v1.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:796:                    # TODO: (optimization) download regular files to copy concurrently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:323:    TODO: factorize logic with `read_download_metadata`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:380:            # TODO: can we do better?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:466:        # TODO - maybe handle this similarly to EvalResult?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:752:    # TODO - Check if there cases where this list is longer than one?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:476:                TODO - Some args above aren't used since we are calling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:494:        # TODO: change this in a future PR. We are not returning a KerasModelHubMixin instance here...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/_oauth.py:158:    # TODO: handle generic case (handling OAuth in a non-Space environment with custom dev values) (low priority)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/constants.py:138:hf_cache_home = HF_HOME  # for backward compatibility. TODO: remove this in 1.0.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:121:    >>> from huggingface_hub import load_torch_model  # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:327:        # TODO: use `commit_description` to list all the deleted paths?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:701:                    "tree_id": None,  # TODO: tree_id of the root directory?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/jinja2/ext.py:251:    # TODO: the i18n extension is currently reevaluating values in a few
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/quantization/fuse_modules.py:10:# TODO: These functions are not used outside the `fuse_modules.py`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/quantization/__init__.py:42:    # 'fuse_fx', 'quantize_fx',  # TODO: add quantize_dynamic_fx
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/uniform.py:28:    # TODO allow (loc,scale) parameterization to allow independent constraints.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/laplace.py:73:        # TODO: If we ever implement tensor.nextafter, below is what we want ideally.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:249:# TODO define a bijection for LowerCholeskyTransform
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:551:# TODO: Add Beta-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:590:# TODO: Add ContinuousBernoulli-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:649:# TODO: Add Exponential-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:694:# TODO: Add Gamma-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:726:# TODO: Add Gumbel-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:823:# TODO: Add Pareto-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:920:# TODO: Uniform-Laplace KL Divergence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/functional.py:105:    # TODO Move this to C++ once the jit has better support for torch.Size.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/functional.py:1477:    # TODO: type dim as BroadcastingList when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/functional.py:1643:            _dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/functional.py:1646:    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:408:    # TODO(albanD) This needs to be updated when more than one level is supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:434:    # TODO: add an API to map real -> complex dtypes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:590:            # TODO: This implies that ellipses is valid syntax for allocating
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:7:# TODO: Should use `torch._C._get_privateuse1_backend_name()` to get
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:12:# TODO: Limitations and things about enable_torch_dispatch_mode we should fix before exposing it:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:629:                # TODO(https://github.com/pytorch/pytorch/issues/76750)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:650:        # TODO: add limited pickling support for sharing an iterator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/graph.py:22:# TODO(VitalyFedyunin): Make sure it works without dill module installed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:6:# TODO: Caveats
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/decoder.py:320:                # TODO: xinyu, figure out why Nvidia do this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:36:            # TODO(VitalyFedyunin): Replacing with TorchArrow only API, as we are dropping pandas as followup
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:120:        except Exception:  # TODO(VitalyFedyunin): Replace with better iterable exception
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:8:# TODO(VitalyFedyunin): Add error when two different traces get combined
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:53:#  TODO(VitalyFedyunin): Extract this list from the DFIterDataPipe registred functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:61:    # TODO: All operations are shared across entire InitialCapture, need to figure out what if we join two captures
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:78:        # TODO(VitalyFedyunin): Currently can't pickle (why?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:131:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:142:    # TODO(VitalyFedyunin): Add tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:143:    # TODO(VitalyFedyunin): Need to join context if one of them are empty because we used capture
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:146:        # TODO: Check if args or kwargs have more than one different context
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:148:            # TODO: Allow CaptureA to take context from mock
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:190:        # TODO(VitalyFedyunin): Do not use provate function here, copy own implementation instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:220:        # TODO: VitalyFedyunin execute kwargs and maybe nested structures
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:242:    # TODO(VitalyFedyunin): This should be atomic and thread safe
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:261:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:421:    # TODO(VitalyFedyunin): Must implement all special functions of datapipes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:146:            # TODO: Add try-except to in-place reduce traceback from the Exception
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:197:                # TODO: Simplify the traceback message to skip over `response = gen.send(None)`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/gen_pyi.py:227:    TODO: The current implementation of this script only generates interfaces for built-in methods. To generate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:67:    # TODO: Lambda for picking
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:167:    # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/fileopener.py:54:        # TODO: enforce typing for each instance based on mode, otherwise
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:136:    # TODO(VitalyFedyunin): Verify that item is any sort of batch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:138:        # TODO(VitalyFedyunin): Compact all batch dataframes into one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:155:            # TODO(VitalyFedyunin): Add default collation into df_wrapper
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:166:    # TODO(VitalyFedyunin): We can dynamically extract types from the tuple_values here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:167:    # TODO(VitalyFedyunin): Instead of ignoring mypy error, make sure tuple_names is not empty
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:227:        # TODO(VitalyFedyunin): Replace `Callable[..., Any]` with `Callable[[IColumn], Any]`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:228:        # TODO(VitalyFedyunin): Replace with `Dict[Union[str, IColumn], Union[Callable, Enum]]`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:235:                # TODO(VitalyFedyunin): Validate passed dictionary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:104:        # TODO: Performance optimization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:15:# TODO: Use TypeAlias when Python 3.6 is deprecated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:206:# TODO: When PyTorch drops the support for Python 3.6, it can be converted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:262:        # TODO: the statements below are not reachable by design as there is a bug and typing is low priority for now.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:280:    # TODO: Fix isinstance bug
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:327:    # TODO: Fix isinstance bug
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:336:    # TODO: Fix isinstance bug
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:380:    # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/__init__.py:1:# TODO(VitalyFedyunin): Rearranging this imports leads to crash,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:156:# TODO: Implement `SeedSequence` like object for `torch.random`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:496:    TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py:8517:        # TODO: Undo this special-case; see the header for motivation behind this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:13:            # TODO: Remove this once ScriptModule supports registering None buffer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:54:            # TODO: Remove this once ScriptModule supports registering None buffer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:238:    # TODO(XuehaiPan): remove this condition when we make Python pytree out-of-box support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:110:        # TODO: when the bounds have free variables, this may be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:180:    # TODO: this doesn't work with bools but arguably it should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:606:        # TODO: We should tighten value ranges
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:622:        # TODO: We should tighten value ranges
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:768:        # TODO A better way of doing this would be to assign them a range upon creation, as
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:163:# sharing (TODO: considering splitting out a BaseReferenceAnalysis).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:31:# TODO: Dedupe this with SYMPY_INTERP
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:36:    # TODO add CeilDiv (it doesn't appear in the index_expr)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:38:    # TODO default to some decompositions if the interpreter doesn't have them
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:144:                        # TODO if https://github.com/openai/triton/issues/619 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:299:# TODO: As an indicator, this != 0 implies == 1 (and vice versa).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:312:        # TODO: it is possible to make progress evaluating this guard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/weak.py:319:        # TODO, add _fix_weakref type binding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:103:        # TODO: make storage support buffer protocol so this isn't
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:112:    # TODO: factor this into a random utility
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:153:    # TODO: offer some sort of non-blocking API to speed things up
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:158:        # TODO: consider not using torch.save for this; we don't actually
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:184:        # TODO: Support more advanced snapshotting of requires_grad/grad/etc
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:33:    # TODO(#105471): Rename the count field
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:841:            # TODO: we can probably make this check stricter by checking that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1155:    # TODO: unify _is_compiling across all compile stacks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:205:    # TODO: expose other parameters in the future.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:45:        # TODO; Specify a __slots__ for this class or potentially
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:114:        # TODO: See if we can remove this in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:216:        # TODO: compute correct memory usage and CPU time once
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:344:    # TODO: See if we can extract GPU vs CPU information from the PyTorch model
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:72:        # TODO: See if we can remove this in the future if we are
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:395:        # TODO: Should we do this even for non-contiguous tensors?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:405:        # TODO: Provide more useful diagnostics.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/dlpack.py:47:# TODO: add a typing.Protocol to be able to tell Mypy that only objects with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:83:                # TODO: This creates a temporary file for every frame, but we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:174:            # TODO: Maybe indicate that the traceback was elided?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:299:            # TODO: change this warning to an error after OSS/internal stabilize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1407:# TODO(angelayi): remove this function after OSS/internal stabilize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1413:# TODO(angelayi): remove this function after OSS/internal stabilize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:74:      // TODO: Maybe check that compressed_size === file_size.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:81:  // TODO: Better formatting.  Right-align this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:121:      // TODO: Maybe show simple lists and tuples on one line.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:125:      // TODO: Maybe show simple lists and tuples on one line.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:129:      // TODO: Maybe show simple (empty?) dicts on one line.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:217:    // TODO: Check stride and indicate if the tensor is channels-last or non-contiguous
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:218:    // TODO: Check size, stride, offset, and numel and indicate if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:220:    // TODO: Maybe show key?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:268:        // TODO: Less copy/paste between this and normal dicts.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:308:  // TODO: Add human-readable sizes?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:309:  // TODO: Add sorting options?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:310:  // TODO: Add hierarchical collapsible tree?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:481:// TODO: Maybe track by dtype as well.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:482:// TODO: Maybe distinguish between visible size and storage size.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:48:    - Fix various TODO comments in this file and the JS.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:179:            # TODO: Undo at least that second hack.  We should support string states.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:293:                # TODO: Handle this case better.  TorchScript ranges are in bytes,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:326:                # TODO: handle errors here and just ignore the file?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:278:        # TODO: Make this work with autograd
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:507:    # TODO: Figure out how to handle this better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1055:    # TODO: Handle inference mode properly.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:170:            # TODO: Don't guard on this!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:236:# TODO: Remove ViewBufferFromNested, ViewNestedFromBuffer, and buffer_from_jagged once the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:327:        # TODO: An alternative way to construct offsets is to use F.pad. This avoids creating
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:64:        # TODO: Figure out whether masks are actually supported for this layout or not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:315:        # TODO: Explore performance impact of copying
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:320:        # TODO: Explore performance impact of copying
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:326:        # TODO: Explore performance impact when compiling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:370:# TODO: Next iteration should add test cases and check it works
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:550:    # [TODO] K and V have to have the same Nnz, should probably torch_check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:603:# TODO: coalesce with torch/nn/utils/attention.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:605:    # TODO: Investigate why math.sqrt() isn't properly handled by Dynamo?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nested/__init__.py:235:        # TODO: switch to as_nested_tensor(tensor) when it is available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:78:    # TODO: test the specs match; empirically  sometimes we have a tuple
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:126:                # TODO: suppress guards
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:136:        # TODO: This probably does the wrong thing if you're running other
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:198:            # TODO: support get_autocast_gpu/cpu_dtype
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:271:                    # TODO: is there a way to split by device and dtype without appending in the inner loop?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:643:    # TODO: This feature could be added in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:670:                # TODO: Once we decide to break serialization FC, this case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:708:            # TODO: There's an issue here with FC. It might be impossible to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:786:    # TODO: This feature could be added in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:798:                # TODO: Once we decide to break serialization FC, this case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:1138:                    # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:1150:                    # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:1206:                # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:1226:                    # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:1387:        # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:3881:    # TODO: handle out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5007:# TODO: Deduplicate this with canonicalize_dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5771:    # TODO: Query cudnnGetRNNTrainingReserveSize (expose to python)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1376:    # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2400:            # TODO: Remove this once script supports type() calls
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2466:    # TODO: make use of reduce like below when JIT is ready with the missing features:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4524:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5412:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5421:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:1284:    # TODO: consider removing this check and allowing users to specify
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:65:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:136:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:20:    # TODO Make return type more specific
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:238:    # TODO allow kwargs such as unsafe and others for parametrization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:653:                        # TODO: Fix this for tensor subclasses that are parameters:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:171:        # TODO: Re-enable this check (.type isn't supported in TorchScript)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:295:# TODO: ContrastiveNorm2d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:296:# TODO: DivisiveNorm2d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:297:# TODO: SubtractiveNorm2d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:286:        padding_mode: str = 'zeros',  # TODO: refine this type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:438:        padding_mode: str = 'zeros',  # TODO: refine this type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1109:# TODO: Deprecate and remove the following alias `_ConvTransposeMixin`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1132:# TODO: Conv2dLocal
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1133:# TODO: Conv2dMap
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1134:# TODO: ConvTranspose2dMap
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1300:        padding_mode: str = 'zeros',  # TODO: refine this type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:# TODO: fail fast on quantization API usage error, then remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:264:# TODO: PartialLinear - maybe in sparse?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/padding.py:10:# TODO: grad_output size asserts in THNN
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1843:    # TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1889:        # TODO: Remove `args` and the parsing logic when BC allows.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:626:# TODO: remove the overriding implementations for LSTM and GRU when TorchScript
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1287:            ret = input  # TODO: remove when jit supports exception flow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:57:        # TODO: check in THNN (if inplace == True, then assert value <= threshold)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:153:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1788:# TODO: L1HingeEmbeddingCriterion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1789:# TODO: MSECriterion weight
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1790:# TODO: ClassSimplexCriterion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/_reduction.py:18:        ret = -1  # TODO: remove once JIT exceptions support control flow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/comm.py:122:    # TODO: When `len(inputs) == 1` and all inputs are on `destination`, just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:89:    # TODO (rohan-varma): keep_low_precision_grads: bool = False
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:90:    # TODO (rohan-varma): APIs to allow users to run batchnorm and layernorm
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:147:        # TODO: Expand to remote RRefs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:290:        # TODO: make DDP uneven inputs context manager support buffer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:840:            # params. TODO (rohan-varma): Make this compose with general
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1039:                        # TODO: when zero_grad(set_to_none=False) or in grad
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1511:            # TODO (rohan-varma) test this codepath.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1548:        # TODO: DDPSink is currently enabled for unused parameter detection and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:126:    # TODO: update notes/cuda.rst when this class handles 8+ GPUs well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/attention/bias.py:230:                    is_causal=True,  # TODO: Flash accepts causal = True and for this particular op it means lower right
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/attention/__init__.py:21:# TODO: Consider using this for sdpa regardless of subclasses
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:969:    # TODO: __name__ not set for submodules in recursive script
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:1368:# TODO support future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/library.py:146:            # TODO: in future, add more info about where the existing function is registered (this info is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/library.py:455:    # TODO(rzou): We're gonna need to stage this change with torchvision,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_script.py:837:                # TODO: we don't have _concrete_type set after load(), and in general we lose constant information.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_script.py:845:                # TODO: it's possible that the following is confusing:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_script.py:996:    # TODO MAKE SURE THAT DISABLING WORKS
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:64:    TODO: To remove this check once Union support lands.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:130:                    # TODO: To remove this check once Union suppport in TorchScript lands.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:443:        # TODO: this is hack to recognize NumberType
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:449:        # TODO: Determine if the other cases need to be fixed as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:539:    # TODO: Consider not exporting these during wildcard import (reserve
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:253:    # TODO: proper overriding analysis when implementing class inheritance
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:382:# TODO: more robust handling of recognizing ignore context manager
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:516:        # TODO: add input, output validator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:755:            # TODO: try to recover the location of else:? Python doesn't give us useful
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:32:# TODO: there should be a more principled way of doing this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:300:            # TODO: We should really error in this case, but its bc-breaking so
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:319:            # TODO: We should really error in this case, but its bc-breaking so
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:400:            # TODO: could add more detail here. For example, what the user should do
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:680:            # TODO: Why skip this? Because @torch.jit._overload_method will
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:686:        # TODO: we don't currently do this functions that are recursively
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:843:    (TODO add a link when the rules are published).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:86:# TODO: replace torch.sigmoid -> aten.sigmoid
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_builtins.py:120:    # TODO: add support for more ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_serialization.py:164:    # TODO: Pretty sure this approach loses ConstSequential status and such
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:159:            # TODO: figure out one liner to .clone() and set requires_grad
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:228:    # TODO: In principle, we track device information in our trace, so it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:232:    # TODO: Consider adding a utility function to torch.jit to test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:272:        # TODO: I'm not sure if the clone here is necessary but it is safer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_check.py:147:        # TODO @ansley: add `Union` once landed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:39:            # TODO: only assertion error is bound in C++ compilation right now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:94:            # TODO: only assertion error is bound in C++ compilation right now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:405:    # TODO: return self
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:611:        # TODO: handling of slice
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:617:        # TODO: handling of slice
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:678:    # TODO: look into rewriting with early return and getting loop unrolling to fire
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:698:    # TODO: assertions could be expanded with the error messages
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1029:        # TODO: return self
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1037:    # TODO: use slicing when slice optimization has landed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1439:# TODO: migrate over all of symbolic_shape_registry_util.cpp
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1454:# quantized_conv_prepack TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:687:                # TODO: handle the other Ju
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:928:            # TODO: To cover more problematic cases, replace stride = 0 check with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1720:    # TODO: properly handle case when u is tuple instead of only taking first element
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1902:    # TODO: replicate https://github.com/pytorch/pytorch/pull/77743 for fast gradcheck as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:2194:    # TODO: do we want to test this too?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/_functions/tensor.py:30:# TODO: deprecate this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:598:        # TODO: TorchScript ignores standard type annotation here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:618:        # TODO: Too slow with __torch_function__ handling enabled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:655:        # TODO: Too slow with __torch_function__ handling enabled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:921:        )  # TODO: find in sqlite database
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:71:            # TODO: We can remove this conditional once we uniformly use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:538:        # TODO: Raise exception instead of converting value.  This is only for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:563:        # TODO: Raise exception instead of converting value.  This is only for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:626:        # TODO: Raise exception instead of converting value.  This is only for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:674:    # TODO: Enable data-dependent checks with debug mode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:675:    # TODO: This check does not work with FakeTensor inputs; See Issue #85834
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:754:    # TODO: raise exception instead of converting value
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:810:# TODO: This ref supports int reduction and out kwarg to be compatible with ATen:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:812:# TODO: Could be rewritten to support complex:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:896:        # TODO: Raise exception instead of converting value.  This is only for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1042:        # TODO: Raise exception instead of converting value.  This is only for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/special/__init__.py:231:# TODO: add docstring
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:114:    "round",  # TODO: model kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:204:    "copy_to",  # TODO: add OpInfo (or implement .to)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:386:    # TODO: make common validations available as utils
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:450:# TODO: add type promotion support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:740:# TODO: if this is special maybe it should be defined there and imported here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:965:# TODO: register this as a real ref/decomposition once TorchInductor supports complex!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1614:# TODO: skip unnecessary conversion of long to float
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1695:# TODO: consider refactoring this with add impl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1898:# TODO: implement alternate where
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2095:    # TODO: is_pinned is not currently supported in refs or fake_tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2119:    # TODO: non_blocking should be handled by `copy_to`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2151:            # TODO - this is true for eager mode currently, but it's wrong behavior for complex norms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2782:        # TODO: fix this to work with meta tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2993:    # TODO: we could look at directing collapse_view to skip its meta function here (unsafe_collapse_view)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3058:# TODO: This must return a sparse tensor if the input is sparse, but refs have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3222:# TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4416:    # TODO: Add sparse support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4544:# TODO: Turn this into a decomposition (currently fails on reshape meta tests)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5343:    requires_grad: bool = False,  # TODO: unused
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5370:    # TODO: Use requires_grad.  All refs taking the requires_grad kwarg must
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5970:    # TODO: fix inductor rand_like for integer, bool dtypes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6004:# TODO: add support for functionalization aten.normal_functional
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6264:    # TODO: this is inaccurate, we actually test PySequence_Check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6305:    # TODO: this is inaccurate, we actually test PySequence_Check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6315:            # TODO: test this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6373:    # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6377:    # TODO: test for numpy input with PyArray_Check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6405:    # TODO (or not): support names kwarg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6415:        {"device": "cpu"},  # TODO: use torch.get_default_tensor_type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:126:        # TODO: This solution is no ideal since we may miss some factory methods. In future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:183:    # TODO: this part is TS backend specific for now and will be generalized to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:9:    TODO: This API is currently ts backend specific. We are working on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:23:    TODO: This API is currently ts backend specific. We are working on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_lazy/__init__.py:16:    # TODO(whc) expand this to include backend hooks and align with XLA backend needs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:222:    # TODO: Uhh.... it shouldn't matter, but changing this to true_fn results in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:225:    # TODO Sometimes the operands are not completely FakeTensor, something seems went wrong in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:16:# TODO to figure out a more generic approach
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:48:        # TODO(ydwu4): Subclassing HigherOrderOperator causes __module__ to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:21:# TODO: this is not really sufficient. While passes (hopefully) check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:77:# TODO: currently we just run the C++ implementation with fake tensors.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:290:                # TODO(oulgen): add support for tt.reduce
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:325:    # TODO(oulgen):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:723:    # TODO(oulgen): Preexisting bug, if two kernel inputs are views of each
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:758:    # TODO(oulgen): For performance reasons, we want to ensure that these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:774:    # TODO(oulgen): For performance reasons, we want to ensure that these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:177:            # TODO: We want to use the same `checkpoint(Interpreter(gmod).run, *args, **kwargs)` here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/map.py:28:# TODO: We add this to prevent dymamo from tracing into map_wrapper,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_utils.py:176:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_utils.py:263:                # TODO: Validation currently involves an expensive traversal
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_utils.py:363:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_utils.py:855:    TODO(khabinov): we should deprecate this function and use torch.compiler.is_compiling().
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_utils.py:97:            # TODO: there are many flatten/unflatten in IterGraph that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:50:        # TODO: if we do ``deepcopy(_codegen)`` and the input argument contains
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:352:        # TODO: This is a temporary solution. We are going to remove DCE usage
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:598:        # TODO: remove this API after DCE is removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:614:        # TODO: remove this API after DCE is not used with IterGraph
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:739:        # TODO: remove this API once it is not used.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:59:# TODO(@fegin): Support multiple runs of graph optimization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:60:# TODO(@fegin): With this design, circular imports will happen when a pass
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:215:    # TODO: populate all the tensor metadata and remove the default.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:218:        # TODO: support symbolic shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:242:    # TODO: fix the memory_format
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:264:        # TODO: fix these value
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:324:                # TODO(@fegin): support symbolic shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:485:        # TODO: determine the dtype
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:601:# TODO(fegin): Have a template class for all Block class.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:611:    # TODO(fegin): populate/generate the max_exp_avg_sqs if exists
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:927:# TODO(fegin): The API only support fused adam now. Should extend it to support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:165:            # TODO: figure out why turning on cudagraphs cause exceptions.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:193:    # TODO(yifu): apparently having a meta kernel is not a necessary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/comm_tensor.py:141:                # TODO(ezyang): I don't really understand what's going on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:483:    # TODO(@mrshenli): @yifuwang has a suggestion of conducting expansion and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:496:# TODO: ensure the key is unique.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:553:                    # TODO: SPMD should provid a default and configurable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/log_utils.py:47:        # TODO(anj): Add loggers for MPMD
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:39:        TODO(@wanchaol): some of these arguments are not necessary for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:53:        # TODO: add more necessary arguments to this interface.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:93:        # TODO: what if user passes in a incorrect `input_batch_dim`, how should we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:100:            # TODO: add a few default passes here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:113:        # TODO: figure out a way to avoid explicit "cuda" mesh.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:132:        # TODO: add more necessary arguments to this interface.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:150:            # TODO: add a few default passes here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:215:        # TODO: move the trasnformation passed to this function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:227:    # TODO: provide schema_suggestions when placements do not match
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:393:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:141:    # TODO: this is broken because it won't redistributed potential tensors on the kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:480:    # TODO(anj): This depends on the call function node -> actual DTensor output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:522:        # TODO(anj): We require mapping of the final DTensor output to the wait
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:540:                # TODO(anj): We are depending on the concrete DTensor output of the dummy add.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:730:            # TODO(anj): Pipe the output schema for the BW pass
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:158:    # TODO: Only NCCL supports AVG so using backend like Gloo would
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:358:                # TODO: Currently this specializes to fused optimizer ops, but we need
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:397:                    # TODO: optimizer parts should follow the dtensor prop logic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:536:                    # TODO: add support for default mode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:226:            # TODO(yeounoh) implement DeviceMesh backend and register XLA backend.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:246:            # TODO: if user want to pass pg_options, offer a way to do it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:273:            # TODO(yifu): remove tag and ranks once we fully migrate to native
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:304:                        # TODO: Add two tests to cover internal tests scenarios and re-enable reuse subgroup if exists.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/nn/jit/templates/remote_module_template.py:60:# TODO: Merge these two templates together in the future once TorchScript syntax is improved.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:261:            # TODO: We need to change this to rpc.remote, and make it async (see the else branch below).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:204:# TODO assert if ranks has duplicated entries
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:232:    # TODO add dim support?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:280:    # TODO add dim support?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:80:    # TODO: should we use pytree?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:149:                # TODO: support DTensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:89:        # TODO: figure out dynamo support for instance method and switch this to instance method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:394:                    # TODO: re-enable the check once we fix the compile path
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:471:                    # TODO: re-enable the check once we fix the compile path
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:80:        # TODO: we should allow user to pass in the default seed from a config
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:23:    # TODO: Will follow up with dynamo POC to make warnings.warn working with dynamo.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:40:    # TODO: To add perf optimizations to this iterations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:94:    # TODO: To add test cases and ensure that it works for nested modules
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/fsdp.py:350:            # TODO: this is a short term fix and we should make the get_unflat_views
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:20:        # TODO(@fegin): this variable is originally create for testing, we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:131:    # TODO(fegin): using kwargs is not a good idea if we would like to make
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_init.py:129:    # TODO: De-duplicate with `_apply` after `swap_tensors` path lands:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:146:        # TODO: Replace the sharded DTensor parameter construction logic with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:148:        # TODO: Simplify the following sharded parameter padding logic after
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:178:            # TODO: Hard code FSDP + TP; need to support HSDP + TP
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:353:        # TODO: Prefer this DTensor to be read-only and generalize the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/fully_shard.py:218:        # TODO: Remove this padding logic once DTensor pads the local tensor:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:18:# TODO: we can add additional info to RegistryItem to share across APIs. E.g.,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:165:            # TODO: a stricter verification should also reject changing module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:168:            # TODO: verify that installed distributed paradigms are compatible with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:176:                {},  # TODO(@yhcharles): this is a temporary fix, need a better way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:57:        # TODO: Once step_param interface is robust, refactor step to call
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py:71:            # TODO: Remove these attributes once we have a better way of accessing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:58:    TODO: Add tutorial for _NamedOptimizer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:59:    TODO: Add documentation in the docstring for the public attributes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:313:        # TODO(chienchin): This API should be FSDP agnostic and should support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:322:        # TODO(chienchin): This API should be FSDP agnostic and should support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:29:# TODO (wanchaol): remove this once we added TorchScript
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:60:# TODO (wanchaol): remove/merge this with ScriptLocalOptimizer once
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:112:    # TODO: improve error propagation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1535:        # TODO: Manually add `self.param_groups` if using a functional
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:57:        # TODO: no union or any types in TorchScript, make step a scalar tensor instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/pipeline/sync/skip/skippable.py:241:# TODO(sublee): Move to above of Skippable class for better read flow.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_loader.py:33:        # TODO: test returning `load` here instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:9:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:19:# TODO: Update Docstring for nested_dict.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:34:# TODO: update docstring for traverse.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:145:        # TODO: add local offset for _local_tensor in print_nested.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_sharded_tensor_utils.py:15:# TODO: We need to refactor this code.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:384:# TODO: integrate with distributed logging flag
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:60:# TODO: Update docstrings for default_planner.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:46:# TODO: Update docstrings for optimizer.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:189:            # TODO: The ReadItems will have a displaced MetadataIndex, fix it.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:190:            # TODO: we should change _create_sharded_read_items to have more ergonomic API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:77:        # TODO: add logging for the gc details/time
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:373:        # TODO: make this faster.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:573:            # TODO: check if value is the same if exists.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:962:# TODO: correct the state_dict function signature.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:963:# TODO: this API is not yet fully tested. Make it private
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1017:# TODO: correct the load_state_dict function signature.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1018:# TODO: this API is not yet fully tested. Make it private
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:39:    # TODO: test returning `save` here instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_dedup_tensors.py:30:# TODO add docstring for dedup_tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:220:        # TODO replace with headq
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:269:            # TODO: Using the OverlappingCpuLoader with multiple threads creates significant
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:572:                # TODO sort by offset and cache the reading
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/format_utils.py:118:        # TODO: read on each host, instead of only the coordinator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:317:            # But maybe we need to? TODO(voz): Look into this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:579:        # TODO: Do not use the side stream for tensor copies for now; investigate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:784:    # TODO: Post-backward prefetching does not support the multiple handles
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:961:    # TODO: Investigate why `NO_SHARD` breaks correctness when using
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:963:    # TODO (rohan-varma): When CPU offload and optimizer overlap,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:994:                # TODO (rohan-varma): For CPU offload, this unfortunately
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1084:        # TODO (rohan-varma): this also waits for the overlapped optimizer step to finish
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1127:            # TODO: This already-resharded check is brittle:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:155:    # TODO: need to check if this is always correct for composable FSDP.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:449:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:506:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626:            continue  # TODO: Improve unittesting for state_dict finetuning
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_wrap_utils.py:43:    # TODO: We may relax this no-nested-wrapping constraint to support manual
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:115:        # TODO: Move all the attributes to this class to enable typing for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:195:    # TODO: This is a temporary hack for differentiate between code paths.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:238:    # TODO: Explicitly replacing the checkpoint wrapper prefix is not ideal as
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:337:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:422:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:430:                            # TODO(voz): Don't graph break on this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:511:            # TODO: We need to run this mixed precision ignored module in fp32,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:559:        # TODO(voz): Extend a dynamo util to answer the above, unify the codepaths here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:81:        # TODO: figure out the case for the composable APIs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:96:        # TODO: figure out the case for the composable APIs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:142:        # TODO: Rank 0 can broadcast the `FlatParameter` to allow all ranks to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:253:            # TODO (awgu): The traversal function does not traverse through
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1448:        # TODO: This solution is not general and only apply to PTD TP solution.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1748:                # TODO: it is unclear if we need to do the same check with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:80:        # TODO (awgu): We can broadcast the metadata of rank 0's `all_handles`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:214:            # TODO (awgu): Since every module has at most one handle in the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:218:                # TODO(voz): Don't graph break on this - dynamo hates the n1 != n2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:244:                # TODO(voz): Don't graph break on this - dynamo hates the i1 != i2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:39:    # TODO: Add any other composable APIs that are mutually exclusive.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:46:# TODO (awgu): We may be able to remove this function if we retired the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:115:# TODO: Define this for now to avoid circular imports. See if we can remove.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1566:                # TODO (awgu): Gradient accumulation outside `no_sync()`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1607:            # TODO (rohan-varma): test for full precision with keep_low_precision_grads
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1616:        # TODO (awgu): We should replace these conditional checks to encode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1785:                # TODO: Change `_unpadded_unsharded_size` if we change the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2293:        # TODO: If we want to handle shared parameters, we need to re-generate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:77:# TODO (awgu): Refactor this later
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:321:    # TODO: FSDP's contract for buffers is not well-defined. They are
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:517:    # TODO: we need to add additional check once we support FSDP + PiPPy.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:657:            # TODO: We may relax this by taking the FSDP instance's wrapped
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:832:    # TODO: We need to establish a contract for FSDP and buffers. For now, we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1052:# TODO: See how to deprecate!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/distributed.py:77:            # TODO properly map the exceptions in pybind (c10d/init.cpp)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:430:        # TODO log_line_prefixes can be exanded too
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:144:        # TODO: look into using weakref here instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:190:# TODO: we should probably handle a few additional errors,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:248:        # TODO: look into using weakref here instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:919:        # TODO: implement timeout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:84:    # TODO @kiuk - make entrypoint a required field
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:701:        # TODO after stopping workers, wait at least monitor_interval*2 for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py:100:# TODO: create an internal helper function and extract the duplicate code in FP16_compress and BF16_compress.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:72:            # not average. TODO: (rohan-varma) the div factor may be different
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:77:            # TODO (rohan-varma): upcast as needed for DDP mixed precision,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:593:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:814:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:285:    # TODO: Importing inside function to avoid circular import issue between FSDP and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:76:    # TODO: register_fsdp once FSDP supports communication hook.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:241:    # TODO this should be done inside AsyncCollectiveTensor to delay the wait() call
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:698:        # TODO: it should run collective in the whole mesh instead of dim 0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:967:    group,  # TODO add a type,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:981:    op: str = "sum",  # TODO type is actually c10d ReduceOp. is this ok?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:982:    group=None,  # TODO add a type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/sharding_prop.py:173:        # scalar. TODO: figure out a better way to handle this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:138:            # TODO: by default check tensor metas across rank
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:139:            # TODO: See if we need to make this run_check logic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:181:            # TODO: return the redistributed local tensor directly without
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:185:        # TODO: backward is also differentiable now, add a test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:248:        # TODO: consider all_gather the local tensors for better debugging
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:561:    # TODO: the value assignment to global variable is not the ideal solution
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_utils.py:16:# TODO: audit existing code base to see if we can safely remove this API.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:154:        # TODO: alltoall/permute reshuffling to change device_mesh if they are not the same
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:212:                # TODO: enable this with all_to_all
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:718:        # TODO: we can avoid forcing the redistribution once we figure out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:735:            # TODO: we can avoid forcing the redistribution once we figure out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:752:            # TODO: we can avoid forcing the redistribution once we figure out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:820:        # TODO: change the strategy to the following rule.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:827:            # TODO: now grad_out spec follows input spec. we may need
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:871:            # TODO: now d_weight spec follows input spec w/ a reduction.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:663:            # TODO: optimize this. we shouldn't simply blindly replicate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/utils.py:140:        # TODO: maybe we should determine is_shardable based on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/random_ops.py:26:            # TODO: figure out how inplace random op should behave when it's partial
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/matrix_ops.py:151:    # TODO: sdpa might be a good candidate for us to explore decomposed sharding propagation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:98:                # TODO: further merge the sharding properly (i.e. reshard one input to replicate)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:164:            # TODO: consider a more advanced heuristic to pick the best sharding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:115:            # TODO: see if this is valid for the submesh case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:171:    # TODO: filter out invalid strategies, at this point we generate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/pointwise_ops.py:527:# TODO: add all for_each ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:178:        aten.new_empty_strided.default,  # TODO: re-think new_empty_strided
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:183:    # TODO: maybe we should generate all possible shardings intead of just stay
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:294:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:500:    TODO: exception: when the dtype of second input is "bool", then a torch.nonzero needs to be triggered first.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:775:    # TODO: tensor to split cannot have _Partial
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:785:    # TODO: just like slice op, split replicates before
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:44:        # TODO: evaluate if we need to release the mask buffer or the buffer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:177:    # TODO: implement rowwise sharding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:253:    # TODO: implement rowwise sharding backward
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/dispatch.py:238:        # TODO: the op schema should probably just remain flattened so that we can avoid this tree flatten
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/tp_conv.py:13:    # TODO: whether there requires data exchange is currently determined by padding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/placement_types.py:358:        # TODO: if the reduce_op is min/max, etc. the _partition_value should be a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/op_schema.py:214:    TODO: make this a frozen dataclass
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:26:# TODO: we need to migrate these APIs to be functional collectives
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:53:    # TODO: Ideally we should use the meta tensor way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:109:    # TODO: Ideally we should use the meta tensor way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:125:# TODO: test uneven split on GLOO and NCCL
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:142:        # TODO: pull the handle of uneven case in #492
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:207:                # TODO: see if we need to tweak this or offer a way for user
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:268:        # TODO: see if we want to support this once there's cross mesh communication
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/api.py:165:        # TODO: figure out a generic and efficient way to scatter the shards for EnumerableShardingSpec
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:150:        # TODO: Can we improve this error message to point out the gaps?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding.py:287:    # TODO: Make the result a PartialTensor.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding_bag.py:407:    # TODO: Make the result a PartialTensor and move the logic below there.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py:66:        # TODO: support named dimension
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:79:        # TODO: implement state_dict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:90:        # TODO: implement load_state_dict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:96:        # TODO: implement add_param_group
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:427:            # TODO make it as a view of out tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:492:        # TODO: make this a __torch_function__ op once ShardedTensor becomes a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:835:        # TODO: figure out what the API should behave when some rank have no shard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/tensor_ops.py:30:# TODO: set grad with a ShardedTensor that consists of all local grads
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:283:            # TODO: make async?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:342:        # TODO: add try-except and destroy _agent in all processes if any fails.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:245:        # TODO: remove this exception once UCC plugin is fully deprecated.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:482:        TODO don't expose the map, expose fine grained ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:492:        TODO don't expose the map, expose fine grained ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:502:        TODO don't expose the map, expose fine grained ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:512:        TODO don't expose the map, expose fine grained ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:522:        TODO don't expose group_count, use something else instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:611:            # TODO moco benchmark on CPU initializes pgnccl backend today, triggered this assert in CI before it was
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:816:# TODO: remove this once the ecosystem moves away from it.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:852:    # TODO(yifu): remove this function once ranks + tag is not a supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1506:            # TODO: remove this check after lazy initialization is supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1537:            # TODO: once UCC plugin is fully deprecated, remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1575:        # TODO: This defaults to the old behavior for PythonProcessGroups which overwrites the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3753:        # TODO(whc) aparently some existing test case for monitored_barrier passes in a timeout in float format?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4225:    # TODO copy settings and timeout from default PG
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_torch_docs.py:5271:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:43:# TODO: implement ref.cast with an option to enforce safe casting
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:172:# TODO: handle tuples of tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:362:            # TODO: There is a subtle bug here: prims like copy_to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:379:# TODO: when tracing this will add torch tensors and not TensorMeta objects
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:381:# TODO: this wrapper is currently untested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:43:# TODO: Type[torch.SymInt], Type[torch.SymFloat]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:45:# TODO: This needs a lot more type annotations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:107:            # TODO: We should check that the symbols are consistent
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:134:# TODO: look at using torch.testing.assert_close instead with an option
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:164:        # TODO: we should review why this happens and see about fixing it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:440:    # TODO: are these necessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:449:    # TODO: do channels last too
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1034:        # TODO: type error here is real, replace with sym_complex
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1053:    # TODO: sym_complex_float?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1195:# TODO: maybe unify with can_cast_to?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1349:# TODO: when NumberType contains the sym types, can simplify this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1367:# TODO: document type promotion kinds
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1630:    # TODO: maybe inform the user of channels_last_3d if rank of the tensor is 5?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1923:    # TODO: a better way to handle this would be with a new op, "_unsafe_as_strided"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:123:    # TODO: no real reason to restrict multiple outputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:167:        # TODO: file issue
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:195:    # TODO: I think this does the wrong thing if r is inp
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:247:    # TODO: remove me
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:276:        # TODO: consider a memo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:309:        # TODO: Add a config knob to turn off this unsound behavior
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:559:            # TODO: We can make this a little more faithful with best effort
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:941:            # TODO: Minor optimization: track if the shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:980:            # TODO: we don't need the compute type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:1002:        # TODO: is_non-overlapping_and_dense (not bound from Python
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/schema_check_mode.py:50:                # TODO: This is only OK if can't have NaN quantized; idk if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_utils.py:109:                # TODO: enable_python_dispatcher() here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:69:    # TODO (tmanlaibaatar) make it a tag
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:103:            # TODO: right now, _make_wrapper_subclass's dynamic shape interaction is not great.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:288:            # TODO (tmanlaibaatar)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:468:    # TODO: pull these from aot autograd
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:82:        # TODO: test if is resizable (no direct query for this atm)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:83:        # TODO: audit AutogradMeta to see if it matches
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:84:        # TODO: test forward AD
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:216:            # TODO: make a dedicated UnknownSource for this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:415:                # TODO: Change this logic to use view replay for consistency?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:593:                    # TODO: Handle this better in Dynamo?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:872:                    # TODO: Use a valid grad-specific symbolic context instead of recycling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:898:        # TODO: zero tensors?  We appear to have eliminated them by
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:913:                # TODO: sparse should support meta
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:50:# TODO: Hack to unblock https://github.com/pytorch/pytorch/pull/108186
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:416:    # TODO: Generalize this as needed, e.g., into a trie of memos
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1099:        # TODO: support caching sparse outputs?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1386:                    # TODO: Remove these exclusions, so that we can remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1405:        # TODO - we should be use the prim aten impl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1406:        # TODO - fix prims complex ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1714:    # TODO: also check metadata change on inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:13:# TODO: Add type annotations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:14:# TODO: Check tensor types for ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:150:# TODO: Expose these directly to Python to avoid maintaining this list.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:206:    # TODO: Make this an enum.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:239:    # TODO: Support non-equal-rank broadcast where semantics match.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:264:    # TODO: Handle dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:492:                # TODO: Improve this error message, possibly after converting
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1169:            # TODO: Possibly check scale and zero point.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1171:            # TODO: Possibly support variable-sized inputs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1466:                # TODO: Support this by adding trailing 1 dims.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1496:        # TODO: Validate ceil_mode semantics.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1753:        # TODO: Transform at load time to share weights with CPU model.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1793:        # TODO: Support automatic reshape
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1832:        # TODO: Transform at load time to share weights with CPU model.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:2055:        # TODO: Transform at load time to share weights with CPU model.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:72:            # TODO: See if it's possible to use those directly.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:84:            # TODO: See if it's possible to use those directly.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:139:    # TODO: Maybe make these names match the original.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_custom_op/autograd.py:46:# TODO(#101191): Use the actual C++ autograd not implemented fallback,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:24:# TODO: Maybe we should allow for some sub-hierarchy so you can control which
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:113:    # flattens all the qnames together (TODO: consider memoizing?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:1055:            # TODO: Actually, the rank probably should just be emitted once at
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset13.py:549:    # TODO: So far we don"t have a module using this method. We"ll keep
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1510:        # TODO: remove this as onnx opset 11 spec allows negative axes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1561:    # TODO(justinchuby): Looks like this op is deprecated in torch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2446:    # TODO: remove this as onnx opset 11 spec allows negative axes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3451:# TODO(justinchuby): Support multiple quantized args in output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3477:# TODO(justinchuby): Support multiple quantized args in output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4261:# TODO(justinchuby): Support multiple quantized args in output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4291:# TODO(justinchuby): Support multiple quantized args in output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5376:    # TODO: remove this as onnx opset 11 spec allows negative axes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5856:            # TODO: If indexing is supported natively in ONNX in future opsets,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6311:        # TODO: Might need a fix in torch group_norm module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6820:# TODO: It would be better to export this as a chunk directly, as this is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6822:# TODO: Once we have proper scoping, stop reimplementing chunk, delete this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6884:        # TODO(justinchuby): Use a public method in the helper module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:112:# TODO(justinchuby): Add type checking by narrowing down the return type when input is None
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:252:            # TODO: Remove `check_shape` option once every shape inconsistent issue is addressed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:435:        # TODO: remove this and treat mutating model separately. See #77679
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:619:    # TODO: refactor utils.py to remove duplicated code of context setup. See #78834
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:691:    # TODO: Below is doing aten graph to onnx. It should be abstracted as a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:873:        # TODO(#77679): remove this and treat mutating model separately.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:921:    # TODO: Only copy the argument if mutation is detected in Graph.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1278:            # TODO: A more compact graph printer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1853:    # TODO: Copied from utils.py `export` until `_optimize_graph`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_experimental.py:14:    TODO: Adopt this in `torch.onnx.export` api to replace keyword arguments.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:39:        # TODO(thiagocrepaldi): handle overload_name?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:45:        # TODO(thiagocrepaldi): handle overload_name?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:16:                        TODO: test coverage for mixed types inputs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:19:                        TODO: bfloat16 support.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:22:                        TODO: optional start/end attribute.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:156:    # TODO(justinchuby): Replace insinstance with _is_value once we figure out mypy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:432:            # TODO(justinchuby): Only single output is supported for now. We may want to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1346:        # TODO(justinchuby): Check if dtype is indeed a int.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1718:# TODO: remove these once we support Type's in the JIT IR and we can once again
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:75:# TODO(justinchuby): Remove dependency to this global variable from constant_fold.cpp
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1127:    # TODO: can we simplify this to always return a tuple of Tensor or None?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1379:            # TODO(justinchuby): Create a way to check if an op is fully supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1625:            # TODO: Don't allocate a in-memory string for the protobuf
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1851:        # TODO(justinchuby): Update the module name of GraphContext when it is public
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1952:                # TODO Wrap almost identical attrs assignment or comment the difference.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:134:        # TODO: get opset version from torchlib
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:362:        from torch.onnx._internal.fx import (  # TODO: Prevent circular dep
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1017:            # TODO: Should this be part of the serializer?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1080:        # TODO: Should we populate ONNXProgram with more info, such _model_torch for easier debug?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1119:    # TODO: Design the passes API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1154:        # TODO: https://github.com/pytorch/pytorch/issues/107714
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1164:        # TODO: Defer `import onnxscript` out of `import torch` path
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1174:            # TODO: Defer `import onnxscript` out of `import torch` path
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1451:    # TODO: Import here to prevent circular dependency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/registration.py:149:    # TODO(justinchuby): Add @functools.lru_cache(maxsize=None) if lookup time becomes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:119:    # TODO: select a good default based on the capabilities of the host
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:683:    # TODO(wschin): Make it to inference session level flag.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:774:        # TODO(wschin): this is a naive implementation of cache without proper guard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:951:            # TODO(wschin): enable external allocators.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1079:                # TODO(wschin): use a better way to identify fused submodule
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:4:# TODO(justinchuby): Move more of the symbolic helper functions here and expose
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:359:# TODO: Expose this to user when migrating symbolic helper functions to here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:7:# TODO: Remove after https://github.com/huggingface/safetensors/pull/318
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:41:    TODO: Should this really be a global patcher? Can we make it a local patcher?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:98:# TODO: generalize to allow more checkpoints formats (torch or gguf)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:39:        # TODO: Figure out how to retrieve commit hash.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:188:    TODO(bowbao): Add more overridable methods in call hierarchy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:189:    TODO(bowbao): Create an example once more overridable methods are added.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:315:            # TODO(titaiwang): aten::sym_size has overload, but fx graph is using
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/op_validation.py:92:            # TODO(titaiwang): How to bound indices/dim: INT64
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:38:# TODO(bowbao): move to type utils.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1267:        # TODO(bowbao): diagnostic.emit and diagnostic.set_message api.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:54:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:109:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/diagnostics.py:129:    # TODO: Compact display of `param_schema`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:56:    TODO(bowbao): Create fx utils module and move this function there.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:321:    # TODO: aten::sym_size has overload, but fx graph is using
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:400:    TODO: Convert methods to @staticmethod when the diagnostic system supports it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:409:        # TODO: Diagnostics API should be revised to get rid of this attribute.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:567:        # TODO: Fix FakeTensorMode limitation asap
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:761:        # TODO(wechi): Support call_method.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:818:        # TODO: We may want to consider other naming styles. The goal is to be stable and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/torch_export_graph_extractor.py:106:        # TODO: Import here to prevent circular dependency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:125:# TODO: Migrate to `DynamoExporter` after fake model tracing is supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:159:        # TODO: plumb ``concrete_args`` to symbolic_trace call at ``generate_fx``
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:24:# TODO(bowbao): Add diagnostics for IO adapters.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:152:# TODO: make_fx lose stack info https://github.com/pytorch/pytorch/issues/90276
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:182:    # TODO(bowbao): Turn this check into diagnostic. Consider warning instead of error.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:493:                    "markdown": 'This error occurs when the ONNX converter is unable to find a corresponding symbolic function\nto convert a "call_function" node in the input graph to its equivalence in ONNX. The "call_function"\nnode represents a normalized function call in PyTorch, such as "torch.aten.ops.add".\n\nTo resolve this error, you can try one of the following:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/tutorials/beginner/onnx/onnx_registry_tutorial.html#overview) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:518:                    "markdown": "This error indicates that an FX graph contains one or more unsupported nodes. The error message\nis typically accompanied by a list of the unsupported nodes found during analysis.\n\nTo resolve this error, you can try resolving each individual unsupported node error by following\nthe suggestions by its diagnostic. Typically, options include:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:104:            # TODO(bowbao): by default diagnostic doesn't have stack.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:158:# TODO(bowbao): decorator to report only when failed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:280:    # TODO(bowbao): Implement this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:406:            # TODO(bowbao): Create builtin-rules and create diagnostic using that.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/_infra.py:264:    # TODO: Implement this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:30:# TODO(After 1.13 release): Remove the deprecated SymbolicContext
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:146:# TODO(justinchuby): Deprecate these logging functions in favor of the new diagnostic module.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset10.py:763:    # TODO(justinchuby): Extract all the cast ops into a helper function.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/utils.py:75:                # TODO(avik): Assert the following property in the IR verifier:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:30:    # TODO(angelayi): remove this in favor of _check_val
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:42:        elif isinstance(val, (FakeTensor, torch.Tensor)):  # TODO(zhxchen17) Remove Tensor.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:161:            # TODO Remove this allowlist.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:170:                # TODO (tmanlaibaatar)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:199:                # TODO(T140410192): should have fake tensor for all dialects
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:247:                # TODO(zhxchen17)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/upgrade.py:109:        # TODO(larryliu0820): Add support for custom ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:234:        storage_offset=serialize_sym_int(0),  # TODO needs to be fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:271:        # TODO: this should be fixed by deserialization instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:402:            # TODO(zhxchen17) Maybe provide a function name helper in FX.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:406:        else:  # TODO(zhxchen17) Don't catch all here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:439:                # TODO: create a new tensor_values here, meta might have faketensor info
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:476:                # TODO: This is not ideal, we should fix this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:858:            raise AssertionError("TODO")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1119:        # TODO: Directly serialize exported_program.constants once
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1179:        if serialized_target.startswith("_operator"):  # TODO(zhxchen17) Follow up on this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1185:        else:  # TODO(zhxchen17) Don't catch all here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1886:            # TODO(larryliu0820): Add support for upgrader & downgrader
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:102:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:107:                        # TODO we should allocate static shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:116:                        # TODO: This is just a workaround to get over the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:135:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:143:                        # TODO: This is just a workaround to get over the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:275:        # TODO(angelayi): Update this with what we decide to do for metadata in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py:16:# TODO (tmanlaibaatar) remove this after https://github.com/pytorch/pytorch/pull/100749
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:104:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:181:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:213:        # TODO(avik): Maybe record the constraint violation error instead and replay later?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_export/exported_program.py:8:# TODO(ycao): This is added to avoid breaking existing code temporarily.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/context.py:53:        # TODO: Should these methods be mapped some other way?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:233:        # TODO: This looks wrong, a number that is wrapped into a tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:338:# TODO: implement dtype validation here, too, or on the corresponding refs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:420:    # TODO: fix number type promotion (bool, complex->float)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:950:# TODO: complex needs a special meta to account for its float -> complex behavior
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1456:        # TODO: this is only here to support the unsqueeze ref
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1644:# TODO: make stride SymInt
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1695:# TODO: consider renaming split_dim_view
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1903:# TODO: review stride logic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2054:        # TODO: update meta objects so this can be acquired directly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2118:# TODO: create a new return type for scalars?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2150:# TODO: create a new return type for scalars?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2182:# TODO: create a new return type for scalars?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2203:    # TODO: move this as an option on the reference
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2225:# TODO: Remove safe casting and implement on reference instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2288:# TODO: review support arbitrary resizes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2438:# TODO: layout, pin_memory, memory_format
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2439:# TODO: model requires_grad on TensorMeta
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2486:# TODO: layout, pin_memory, memory_format
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2487:# TODO: model requires_grad on TensorMeta
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2529:# TODO: add layout, pin_memory
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2584:# TODO: add layout, pin_memory
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2624:# TODO: add layout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2707:# TODO: add layout and pin_memory support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2748:    # TODO The MAGMA backend returns V, so this is wrong if used with the MAGMA backend
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2875:# TODO: we should more seriously review randomness modeling and prims
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/executor.py:53:        # TODO: caching
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/maskedtensor/reductions.py:127:        # TODO: autograd.Function doesn't support kwarg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:524:    assert mask.dense_dim() == input.dense_dim()  # TODO: eliminate this restriction
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:816:    # TODO: implement sparse CSR specific where operator for efficiency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1381:            # TODO: compute count analytically
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1605:            # TODO: compute count analytically
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1621:        # TODO: replace torch.subtract/divide/square/maximum with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1785:    # TODO: eliminate mask_input as unnecessary when using masked divide.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1789:        # TODO: replace torch.maximum with masked maximum when available.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1791:        # TODO: replace torch.divide with masked divide when available.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:112:        # TODO(avik): use sympy value range analysis instead?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:126:        # TODO(avik): use sympy value range analysis instead?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:188:    # TODO: We don't need t_id; we can get it off of w_tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:287:        # TODO: A better way is needed. Currently we use 't_id' to map the constraint,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:364:        # TODO(avik): clean this up
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:277:            # TODO(suo): untangle this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:281:                # TODO(suo): The FlatArgsAdapter returns a list of flat args,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_unlift.py:246:    # TODO(suo) this should not be optional, but is since we still ahve
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:129:                # TODO(suo): this is horrible.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:270:        # TODO Make this tuple.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:281:        # TODO Make this tuple.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:302:        # TODO Make this tuple.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:312:        # TODO Make this tuple.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_trace.py:133:    # TODO properly use the cached fake tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_trace.py:186:                    # TODO Figure out why sometimes we have root sometimes we don't.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_trace.py:208:                    except Exception:  # TODO(zhxchen17) Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_trace.py:413:    transform=lambda x: x,  # TODO(zhxchen17) Revisit if this is needed later.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_trace.py:446:    # TODO unfortunately preserving graph-level metadata is not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/_trace.py:496:            # TODO: this branch is likely wrong, all permissible ConstantArgument type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:138:        verifier: Optional[Type[Any]] = None,  # TODO Change typing hint to Verifier.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:141:        ] = None,  # TODO: deprecate this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:478:        # TODO(zhxhchen17) Return the new graph_signature directly.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:543:        # TODO unfortunately preserving graph-level metadata is not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:584:        # TODO(zhxchen17) Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:675:    # TODO(zhxchen17) Formalize this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_numpy/_unary_ufuncs_impl.py:71:# TODO set __name__ and __qualname__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_numpy/random.py:162:    # TODO: check a.dtype is integer -- cf np.random.choice(3.4) which raises
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/optim/radam.py:466:            # TODO(mlazos): we should try and get a foreach_where op https://github.com/pytorch/pytorch/issues/117884
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/optim/_functional.py:19:# TODO: use foreach API in optim._functional to do all the computation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/optim/adam.py:51:            # TODO(crcrpar): [low prec params & their higher prec copy]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:59:            # TODO(crcrpar): [low prec params & their higher prec copy]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/package/importer.py:81:            # TODO: I guess we should do copyreg too?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/package/package_exporter.py:918:                # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:246:                # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:283:        # TODO from zdevito:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:27:# TODO: The mechanism we are using to register decompositions doesn't
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:97:# TODO: do these also belong here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:27:# TODO - We have to register many more distributions here, and also higher level
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:168:        # TODO: Investigate if there is be a better way to wrap the tuple in a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:59:        # TODO: pretty sure this is not quite right
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:387:# TODO: None of these loss castings are quite correct, see
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1413:# TODO: this doesn't appear to have enough precision in bfloat16
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1591:# TODO: Take a closer look at the type promotion semantics
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1798:# TODO: this decomposition is NOT here to stay. We would much prefer replacing native_batch_norm
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1965:    assert not layout or layout == torch.strided, "TODO"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1966:    assert not pin_memory, "TODO"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2257:            # TODO make minimum accept scalars
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4055:        # TODO: handling of slice
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:23:# TODO: relax key type here; torch registrations should be possible to; but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/cpu/amp/autocast_mode.py:34:    # TODO: discuss a unified TorchScript-friendly API for autocast
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:293:    # TODO: Handle distinguishing between subclass and non-subclass versions of NT better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:592:    # TODO: Maybe this should be in tensor_classes? :)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_lobpcg.py:993:        # TODO use torch.linalg.cholesky_solve once it is implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_deploy.py:24:                # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_deploy.py:68:            # TODO: Once we decide to break serialization FC, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_guards.py:60:    # TODO: consider also tracking the recompilation count
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_guards.py:779:# TODO(voz): Consider a toplevel torch/_source.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__init__.py:32:# TODO(torch_deploy) figure out how to freeze version.py in fbcode build
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__init__.py:566:                # TODO: fix their module from C++ side
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__init__.py:651:            # TODO: Call like get_device_index() method corresponding to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__init__.py:1507:        # TODO: Once the undocumented FC window is passed, remove the line bellow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__init__.py:1937:# TODO: remove the function for PyTorch v 1.15.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:390:            # TODO: binary search
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:634:            # TODO: type annotations for *args and **kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:132:        # TODO node_name_to_scope will be depreciated in favor of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:479:                # TODO: Define how to symbolically trace HigherOrderOperators
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:73:        # TODO: Figure out if this is safe. It seems like when generating the type signatures for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/meta_tracer.py:194:            # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:141:    TODO: we have to check if this is the case for all HF models
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:370:    # TODO: add the extra check mentioned here:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:393:        # TODO: review this rule; should input = dyn; output = dyn be included here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:519:            # TODO: we should figure out why there is a key-error here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:780:# TODO normalize index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:884:        # TODO generate add constraints for scalar addition
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/schema_type_annotation.py:48:                # TODO: can we emit the union of these? What are the implications on TorchScript
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:354:                # TODO: add different size support for sparse_nn_partition
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:472:    TODO: Make Dynamo handle this appropriately if this is seen in Dynamo-ed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:477:    TODO: I didn't support min/max because I didn't have a use case where this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:540:    that doesn't have a lot of safety guarantees (TODO: provide higher level
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:580:    # TODO: Shouldn't we install a guard if the symbol is backed?  Or is the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:599:    # TODO: this does not install a deferred runtime assert yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:601:    # TODO: Maybe dedupe this with _maybe_guard_rel?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:610:        # TODO: Actually, we can support this as long as one of them is a symbol.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:657:        # TODO: check perf implications of this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:782:        # TODO: better printing for -oo and oo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:939:    # TODO: add storage offset and stride symbolic_context
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:967:# TODO(voz): Shape env validation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:991:    # TODO(voz): consider a weakref to the shape_env here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1038:# TODO: Deduplicate this with torch/_prims_common/__init__.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1354:        # TODO(avik): https://github.com/pytorch/pytorch/issues/101093
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1756:                    # TODO(avik) Maybe we should generate an assertion here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1764:                    # TODO(avik) Maybe warn that `arg` in not in `signature`?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2383:        # TODO: make this configurable from outside symbolic_context; we made a symbolic_context
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2388:        # TODO: This should be DYNAMIC, using DUCK for BC
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2904:        # TODO: Make this more efficient by binding all the size/stride/offsets
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3566:        # TODO: when unbacked_only, can sometimes early return even when there
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3603:        # TODO it would seem that this pass is not necessary given the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3667:        # TODO: in a Dynamo context, having user code, and having the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3695:            # TODO: Help text about how to use our runtime tests to fix this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3748:            # TODO: Should we propagate size-like-ness?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4053:        # TODO: split conjunctions and evaluate them separately
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4126:                # TODO: dedupe this with _maybe_evaluate_static
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4175:                # TODO: If we successfully eliminate a symbol via equality, it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4187:                # TODO: deal with duplicate guards somehow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4247:        # TODO: split conjunctions and evaluate them separately
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4285:            # TODO: Do this in a way that is less janky than int(s.name[1:])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/merge_matmul.py:116:        # TODO: Properly handle aliasing caused by get_attr. For now,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/_sym_dispatch_mode.py:50:        # TODO: properly compute types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:184:    # TODO. We leave it like this till we add a type to represent tensor sizes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/_config.py:30:# TODO: Perhaps consider allowing unions for the configs below (so you can hit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:154:            # TODO: This doesn't properly track storages.  A more robust
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:261:    # TODO: figure out if this API generally makes sense and bake it into the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:306:    # TODO: we could use types to test this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:332:        # TODO: maybe constant SymInts should also be allowed?  Not sure if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:603:            # TODO(tmanlaibaatar): we should systematically couple it with expoert verifier,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:737:# TODO: I'm not sure what the point of this class is; you can just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:756:        # TODO handle case where the first character of target is '*'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1042:            # TODO: it would be nice to line these up with the names
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1068:            # TODO: Would be nice to fix this at the source...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1083:        # TODO: kind of a bad way to do it, should maybe figure out a better way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:62:# TODO: An incomplete list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:350:        # TODO: use the file/line for some useful diagnostic on why a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:360:        # TODO: use the file/line for some useful diagnostic on why a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:372:        # TODO: use the file/line for some useful diagnostic on why a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:389:        # TODO: file/line here is very important, because the assert has been
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:420:        # TODO: use the file/line for some useful diagnostic on why a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:444:# TODO: this probably needs the sizes-strides eval functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:817:# NB: There is a TODO in C++ to allow omitting the batch dim.  If that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:882:    # TODO: These could also be done with indicators, maybe it is better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:914:    # TODO: let C++ also take advantage of this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:957:        # TODO: consider constant prop here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1002:        # TODO: consider constant prop here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1103:            # TODO: Remove the args construction below if a different sentinel is used by FX.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1163:    # TODO: This is technically hotpath, but in the ideal end state
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1184:            # TODO: this is an awful implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:121:# TODO: Determine whether this can be removed after type inference.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:90:        # TODO: assert pattern is a connected graph
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:110:        # TODO(tmanlaibaatar) should probably make this actual API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:212:        # TODO: use a more efficient way to check if gn is matched before: two-way dict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:133:            # TODO: do we really need copy the get_attr node into the graph?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/fake_tensor_prop.py:49:                # TODO: How is it possible that we get a non fake tensor?  We
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:11:    # TODO: why is submodules passed here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:51:    # TODO: single node partition may be wrong due to the pessimization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:295:        # TODO currently placeholders/parameters aren't put into random partitions,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:210:        # TODO(alexbeloi): add constraint management/validation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:129:# TODO: this should be beefed up to be able to properly re-inplace with:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:132:# TODO: we should also figure this info out using torchgen.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:538:                # TODO: later, add the optimization for handling `copy_()` calls in the graph.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/node.py:42:# TODO: Either refactor this into 2 functions 1 dce for functional graphs and 1 dce for all graphs,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:127:    # TODO: we shold handle __reduce_deploy__ the same way as __reduce_package__,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/hub.py:290:    # TODO: Remove `None` option in 2.0 and change the default to "check"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:280:        # TODO: Instead of always upcasting to int64, it would be sufficient to cast to the next higher dtype to avoid
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:787:        # TODO: Remove this conversion as soon as all operations are supported natively by the MPS backend
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1522:        # TODO: compose all metas into one AssertionError
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:324:        ),  # TODO: Move out to testing in param_group?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:345:# TODO: consider tensor LR! See multi_tensor_optimizer_configs in test_optim.py --> tensor LR should work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:831:        ),  # TODO: Move out to testing in param_group?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:87:# TODO: due to case sensitivity problems, for now list these files by hand
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:701:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:707:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:733:        # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:29:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1547:            # TODO: now that nccl send/recv is supported, there does not seem to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2546:            # TODO: move this test to use torch.profiler once kineto issues are
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3593:            # TODO: Instead we should probably go through _rank_not_in_group
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6436:            # TODO: NCCL backend does not work correctly for bitwise reduction ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8408:            # TODO: enable this for general training use cases:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8637:            # TODO(#54879): Provide ability to wait and report all failed ranks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:374:        # TODO: dist tensor need to support quantized and sparse
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:411:        # TODO: add multi mesh choices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:928:        # TODO, need more investigation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:1152:            # TODO: Can't get a reliable time for this profiling event since
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1566:        # TODO, need more investigation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:548:    # TODO: use torch.futures.collect_all
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:1421:        # TODO: with TCP init, rank 0 raises Address already in use because
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3462:        # TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:5106:        # TODO: Cuda RPC is failing due to:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1037:        raise unittest.SkipTest('TODO: Memory availability checks for XLA?')
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1522:# TODO: the "all" in the name isn't true anymore for quite some time as we have also have for example XLA and MPS now.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:144:    # TODO: reference function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:151:        # TODO(#50743): Figure out the error. "RuntimeError: Unrecognized tensor type ID: Batched"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2519:        # TODO(#50743): figure out the error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2802:            # TODO: This code can path can be removed if #61309 is resolved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3174:# TODO : Fix these discrepancies
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3317:            # TODO: compare structure (ensure analytic jacobian has correct shape)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3436:                # TODO: do this with in-memory files as soon as torch.save will support it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3732:                # TODO: torch.complex32 when properly supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3814:    # TODO: check that criterions don't ignore grad_output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:45:# TODO: TensorBase should work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:61:            # TODO: clone storage aliasing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:105:# TODO: Expand this class to handle abritrary settings in addition to boolean flags?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1261:# TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2349:# TODO: Revisit the relaxed pairs and check how much work it is to fix the tests that would fail without the relaxation.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2715:        # TODO: sure looks like we unconditionally initialize the context here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2788:        # TODO: Remove this; this is grandfathered in because we suppressed errors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3486:    # TODO: add args/kwargs for passing to assertEqual (e.g. rtol, atol)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3547:            # TODO: default this to True
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3621:            # TODO: compose all metas into one AssertionError
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3705:    # TODO: Support context manager interface
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4094:# TODO: consider more complicated noncontiguity schemes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4115:# TODO: remove this (prefer make_symmetric_matrices below)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4165:# TODO: remove this (prefer make_symmetric_pd_matrices below)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:341:    # TODO(future PR): consider combining with skipIfNoQNNPACK,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:975:            # TODO: make img_data a single example instead of a list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1488:        # TODO: remove this check and define two fuse_modules function on this module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1710:# TODO: self.fc should be self.conv
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1724:# TODO: self.fc should be self.conv
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1741:# TODO: self.fc should be self.conv
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1890:        # TODO: remove this check and define two fuse_modules function on this module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2427:        # TODO: remove this check and define two fuse_model function on this module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:62:    # TODO: FSDP non-recursive wrapping
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1350:        # TODO: Disable checking the parameters for pure FP16 due to floating
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/hypothesis_utils.py:131:    # TODO: Maybe embed the enforced zero_point in the `torch.iinfo`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:166:# TODO: Update all quantization tests to use this decorator.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:532:        # TODO: check gradients for parameters, not just inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:688:# TODO(suo) remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:752:# TODO: Remove me once https://bugs.python.org/issue42666 is resolved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:821:        # TODO: inplace tests currently fail, fix and add inplace variant
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:825:    # TODO: find better way to standardize on op registration itself..
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:492:    # flaky test - TODO fix
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:530:# TODO: delete this list once we make all nn_tests work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_cuda.py:53:# TODO(eqy): gate this against a cuDNN version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:53:        "aliases": None,  # TODO add a check for alias coverage
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:55:        "inplace_variant": None,  # TODO: add a check for inplace coverage
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:754:    # TODO: rename this to supports_bwgrad_bwgrad to be consistent with below
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:835:    # TODO: rename supports_sparse to supports_sparse_coo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1414:    # TODO(@heitorschueroff) Once all reduction operators are using
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1418:    # TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:2363:# TODO: in the future generalize the reference generators to handle n-ary elementwise operations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1534:        # TODO: backward uses in-place operations that vmap doesn't like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2394:            # TODO: is this really needed?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:150:                # TODO: remove this if-block after gh-98495 is fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:215:            # TODO: remove this if-block after gh-98495 is fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:248:            # TODO: remove this if-block after gh-98495 is fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:42:# TODO: Consolidate `i0e` with sample_inputs_unary when `make_tensor`,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:70:        # TODO: eliminate low after gh-106692 is fixed:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:771:            # TODO Move fftshift to decomps
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:780:            # TODO Move ifftshift to decomps
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/signal.py:302:            # TODO: same as this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:791:        # TODO: we should pipe the exception of the failed subprocess here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:925:        # TODO: get test name from kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1025:        # TODO: figure out a better way to do this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:364:    # TODO: Uncomment when negative weights is supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:1507:        # TODO: add pos_weight to the definition here and corresponding SampleInputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1313:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1320:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1408:# TODO: add reduction kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1870:        # TODO: no layout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1878:    # TODO: no layout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2128:        # TODO: fix bug in the documentation for svd_lowrank:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3231:            # TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4405:    # TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5034:    # TODO: can't switch `to.device` overload to use positional arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:7564:# TODO: add reference inputs for where(condition) signature
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8904:        # TODO: remove once the issue is resolved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10179:                       # TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10821:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10832:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12524:           # TODO: some signatures of median do support out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12532:           # TODO: some signatures of nanmedian do support out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12540:           # TODO: some signatures of var_mean do support out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12553:           # TODO: some signatures of var_mean do support out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12565:           # TODO: some signatures of std_mean do support out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12578:           # TODO: some signatures of var_mean do support out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13032:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13052:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13081:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13246:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13288:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13336:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13386:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13446:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13488:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13521:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13565:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13582:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13603:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13653:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13670:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13687:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13940:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13959:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13987:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14033:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14049:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14077:           # TODO: add shape checks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14142:           # TODO: add shape checks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14146:           # TODO: investigate nondeterminism
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14261:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14350:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14400:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14481:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14508:            # TODO: Do not work even on MI200 because of stride mismatching.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14522:            # TODO Need to understand what this is testing and why it doesn't work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14525:            # TODO skip this for now since we can't skip on runtime arch support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14582:            # TODO: Do not work on MI200 because of stride mismatching.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14603:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14648:    # TODO: combine this with the nn.functional.silu OpInfo when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14726:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14825:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14831:        # TODO(whc) should not need sample_inputs_func, but without it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14922:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14946:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14965:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15132:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15287:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15889:               # TODO: Investigate this more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16191:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16266:           # TODO(@heitorschueroff) update SampleInput to handle such cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16379:    # TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17332:               # TODO: same as this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17424:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17510:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17570:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17591:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17607:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17632:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17643:           # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17887:    OpInfo('trapz',  # TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18131:               # TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18315:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18403:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18451:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18478:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18511:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18544:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18569:        # TODO Benchmark again with the new implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18680:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18693:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18830:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18867:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18881:            # TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18908:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18959:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18962:    # TODO: delete this OpInfo once we add meta support for grid_sampler_3d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18970:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19326:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19375:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19450:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19526:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19544:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19639:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19661:        # TODO: Avoid COW materialize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19838:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19839:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19867:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19868:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19899:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19900:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19926:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19927:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19953:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19954:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19982:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19983:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20012:            # TODO: RuntimeError: no _refs support for torch.rand_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20013:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20946:    PythonRefInfo(  # TODO: Port this to an UnaryOpInfo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21663:        # TODO: Uses minimum and clamp
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21691:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21699:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21707:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21718:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21748:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21756:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21764:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21772:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21783:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21794:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21805:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21813:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21821:        # TODO: If self already has the correct dtype and device, then self is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22680:# TODO: review porting these to make_tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_subclass.py:7:# TODO: Move LoggingTensor here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:227:        # TODO(future PR): consider designing this better, as the difference
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:233:        # TODO(future PR): consider refactoring this to better reuse the parent
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:260:        # TODO(future PR): make the comparison function configurable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:396:    # TODO(future PR): expose these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:423:    # TODO(future PR): do not observe nodes we do not care
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:509:    # TODO(future PR): expose these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:536:        # TODO(future PR): better check when scripted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:583:# TODO(future PR): align on naming
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:664:    # TODO(future PR): expose these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:805:    High level TODOs for future PRs:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:840:    # TODO(future PR): deduplicate repeating entries
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:864:# TODO(future PR): we should rethink the names of all the PNP APIs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:940:# TODO(future PR): we should rethink the names of all the PNP APIs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:963:# TODO(future PR): consider aligning API signature with other similar quantization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:973:# TODO(future PR): consider aligning API signature with other similar quantization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:996:        # TODO(future PR): consider matching in a safer way than
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:487:# TODO(future PR): clean this up
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:530:        # TODO(future PR): implement shadowing for binary ops and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:10:    # TODO(future PR): make this work correctly for methods
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:33:# TODO(future PR): reuse existing mapping instead of creating a new one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:112:    # TODO(future PR): try reversed(list(matches.items()))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:166:            # TODO(future PR): make this code less confusing,  see discussion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:242:    # TODO(future PR): reconsider the design to make this more intuitive.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:307:            # TODO(future): some graphs could have placeholders which are unrelated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:346:            # TODO(future PR): handle non-normalized kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:373:            # TODO(future PR): this is not handling complicated graphs correctly, need to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:375:            # TODO(future PR): this is ignoring kwargs, will need to support kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:459:    # TODO(future PR): move logger classes to utils to remove circular dependency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:491:        # TODO(future PR): deduplicate equivalent qconfigs that come from
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:528:            # TODO(future PR): handle fusion patterns where non-first nodes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:547:                    # TODO(future PR): clarify why we are adding kwargs to args
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:588:    # TODO(future PR): implement this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:609:        # TODO(future PR): add a test case for this once we have an easy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:623:    # TODO(future): consider making this configurable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:702:    # TODO(future PR): move logger classes to utils to remove circular dependency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:800:                # TODO(future PR): make this support all possible args/kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:815:                        # cur_node_orig.name,  # TODO(future PR): set name explicitly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:992:    # TODO(future PR): move this to config
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1006:        # TODO(future PR, if needed): support kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1007:        # TODO(future PR, if needed): support multiple shadow users
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1011:            # TODO(before land): fix string match
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1086:# TODO(future PR): redesign this to make it easier to consume outputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1172:# TODO(future PR): redesign this to make it easier to consume outputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1252:# TODO(future PR): redesign this to make it easier to consume outputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:23:# TODO(future PR): consider deleting this enum and using the torch types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:30:    # TODO(future PR): while these functions can support multiple dtypes,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:35:    # TODO(future PRs): dynamic quant, fake quant, etc
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:45:    # TODO(future PR): clean this up
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:196:        # TODO(future PR): handle more functionals
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:197:        # TODO(future PR): handle functional ops which inherit qparams from input
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:314:        # TODO(future PR): use relationship map instead of hardcoding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/ns_types.py:18:# TODO(future PR): see if we can use typing_extensions's TypedDict instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:240:        # TODO(future PR): determine the actual dtype of node_c,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:303:                # TODO(future PR): add handling for quantize_per_tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:320:# TODO(future PR): look into using copy_node API instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:449:    TODO(before land): real docblock
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:480:            # TODO(future PR): enable multiple inputs for nodes which are not at start of subgraph
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:842:                    # TODO: explain this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:72:    # TODO(future PR): make more generic, handle everything
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:149:    # TODO(future PR): why does packed_weight.unpack() not work?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:24:    # TODO(future PR): allow customizations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:25:    # TODO(future PR): reuse existing quantization mappings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:26:    # TODO(future PR): add the rest of modules and ops here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:69:    # TODO(future PR): allow customizations from default patterns.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:74:        # TODO: this is a temporary hack to flatten the patterns from quantization so
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:90:        # TODO(future PR): if needed, implement matching for a node
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:183:    # TODO(next): make this code handle matching by what is before the base op
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:211:                # TODO(future PR): check for matches start_op_node and base_op_node
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:342:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:474:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:590:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:640:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:691:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:49:    # TODO: deprecated, remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:247:            # TODO: make this compatible with xnnpack constraints
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:368:            # TODO: make this compatible with xnnpack constraints
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:171:        # TODO: keeping self.quant_min/max for BC; remove after a couple releases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:274:    # TODO: rename observer to observer_ctr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:395:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:37:# TODO: replace all usages with these constants
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:44:# TODO: derive this map from the BackendConfig
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:112:    # TODO Currently it's required that separate ops in a fused op/module have the same qconfig.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:126:    # TODO: add assert for backend choices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:294:    # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:321:    # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:20:# TODO(future PR): improve this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:27:# TODO: not sure if typing supports recursive data types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:33:# TODO: maybe rename this to MatchInputNode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:115:# TODO: not used now, remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:117:    # TODO: reuse is_fixed_qparam_node after we move this function to _lower_to_native_backend.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:360:    # TODO(jerryzh): Figure out why custom quant_min/quant_max are still adjusted.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:533:# (last update over 1 year ago) and when torchscript is fully deprecated we can refactor. TODO(jakeszwe, jerryzh168)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:591:        # TODO: switch to scale.item() after adding JIT support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:594:        # TODO: switch to zero_point.item() after adding JIT support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:122:    # TODO: change the value to QuantizationSpec in a separate PR
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:147:        # TODO: qat + per channel?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:272:        # TODO: move this to BoltNNQuantizer?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:379:        # TODO: implement the support for None to be canceling out previous annotations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:396:        # TODO: implement the support for None to be canceling out previous annotations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:129:    # TODO: Add more supported operators here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:502:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:559:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:606:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:641:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:55:    # TODO: remove, since we can use observer_or_fake_quant_ctr to express this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:488:        # TODO: annotate the uses of input, weight, and bias separately instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:902:# TODO: remove Optional in return type, fix annotated_partitions logic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:918:            # TODO: change this to AnnotationException
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:958:        # TODO: remove?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1002:# TODO: make the list of ops customizable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:32:# TODO remove this once BC is no longer required to avoid a SEV
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:204:        # TODO remove Dropout special after codebase stable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:226:            # TODO: These are the modules that cannot be observed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:304:    # TODO: remove allow_list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:322:    # TODO: maybe we should change activation_post_process to _activation_post_process
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:342:# TODO: rename to something more general
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:169:# TODO: rename this to _is_conv_node
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:179:# TODO: rename this to _is_conv_transpose_node
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:284:    # TODO: move this information to fx node itself
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:513:# TODO: Handle this in export itself and don't wrap the model in another GraphModule
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:78:    # TODO: change to mul.Scalar
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:83:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:125:    # TODO: use out_dtype(mul, ...) here when the op is ready
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:245:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:288:    # TODO: change this to mul.Scalar?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:328:    # TODO: use out_dtype op
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:398:    # TODO: use out_dtype(mul, ...) here when the op is ready
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:427:    # TODO: use out_dtype op
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:429:    # TODO: debug the implementation later when torchdynamo time out issue is resolved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:100:    # TODO(Leslie): This function still fails to support custom momentum and eps value.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:162:# TODO: expose these under this namespace?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:27:# TODO: make pt2e folder private?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:125:    # TODO: add assertions for types of root qspecs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:263:            # TODO: maybe edge_or_node_to_qspec should be edge_or_node_to_root_qspec, this will simplify
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:474:        # TODO: simplify logic for inserting observers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:95:# TODO: merge this with the `no_conv_bias` case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:111:        # TODO: allow setting eps
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:142:        # TODO: allow setting eps
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:196:    # TODO: allow setting eps
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:240:    # TODO: allow setting eps
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:427:# TODO: this is error prone, use the replace_literals_with_placeholders hack instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:555:    # TODO: use the public replace_pattern API once it also returns replacement nodes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:598:    #       TODO: do this for literal args for batchnorm as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:102:    # TODO: check qconfig_mapping to make sure conv and bn are both configured
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:104:    # TODO: (maybe) rewrite this with subgraph_rewriter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:179:    # TODO: only fuse if conv and bn are both configured to be quantized
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:80:            # TODO: currently it only works for modules,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:82:            # TODO: currently it only works for object_type configurations,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:235:# TODO: correct the namespace for these modules
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:241:# TODO: merge with STATIC_LOWER_MODULE_MAP after we merge
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:268:    # TODO: LinearLeakyReLU is registered as global but it is only fused and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:354:# TODO: add tests for lowering these ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:733:        # TODO: maybe define a WeightedDynamicallyQuantizedModule
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:756:        # TODO: WeightedQuantizedModule is currently assuming static quant apis
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:759:        # TODO: maybe define a WeightedWeightOnlyQuantizedModule
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1021:        # TODO: add safety checks that users for the ref_node and dq_node needs to be one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1024:            # TODO: add a warning or error out here? (bc-breaking if error out)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1032:            # TODO: add a warning or error out here? (bc-breaking if error out)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1054:        # TODO: enable we have patterns that needs to swap the modules
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:47:# TODO: revisit this list. Many helper methods shouldn't be public
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:305:                        # TODO(future PR): remove this entire function  and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:322:                    # TODO(future PR): remove this entire function  and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:726:        TODO: traverse upwards from the output and handle the case when tuple is not a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:802:    # TODO: log warnings only when the user enabled a debug flag
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:810:        # TODO: for now, just use the existing eps value as scale_min. In the future, we should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:845:            # TODO: handle fp16 qconfigs properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:103:# TODO: remove other variants and keep this one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:173:        # TODO: investigate why
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:213:# TODO: remove other variants and keep this one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:465:        # TODO: investigate why
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:547:# TODO: move this to https://github.com/pytorch/pytorch/blob/main/torch/ao/quantization/fx/_decomposed.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:729:    # TODO: support fp16
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:739:# TODO: dtype is ignored for now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:760:    # TODO: check for dtype, currently we can't express torch.int4 so it's omitted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:18:# TODO: replace all usages with these constants
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:168:    # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:330:    # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:397:    # TODO: remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:100:        # TODO: change the signature for fuser_method to take matched module patterns
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:118:            # TODO: is this logic right?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:270:    # TODO: instead of instantiating the instance, we can use inspect to get the default args
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:292:    # TODO: support check for standalone module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:300:        # TODO(future PR): remove the cast to bool below after figuring
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:308:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:318:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:333:    # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:335:    # TODO: we should check is_dynamic here as well, the code from _is_input_arg_dtype_supported_by_backend
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:341:    # TODO: this is a hack because we can only specify one activation_obs_or_fq for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:508:        # TODO: refactor the following code in terms of apply a qconfig to a pattern
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:555:    TODO(future PR, if needed): explicitly spell out the non-Tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:759:    # TODO: move this to a separate function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:769:            # TODO: we are assuming "target_dtype_info" exists here, maybe
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:829:        # TODO: this is looking into how the value is used in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1071:            # TODO: this does not handle dynamic quantization yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1128:    # TODO: probably need to remove `is_general_tensor_value_op`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1261:    # TODO(future PR): delete the orphaned observer modules
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1367:    # TODO: we probably don't need this counter since each graph will only have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1417:            # TODO(future PR): update the output_quantized_idxs API to match
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1422:            # TODO(future PR): support more dtypes in model outputs, if necessary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1443:        # TODO: we might want to handle these more uniformly with the default path
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1473:    # TODO: reuse placeholder_node_to_input_index and output_node_to_output_index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1480:    # TODO: change this to insert obs/fq by pattern instead of by node
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1512:            # TODO: take a closer look to see if we can remove this check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1581:                            # TODO: This currently diverges from how custom modules are handled today,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1802:    # TODO: support regex as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:26:# TODO(future PR): the 1st argument is typed as `List[Node]`, but a better type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:141:    # TODO: 1. merge with fuse matcher 2. document the code
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:40:    # TODO: We should make this private in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:80:    # TODO: change this to inplace changes to graph, since we no longer construct
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:109:            # TODO: add validation that root_node is a module and has the same type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:133:    # TODO: dedup with quantization matching function in match_utils.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:141:        # TODO: probably should cleanup this condition check, it's hard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:186:                # TODO: we can add the information of whether a value needs to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:196:                    # TODO: maybe need more complex attr name here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:296:                # TODO: we can add the information of whether a value needs to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:377:        # TODO: probably should cleanup this condition check, it's hard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:402:                # TODO: we can add the information of whether a value needs to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:406:                    # TODO: maybe need more complex attr name here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:424:        # TODO: get reduce range from observer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:447:                # TODO: we can add the information of whether a value needs to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:461:# TODO: DeQuantStubs are currently inserted only after custom module LSTM, while observers are inserted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:548:    TODO: this logic is hacky, we should think about how to remove it or make it more
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:582:        # TODO: it's not used, so actually we can skip quantization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:633:    # TODO: remove is_reference flag
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:666:    # TODO: allow convert_custom_config to override backend_config
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:723:    # TODO: rename weight_is_statically_quantized to weight_is_int8_quantized
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:738:    # TODO: move this to the reference quantized module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:854:        TODO: maybe we want to redesign this part to align with reference model design
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:880:            # TODO: This is the first step in enabling the full fx custom module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:991:    # TODO refactor this code once we update the prepare logic to have additional information on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1120:    # TODO: maybe move this to quantize_fx.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1124:    # TODO: this looks hacky, we want to check why we need this and see if we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:145:# TODO: remove this class, this is still exposed in torch.ao.quantization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:153:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:157:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:161:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:165:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:169:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:173:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:179:# TODO: remove this class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:183:# TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:187:# TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:191:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:195:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/pattern_utils.py:14:# TODO(future PR): fix the typing on QuantizeHandler (currently a circular dependency)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:19:# TODO: move all LSTM util functions from fx/utils.py to this file
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:92:    # TODO: maybe make this work for layer_bw as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:327:        # TODO(jakeszwe, jerryzh168)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:371:            # TODO: switch to scale.item() after adding JIT support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:374:            # TODO: switch to zero_point.item() after adding JIT support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:392:# TODO(after v1.13): delete this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:479:        # TODO: MinMaxObserver by itself doesn't support dynamic quantization, but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1239:            # TODO: For some reason, this is required for it to pass torchscript test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1393:        quant_min: minimum value in quantized domain (TODO: align behavior with other observers)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1670:# TODO(future PR): remove these defaults and enforce activation functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1676:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:1:# TODO: rename executorch to qnnpack_executorch since executorch is a general runtime
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:262:        # TODO: we can add fusion for torch.relu as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:306:        # TODO: this is not used right now since we have extra check in prepare
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/native.py:158:    # TODO: express this BackendConfig as a union of the FBGEMM and QNNPACK BackendConfigs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/utils.py:158:# TODO(future PR): move backend_config_dict to use dataclass and move this logic to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/qnnpack.py:80:# TODO: add additional restriction on qscheme to ensure it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/fbgemm.py:25:# TODO: For now, these DTypeConfigs are identical to the ones defined in native.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/tensorrt.py:26:    TODO: add a README when it's more stable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:23:    # TODO: need to fix the way we insert observers for this pattern
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:88:    # TODO: remove when functionalization is supported in PT2 mode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:130:        # TODO: this is not used right now since we have extra check in prepare
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:141:            # TODO: remove when functionalization is supported in pt2_mode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:28:# TODO: rename to be more explicit, e.g. qat_conv_relu
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:86:        # TODO: this is not used right now since we have extra check in prepare
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:323:        # TODO: we can add fusion for torch.relu as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:46:# TODO: maybe rename this to something that's not related to observer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:263:    # TODO: refer to NativeBackendConfig once that is implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quant_type.py:22:# TODO: make this private
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:181:# TODO: merge with default static mapping
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:329:# TODO: merge with get_static_quant_module_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/rnn.py:86:        # TODO: make this tanh a member of the module so its qparams can be configured
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/activation.py:308:        # TODO: This method has some duplicate lines with the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:237:        # TODO: dedup with __init__ of RNNBase
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:924:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:939:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1005:            ret = input  # TODO: remove when jit supports exception flow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:118:    # TODO: maybe change to this when https://github.com/pytorch/pytorch/pull/32958 is landed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/activation.py:221:        # TODO: This is a potential source of accuracy drop.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:144:    # TODO: add an util function for converting qdtype to dtype
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:165:        # TODO: torch.quint4x2 is not supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:191:    # TODO: get the quant_min and quant_max from activation_post_process
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:197:    # TODO: add an util function for converting qdtype to dtype
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:218:        # TODO: torch.quint4x2 is not supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:44:        # TODO(jerryzh168): maybe make this arg a required arg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:66:            # TODO: refactor the duplicated code to utils.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:126:    # TODO: refactor nn.RNNCell to have a _forward that takes weight_ih and weight_hh as input
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:153:            ret = input  # TODO: remove when jit supports exception flow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:292:        # TODO(jerryzh168): maybe make this arg a required arg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:539:        # TODO: maybe we can try inheriting from that class and define get_flat_weights
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/dynamic/modules/linear_relu.py:36:            # TODO check if we should set reduce_rage = True by default here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:41:        # TODO: Add qat support for BNReLU2d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:77:        # TODO: Add qat support for BNReLU3d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:18:# TODO: factor out the common parts to ConvNd
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:220:        # TODO(jerryzh): extend
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:102:        # TODO: Need to add options to qconfig to avoid the calibration.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:103:        # TODO: Add calibration for the sparsity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:117:        # TODO (zaf): Mask might not be part of the qconfig (T83295194)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:8:# TODO (zaf): Inherit from `quantized.LinearPackedParams` (T83294430)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:66:# TODO (zaf): Inherit from `quantized.Linear` (T83294430)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:155:        TODO(zaf): Need to add the sparse params to the qconfig
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:165:        # TODO: Need to add options to qconfig to avoid the calibration.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:166:        # TODO: Add calibration for the sparsity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:28:# TODO update desc with new config args
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:95:        TODO: Need a clean way of loading the state of the "prepared" module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:165:        self.model = model  # TODO: Need to figure out how to load without this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:172:        # TODO: Remove the configuration by reference ('module')
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:297:                # TODO handle multiple tensor being quantized on a single module, where to store sparse_params?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:40:        # TODO Fix this typing, as Type[Module] has no attribute "from_dense"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/base_structured_sparsifier.py:108:        # TODO LSTM Structured pruning does not support returned state currently.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:320:        TODO: Might have to treat functions (reduce_fn, mask_fn etc) in a different manner while serializing.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/cuda/amp/autocast_mode.py:43:    # TODO: discuss a unified TorchScript-friendly API for autocast
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:225:        # TODO(torch_deploy): this accesses linecache, which attempts to read the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_library/utils.py:104:    TODO: torchgen/model.py's FunctionSchema.parse is the source of truth for this,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/pytree_hacks.py:9:# TODO: remove this file when the migration of the pytree utility is done
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:175:        # TODO: Resolve this so we always have matching real / symbolic tensors / metadata.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:251:    # TODO: we should kill this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:301:        # TODO: we should apply the below "detach inputs if their gradients are statically known to be None"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:777:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:856:                        # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:884:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:915:        # TODO: Check aliasing relationships
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:916:        # TODO: Check strides for metadata mutation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:193:# TODO: UNUSED. delete?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:225:    #   TODO: add a test case to assert we error when this happens, instead of getting silent correctness
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:117:    # TODO: should factor this into a separate function for export that always only returns just the graph.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:184:    # TODO: in AOTAutograd, we create metadata like _indices_of_inps_to_detach to detect
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:115:            # TODO: Please remove soon
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:515:    # TODO (tmanlaibaatar) revisit this if we ever need to turn on non-strict joint graph export
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:562:    # TODO: add subclass guards (later PR).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:652:        # TODO: handle Tensor returns
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:155:                    #     TODO: discuss on the PR and decide if we want to tr to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:261:                # TODO: handle the custom autograd function case here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:524:    # TODO: Can avoid the zip here too, probably
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:540:        # TODO(voz): This structure is 1:1, we could consider an alternate structure like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:608:        # TODO: work out how to setup this assert correctly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:15:# TODO: It would be nice to reset the numbering every time aot_id goes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:47:    # TODO: Don't shove the aot_id in here; set it in the context
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:74:    # TODO: refactor to kill this flag
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:174:            #     TODO: discuss this in the PR. Both supporting this, and detecting + erroring out,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:319:    # isn't actually true.  (TODO: Could this cause problems for Inductor?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:96:        # TODO: Remove the following hack for namedtuples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:162:            # TODO: There is some sort of problem where we record that an
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:181:        # TODO: update following link from master to stable once that's out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:274:            # TODO: Update link to stable once that's out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:286:        # TODO: Update link to stable once that's out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:346:        # TODO: What is to_size_hint suppose to be?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:808:            # TODO: Investigate why this hack helps.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:809:            # TODO: Investigate the interaction with compiler assisted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:279:        # TODO: We don't need to copy the model to create a stateless copy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:330:        # TODO: We don't need to copy the model to create a stateless copy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:438:    # TODO: Chillee argues that dynamo itself should pass in fake tensors to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:513:                    # TODO: Ensure that this codepath is never exercised from
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:549:                    # TODO: refactor the subclass path of run_functionalized_fw_and_collect_metadata
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:612:        # TODO: Do this properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:909:    # TODO: There is something deeply wrong here; compiled_fn running with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1167:    # TODO: we might have to temporarily patch config.functionalize_rng
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__config__.py:12:# TODO: In principle, we could provide more structured version/config
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor.py:96:            # TODO: skipping storage copy is wrong for meta, as meta
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor.py:149:                    # TODO: Once we decide to break serialization FC, no longer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor.py:316:            # TODO: Once we decide to break serialization FC, no longer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor.py:372:                # Ideally, we'd use a private API for this instead. TODO: Switch to this if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor.py:413:                # TODO: Once we decide to break serialization FC, no longer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_tensor.py:1130:            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:247:            # TODO(jansel): explore this further normalization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:116:# TODO(jansel): ezyang says we won't need this in the future, try removing it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:132:    # TODO(jansel): add quantized types?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:275:        # TODO maybe we need to use pytrees here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:837:        # TODO: It would be better to realize the input if any of its sizes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1144:        # TODO <leslie> Remove this fallback when we support vectorization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1206:    # TODO: We observed negative performance impact of pointwise_cat optimization on CPU so disabled it.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1315:        # TODO: We don't have to guard on sizes per se, but the number
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1400:    # TODO: don't guard on static shape here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2182:# TODO(jansel): we should implement decomps or lowerings for these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2457:    # TODO(jansel): memory format
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3448:            # TODO: Need to support more reduction type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3672:            # TODO(Lezcano) Here we may not need to set-up a device_size
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4025:    # TODO(jansel): should we force these to be realized?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4059:        # TODO will need a better way of determining if inputs are channels-last
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4323:    # TODO: should we force these to be realized?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4685:            # TODO(jansel): optimize to do `int(x<h)` rather than `x<h?1:0`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4694:    # TODO(jansel): should we force these to be realized?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:41:    TODO will it be necessary to tune multiple fields simultaneously.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:44:    TODO: what if both increasing and decreasing a field can improve perf.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:319:        TODO(ezyang): I think, in principle, every IRNode should have an
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:743:            # TODO the best heuristic currently has XBLOCK (corresponding to numel_hint) 128
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:842:            # TODO this will fail for something like ((1, N) * (N, 1)).sum()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:867:            # TODO determine splits when all inputs are broadcast
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1257:        # TODO(jansel): realize the reduction so we can do dynamic indexing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1422:        # TODO: Unrolled reduction
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1592:        # TODO: Can combine_fn/reindex close over unbacked symbols? If so, we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1655:            # TODO: CPU support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1720:        # TODO: custom splitting heuristic for scan
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2115:        # TODO: a new class for FixedTransferLayout that output layout is constrained by input layout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3148:        TODO(jansel): A better algorithm here would look at downstream consumers of this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3802:        # TODO(jansel): replace this with dynamic shape formulas
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3829:        # TODO: Unconditionally do this, not just when example_output has
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3905:            # TODO(jansel): impose layout preference on realized buffer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3949:        # TODO - Storage to InputBuffer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4456:        assert isinstance(new_size, int), "TODO: dynamic shapes"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4661:    # TODO: handle bools carefully
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5399:        # TODO <Leslie> cleaned up the fake_tensor trace as Linear implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5693:        # TODO: op.call: input[0] should be at::Tensor&
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7318:        # TODO(whc) i'm not sure what's going on here, this probably means I missed something upstream
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7382:            # TODO: avoid more than one ref of the same pg (even though they are cached inside the api)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7429:        # TODO: A better fix is to figure out how to propagate the aliases properly,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7798:# TODO(yifu): replace the CollectiveKernel IR hierarchy with _CollectiveKernel.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7879:    # TODO(yifu): add a pre-grad pass to validate the correctness of collective
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:8056:        # TODO: might be necessary to do some pretty printing on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:545:                # TODO: migrate all disable reasons to stack trace, refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:601:    # TODO: Should we actually dump this?  It should be redundant with the aot
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:864:    # TODO(jansel): figure out why this version doesn't work:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:948:                    # TODO - could make one single op of multiple slices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1303:    # TODO: can add logging before/after the call to create_aot_dispatcher_function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1344:    # TODO(voz): It would be nice to enable this assert, but there are lots of tests that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1357:    # TODO(voz): Should we always have one anyway?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:39:# TODO: A superclass that does desugaring for operations like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:180:    # TODO: Better explain how the "collective" semantics of these ops;
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:202:    # TODO: in practice, this seems to actually return None, but not returning
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:218:        # TODO: Improve the description with some pseudocode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:465:    # TODO(ezyang): Is this really the best way to do this?  What if we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/index_propagation.py:80:            # TODO: Inductor doesn't handle floating point in sympy expressions well at the moment
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/utils.py:218:    # TODO: There is a bug in a call to this function, to repro:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:45:    # TODO (tmanlaibaatar) figure out why this is different
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:105:    # TODO - further restrict cse ? right now needed to dedup aliasing ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1078:    # TODO: Revisit the functionalize_rng_ops for lowmem dropout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1357:    # TODO - look into using aot autograd, asserting no mutating ops here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/triton_helpers.py:340:    # TODO(isuruf): use inline_asm_elementwise here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:60:    # TODO when we drop support for Python < 3.10, we can use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:143:# TODO(xmfan): reuse an existing mapping for this if it exists, or formalize this into ir.py:ExternKernel
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:385:                            # but TODO this might be a convenient place to signal to the Collective kernels to inplace
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:453:            # TODO(voz): Should the pragma be constant somewhere?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:474:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:625:                    # TODO(xmfan): find a better heuristic to model FLOPS/latency relationship
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:665:            # TODO make this a property of the IR
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1597:        # TODO: ideally, we should deduplicate .users and .node_users,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1724:            # TODO support benchmarking epilogue fusion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:156:            # TODO: this should not be needed once #93059 lands
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:158:            # TODO: make a dedicated UnknownSource for this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:419:            # TODO - get different values per hardware
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:746:        # TODO(jansel): handle input aliasing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:948:                # TODO: this is sus, it probably should be handled in the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1049:                # TODO(jansel): introduce a store vs inline choice
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1124:            # TODO(Eikan): Only support mixing cpu and other device now.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1191:            # TODO: reuse self.scheduler from the first pass to speed up the second pass
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1262:        # TODO. Revisit this once the logging API is more mature
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:423:        # TODO: These tensors don't currently pickle, so we can't cache a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:654:    # TODO(masnesral): Investigate whether it's beneficial to store compiled graphs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:920:    # TODO: When making an API that can save compiled models e2e to disk
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:179:    - 8 gpus per node  # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:187:    # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:553:    # we could also generate all these patterns in 3d.. TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:685:            # TODO: Enable CUDA after solving Bert accuracy issue of calling efficient attention
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:55:        # TODO: remove the need to run fake_tensor_prop on the whole model.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:59:        # TODO - decompose/type promote to avoid this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:85:        # TODO handle Tensor-Scalar adds, it's a different schema
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:182:        # TODO - we could also Tensors which get replaced with arange here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:127:        # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:22:# TODO: need a better strategy for decomposing mm
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:173:            # TODO: support scalar case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:191:        # TODO: support scalar case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:269:                # TODO: support linear?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/serialized_patterns/central_index.py:111:    # TODO - could add more validation that the same set of decomps used when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:762:                # TODO: Haozhe investigate how add guard here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:890:            # TODO: Support dynamic shape case for MKLDNN conv transpose.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1186:        # TODO: aarch64: enable op fusion for acl once it supports fused operators. Disabling it for now.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:313:                # TODO: support kwargs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:475:                # TODO(yifu): this doesn't properly remove copy epilogues for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:249:    # TODO - finetune coefficient here. As a reference point, Triton mm model assumes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:402:        # TODO: Build a learned model which would be better than this heuristic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:377:    # TODO(jansel): rewrite this as a bmm?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cuda.py:195:        # TODO: only works for constant now, need type info
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:470:                        # TODO: input shape checking for regular tensor interface as well?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1077:        # TODO: support other overload for cpp wrapper and remove the below assertions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1204:            # TODO: Add buf name directly into check_inf_and_nan.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1647:        # TODO: Only support tensor(s) returns for now, SymInt is not implemented yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1302:    # TODO: these look dead, but with all the getattr it's hard to tell...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1429:        # TODO: hoist this to top level
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:587:        # TODO(jgong5): A more accurate way of deciding the dtype of the variables is to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1280:    # TODO: this seems to be dead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1393:        # TODO(jgong5): support conversion for other types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2427:            self._load_mask is None  # TODO: support transposition with mask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2773:            # TODO(Eikan): To record, deduce and propagate the data type of every expression.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3059:                # TODO(Eikan): Regarding get_index and index_expr, we should conclude the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3380:            # TODO(jgong5): support alternative tiling factors and data types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3546:        # TODO(jansel): allow fusion pointwise (vars1, ()) suffix?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3565:        # TODO: we can extend fusion support with compatible ranges for FusedSchedulerNode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3589:        # TODO: we can fix if it allows us to CSE at least one of the variables
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3682:        # TODO: support kernel profile on other platforms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3713:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3912:            # TODO(jansel): look into chunk size and other schedules
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:210:                # TODO mlazos: support dynamic shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:243:            # TODO: refactor generate_kernel_call
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:284:            # TODO(jansel): we could try harder here by merging overlapping in space
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:677:                # TODO(jansel): we should support reusing buffers created via ExternKernelAlloc
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:51:    # TODO(ipiszy): remove this hack when CUTLASS solves Python scripts packaging structure issues.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:122:    # TODO: these three look dead?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_epilogue_gen.py:135:        # of a previous epilogue node, a constant or (TODO) an auxiliary input.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:219:        TODO: Will add needed args to pass it in if it is dynamic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:243:        TODO: Will add needed args to pass it in if it is dynamic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:263:        TODO: Will add needed args to pass it in if it is dynamic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:319:        )  # @TODO: Hack for ensuring that Cutlass Kernel is preferred
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:400:        # TODO(ipiszy): Check whether it's necessary to swap X/W.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:482:        # TODO: update epilogue functor according to epilogues.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:682:            # TODO: Support split_k.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1628:        # TODO instead of trying to blindly find complicated exprs, we should hoist the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1701:            # TODO(jansel): it is sometimes possible to do higher dimensional block_ptrs with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1800:            # TODO(jansel): do we need a reshape here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2904:        # TODO(jansel): if there are constants, we shouldn't bother passing them as args
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3504:                    # TODO - use split ranges ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3533:            # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3582:            # TODO: Maybe unify CUDATemplateKernel to also use PartialRender for flexible epilogue fusion.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3737:            # TODO(jansel): should we tile reductions?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:136:# TODO: Move to a well known place
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:705:        # TODO: Add check for python too.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:725:                # TODO: integrate memory planning & stack allocation?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:778:            # TODO: this seems legit, NullLine has no node
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1068:            # TODO(aakhundov): add None args to constants, too. currently, this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1187:        # This is handled in `generate_args_decl` which has a correct comment of: TODO: only works for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:13:        # TODO: Remove fp8 special handling when Triton supports PyTorch fp8 dtypes.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:90:            # TODO(voz): These are kinda redundant, if we can solve out statically_known_multiple_of with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:186:    # TODO - remove, prevents cleanup
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:207:    TODO: in the future, we would like to do the following once storage weak refs land
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:253:        # TODO - when issue #91395 is landed, we can set a weakref on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:924:        # TODO - one jit kernel across multiple inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1452:        # TODO: - should we make the storage resizable ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1535:            lambda: "TODO: graph recording observed an input tensor deallocate during graph "
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1659:    # TODO: make generation increment configurable, warn on overwrite.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:2078:        # TODO: we could also allow the these weak refs to continue to be allocated,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:506:                # TODO(jansel): should we use sympy.diff here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1293:        # TODO: this may only be beneficial when each iteration of the reduction
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1348:    # TODO(jansel): we should be able to improve these heuristics
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:114:        # TODO - fix errors with this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:121:        # TODO - constant folding triton kernel returns the inputs -- fix this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:130:        # TODO - more complicated strategy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:509:                # TODO(nmacchioni): fix sympy division by zero
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:820:        # TODO(nmacchioni): remove once CI tests are fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:377:    # TODO: check if it's beneficial to convert Conv1d to Conv2d and then
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:382:        # TODO maybe we can convert weights to channels last just once before
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:454:                # TODO(jansel): try unroll for bigger kernels once fixed:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm.py:170:        # TODO: Re-enable eager mode implementation once cuBLAS is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm_plus_mm.py:208:        # TODO(jansel): support different K values when this is fixed:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:329:# TODO: fork is not safe in a multithreaded environment, we should evaluate changing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:406:# TODO: remove later
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:510:    # TODO - need to debug why this prevents cleanup
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:624:        # TODO: Support non-zero workspace_size.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:637:            None,  # set workspace ptr, TODO: update it to a real ptr if workspace_size > 0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:97:# TODO: for now, inductor doesn't handle asserts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:324:    assert not self.is_complex(), "TODO: implement this"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:386:    # TODO: _to_copy tensor to stride permutation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:50:    # TODO - there are dominated uses whose dtype does not depend on whether
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:71:                    # TODO - not sure if we should be doing int/float casts while tracing,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:109:    # TODO - if dominated node of one to_dtype is not expressible in int32,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:39:   TODO: Define a parent class / protocol that defines all of the operations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:128:            # TODO: To be honest, I feel we probably should just error in this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:159:)  # TODO: improve type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:43:    TODO: We might want to adjust this in the future to account for memory limitations.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:99:    TODO: Come up with a better approach
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:259:                # TODO: Smarter heuristics here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:331:        # TODO - Running exec generated frame seems propagates f_globals to the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:354:                assert recompile_reasons, "TODO(whc) any other recompile reasons?"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:832:# TODO mlazos: add support for same args, or record them
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:877:            # TODO: the first condition is not covered by any test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:214:            # TODO: replace `same` function with the one in testing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:269:        # TODO: maybe should just pass the entire f_code in here?  Not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:306:            # TODO (tmanlaibaatar) Remove this once we always lift params and buffers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:461:    # TODO(rzou): can delete after we refactor speculate_subgraph to use nested GraphTracer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:538:        # TODO - Consider having a torch level API for torch_function_state. As
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:658:            # TODO: don't readd symint if we already have it in graph
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1158:            # TODO(voz): The way export uses gm, and fake tensors, is not supported with us resetting
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1162:            # TODO(voz): Ostensibily, this should be scoped and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1206:            # TODO: Why isn't this stored in meta :think:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1324:    # TODO: this is a generic pass that should live outside of Dynamo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1334:        # TODO: Request simplification on runtime asserts before emitting them
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1496:                            # TODO: Remove relaxing assert on unbacked_symint https://github.com/pytorch/pytorch/issues/119689
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1507:                                # TODO: use ra.msg here, but it's pretty
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:237:                # TODO(whc)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:350:            # TODO - better way of doing this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:58:                    # TODO: not correct for args that contain tensors in a struct
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:64:        # TODO: error on unrecognized nodes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/tvm.py:86:            # TODO(shingjan): This could be replaced by tvm.contrib.torch.optimize_torch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:733:    # TODO: this is questionable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1467:     * (TODO)confirming which functions got compiled/skipped
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1956:            from tabulate import tabulate  # TODO: Check that this is installed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2172:    # TODO - This is a temporary situation where we have two versions of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:112:            # TODO: Maybe complain if this isn't a int/bool/float variable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:129:        # TODO: The default repr is pretty bad, do better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:132:    # TODO: API for adding a custom guard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:217:        # TODO: improve printing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:228:        # TODO: improve by improving the VariableTracker printing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:259:        # TODO: improve print format, current guard format is extremely
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:11:    # TODO(jansel): double check exception handling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/types.py:85:        # TODO(whc) how do I annotate a _RecordFunction here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/source.py:538:# TODO: can probably write a generic "test this on everything in the chain"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:91:    # TODO(jansel): we should move guarded_backend_cache to C++
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:687:# TODO(voz): Consider making "explain" output alongside a run / part of a run
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:691:        # TODO(voz): Do we want a decorator for this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:727:        # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:748:        # TODO(voz): Do we want a decorator for this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:803:                    # TODO(zhxchen17) Also preserve all the user constraints here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:903:            # TODO: option to print ALL of the stack traces at once
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1309:            # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:52:# TODO(jansel): need to ensure this does not get DCEed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/test_minifier_common.py:129:            # TODO: return a more appropriate data structure here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:802:                # TODO(voz):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:833:                # TODO(jansel): returning None here is wrong, it should be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:912:        # TODO: Should we allow non SymTypes here?  Today it is allowed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1024:            unimplemented(f"TODO: add support for ndarray.{name}")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:179:    # TODO: storing a SymInt here but not a FakeTensor is a pretty strange
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:656:            # TODO: this doing it manually is bad
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:665:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:669:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:673:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:769:            # TODO(whc): Why do we limit this to methods on NNModules?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:797:                # TODO(jansel): combine this case with the one above
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:929:            # TODO(whc) We could add a guard on the opposite case, where a user compiled/ran
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1227:                # TODO: This should be dynamic, as we in general do not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1236:                    # TODO: dynamic_dim = DimDynamic.STATIC should work but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1460:        # TODO: not sure about this fake mode test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1722:    # TODO: index export_constraints ahead of time so we don't have to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:218:    TODO: make it possible to use ProcessGroupVariable as input to simple functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:223:    TODO: should we make this inherit VT instead of UDOV? Do we want any of the default behaviors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:251:        # TODO should this just raise unimplemented?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:417:            # TODO: support pytree output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:569:        # TODO(voz): Support fake tensor dispatch for recursive
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:636:            # TODO: Support kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:924:        # TODO: Support kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1020:        # TODO: Support `fn` with kwargs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1056:        # TODO: Support kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1300:        # TODO (tmanlaibaatar) support pytree here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1597:        # TODO: assert that bwd_graph didn't capture values that were
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1600:        # TODO(oulgen): Ideally, we would not do a linear search for output
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:287:                # TODO: If we expand this to handle tensor args, we need to manually
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1331:                    # TODO(voz): Make it work properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:471:            # TODO(voz): This is rewritten as a call_method because
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:481:        # TODO: These special cases shouldn't be necessary; we should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:606:            # TODO: this probably should be folded somewhere else but I'm not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:608:            # TODO: some of the other symbolic_shapes special tools can also
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:641:            # TODO(voz): Replace w/ dynamic shape rewrite table.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:660:                    # TODO: there maybe other recursive structures you need to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:270:                # TODO: Use named_children when it supports remove_duplicate=False.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:323:                    # TODO: do we want to support __call__ for GM's?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:91:        # TODO(jansel): there is a small chance this could trigger user code, prevent that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:209:        # TODO: support an expression form as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:739:            # TODO Add all the functions that go from constants to constants to can_constant_fold_through
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:72:            # TODO Temorarily remove to figure out what keys are we breaking on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:98:            # TODO: Put this in utils and share it between variables/builtin.py and here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:579:            # TODO(jansel): implement unpacking logic in ModelOutput.__post_init__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:779:    # TODO(voz): Upstream to transformers lib
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:299:            )  # TODO(voz): These can invoke user code!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:302:            )  # TODO(voz): These can invoke user code!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:305:            and len(kwargs) == 0  # TODO(ybliang): support kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:575:                # TODO(jansel): add a guard to check for monkey patching?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:880:        # TODO this should probably be merged with the dict handling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:169:        # TODO: shouldn't this be f_locals/f_globals from frame?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:159:        # TODO - Assuming that all modules can be safely repr'd. Check if that assumption is correct.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:214:        # TODO - Keep this code for now. But, I don't think we will need this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:531:# TODO: Support bundling the entire repro into a zip file for ease of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:558:                    # TODO: transfer it to the right device?  But failing this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:620:        # TODO: consider ensuring tensor and storage counters line up?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:654:        # TODO: being optional on device is kind of pointless as the default
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:699:    # TODO: this doesn't actually symint atm
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/cache_size.py:74:    TODO(janimesh) - Consider adding a map from tuple_of_match_ids to count -
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3120:    # TODO: Once we require py3.9 use removesuffix instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:856:# TODO use the actual object instead, can interface from eval_frame.c
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/resume_execution.py:467:            # TODO(jansel): add dead code elimination here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:266:        # TODO: something here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:367:            # TODO(janimesh) - This is currently restricted to nn.Module objects
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:474:        # the internal types match.  (TODO: what about nested lists?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:494:        # TODO: It feels like it would be better to just implement our own
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:574:    # TODO(voz): Deduplicate w/ AOTAutograd dupe input guards
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:748:            # TODO(voz): Either populate a dispatch_key check into the guards, or error on users passing in an unsupported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:752:            # TODO(voz): We are missing storage offset in all our tensor guards?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1041:                # TODO: we could make use of 'DefaultsSource' and offer a .guard.is_defaults() API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1053:        # TODO(janimesh) - Currently this information is stored as an attr on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1187:        # TODO: the "guard" here is actually just the top level SHAPE_ENV
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1232:        # TODO(whc) maybe '.code_parts' was only kept around for the guard callback? so we don't need both
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1481:        # TODO(voz): Combine local and global guard builders.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:21:    TODO(khabinov): we should deprecate this function and use one of these two:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:159:    TODO(voz): We now have allow_in_graph, disallow_in_graph, forbid_in_graph - some more robust
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:222:        # TODO: Make this configurable via a supported public API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:231:        # TODO(voz): Should we bounds check?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:249:        # TODO: Make this configurable via a supported public API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:255:        # TODO(voz): Should we bounds check?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:286:        # TODO: Make this configurable via a supported public API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:292:        # TODO(voz): Should we bounds check?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:321:# TODO: we should delete this whole _allow_in_graph_einops logic by approximately 2024 Q2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:86:        # TODO(jansel): are all these modes needed?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:330:            # TODO maybe should respect DtoH sync intention of users later??
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:463:                # TODO link the torch.cond doc later
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:504:                # TODO: Also report the traceback from the parent frame
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2157:        # TODO(jansel): check the id of the cell rather than the contents
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2357:        # TODO: mlazos, add support for enabling multiple artifact logs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2555:        # TODO(jansel): figure out why this is needed, it isn't in the docs for YIELD_VALUE
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2578:                    # TODO(voz): Unclear if we need the push None in YIELD_VALUE?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:150:    # TODO: Figure out why torch.compile'd hash isn't work on this codepath
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:156:            # TODO: improve these names with FQN
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:236:    # TODO: factor this out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:263:    # TODO: It's inconsistent to pass SymInt inputs but REAL tensors.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:424:            # TODO: disable clone
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:76:        # TODO: why do we need to deepcopy the original graph?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:85:            # TODO: Failures here are troublesome because no real inputs,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:236:            # TODO: improve these names with FQN
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:315:    # TODO: factor this out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:480:    # TODO: speed this up
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:555:    # TODO: The logic for cloning inputs/models here is intentionally
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:644:    # TODO: check eager determinism
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:711:# TODO: lazily load the inputs or something, rather than cloning them
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:860:    # TODO: make this an option for --analyze too
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:102:# TODO(janimesh, voz): Remove both of these flags (or atleast guard_nn_modules)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:180:# TODO: Detect this situation automatically so the user doesn't need
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/contrib/_tensorboard_vis.py:137:        # TODO: handle attrs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:58:        # TODO: The cache is NOT currently used by HigherOrderOperator, but it should!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:103:                # TODO(voz): Should we replace setting torch._C.DispatchKey.Python entirely with setting mode keys?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:276:        # TODO (tmanlaibaatar) Make it generic fallback mechanism
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:660:                # TODO: We also need to handle tensor subclasses here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:661:                # TODO(voz): We should walk all the nodes here / turn it into a list, topmode is ok for now.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:667:                    # TODO: This path is slow, should generally encourage this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:670:                # TODO(voz): The idea behind this is that we do not yet support dispatch by key + mode, only key.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:705:                            # TODO: need to double check the semantics of the "types" argument to torch_dispatch.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:713:                        # TODO: check that I got these args correct (in C++, we pass in "0000"??)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:731:        # TODO: We could potentially have lots of debugging wrappers against
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:766:    # TODO: add more methods to expose information about input and output arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:828:            # TODO: disallow access to overloads registered by JIT
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_ops.py:856:    # TODO: use this to make a __dir__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:91:        # TODO: investigate if contiguity along other axes than the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:261:            # TODO in the future we can add in padding to support sparse dimensions that aren't perfect multiples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/xpu/XPUEvent.h:112:    // TODO: provides the ability to time the execution of commands in a SYCL
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/CUDAFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:29:// TODO: Add constructors for all of the descriptors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:99:  // TODO: Figure out why const-correctness doesn't work here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:369:        "TODO: support more cuDNN activation modes");
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradNestedTensorFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:62:// [TODOs]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:111:// TODO: move this from `at::` to `jit::torch::` after
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/Utils.h:93:    // TODO: is this necessary?  We used to treat nullptr-vs-not in IntList
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/CPUFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/quantized/QTensorImpl.h:33:  // TODO: Expose in PyTorch Frontend
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:35:// TODO: try to remove this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/symbol.h:77:  // TODO: eliminate me
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/DispatchKeyExtractor.h:41:  // TODO: It's a bit irritating that we have to do logical ORs here, it would
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/Dispatcher.h:187:  // TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:256:  // TODO Use list_element_from?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:282:  // TODO Use list_element_from?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:69:  // TODO(jerryzh): add a Get(c10::DeviceType) function?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:78:    // TODO: after we add Get<Tensor>(c10::DeviceType)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:108:      // TODO Re-enable logging
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TransformationHelper.h:129:  // TODO: must be investigated and unified!!!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:13:// TODO: consider storing namespace separately too
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:20:  // TODO: These two functions below are slow!  Fix internal data structures so
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PythonOpRegistrationTrampoline.h:5:// TODO: this can probably live in c10
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/stack.h:9:// TODO move this to c10 namespace
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:132:    // TODO(min-jean-cho) change to Polar method, a more efficient version of Box-Muller method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:133:    // TODO(voz) We use std:: below, and thus need a separate impl for CUDA.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:1764:// TODO this is deprecated but we don't throw a warning because a lot of ops in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:196:  // TODO: temporarily disabled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:235:  // TODO: Deprecate me
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:1368:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:273:   * TODO: need to support customizing equality
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:345:    // TODO: Find way to expose alias info for opaque tensors.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:465:    // TODO (after Tensor merge) If we pass in a Blob holding a Tensor, extract
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1085:        // TODO: Find way to expose alias info for opaque tensors.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1120:  // TODO: There are several places that recurse over IValue. This is fragile.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dynamic_type.h:133:  // TODO Change Ptr to DynamicTypePtr when all migrations are done.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:506:  // TODO remove the mutation here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List.h:457:  // TODO Test use_count
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:576:// TODO: investigate making this SingletonOrSharedTypePtr<TensorType>
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2098:  // TODO: static_assert that a templated function exists, and throw a friendly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2105:  // TODO: static_assert that a templated function exists, and throw a friendly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/Generator.h:51: * TODO: Look into changing the threading semantics of Generators in ATen (e.g., making
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/BoxedKernel.h:130:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:15:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:209:  // TODO: it probably would be good to tighten this up quite a bit more with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:268:    // TODO static_assert(AllowDeprecatedTypes, "You tried to register a kernel with an unsupported output type: std::vector<T>. Please use List<T> instead.");
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:432:  // TODO Delete this once kernels don't do that anymore
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/test_helpers.h:29:  // TODO: We add this to simulate the ideal case where we only have Autograd backend keys
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/boxing.h:80:  // TODO Reuse stack vector instead of allocating?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:13:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:157:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:404:  // TODO: once modules support arbitrary ivalue attributes, we don't need this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:406:  // TODO: This is better represented as an OrderedDict, but alas it is not yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:551:  /// TODO: it's not in native_functions.yaml yet as it's not exposed to python
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:589:  // TODO(#97856) Make this return a const pointer. This currently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:612:  // TODO(#97856) Make this return a const pointer. This is currently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:9:// TODO: Clean up what remains here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:70:// TODO: AutoNonVariableTypeMode should be removed in release 1.10.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/adaption.h:49:  // TODO: Remove this once the following issue is addressed:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:249:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:278:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:293:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:308:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:349:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:390:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:528:       // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:559:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:576:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_allowlist.h:3:// TODO: unify to C10_MOBILE. In theory this header could be used in OSS.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/NestedIntSymNodeImpl.h:40:  // the higher-level API in python instead (TODO: actually introduce that).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/detail/CUDAHooksInterface.h:59:// TODO: Consider putting the stub definitions in another class, so that one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/FunctionalTensorWrapper.h:207:  // TODO: maybe it's possible to arrange for that to happen automatically
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:31:// TODO: Move the MPSGuardImpl to inherit from NoOpDeviceGuardImpl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:64:    // TODO: Currently setting only device 0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:81:      //TODO: extend it for multi-device case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:19:// TODO: Unify the logic with CUDACachingAllocator and remove redundant code.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:119:    // TODO: check the caching performance of write-combined mode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:316:  // TODO: make a common function to do size unit conversions in PyTorch.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:46:  // TODO: don't expose private implementation details like this; in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:52:  // TODO: don't expose private implementation details like this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:112:  // TODO: numel_custom and is_contiguous_custom can be profitably overridden
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:170:  // TODO: maybe we can remove this metadata since
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradNonFunctionalFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpp_custom_type_hack.h:93:  at::AutoDispatchBelowADInplaceOrView guard; // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_int.h:747:      // TODO<leslie> We can use _mm512_zextsi128_si512 in the furture,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_double.h:159:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_float.h:574:// TODO(jgong5): rewrite with ATEN vectorized (need to add unpack and shuffle)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_bfloat16.h:1053:// TODO(Leslie): Add the AVX2 Version of transpose_mxn for BFloat16 and Float16
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_float.h:654:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:118:    // TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:273:  // this should be removed. TODO (kimishpatel)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_int.h:686:      // TODO<leslie> We can use _mm256_zextsi128_si256 in the furture,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:196:  // TODO: can we support caching this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:240:  // TODO: can we support caching this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/MetaFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/utils/Factory.h:13:// TODO: Remove this function when at::native::empty() is modified to accept a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:47:// TODO: Figure out if we need a non-moving wrap_buffer()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:287:// TODO: Add static assert to verify lambda arguments match nested_node types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:15:// TODO: make all operations that resize given outputs use this function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/AffineQuantizerBase.h:11:// TODO combine this with quantize_val once the numerics for ARM are aligned
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/fbgemm_utils.h:312:// TODO: Remove functions below when ChannelsLast3d is ready.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:339:// TODO: Move it to third_party/ideep
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:394:  // TODO Support more OSs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/OperationUtils.h:194:// TODO: Improve the overall design of MPSGraphCache.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/MPSGraphVenturaOps.h:4:// TODO: Remove me when moved to MacOS 13
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:19:// TODO: This file only supports AVX2. We could split the AVX kernels into
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:178:  // TODO: we may want to merge that into the fallback code (currently called
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:254:  // TODO: we may want to merge that into the fallback code (currently called
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:293:// future improvement that can be done: look for the TODOs in this file.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:1197:  // TODO: Do we also need block 4 ???
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:55:// TODO: put this into the public API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:67:// TODO: Expose this for real in ATen, some day?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:36:// TODO: CPU instruction set selection should be folded into whatever
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:212:    // TODO: make this point at hip_dispatch_ptr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:296:// TODO: cut this over to HIP dispatch once we stop pretending that CUDA
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/MaxPooling.h:64:// TODO(Heitor) Template by dimension
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:350:  // TODO: instead of variable name 'sigma', use 'gamma' or 'scale'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:384:  // TODO: Fix resize_as_. See pytorch/pytorch#11665.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:27:  // TODO: remove this special case for HIP when issue is fixed:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:38:  // TODO: remove this special case for HIP when issue is fixed:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:17:// TODO: update and add a usage example after https://github.com/pytorch/pytorch/pull/58092 lands.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:25:            // TODO: figure out how to make compiler happy without dynamic casts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:33:            // TODO: get std::forward<> to work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:302:    // TODO: Our current linear mode impls use unbound indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:202:  // TODO: check that output->size() matches output_sizes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:203:  // TODO: check that weight matches output->sizes()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:362:  // TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:209:  // TODO: implement negative step
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:314:  // TODO: check scalarType
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/DynamicLayer.h:39:// TODO: we can excise DynamicLayer in favor of Interpreter,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/LegacyVmapTransforms.h:102:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/PlumbingHelper.h:59:  // TODO: should really check this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/BatchedTensorImpl.h:156:// TODO: should probably contain more (or all?) backend keys
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/LegacyVmapTransforms.h:95:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/cuda/detail/CUDAHooks.h:8:// TODO: No need to have this whole header, we can just put it all in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:58:// TODO: Consider generalizing this into a call stack.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/caffe2/serialize/versions.h:92:// risk of breaking existing clients. TODO: A better way would be to allow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/GeneratorImpl.h:44: * TODO: Look into changing the threading semantics of Generators in ATen (e.g.,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:214:  /// TODO: This function encourages bad behavior (assuming CUDA is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:403:  // TODO: Deprecate this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:436:  // TODO remove after TensorOptions rationalization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:545:  // TODO: MemoryFormat is not implemented in this way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/Storage.h:92:  // TODO: remove later
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/Scalar.h:138:  // TODO: Support ComplexHalf accessor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymBool.h:81:  // TODO: optimize to union
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymbolicShapeMeta.h:162:  // TODO: should the SymBool cases avoid the short circuit?  Need to reason
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/StorageImpl.h:107:  // TODO: remove later
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:251:  // TODO: Consider reading Tensor and TensorList constructors here, when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/SizesAndStrides.h:25:  // TODO: different iterator types for sizes & strides to prevent
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:72:    // TODO: make a version that takes an impl argument.  Unfortunately,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:179:  // TODO: put this in BackendComponents
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:183:  // TODO: put this in BackendComponents
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:192:  Vulkan, // TODO: put this in BackendComponents
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:193:  Metal, // TODO: put this in BackendComponents
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:209:  // TODO: Make Mkldnn a functionality key, so we can give it Meta
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:236:  // TODO: delete this in favor of Python-implemented fake tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:262:  // TODO: delete this once torchdim lands in functorch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:354:  // TODO: make Autocast a functionality key
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/CPUAllocator.h:12:// TODO: rename to c10
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:255:      // TODO dim == 3 case will be enabled once it is fully tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:271:      // TODO dim == 4 case will be enabled once it is fully tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarTypeToTypeMeta.h:8:// TODO move to typeid.h (or codemod away) when TypeMeta et al
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:98:// TODO: To add unsigned int types here, we must define accumulate type.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:167:    /* TODO: remove once the bug is fixed. */                                \
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:380:    // TODO: Replace the link to the documentation once it's available.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:534:  // TODO: When Variable is added, delete these constructors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:637:  // TODO: does C++14 have a stdlib template for this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:743:    // TODO: maybe this should be toggled by strides
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:911:      // TODO: provide stride_custom, symmetrically with size_custom.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:968:    // TODO: We could add support to Python dispatch here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:969:    // TODO: We could call into aten::size.int instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:976:    // TODO: We could add support to Python dispatch here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:977:    // TODO: We could call into aten::size.int instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1218:  // TODO: remove this once we don't automatically enabled Autograd dispatch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1285:      // TODO: implement layout() as native function/method so that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1748:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1767:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1794:    // TODO: this should probably consult policy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1891:    // TODO: at some point, we should kill this field completely.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:2140:    // TODO: A useful internal assert would be to show that device_opt_ is null
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:3050://    strong refcount           TODO: pack these into one word
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymFloat.h:107:  // TODO: optimize to union
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:57:      // TODO dim == 3 case will be enabled once it is fully tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:86:      // TODO dim == 4 case will be enabled once it is fully tested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymInt.h:55:  // TODO: these implementations are not optimal because they allocate a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymIntArrayRef.h:16:// TODO: a SymIntArrayRef containing a heap allocated large negative integer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/Backend.h:284:// TODO: This probably shouldn't actually be static inline
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/core/DeviceGuard.h:49:  /// TODO: The consistency check here is inconsistent with StreamGuard's
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/ApproximateClock.h:79:// TODO: We should use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/Deprecated.h:27:// TODO Is there some way to implement this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:345:// TODO: Brian Vaughan observed that we might be able to get this to work on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:563:// TODO: We're going to get a lot of similar looking string literals
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeList.h:158:  // TODO Direct implementation might be faster
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:14:// TODO Make it work for more compilers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:67:  // TODO Disallow this and rather use std::unordered_map/set everywhere
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeCast.h:169:// Trigger tests for D25440771. TODO: Remove this line any time you want.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:622:  // TODO: Use std::bit_cast once C++20 becomes available.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/C++17.h:92:// TODO This is an incomplete implementation of std::apply, not working for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:43:// TODO(xiaofeng): Define GOOGLE_PROTOBUF_HAS_CONSTEXPR when constexpr is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:143:// TODO: perhaps it would be nice to have int128, a signed 128-bit type?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:46:  // TODO Making operator== noexcept if underlying type is noexcept equality
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:55:  // TODO Making operator!= noexcept if operator== is noexcept doesn't work with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/Half.h:395:// TODO : move to complex.h
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/intrusive_ptr.h:572:   * TODO: https://github.com/pytorch/pytorch/issues/56482
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/MathConstants.h:13:// TODO: Replace me with inline constexpr variable when C++17 becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:110:    // TODO: split out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:530:    // TODO At some point this should probably be done, including tricks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex_utils.h:20:// TODO: Write in more idiomatic C++17
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:140:// TODO(@zasdfgbnm): c10::complex<c10::Half> is not currently supported,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:581:// TODO(@zasdfgbnm): implement them as c10::conj
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:589:// TODO(@zasdfgbnm): implement it by ourselves
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/ArrayRef.h:75:  // TODO Make this explicit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/hash.h:58:// TODO: Compare vs OpenSSL and/or CryptoPP implementations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:37:// TODO: This file is still in the caffe2 namespace, despite living
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:87:// TODO Disallow this and rather use std::unordered_map/set everywhere
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/cuda/CUDACachingAllocator.h:36:// TODO: Turn this into an honest to goodness class. I briefly attempted to do
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/macros/Macros.h:125:// TODO: It's possible this is still triggering
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class_detail.h:137:  // TODO We shouldn't use c10::impl stuff directly here. We should use the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class.h:401:      // TODO: we need to figure out how to profile calls to custom functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:108:  // TODO: This is morally the same thing as KernelRegistrationConfig, but it's
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:167:        // TODO: Don't go through WrapRuntimeKernelFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:184:        // TODO: Don't go through WrapRuntimeKernelFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:201:        // TODO: Don't go through WrapRuntimeKernelFunctor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:681:    // TODO: need to raise an error when you impl a function that has a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:702:    // TODO: need to raise an error when you impl a function that has a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/throughput_benchmark-inl.h:57:  // TODO: add GUARDED_BY once it is available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:388:// TODO: this can return MaybeOwned
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:1168: * TODO: we could use different names for the following 'handle_torch_function'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/model.h:249:    // TODO: Handle shared storage case.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/arrayref_tensor.h:40:  // TODO Make this explicit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/interface.h:22:// TODO: Deprecate this API. This was kept for BC compatibility.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runner/model_container_runner.h:78:  // TODO: need an OSS proxy executor implementation. For now,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/tensor.h:40:    // TODO(alanwaketan): Remove this ctor. This is a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:109:  // TODO: even though this API is currently used **only** in codegen to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:136:  // TODO(alanwaketan): Revisit if all of them need to be accessible to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:264:  // TODO(alanwaketan): Add a registry such that we don't need to make all
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_metadata.h:35:// TODO(whc) is this going to be used outside of in IR decompositions?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/trie.h:46:  // TODO: Because we don't expect user to explicitly call this function via
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:19:// TODO(alanwaketan): Consolidate it with c10::scope_exit.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:68:// TODO(alanwaketan): This is clever, but is there really no std or c10
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_builder.h:140:// TODO: this should return Value
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir.h:209:  // TODO: Some IR classes share the same opkind, such as Mean and MeanDim, so
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/helpers.h:16:// TODO: Consolidate this file with util.h
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_node.h:85:// TODO(whc) once Shape() API is moved to Node base, also make it virtual, and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/config.h:4:// TODO(whc) unclear if this is useful, has only been tested as true
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:21:  // TODO: Scalar node is not currently used by ts_backend. Enable reusing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:55:  // TODO: verify if IR node reusing works for Dynamic shape ops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:31:        "TODO(whc) implement TS computation shapes or change interface");
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:41:        "TODO(whc) implement TS computation shapes or change interface");
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:82:  // TODO(whc) need to keep this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:131:  // TODO(whc)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/instruction.h:89:  // TODO: check for overflow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:53: * TODO Instead of doing it this way, we should only have pure-jit ops in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:146:    // TODO: some sort of caching mechanism?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:178:                  // TODO What if it gets set later?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/register_ops_utils.h:360:    // TODO: remove when possible, since it just slows down
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/flatbuffer_loader.h:132:// no op, TODO(qihan) delete
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/observer.h:39:  // TODO: Kimish
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/code.h:27:  // TODO After we actually export CALL instructions we can remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:583:// TODO: supports only single comprehension for now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:597:  // TODO: no ifs for now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:607:// TODO: supports only single comprehension for now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:624:  // TODO: no ifs for now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/source_range.h:368:    // TODO: c10::optional<>::value returns an rvalue ref so can't use it here??
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:74:  // TODO @wconstab refactor to use ModuleValue::asTuple instead of new API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:425:  // TODO holding this thing is creepy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/graph_opt.h:104:// TODO: add error reporting for graphs that can't be converted.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/reduction.h:268:  // TODO possible to remove this arg by deferring the init value until we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:393:  // TODO: add memory types.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:841:// TODO: move to this an internal IR.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:842:// TODO: make IR nodes extensible.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:141:  //     loop variable. TODO: Remove this constraint.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:144:  //     TODO: Remove this constraint.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:473:  // TODO: Add an IR verifier check to detect invalidly compressed buffers.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:584:// TODO: Revisit this once we decide on how dependencies analysis should look
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/external_functions_registry.h:20:// case we need to run aten ops (TODO: support different devices). The first
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/codegen.h:69:  // TODO: Figure out how to unify these call interfaces.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/mem_dependency_checker.h:245:  // TODO: this will return only the AccessInfo for A. It's included for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:171:  // TODO: unique_name
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:215:  // TODO: unique_name
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:263:// TODO: add TORCH_API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:287:// TODO: add TORCH_API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/python_list.h:39:  // TODO: Do these make sense?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind.h:140:    // TODO: Is there a way to py::cast that doesn't raise an exception on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:635:      // TODO: this message is not correct anymore, since this InferredType is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:971:// TODO: Remove once we clean up the GraphExecutor usage.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:1105:  // TODO: we could add __torch_function__ dispatch here but I don't know
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/quantization_patterns.h:553:  // TODO: add %dtype after when https://github.com/pytorch/pytorch/issues/34351
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:138:// TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:142:// TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:148:// TODO: refactor all current uses of this function to the Opt one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:186:// TODO: add a macro to declare the filters
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/symbolic_shape_cache.h:10:  // TODO: Consider in the future if it is reasonable to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/value_refinement_utils.h:18:// TODO: vector may be faster
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickle.h:39:///  // TODO: when tensors are stored in the pickle, delete this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickler.h:249:  // TODO: only use this if necessary (add a pass to find all shared ivalues,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/flatbuffer_serializer.h:90:// TODO(qihan): delete
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/export.h:258:// TODO remove these switches once interface call is rolled out.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:41: *  - Pattern graph nodes cannot alias. TODO: the check not implemented yet.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:43: * found matches, no nodes in the subgraph alias with each other). TODO: check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:249:  // TODO: make this more const correct
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1746:  // TODO: return iterator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1822:  // TODO: return iterator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/function_impl.h:141:  // TODO: add more executors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/compilation_unit.h:173:    // TODO: class types cannot be redefined because we have no way right now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:22:    // TODO: Nested Tensor does not have an implementation of detach. The
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:44:        // TODO: Actually detect views in the accumulateGrad function so that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/VariableTypeUtils.h:134:// TODO: Blegh, bare references
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function.h:561:  /// TODO: it might be possible to handle cases where backward is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/custom_function.h:271:  // TODO Add tracing here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/forward_grad.h:205:  // TODO(albanD): replace this with a SmallVector
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:167:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:185:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:204:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:220:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:853:/// TODO: Eliminate this function as much as possible, as it can be expressed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/dynamo/compiled_autograd.h:141:    // TODO(jansel): Here we unpack the SavedVariable exactly once.  This might
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:491:    // TODO: HACK for backend name to get sequence number for that backend.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:512:    // TODO: HACK for backend name to get sequence number for that backend.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:581:    // TODO: if nccl was specified then use it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:626:    // TODO: should we add these entries after the backend setting succeeds?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/logger.hpp:70:  // TODO to support single process multiple devices and multi device modules,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:124:  // TODO this function makes broadcast communication call and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:396:    // TODO(@pietern)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/Utils.hpp:537:    // TODO: see if we should add overflow protection for offset
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/tensorpipe_agent.h:314:  // TODO: To achieve better performance we can have a pipe pool per
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_proto.h:15:// TODO: Remove all these messages and use rpc + registered functions instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_context.h:201:  // TODO: make this a context guard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:75:// TODO: current RRef implementation does not tolerate failures
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:88:// TODO: RRef internal messages are not yet idempotent
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:186:// TODO: make RRef an IValue, and edit createStackForSchema accordingly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:187:// TODO: make RRef system messages idempotent and retry on failures.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/tensor/python_tensor.h:27:// TODO: This is nuts!  There is no reason to let the default tensor type id
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/CudaIPCTypes.h:71:  // TODO: Can be changed to FIFO in order to avoid full traverse on every
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/parallel/data_parallel.h:89:      // TODO: use nccl reduce
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:10:// TODO: These don't really belong here but torchvision builds in CI need them
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/util.h:17:// TODO: replace with pytorch/rfcs#43 when it is ready.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/containers.h:180:  // TODO: cbegin and cend()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/collection.h:476:    TensorListBegin, // TODO: generalize to other lists.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:188:    // TODO PYBIND11_DEPRECATED(
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:1365:// TODO: After the deprecated constructors are removed, this macro can be simplified by
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/common.h:357:/// Compatibility macros for Python 2 / Python 3 versions TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/type_caster_base.h:482:        // TODO: is this still true for pure Python 3.6?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/tensor.h:503:    // TODO: Move to std::optional once std::optional has more support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/matrix.h:94:          // TODO: when Eigen bug #747 is fixed, remove the tests for non-negativity.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1295:    using module_def = PyModuleDef; // TODO: Can this be removed (it was needed only for Python 2)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1322:        // TODO: Should be reinterpret_steal for Python 3, but Python also steals it again when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2346:                    // TODO consolidate the erasure code in pybind11_meta_dealloc() in class.h
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2433:    // TODO: state captures only the types of Extra, not the values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:141:            # TODO: find a better way to identify cudaLaunchKernel
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:145:            # TODO: find a better way to identify CUDA Kernel
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:367:# TODO(dberard) - deprecate / remove workaround for CUDA >= 12, when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:167:        # TODO(robieta): Move away from load bearing names
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:305:        # TODO(robieta):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:1061:        # TODO: Write a faster serialize (orjson not available in CI)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:181:        # TODO: We should also check tensor identities
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:216:        # TODO: Check if tensor is reused
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:418:        # TODO: fixme! Due to lifetime issues of the function name, this field might
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:437:        # TODO: We should also check if the loader is bottleneck.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:483:        # TODO: We should also check if the optimizer's numerical behavior will change.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/beta/_client_adaptations.py:85:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:43:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:413:                return None  # TODO(nathaniel): call the multimethod.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_auth.py:37:    # TODO(xuanwn): Give credentials an actual type.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_server.py:1182:        # TODO(https://github.com/grpc/grpc/issues/6597): eliminate these fields.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_server.py:1238:# TODO(https://github.com/grpc/grpc/issues/6597): delete this function.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_server.py:1463:        # TODO(xuanwn): We should validate method_handlers first.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_channel.py:257:# TODO(xuanwn): Create a base class for IntegratedCall and SegregatedCall.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_channel.py:1835:    # TODO(xuanwn): Refactor this: https://github.com/grpc/grpc/issues/31704
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_channel.py:2253:        # TODO(https://github.com/grpc/grpc/issues/12531): Several releases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/_observability.py:271:    # TODO(xuanwn): use channel args to exclude those metrics.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_server.py:87:        # TODO(xuanwn): Implement this for AsyncIO.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:409:                # TODO(lidiz) drop this hack after 3.8 deprecation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:484:    # TODO(xuanwn): Implement this method after we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:489:    # TODO(xuanwn): Implement _registered_method after we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:509:    # TODO(xuanwn): Implement _registered_method after we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:529:    # TODO(xuanwn): Implement _registered_method after we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:549:    # TODO(xuanwn): Implement _registered_method after we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_psaix.py:56:    cext.SSWAP: _common.STATUS_RUNNING,  # TODO what status is this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_psaix.py:180:    # TODO - the filtering logic should be better checked so that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_psaix.py:256:        # TODO: rewrite this in C (entstat forks, so use truss -f to follow.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_psaix.py:531:        # TODO rewrite without using procfiles (stat /proc/pid/fd/* and then
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_pswindows.py:866:                # TODO: the C ext can probably be refactored in order
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:230:    # TODO - the filtering logic should be better checked so that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:288:        # TODO: refactor and use _common.conn_to_ntuple.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:639:        # TODO: rewrite this in C (...but the damn netstat source code
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1004:    # TODO: #595
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1041:    # TODO: #595
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:564:    # TODO: remove this once 1892 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:841:                        # TODO: skip AF_INET6 for now because I get:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_osx.py:122:    # TODO: remove this once 1892 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:254:        # TODO: UNIX sockets are temporarily implemented by parsing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:368:    # TODO: remove this once 1892 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:386:    # TODO: remove this skip when this gets fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_unicode.py:116:        # TODO - this is quite random and I'm not sure why it happens,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_aix.py:60:        # TODO maybe try to use "swap -l" to check "used" too, but its units
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_bsd.py:7:# TODO: (FreeBSD) add test for comparing connections with 'sockstat' cmd.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:2028:    # TODO: re-enable this test.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:284:        # TODO: check ntuple fields
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/psutil/tests/test_contracts.py:235:    # TODO: remove this once 1892 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/click/_termui_impl.py:525:    # TODO: This never terminates if the passed generator never terminates.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pluggy/_hooks.py:411:        # TODO: Document, or make private.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pluggy/_hooks.py:417:    # TODO: Document, or make private.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pluggy/_hooks.py:421:    # TODO: Document, or make private.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/yaml/scanner.py:187:        # TODO: support for BOM within a stream.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/yaml/scanner.py:761:        # TODO: We need to make tab handling rules more sane. A good rule is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic_core/core_schema.py:1135:            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/client.py:95:        # TODO: Migrate things away from scoped_config in favor of the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/client.py:680:            # TODO: fallback partition_name should be configurable in the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/client.py:758:        # TODO: This normalization logic is duplicated from the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/utils.py:2314:                # TODO: Update message to reflect use_arn_region
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/docs/bcdoc/style.py:321:        # TODO: Need to control the bullets used for LI items
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/discovery.py:276:        # TODO: Improve eviction behavior to only evict the bad endpoint if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/handlers.py:976:# TODO: Remove this class as it is no longer used
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/auth.py:245:            # TODO: We should set the host ourselves, instead of relying on our
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/auth.py:943:        TODO: Do we need this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/serialize.py:71:    # TODO: Unknown protocols.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/retryhandler.py:157:        # TODO: send a signal.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/response.py:102:            # TODO: the url will be None as urllib3 isn't setting it yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/response.py:119:            # TODO: the url will be None as urllib3 isn't setting it yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/response.py:203:    # TODO: Unfortunately, we have to have error logic here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/retries/special.py:17:# TODO: This is an ideal candidate for the retryable trait once that's
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/botocore/endpoint.py:346:        # TODO: avoid naming conflicts with ResponseMetadata and Error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/h2/windows.py:116:        # TODO: Can the window be smaller than 1024 bytes? If not, we can
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/h2/utilities.py:417:    # TODO: We should also guard against receiving duplicate Host headers,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/httpx/_auth.py:267:        # TODO: implement auth-int
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/typing_extensions.py:3267:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:26:  # TODO: Remove this import after fix api_implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:271:    # TODO: Add function to calculate full_name instead of having it in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:474:# TODO: We should have aggressive checking here,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:480:# TODO: for this and other *Descriptor classes, we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:539:  # TODO: Find a way to eliminate this repetition.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:563:  # TODO: Find a way to eliminate this repetition.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:600:  # TODO: Find a way to eliminate this repetition.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:139:    # TODO: implement this API.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:143:    # TODO: implement this API.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_pool.py:1360:  # TODO: This pool could be constructed from Python code, when we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/pyext/cpp_message.py:21:# TODO: Remove this import after fix api_implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:100:        # TODO: Remove this check here. Duplicate extension
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:140:      # TODO: Remove this check here. Duplicate extension
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:88:    # TODO: fail back to python
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:135:# TODO: Remove the API, it returns a constant. b/228102101
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:10:# TODO: Helpers for verbose, common checks like seeing if a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:215:  # TODO: Escape Python keywords (e.g., yield), and test this support.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:230:  # TODO:  Remove this method entirely if/when everyone agrees with my
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:464:    # TODO: This may be broken since there may not be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:717:    # TODO: This may be broken since there may not be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:767:  # TODO: Remove duplication with similar method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:824:  # TODO: Migrate all users of these attributes to functions like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:827:    # TODO: Use cls.MESSAGE_FACTORY.pool when available.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:977:  # TODO: Don't use the factory of generated messages.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:989:  # TODO: For now we just strip the hostname.  Better logic will be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:1035:    # TODO: Fix UnknownFieldSet to consider MessageSet extensions,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/builder.py:96:  # TODO: Remove this on-op
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:37:# TODO: Unify error handling of "unknown extension" crap.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:38:# TODO: Support iteritems()-style iteration over all
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:98:# TODO: Remove this. BaseContainer does *not* conform to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:214:# TODO: Constrain T to be a subtype of Message.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/symbol_database.py:136:    # TODO: Fix the differences with MessageFactory.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:22:# TODO Import thread contention leads to test failures.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:477:          # TODO: refactor and optimize if this becomes an issue.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1081:        # TODO: Change to _allow_singular_overwrites.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1637:# TODO: Migrate violators to textformat_tokenizer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:8:# TODO: We should just make these methods all "pure-virtual" and move
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:43:  # TODO: Link to an HTML document here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:45:  # TODO: Document that instances of this class will also
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:49:  # TODO: Document these fields and methods.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:66:    # TODO: Remove this once the UPB implementation is improved.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:182:  # TODO: MergeFromString() should probably return None and be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:217:    # TODO: Document handling of unknown fields.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:218:    # TODO: When we switch to a helper, this will return None.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:263:  # TODO: Decide whether we like these better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/google/protobuf/message.py:269:  # TODO: Be sure to document (and test) exactly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578:        # TODO: Add optional support for socket.gethostbyname checking.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095:        # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38:    # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144:        # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234:                # TODO: Arbitrary read value.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282:            # TODO this is often present from upstream.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325:    # TODO: This is a woefully incomplete response object, but works for non-streaming.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332:        decode_content: bool = False,  # TODO: support decoding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/exceptions.py:306:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/util/url.py:454:    # TODO: Remove this when we break backwards compatibility.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/util/request.py:229:    # File-like object, TODO: use seek() and tell() for length?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/connection.py:330:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/connection.py:436:        # object later. TODO: Remove this in favor of a real
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/connection.py:561:        # TODO should we implement it everywhere?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/response.py:1005:                # TODO make sure to initially read enough data to get past the headers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20:    # TODO: Remove this in favor of a better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499:        # TODO should we eliminate the recursion?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503:                    # TODO check whether we need to call `list_hook`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511:            # TODO is the interaction between `list_hook` and `use_list` ok?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516:                    # TODO check whether we need to call hooks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863:    TODO: clean up the code here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558:            # TODO: Not sure if we need the SecTrustResultType for anything?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:839:            # TODO version verification
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:922:                # TODO SHA256 digest
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401:        # TODO check k, v for valid values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:560:    # TODO could add iter* variants
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:984:        # TODO: any other fields wanted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:1020:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:3568:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522:        # TODO: Add optional support for socket.gethostbyname checking.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659:        # TODO: should I do clean shutdown here? Do I have to?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819:        # TODO: Well, crap.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829:        # TODO: Update in line with above.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1:# TODO: Add Generic type annotations to initialized collections.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122:_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598:        # TODO: Add a deadline?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227:        # TODO: There is an assumption that the result will be a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/cache.py:278:                # TODO: use DirectUrl.equivalent when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:227:        # TODO performance: this means we iterate the dependencies at least twice,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:362:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:201:        # TODO: Check already installed candidate, and use it if the link and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:622:        # TODO: Are there more cases this needs to return True? Editable?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:344:        # TODO: In the future, it would be nice if pip supported PEP 691
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:204:        # TODO: Try to get these passing down from the command?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6:# TODO: This needs Python 3.10's improved slots support for dataclasses
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:107:    # TODO: replace this with slots=True when dropping Python 3.9 support.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:526:    # TODO: handle space after '\'.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:285:        # TODO: The is_installable_dir test here might not be necessary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:75:        TODO remove this property together with the legacy resolver, since the new
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:167:        # TODO: this property is relatively costly to compute, memoize it ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:177:                # TODO: get project location from second line of egg_link file
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:557:        # TODO: separate this part out from RequirementPreparer when the v1
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/compat.py:115:    # TODO(RonnyPfannschmidt): This function should be refactored when we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/python.py:296:        # TODO: Improve the type of `parent` such that assert/ignore aren't needed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/python.py:1532:    # TODO: If escaping is turned off and the user passes bytes,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/python.py:1705:    # TODO: Type ignored -- breaks Liskov Substitution.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/junitxml.py:512:            # TODO: breaks for --dist=each
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/assertion/rewrite.py:881:            # TODO: This assert should not be needed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/legacypath.py:389:        # TODO: This assert is probably not valid in all cases.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/cacheprovider.py:242:                # TODO: pass ignore_cleanup_errors=True when we no longer support python < 3.10.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/cacheprovider.py:575:        # TODO: evaluate generating upward relative paths
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/mark/structures.py:158:            # TODO: Refactor to fix this type-ignore. Currently the following
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/doctest.py:316:    # TODO: Type ignored -- breaks Liskov Substitution.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/doctest.py:346:            # TODO: ReprFileLocation doesn't expect a None lineno.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/raises.py:495:    # TODO: harmonize with ExceptionInfo.match
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/raises.py:513:            # TODO: it instructs to use `-v` to print leading text, but that doesn't work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/raises.py:698:    # TODO: move common code into superclass
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/terminal.py:1539:        # TODO: Revisit after marks scope would be fixed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/reports.py:466:    # TODO: Check if this is actually reachable.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/reports.py:518:        # TODO: Investigate whether the duck typing is really necessary here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/nodes.py:514:    # TODO: This omits the style= parameter which breaks Liskov Substitution.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:159:# TODO: Try to use FixtureFunctionDefinition instead of the marker
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1249:# TODO: paramspec/return type annotation tracking and storing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1535:        # TODO: The order of the FixtureDefs list of each arg is significant,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1937:        # TODO: Fix this type ignore.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/capture.py:708:        # TODO: This type error is real, need to fix.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/_pytest/main.py:945:                        # TODO: Remove parametrized workaround once collection structure contains
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:36:    BaseTy.float: "double",  # TODO: how about other floating point types?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:97:            # TODO: BaseTy.Dimname, BaseTy.Generator, etc.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:98:            raise NotImplementedError(f"TODO: add support for arg type {repr(typ)}")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:203:                f"TODO: add support for return type {repr(ret.type)}"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:316:        # TODO: No need to generate C shim for Inductor lowered ops.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:48:    # TODO: Matching on CType seems wrong; should be matching on Type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:60:                # TODO: I don't understand when you should put lazy_ in the name
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:72:                f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:447:                # TODO(alanwaketan): Maybe we want to apply GetLtcTensorOrCreateForWrappedNumber here, but hold it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:455:                    f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:540:            # TODO: this is trolling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:581:            # TODO(whc) remove this if XLA switches to using static method for creation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:39:# TODO: use BackendIndex
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:75:        # TODO: don't hardcode; return type will be inferred based on tags on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:501:        # TODO: don't hardcode ufunc:: namespace here, should be centralized smh
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:160:      // TODO: avoid the redispatch here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:428:            # TODO: dedupe this with the structured codegen
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:453:                    # TODO: handle in place on tensor list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:662:            # TODO: Make sure out argument is guaranteed to be self
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:708:            # TODO: Move to OptionalMPSGuard.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:720:            f"      return {output_value};\n",  # type: ignore[possibly-undefined]  # TODO: audit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:722:            f"    std::array<{output_type}, {len(f.func.returns)}> outputs_;",  # type: ignore[possibly-undefined]  # TODO: audit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:723:            f"{textwrap.indent(proxy_field, indent)}",  # type: ignore[possibly-undefined]  # TODO: audit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:739:        # TODO: Now, there is something interesting going on here.  In the code below,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:762:        # (e.g., at::cpu::add).  We don't generate methods (TODO: do this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:815:                # TODO: dedup this branch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:893:                        # TODO: Stop hardcoding that the output type is a Tensor.  Note
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:908:                # TODO: https://github.com/pytorch/pytorch/issues/53023
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:918:                # TODO: I think this means structured won't work with method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:947:            # TODO: Do this in translate instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:965:            sig_body.append(f"return {ret_expr};")  # type: ignore[possibly-undefined]  # TODO: audit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:342:        # TODO: for ops with structured_delegate it should check the dispatch table of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:786:# TODO: This was historically used to help some JIT interop code
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:1041:# TODO: Get rid of dynamic_type, after getting tools/autograd
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:1310:        # TODO: What exactly is the semantics of the 'dispatch' field?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:1424:    # TODO: how come ValuesView isn't a Sequence lol
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:2227:                    # TODO: this condition is a bit questionable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:2723:    # TODO: --op-registration-whitelist will be removed when all call-sites
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen.py:2790:    # TODO: stop generating CUDA kernels for non-CUDA builds
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_backend_stubs.py:139:            # TODO: allow structured external backends later.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:789:        # TODO: The below ops all have "problematic" schemas that prevent them from
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/utils.py:60:# TODO: Use a real parser here; this will get bamboozled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/utils.py:98:        # TODO: this does the wrong thing with KeyError
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/utils.py:108:# TODO: put this somewhere else, maybe
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/utils.py:159:            # TODO: Update the comment reference to the correct location
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:272:        # TODO: remove the skip after these two operators schemas are fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:327:            # TODO: remove the skip after these two operators schemas are fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:23:# TODO: Duplicated Subset from codegen.tool.gen_oplist, remove declaration in codegen
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:64:        type_alias_map: Dict[str, List[str]],  # TODO: Support unwrapped str val
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:91:            # TODO: Support inlined arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:130:                )  # TODO: fix this discrepancy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:140:        # TODO: keeping these special cases for Tensor[] and Tensor?[] so that we can hookup with ATen kernels.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:215:        # TODO: Consider incorporating this into the data model
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/executorch/api/custom_ops.py:94:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_executorch.py:368:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:149:    # TODO(whc) add a check for shape inference functions that have meta kernels implement and should be retired.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:368:        TODO(alanwaketan): Remove this sorting hack once all ops are grouped properly.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:75:        # TODO: these ones got added recently and need manual inspection
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:252:        # TODO: stop doing type tests by converting to C++ and then testing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:278:    # TODO: stop type testing by converting to C++
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:476:    # TODO: figure out what this does
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:684:            # TODO: verify that the tag is valid and has an entry in tags.yaml
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:763:                # TODO: maybe it's better to test the return
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:926:        # TODO: probably better to accumulate these errors and report them all
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:1293:            # TODO: This discrepancy isn't required; we could also generated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:1359:    # TODO: Need to handle collisions with argument names at some point
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:1733:        # TODO: implement a proper parser if this gets more ugly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:1856:    ConstQuantizerPtr = auto()  # TODO: rename
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:1996:        # TODO: deduplicate annotation matching with Return
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:2281:        # TODO: Use a real parser here; this will get bamboozled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:2400:        # TODO: These invariants are weirdly asymmetric?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/model.py:2401:        # TODO: Fancier types?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:228:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:251:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:298:    # TODO: maybe don't need keep scattered out fields for python signature?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:322:                # TODO: shouldn't this be OptionalType[ListType[...]], since it defaults to None?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:337:    # TODO: create a dedicated SelfArgument type for 'self'?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:354:    # TODO: maybe create a PythonTensorOptionsArgument?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:723:        # TODO: directly translate a.default to python default
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:775:    # [old codegen] TODO: because these aren't guaranteed to be 100% faithful
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:946:            # TODO: this doesn't seem right...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1095:# TODO: This is to keep same byte-for-byte result as the old codegen - maybe unnecessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1127:            # TODO: avoid this special handling?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1405:            # TODO: why this needs to be special case?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1426:            # TODO: make this part of something more general, or get rid of it.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1480:    # TODO: maybe move to the generator side as it's not related to binding.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/native.py:47:    # TODO: delete this!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/native.py:114:        # TODO: Not sure why the arguments assigned here are for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:149:        # TODO: My kingdom for a pattern matcher
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:152:        # TODO: This could get us in recomputation trouble if b.expr is nontrivial.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:253:        # TODO: These are referentially equal, shouldn't have to do this;
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:368:            # TODO: You might also want to solve this from longSymVec_ctype or
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:120:            raise AssertionError(f"TODO add support for type {repr(typ)}")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:125:            # TODO(whc) is this actually correct? or should it use a Vector like above
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:131:            # TODO: return a value type.  The problem here is analogous to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:146:# TODO: Determining this based off of CType is bad; this should be computed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:166:        # TODO: report True for this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:192:# TODO: dedupe with Type.is_generator_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:209:    # TODO: this is lies, it is false for symint list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:229:            # TODO: lists of symints are not currently treated as value types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:306:# TODO: This is not idiomatic with how other torchgen APIs transform on schema.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:314:    # TODO: Need to handle collisions with argument names at some point
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:164:                )  # TODO: fix this discrepancy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:181:        # TODO: remove these special cases, ArrayRef fallthrough works fine
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:285:        # TODO: Consider incorporating this into the data model
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:422:                default = "at::kLong"  # TODO: this is wrong
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:114:    # TODO: maybe the logic to search for all variants is no longer necessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:233:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:241:#   TODO: some cpp naming logic (e.g. resolving name conflict) might be irrelevant?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:250:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:261:# TODO: Update comment below since it is out of date.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:348:# TODO(crcrpar): Avoid hard coding "Default" ideally.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:632:            # TODO(crcrpar): Avoid hard coding "Default" ideally.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:85:    # TODO: Kill this when we eventually remove it!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:188:    # TODO: Kill this when we eventually remove it!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:211:    # TODO: maybe don't represent default here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:246:    # TODO: Kill this when we eventually remove it!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/api/structured.py:76:        # TODO: delete these special cases; see torchgen.api.cpp--these
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/RegisterBackendSelect.cpp:31:  // TODO: fetch scalar type from Tensor? But it doesn't really matter...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:196:  // TODO: temporarily disabled
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:235:  // TODO: Deprecate me
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:539:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:19:// TODO: rename this file to something more generic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:50:// TODO: this doesn't handle restriding empty tensors correctly; see
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/DispatchKeyFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/FunctionalInverses.h:26:// TODO: Change codegen to generate these. See the following link:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/Functions.cpp:10:   AutoDispatchBelowADInplaceOrView guard{}; // TODO: Remove.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:110:    # TODO: byte-for-byte compatible with old codegen behavior - should clean up
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:302:    # TODO: clean up old codegen behavior
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:256:    # TODO: Should handle optional here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:261:    # TODO: Should handle optional here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:338:    return f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:355:    # TODO: Clean this logic up if we get rid of reverse view funcs or reify them.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:174:# TODO: Why is this going through CppSignatureGroup, that doesn't make sense...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:395:            # TODO we are trolling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:592:        # TODO: do we need eagerly calculate and save it here? Can it be derived
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:653:    # TODO: maybe the logic to handle the legacy schema is no longer necessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:943:            # TODO: it would be nice to not have these special cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1079:        # TODO: `cpp_type` is only to keep it byte-for-byte compatible with the old codegen, should remove.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1100:                    # TODO(crcrpar): Make it simpler.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1221:            # TODO: process all derivative formulas!!!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1345:            # TODO: should be `arg.type.is_tensor_like()`?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1605:            base_name = f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1729:        # TODO: flatten allocates a std::vector, which could be expensive
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1857:                # TODO update this when inplace namings are unified
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1967:                    # TODO(crcrpar): Should this (= the foreach specific logic) be refactored somehow?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py:441:# TODO: This is probably not exhaustive, but it's a start
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1250:        # TODO: should use some canonical form instead of 'str(arg.type)' - see comments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1338:        # TODO: Checking `ps.method and ('requires_grad' in parser_outputs)` is a hacky
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_factories.py:22:# TODO: maybe update the cpp argument API to take optional namespace argument?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:73:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:91:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:110:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:126:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:156:    // TODO: consider factoring this out
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:371:  // TODO: change the condition to `self_.dim() != 0` once we expose scalars
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:416:  // TODO: Make this call the TensorOptions version, maybe?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:422:  // TODO: Make this call the TensorOptions version, maybe?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/requests/hooks.py:19:# TODO: response is the only one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/einops/einops.py:52:    # TODO add support for added_axes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/einops/tests/test_einsum.py:352:    # TODO: Include check for giving normal einsum pattern rather than einops.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/iniconfig/__init__.py:80:    # TODO: investigate possible mypy bug wrt matching the passed over data
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:167:# TODO: add support for `axis` tuples
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_correlation.py:10:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:44:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1262:    # TODO: properly avoid NaN when y is negative infinity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1263:    # TODO: silence warning with taking log of complex nan
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1264:    # TODO: deal with x == y better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3015:    # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3453:        # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:4442:    # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_morestats.py:2627:    # TODO: calculate exact distribution considering ties
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_qmc.py:456:        # TODO consider returning both the mean and the standard deviation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_page_trend_test.py:322:    if ranks.ndim != 2:  # TODO: relax this to accept 3d arrays?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:193:    # TODO: add more where possible with test coverage,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:321:    # TODO: add more where possible with test coverage,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_fast_gen_inversion.py:144:# TODO: add more distributions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous_basic.py:136:        # TODO: multiple checks in this function are not robust, tweaking the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:26:    # Check that `var` keyword returns a value.  TODO: check whether returned
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:43:    # TODO: check that implementation is correct.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2367:    # TODO: add method "pearsonr" after fix overflow issue
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2387:    # TODO: add method "pearsonr" after fix overflow issue
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_basic.py:1260:# TODO: for all ttest functions, add tests with masked array inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:5780:        # These are excluded by the filters below. TODO: Rewrite tests so that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous.py:890:    # TODO: add `supported` method and check here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_stats.py:79:    # TODO: write these tests to handle missing values properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs.py:221:    # TODO use a better error approximation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:38:#TODO renovate or move this class when scipy operators are more mature
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:73:#TODO renovate or move this function when SciPy operators are more mature
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_lapack.py:1941:                # TODO: Add a test for ONB?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/pyprima/cobyla/geometry.py:24:    TODO: Check whether it improves the performance if JDROP = NUM_VARS is allowed when
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:181:        # TODO: Does this depend on device?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:243:        # TODO: Does this depend on device?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/torch/_aliases.py:833:    # TODO: is the return type a list or a tuple
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:42:    # TODO: import from typing (requires Python >=3.13)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:119:    # TODO: Should we reject ndarray subclasses?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:264:    # TODO: Account for other backends.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:293:        # TODO: drop support for numpy<2 which didn't have __array_namespace__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:300:        # TODO: drop support for jax<0.4.32 which didn't have __array_namespace__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:642:            # TODO: Support Python scalars?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:876:        # TODO: What if our array is on the GPU already?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:16:    # TODO: import from typing (requires Python >=3.13)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:309:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:381:    # TODO: np.clip has other ufunc kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:32:# TODO: use the QR wrapper once dask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:59:    # TODO: can't avoid computing U or V for dask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:65:    # TODO: respect device keyword?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:96:    # TODO: respect device keyword?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:163:    # TODO: respect device keyword?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:224:    # TODO: This won't handle dask unknown shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_at.py:23:    # TODO import from typing (requires Python >=3.11)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:36:    # TODO import from typing (requires Python >=3.12 and >=3.13)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:307:    TODO this helper should be eventually removed once all the special cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/testing.py:23:    # TODO import override from typing (requires Python >=3.12)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/differentiate/_differentiate.py:372:    # TODO (followup):
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/cluster/hierarchy.py:1385:        # TODO ARRAY_API complex indexing not supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_direct_py.py:256:    # TODO: fix disp argument
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py:349:        # TODO: Use more advanced strategies from [2]_
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py:54:    # TODO: Use a symmetric indefinite factorization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:61:    # TODO: revert this once the warning bug fix in sksparse is merged/released
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:101:    # TODO: Use a symmetric indefinite factorization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_ip.py:92:                # TODO: revert this suppress_warning once the warning bug fix in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2050:    # TODO: add hessp (callable or FD) to ScalarFunction?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_chandrupatla.py:7:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:72:    # TODO: test redundant row removal better
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:73:    # TODO: make solve more efficient with BGLU? This could take a while.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:376:        # TODO: cythonize?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:477:        pass  # TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:716:                    # self.n #TODO: Should always be self.n, this is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1176:        # TODO: Only do this if global mode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1502:            # TODO: Uncertain if n_prc needs to add len(self.LMC.xl_maps)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_chandrupatla.py:970:        # # TODO: Test zero tolerance
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_optimize.py:3063:        # TODO this test should really be equivalent to factorized version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__remove_redundancy.py:5:# TODO: add tests for:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:579:        # TODO: Make default n higher for faster tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:715:        # TODO: This test doesn't cover anything new, it is unknown what the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1179:            sign_det_A_11 = -1  # TODO: Choose another det of j instead?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1180:            # TODO: Unlikely to work in many cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1187:            # TODO: Note that scipy might be faster to add as an optional
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1191:            # TODO: Note if sign_det_A_j0 == then the point is coplanar to the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1217:        # TODO: Is checking the projection of one vertex against faces of other
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1220:        # TODO: Literature seems to suggest using proj.T, but why is this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1222:        if np.linalg.det(proj) == 0.0:  # TODO: Replace with tolerance?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_remove_redundancy.py:423:        v = U[:, -1]  # TODO: return these so user can eliminate from problem?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:862:        if rr and A_eq.size > 0:  # TODO: Fast sparse rank check?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:876:        try:  # TODO: use results of first SVD in _remove_redundancy_svd
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/special/_support_alternative_backends.py:125:            # TODO use xpx.lazy_apply to add jax.jit support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/special/_lambertw.py:146:    # TODO: special expert should inspect this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/special/tests/test_sf_error.py:34:    # TODO: special expert should correct
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/special/tests/test_basic.py:2448:        # TODO: cannot use N itself yet; factorial uses `gamma(N+1)` resp. `(hi+lo)//2`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/io/_harwell_boeing/hb.py:12:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:21:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:842:        # TODO: this is where we are spending time (~80%). I think things
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/io/_netcdf.py:20:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/interpolate/_fitpack_impl.py:19:TODO: Make interfaces to the following fitpack functions:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_legendre.py:56:        # TODO: current converting to/from numpy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:78:        # TODO: Currently only support for degree 7 Genz-Malik cubature, should aim to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:134:        # TODO: Currently only support for the degree 5 lower rule, in the future it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_kronrod.py:83:        # TODO: nodes and weights are currently hard-coded for values 15 and 21, but in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:82:    # TODO: Optimize for hermitian and real?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:194:    # TODO: Optimize for hermitian and real?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/tests/test_basic.py:865:# TODO: Is this test actually valuable? The behavior it's testing shouldn't be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/fft/tests/test_real_transforms.py:110:    # TODO write an array-agnostic pad
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:885:    # TODO: Why are we using _as_euler_from_matrix here? As a sanity check? It is not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:920:    # TODO: Same as before: Remove _as_euler_from_matrix?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:2083:    # TODO: Do we want to support this for all Array API frameworks?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:412:    # TODO: delete next 15 lines [combine with _eye()] once spmatrix removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:541:    # TODO: delete next 10 lines and replace _sparse with _array when spmatrix removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:627:    # TODO: delete next 8 lines and replace _sparse with _array when spmatrix removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:684:    # TODO remove this if-structure when sparse matrices removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:134:                # TODO infer shape here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:346:        # TODO eliminate zeros
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/tests/test_svds.py:626:            # TODO: arpack crashes when v0=v0, which="SM"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/minres.py:357:            break  # TODO check this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:20:# TODO check that method preserve shape and type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:21:# TODO test both preconditioner methods
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:366:    # TODO: minres / tfqmr. It didn't historically use absolute tolerances, so
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:369:        pytest.skip("TODO: Add atol to minres/tfqmr")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:145:        #TODO this test seems to give estimates that match the table,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:146:        #TODO even though no attempt has been made to deal with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:147:        #TODO complex numbers in the one-norm estimation.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_dok.py:474:            # TODO implement resize across dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:227:        # TODO check for duplicates?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:700:        # TODO: don't fall back to fancy indexing here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:967:            # TODO: only sort where necessary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_base.py:656:            # TODO sparse broadcasting
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_csr.py:229:        # TODO: uncomment this once it's faster:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_data.py:18:# TODO implement all relevant operations
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:238:                # TODO: make sparse matrix indexing work for sparray
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:303:            # TODO: handle this for nD (adjacent arrays stay, separated move to start)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_construct.py:23:#TODO check whether format=XXX is respected
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:297:# TODO test prune
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:298:# TODO test has_sorted_indices
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:4733:        # TODO: properly handle this assertion on ppc64le
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:5469:        # TODO check that NC has duplicates (which are not explicit zeros)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_spfuncs.py:16:        #TODO expose through function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:516:                and n_fft > 0):  # TODO: review threshold acc. to benchmark?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:1643:    # TODO in the near future:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:4886:# TODO: Make this a real public function scipy.misc.ff
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/_ltisys.py:1996:    # TODO: This could use some more work.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:604:        # TODO: add meaningful test where X0 is a list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:676:        # TODO: add meaningful test where X0 is a list
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2565:        # TODO: Why so inaccurate?  Is reference flawed?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2570:        # TODO: Why so inaccurate?  Is reference flawed?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2580:        # TODO: Why so inaccurate?  Is reference flawed?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2585:        # TODO: Why so inaccurate?  Is reference flawed?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_windows.py:820:    @xfail_xp_backends(np_only=True, reason='TODO: make resample array API ready')
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:211:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:884:    @xfail_xp_backends(np_only=True, reason="TODO: swapaxes")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:290:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:305:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:319:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:221:# TODO at some point, we could switch to an enum flag, so that multiple sources
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:224:    # TODO if/when https://peps.python.org/pep-0767/ is accepted, add 'read_only'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:319:        # TODO use a match statement when Python 3.9 support is dropped.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/_typing/_dtype_like.py:61:_DTypeLikeNested = Any  # TODO: wait for support for recursive types
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/_typing/_array_like.py:56:# TODO: Wait until mypy supports recursive objects in combination with typevars
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1795:    # TODO: are there no other tests for cholesky?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/getlimits.py:367:    TODO: MachAr should be retired completely ideally.  We currently only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs.py:2312:        assignment examples; TODO).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/arrayprint.py:1466:        # TODO: Custom repr for user DTypes, logic should likely move.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:170:        # TODO: this path can never be reached
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:179:    # TODO: this duplicates the C metastr_to_unicode functionality
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs_scalars.py:320:# TODO: work out how to put this on the base class, np.floating
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:80:        # TODO: Optimize case when `where` is broadcast along a non-reduction
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_scalarmath.py:97:        # TODO: It would be nice to resolve this issue.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:7434:# TODO: test for multidimensional
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:452:        # TODO: This discrepancy _should_ be resolved, either by relaxing the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:892:    # TODO: This is arguably weird/wrong, but seems old:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:12:# TODO: branch cuts (use Pauli code)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:13:# TODO: conj 'symmetry'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:14:# TODO: FPU exceptions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:23:# TODO: replace with a check on whether platform-provided C99 funcs are used
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:26:# TODO This can be xfail when the generator functions are got rid of.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:122:    # TODO This can be xfail when the generator functions are got rid of.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:479:    # TODO This can be xfail when the generator functions are got rid of.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_casting_unittests.py:782:        # TODO: While this test is fairly thorough, right now, it does not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_api.py:163:# TODO: remove when fastCopyAndTranspose deprecation expires
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:1544:        # TODO: Allowing unsafe casting by
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:2520:        # TODO: add absolute (gold standard) time span limit strings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/numeric.py:480:    # TODO: this works around .astype(bool) not working properly (gh-9847)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1873:    /* TODO: Make this definition public in the API, as soon as its settled */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:221: * TODO: Due to the fact that `resolve_descriptors` is also used for `can_cast`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:366:// TODO: These slots probably still need some thought, and/or a way to "grow"?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:398: * TODO: These two functions are currently only used for experimental DType
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:821:        // TODO: do something better than 128 bit math
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:855:        // TODO: do something better than 128 bit math
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/mixins.py:163:    # TODO: handle the optional third argument for __pow__?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:73:# TODO: .zip support, .tar support?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:335:        # TODO: Doesn't handle compressed files!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:401:        # TODO:  This should be more robust.  Handles case where path includes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:515:        # TODO: There is no support for opening a file for writing which
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:518:        # TODO: Add a ``subdir`` parameter for specifying the subdirectory
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:3543:        # TODO: Note that times have dubious rounding as of fixing NaTs!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:4101:        # TODO: Median does not support Datetime, due to `mean`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:311:                sup.filter(ResourceWarning)  # TODO: specify exact message
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/ma/core.py:207:        # TODO: This is probably a mess, but should best preserve behavior?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/ma/core.py:4673:        # TODO: We don't actually support K, so use A instead.  We could
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5430:    # TODO: Test masked_object, masked_equal, ...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/_isocbind.py:55:# TODO: See gh-25229
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:134:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2066:    TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2505:                    # TODO: test .eq., .neq., etc replacements.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2551:                outmess(f'get_parameters[TODO]: '
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2594:        # TODO: use symbolic from PR #19805
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:723:        /* TODO: change the type of `len` so that we can remove this */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:783:            // TODO: update when numpy will support 1-byte and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:808:        /* TODO: This error (and most other) error handling needs cleaning. */
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:830:# TODO: These should be dynamically generated, too many mapped to int things,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:248:    # TODO: support Fortran `len` function with optional kind parameter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:504:        # TODO: Evaluate intent_flags here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:23:# TODO: support logical constants (Op.BOOLEAN)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:24:# TODO: support logical operators (.AND., ...)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:25:# TODO: support defined operators (.MYOP., ...)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:520:                # TODO: other kind not used
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:570:        # TODO: implement a method for deciding when __call__ should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:811:            # TODO: determine correct kind
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:846:            # TODO: determine correct kind
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:896:            # TODO: denom kind not used
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:1108:            # TODO: find common divisor of coefficients
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/src/fortranobject.c:1358:  // TODO: detect the size of buf and make sure that size(buf) >= size(localbuf).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:395:    # TODO: Clean up to prevent passing --overwrite-signature
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:494:    TODO: Test to ensure this has no effect without --latex-doc
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:638:    TODO: Document this in the help string
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:662:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:671:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:727:    # TODO: f2py2e should not call sys.exit() after printing the version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:752:# TODO: These should be tested separately
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:759:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:767:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:775:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:783:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:791:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:799:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:807:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:815:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:823:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:831:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:839:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:847:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:855:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:863:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:871:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:879:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:887:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:895:    # TODO: populate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_docs.py:55:    # TODO: implement test methods for other example Fortran codes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:448:    # TODO: Remove all this when scaninputline is replaced
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/array_api/_set_functions.py:15:# TODO in this implementation as this behavior may be reverted in np.unique().
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/array_api/__init__.py:98:Still TODO in this module are:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/array_api/_creation_functions.py:69:        # to an object array. TODO: This won't handle large integers in lists.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_array_object.py:387:    TODO: Find and use appropriate __setitem__() case.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_data_type_functions.py:29:    # TODO: These will require https://github.com/numpy/numpy/issues/23883
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:436:        # TODO: we're stuck with disabling math formatting until we handle
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/random/tests/test_random.py:1062:    # TODO: Include test for randint once it can broadcast
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:688:    # TODO: Find some kind of fallback if there is no _CHECKPOINT_FOR_DOC in any of the modeling file.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:41:# TODO: This doesn't work for all packages (`bs4`, `faiss`, etc.) Talk to Sylvain to see how to do with it better.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:48:            # TODO: Once python 3.9 support is dropped, `importlib.metadata.packages_distributions()`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:71:                # TODO: remove once `importlib.metadata.packages_distributions()` is supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:401:    # TODO check if some bugs cause push backs on the exact version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:578:        # TODO: more precise exception matching, if possible.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:602:        # TODO: more precise exception matching, if possible.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1048:        # TODO: Bump the requirement to 2.1.0 once released in https://github.com/ROCmSoftwarePlatform/flash-attention
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/attention_visualizer.py:188:            if "token_type_ids" in inputs:  # TODO inspect signature of update causal mask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1803:                # TODO: Remove this check once configuration version is handled natively by Quark.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:93:# TODO: clean this for v5?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:530:# TODO cyril: Deprecated and should be removed in 4.51
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:197:    # TODO: add support for them as it should be quite easy to do so (small blocking issues).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:389:    # TODO: infer shape without performing the computation, this might be quite hard.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:582:        # TODO: infer shape without performing the computation.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:1351:            # TODO: solves GraphModule creation.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:336:        # TODO: remove this hack when the legacy code that initializes generation_config from a model config is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:1117:                    # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:371:        # TODO (Joao): this function might trigger XLA retracing as `cur_len` increases. Fix it if it becomes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:428:        # TODO (joao): enable XLA on this logits processor. See discussion and attempts in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:1942:        # TODO(Patrick): Make sure that official models have max_initial_timestamp_index set to 50
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:317:# TODO (joao): remove the equivalent classes and typing shortcuts below in v5
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:519:        # 8. Remove unexpected `generate` inputs (TODO @joao: fix trainer and examples)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:800:                # TODO (joao): remove output/input mismatch when these old models (xlnet, reformer) are deprecated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1082:            # TODO (sanchit): move this exception to GenerationConfig.validate() when TF & FLAX are aligned with PT
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1088:        # TODO (joao): find a strategy to specify the order of the processors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1353:        # TODO(joao): remove this function in v4.50, i.e. when we remove the inheritance of `GenerationMixin` from
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1428:            # TODO: A better way to handle this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1564:        # TODO (joao): per-model generation config classes.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1821:        # TODO(joao): support static caches in assisted generation. assisted generation needs to roll back caches,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2135:            # TODO (joao): generalize this check with other types of inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3331:                # TODO (joao): this OP throws "skipping cudagraphs due to ['incompatible ops']", find solution
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3386:        TODO: standardize cache formats and make all models compatible with `Cache`. It would remove the need
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3505:        # TODO (joao): This function should take an optional beam scorer function, to manipulate the scores after
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3669:        # TODO (joao): standardize special cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1627:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1911:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2254:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2789:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:537:        # TODO joao: find out a way of not depending on external fields (e.g. `assistant_model`), then make this a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:54:# TODO: Move BatchFeature to be imported by both image_processing_utils and image_processing_utils
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:71:# TODO: (Amy) - factor out the common parts of this and the feature extractor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/image_utils.py:1325:        # TODO raise a warning here instead of simply logging?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1496:            # TODO Matt: This is a workaround for older versions of datasets that are missing the `cols_to_retain`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2025:        # TODO (joao): flagged for replacement (by `_v2_resized_token_embeddings`) due to embeddings refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2065:        # TODO (joao): flagged for delection due to embeddings refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2096:        # TODO (joao): flagged for replacement (by `_v2_resize_token_embeddings`) due to embeddings refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2133:            # TODO (joao): this one probably needs a v2 version with other models
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2156:        # TODO (joao): flagged for replacement (by `_v2_get_resized_lm_head_bias`) due to embeddings refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2283:        # TODO (joao): flagged for replacement (by `_v2_get_resized_embeddings`) due to embeddings refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2954:            # TODO Matt: This is a temporary workaround to allow weight renaming, but requires a method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3335:    # TODO (joao): flagged for delection due to embeddings refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:197:        # TODO use valid to mask invalid areas due to padding in loss
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:210:        # TODO: randomness could apply a random seed, ex. rng = random.Random(random_seed)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/data/processors/squad.py:179:        encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:201:        # TODO: The default inputs only work for text models. We need to add support for vision/audio models.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:227:        # TODO: figure out dynamo support for instance method and switch this to instance method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:261:        # TODO: figure out dynamo support for instance method and switch this to instance method
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:876:        # TODO clean this up at some point (probably by switching to fast tokenizers)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/audio_utils.py:381:# TODO This method does not support batching yet as we are mainly focused on inference.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:279:        # TODO: Remove the `query_length != 1` check once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/onnx/convert.py:141:            # TODO: Check when exporting QA we provide "is_pair=True"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:516:        # TODO: should we set seq_length = 1 when self.use_past = True?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:702:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/tf_utils.py:70:    # TODO: When the issue linked above gets sorted, add a check on TF version here and use the original function if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer.py:271:    # TODO: @AjayP13, @younesbelkada replace this check with version check at the next `accelerate` release
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer.py:1542:                # TODO Change dtypes back to M=FP32, Var = BF16, Kahan = False once they can be cast together in torchdistx.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer.py:2865:            # TODO: in the future support only specific min PEFT versions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer.py:2959:                    # TODO: in the future support only specific min PEFT versions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer.py:3785:        # TODO: this needs to be fixed and made cleaner later.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/trainer.py:4561:                    # TODO: this needs to be fixed and made cleaner later.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:545:        # TODO this is fairly slow to improve!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:1103:        # TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_string
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:213:    TODO(Patrick): Delete safety argument `_enable=True` at next major version. .
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1760:# TODO (joao): remove `GenerationMixin` inheritance in v4.50
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4065:            # TODO: we can relax this check when we support taking tp_plan from a json file, for example.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:160:        # TODO try and retrieve it in a nicer way from _sanitize_parameters.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:103:    # TODO: Update task_summary docs to include an example with document QA and then update the first sentence
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:379:            # TODO: check why slower `LayoutLMTokenizer` and `LayoutLMv2Tokenizer` don't have this key in outputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:467:        # TODO: A lot of this logic is specific to Donut and should probably be handled in the tokenizer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1301:        # TODO hack by collating feature_extractor and image_processor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1344:        # TODO make the get_iterator work also for `tf` (and `flax`).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1419:        # TODO hack by collating feature_extractor and image_processor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:103:    # TODO  Use a faster algorithm this can probably be done in O(n)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:969:    # TODO: we need to make `NO_IMAGE_PROCESSOR_TASKS` and `NO_FEATURE_EXTRACTOR_TASKS` more robust to avoid such issue.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:341:# TODO need to add the __repr__ that shows that it is a colwise parallel
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/sagemaker/training_args_sm.py:29:# TODO: should be moved to `utils` after refactoring of SageMakerTrainer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:61:        # TODO: deprecate this function in favor of `cache_position`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:453:        # TODO: deprecate this function in favor of `cache_position`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:596:    # TODO (tmanlaibaatar) This won't be needed in torch 2.7.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1021:        # TODO: deprecate this function in favor of `cache_position`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1172:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1276:        # TODO: deprecate this function in favor of `cache_position`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1356:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1567:    # TODO(gante, sanchit-gandhi): move following functionality into `.generate`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1659:    # TODO (joao): dive deeper into gemma2 and paligemma -- there are reports of speed loss with compilation. Revert
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1663:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1806:        # TODO: deprecate this function in favor of `cache_position`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1865:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1866:    # TODO (joao): add layer_device_map arg and update code in `generate` accordingly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2044:        # TODO(gante): Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2078:            # TODO(gante): Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2136:        # TODO(gante): Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2148:        # TODO(gante): Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2160:        # TODO(gante): Remove this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/training_args.py:223:# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/training_args.py:2162:        # those deprecated arguments are removed from TrainingArguments. (TODO: v5)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/image_transforms.py:791:# TODO (Amy): Accept 1/3/4 channel numpy array as input and return np.array as default
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:133:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:261:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:414:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:459:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1218:                # TODO: Remove once eetq releases a fix and this release is used in CI
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1506:    # TODO (if possible): Avoid exceptional cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/agents/agents.py:1094:                # TODO: observation naming could allow for different names of same type
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:269:            # TODO: When tracing with TorchDynamo with fullgraph=True, the model is recompiled depending on the input
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:297:                # TODO: maybe revisit this with https://github.com/pytorch/pytorch/pull/114823 in PyTorch 2.3.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:375:    # TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:66:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/helium/modeling_helium.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/shieldgemma2/processing_shieldgemma2.py:153:        # TODO(ryanmullins): Support images from PIL or URLs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:274:    # TODO: maybe jit, otherwise move inside forward
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/pegasus/tokenization_pegasus.py:33:# TODO ArthurZ refactor this to only use the added_tokens_encoder
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/emu3/modeling_emu3.py:1234:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:279:        # TODO: remove the redundant computation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:394:        # TODO replace this with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:467:        # TODO: This code is most likely not very efficient and should be improved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2473:        # TODO (Joao): investigate why LED has numerical issues in XLA generate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmo/modeling_olmo.py:311:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:188:            # TODO: figure this case out.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:287:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:317:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:251:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granite/modeling_granite.py:346:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:99:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:356:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:461:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:525:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:300:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:428:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:203:            # TODO: figure this case out.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:302:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/processing_grounding_dino.py:319:                    # TODO: @pavel, set labels to None since v4.51.0 or find a way to extract ids
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1582:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:26:# TODO Update this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:364:# TODO: ^ interpret this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:418:    # TODO: this file should be downloaded in a setup script
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:2007:# TODO Add information to the docstring about any methods that convert to PDB format, or otherwise prepare
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/esm/tokenization_esm.py:65:        # TODO, all the tokens are added? But they are also part of the vocab... bit strange.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:330:        # `sqrt` in order to prevent NaNs during training in bfloat16. TODO a bit annoying
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:347:    # TODO refactor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:709:        if use_cache and inputs_embeds.shape[1] != 1:  # TODO let's maybe only call in the `generate`?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:776:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->RECURRENTGEMMA,Llama->RecurrentGemma,llama->gemma
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:866:        # Soft-cap the logits TODO remove if always done.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:324:        # TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:971:        # TODO: deal with head_mask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:1046:        # TODO: deal with head_mask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:344:        # TODO check if the t5/llama PR also applies here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:156:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:629:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:210:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:239:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:310:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:424:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:612:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:685:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:740:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:307:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:431:        # TODO: @yoni, change in v4.48 (use_fast set to True by default)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:496:        # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:262:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:270:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:608:        # TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1295:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py:504:                # TODO: Should we use the pre-trained projection as well ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:669:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:487:        # TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:346:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:475:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:687:        # TODO Matt: What is going on here? Why is a non-trainable weight randomly initialized?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama_fast.py:244:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:117:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:268:# TODO: (Amy) Move to image_transforms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:661:        # TODO: (Amy)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:618:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:747:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1577:        >>> # TODO: Add full pretraining example
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1594:        # TODO(PVP) - add pretraining logic and add to tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:338:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:562:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:573:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:622:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:679:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:700:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:203:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1709:        # TODO (joao):workaround until nested generation config is compatible with PreTrained Model
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bark/generation_configuration_bark.py:245:    # TODO (joao): nested from_dict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:462:        # TODO: (amy) add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py:628:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:158:        # TODO ArthurZ fairseq_ids_to_tokens should be removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:423:        # TODO fix this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:516:        # TODO find a better way of exposing other arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1152:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:216:            # TODO: Support arbitrary patch sizes.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:931:                # TODO can we simplify this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:1345:        # TODO (Qian): is it possible to revert the original cell if it is in the final answer?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:388:        self.t2u_variance_predictor_embed_dim = t2u_variance_predictor_embed_dim  # TODO: add to docstrings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:389:        self.t2u_variance_predictor_hidden_dim = t2u_variance_predictor_hidden_dim  # TODO: add to docstrings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:390:        self.t2u_variance_predictor_kernel_size = t2u_variance_predictor_kernel_size  # TODO: add to docstrings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:391:        self.t2u_variance_pred_dropout = t2u_variance_pred_dropout  # TODO: add to docstrings
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:354:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:483:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/configuration_m2m_100.py:274:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:197:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:399:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:412:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:510:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:531:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:313:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/cohere2/modeling_cohere2.py:78:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:504:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:461:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:664:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:793:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt2/configuration_gpt2.py:202:            # TODO: how to do that better?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:300:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:388:            # TODO add support for MLM
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:572:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:170:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:637:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:839:            # TODO(PVP): need to verify if below code is correct
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/byt5/tokenization_byt5.py:97:            additional_special_tokens=additional_special_tokens,  # TODO extra ids are not used :sweatywmile:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:414:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:506:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1446:        # TODO: As is this currently fails with saved_model=True, because
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bridgetower/configuration_bridgetower.py:279:        # TODO: remove this once the Hub files are updated.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:287:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:504:    _supports_static_cache = False  # TODO: needs a HybridCache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:330:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:458:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:63:# TODO: Update before the merge
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1263:    _supports_static_cache = False  # TODO: @raushan more involved due to local/global attn
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:2227:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:696:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:390:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:595:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:817:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:936:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1830:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py:248:        # TODO: @raushan update config in the hub
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:216:            # TODO: Support arbitrary patch sizes.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:129:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:232:        # TODO support align_corners=True in image_transforms.resize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:457:        # TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:307:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:414:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:651:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:176:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:230:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:337:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmo2/modeling_olmo2.py:312:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:73:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:96:# TODO(joao): add me back asap :)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:149:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: this may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:280:    # TODO(joao): add me back asap :)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:374:# TODO(joao): add me back asap :)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:385:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:437:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim].
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:511:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:593:# TODO(joao): add me back asap :)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:124:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:313:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:324:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:371:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:428:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:450:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:1010:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->NEMOTRON,Llama->Nemotron,llama->nemotron
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/ijepa/modeling_ijepa.py:585:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:140:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:266:        # TODO (raushan): remove in v4.46 (RoPE is computed in the model, not in the decoder layers)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:472:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:511:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1024:        # TODO: As of torch==2.2.0, the `attention_mask` passed to the model in `generate` is 2D and of dynamic length even when the static
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:306:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:258:        # TODO check if the t5/llama PR also applies here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:342:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:434:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:51:# TODO @ArthurZucker bring copied from back
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:262:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:303:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:305:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:413:        # TODO find a better way of exposing other arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:287:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:391:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:496:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:352:    # TODO add a deprecation cycle as this can have different behaviour from our API
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:188:            # TODO: figure this case out.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:287:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:297:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:426:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py:213:                # TODO: Check if this is needed, as it ensures that decode(encode(doc)) != doc by adding extra whitespace in the decoded document
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:131:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:630:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:749:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:941:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1707:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py:237:        # TODO: @raushan update config in the hub
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:594:        # TODO: We should check if the opset_version being used to export
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1967:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py:103:    # TODO: make it with torch instead of numpy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gptj/configuration_gptj.py:148:            # TODO: how to do that better?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deit/modeling_deit.py:595:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:34:# TODO this class is useless. This is the most standard sentencpiece model. Let's find which one is closest and nuke this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:353:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:82:        # TODO maybe make it torch compatible later on. We can also just slice
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:112:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:863:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:874:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:168:        # TODO(enijkamp): factor out number of logical TPU-v4 cores or make forward pass agnostic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/codegen/configuration_codegen.py:159:            # TODO: how to do that better?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:345:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1672:        # TODO: Implement `WhisperTimeStampLogitsProcessor`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:366:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:423:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:491:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1005:                    # TODO Handle when language is different from the previous
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:93:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:762:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1436:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:251:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:208:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:243:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/vit/modeling_vit.py:604:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py:2349:            # TODO (joao, raushan): refactor `generate` to avoid these operations with VLMs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:348:# TODO: Implement attention with SDPA for PLBart.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:375:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:638:            # TODO(PVP): need to verify if below code is correct
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:210:            # TODO: figure this case out.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:309:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:422:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:292:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:323:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:194:        # TODO decode outputs do not match between fast and slow
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1289:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:263:# TODO: (Amy) Move to image_transforms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:660:        # TODO: (Amy)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:607:        # TODO: Check fp32 layer norm possiblity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:454:        # TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:49:# TODO: Replace all occurrences of the checkpoint with the final one
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:242:        # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:545:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:754:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:1012:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:2202:        # TODO: we have no attention_mask so this won't work, check if we really won't need attention mask and find another way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:265:            TODO: add aspect_ratio_ids and aspect_ratio_mask and cross_attention_mask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:537:        # TODO Come up with footnote formatting inside a table
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:661:        # TODO: (Amy)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:659:        # TODO: remove the redundant computation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:774:        # TODO replace this with
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1031:        # TODO: This code is most likely not very efficient and should be improved
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:394:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:593:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:604:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:648:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:705:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:726:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1415:        # TODO (Joao): investigate why Speech2Text has numerical issues in XLA generate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:317:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:40:# TODO(PVP) - this should be removed in Transformers v5
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:38:# TODO(PVP) - this should be removed in Transformers v5
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1942:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:188:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:404:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:448:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:522:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:865:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaModel with Llama->Olmoe
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:58:# TODO: Could have better fused kernels depending on scaling, dropout and head mask.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:284:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:521:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:636:# TODO - (Amy) make compatible with other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:659:# TODO - (Amy) make compatible with other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1039:    # TODO (Amy) - update to use `rescale_factor` instead of `scale`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1500:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:475:        # TODO find a better way of exposing other arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:495:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:624:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:601:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:730:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1560:        >>> # TODO: Add full pretraining example
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1597:        # TODO(PVP) - add negative sampling & loss computation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:400:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:411:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:450:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:508:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:530:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:783:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1261:                # TODO(ls): Add cross attention values to respective lists
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1434:                # TODO(ls): Add cross attention values to respective lists
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:2127:        # TODO: As is this currently fails with saved_model=True, because
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:451:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:543:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:107:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:1247:            # TODO(SS): do we need to ignore pad tokens in labels?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:188:            # TODO: figure this case out.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:288:            # TODO: test this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bloom/configuration_bloom.py:156:            # TODO: how to do that better?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:64:    TODO @thomasw21 this doesn't work as nicely due to the masking strategy, and so masking varies slightly.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bloom/tokenization_bloom_fast.py:113:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/starcoder2/modeling_starcoder2.py:305:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/perceiver/tokenization_perceiver.py:182:    # TODO @ArthurZ refactor this as well....
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:193:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:523:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:534:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:573:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:631:# TODO cyril: modular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:653:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:153:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:502:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/cohere/modeling_cohere.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:505:            # TODO(Patrick): if we train more RAG models, I want to put the input first to take advantage of effortless truncation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:506:            # TODO(piktus): better handling of truncation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:415:            # TODO: make sure we are using `FacebookAI/xlm-mlm-enro-1024`, since XLM-100 doesn't have this step
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:431:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:331:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:385:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:458:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:579:        # TODO refer to https://github.com/ArthurZucker/transformers/blob/0f0a3fe5ca5697ee58faeb5b53f049af720b5e98/src/transformers/models/vit_mae/modeling_vit_mae.py#L871
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:120:        # TODO Remove this logic in a subsequent release since subsequences are not supported.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:353:        self.max_position_embeddings = 16384  # TODO Can't derive this from model files: where to set it?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:375:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:445:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:526:            qlen: TODO Lysandre didn't fill
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:527:            mlen: TODO Lysandre didn't fill
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:526:        # TODO find a better way of exposing other arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1123:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1525:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1527:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:489:        # TODO find a better way of exposing other arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:272:        # Tokenizer arguments TODO: eventually tokenizer and models should share the same config
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:396:            # TODO (joao): this should be an exception if the user has modified the loaded config. See #33886
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:62:                # TODO: Update message once eetq releases a fix
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:317:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_awq.py:125:            model._awq_is_fused = True  # TODO: consider storing this flag in model.config instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:274:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mdurl/_parse.py:168:            # v0.12 TODO(isaacs): This is not quite how Chrome does things.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py:26:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/markdown_it/parser_inline.py:96:            # TODO: remove this workaround when CM standard will allow nested links
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/numpy_pickle_utils.py:237:    TODO python2_drop: is it still needed? The docstring mentions python 2.6
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/pool.py:49:    TODO python2_drop : can this be simplified ?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/memory.py:44:# TODO: The following object should have a data store object as a sub
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/memory.py:53:# TODO: Same remark for the logger, and probably use the Python logging
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/memory.py:583:            # TODO (pierreglaser): do the same with get_func_name?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/_store_backends.py:209:                        # TODO(1.5) turn into error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/_memmapping_reducer.py:164:        # TODO: check scipy sparse datastructure if scipy is installed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/parallel.py:2054:            # TODO: this iterator should be batch_size * n_jobs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/test/common.py:18:# TODO straight removal since in joblib.test.common?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/test/common.py:44:# TODO: Turn this back on after refactoring yield based tests in test_hashing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:146:    # TODO: test that the cache related to the function cache persists across
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:170:            # TODO when Python 3.11 is the minimum supported version, use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/compressor.py:235:    TODO python2_drop: is it still needed since we dropped Python 2 support A
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/externals/cloudpickle/cloudpickle.py:1342:        # TODO: decorrelate reducer_override (which is tied to CPython's
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/externals/loky/_base.py:20:# TODO investigate why using `concurrent.futures.Future` directly does not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py:11:# TODO: investigate which Python version is required to be able to use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/func_inspect.py:168:        # TODO: Maybe add a warning here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/boto3/resources/factory.py:586:                    # TODO: Make this configurable in the future?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/boto3/resources/response.py:151:        # TODO: Remove the '$' check after JMESPath supports it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/rrule.py:1182:                    # TODO: Check -numweeks for next year.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:55:# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:265:                ("Tue", "Tuesday"),     # TODO: "Tues"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:267:                ("Thu", "Thursday"),    # TODO: "Thurs"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:272:              ("Feb", "February"),      # TODO: "Febr"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:291:    # TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:777:                                # TODO: not hit in tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:815:                    # TODO: check that l[i + 1] is integer?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:823:                        min_offset = int(l[i + 3])  # TODO: Check that l[i+3] is minute-like?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:910:                # TODO: Check if res attributes already set.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:934:                # TODO: checking that hour/minute/second are not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:941:            value = self._to_decimal(tokens[idx + 2])  # TODO: try/except for this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1032:            # TODO: Are we sure this is the right condition here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1100:        # TODO: Every usage of this function sets res.second to the return
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1112:        # TODO: Is this going to admit a lot of false-positives for when we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:25:    except IOError as e:  # TODO  switch to FileNotFoundError?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:76:# TODO: Remove after deprecation period.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:839:            # TODO: What could we test if loss.approx_hessian?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:874:                # TODO: What could we test if loss.approx_hessian?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_plotting.py:167:        # TODO(1.9): Remove deprecated **kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:258:    # TODO: test with intercept
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:259:    # TODO: test with multiple responses
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:789:            TODO(1.8): remove return value
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:831:    # TODO(1.8): remove generate_only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:1117:        # TODO There are a few errors in SearchCV with array-api-strict because
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3454:    # TODO: find out why PLS and CCA fail. RANSAC is random
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3795:        # TODO(devtools): this should be a separate check.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3827:                    # TODO(devtools): separately check that the constructor doesn't
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:499:# TODO(devtools): allow third-party developers to pass test specific params to checks
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:501:    # TODO(devtools): check that function names here exist in checks for the estimator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:565:    # TODO(1.9) simplify when averaged_inverted_cdf is the default
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:604:            # TODO: dual=True is a stochastic solver: we cannot rely on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:824:    # TODO(devtools): enable this behavior for third party estimators as well
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:853:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:862:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:871:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:880:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:893:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:902:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:941:        # TODO: investigate failure see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:950:        # TODO: investigate failure see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:983:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:992:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1001:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1015:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1027:        # TODO: replace by a statistical test when _dual=True, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1039:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1048:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1057:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1067:        # TODO: fix sample_weight handling of this estimator when probability=False
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1068:        # TODO: replace by a statistical test when probability=True
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1081:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1095:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1104:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1126:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1135:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1148:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1157:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1179:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1188:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1197:        # TODO: replace by a statistical test, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1229:        # TODO: fix sample_weight handling of this estimator when probability=False
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1230:        # TODO: replace by a statistical test when probability=True
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1240:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1258:# TODO: remove when scipy min version >= 1.11
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1285:        # TODO: remove when scipy min version >= 1.16
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:35:# TODO: We can consider removing the containers and importing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:58:# TODO: Remove when SciPy 1.11 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:71:# TODO: Remove when Scipy 1.12 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:84:# TODO : remove this when required minimum version of scipy >= 1.9.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:116:# TODO: Fuse the modern implementations of _sparse_min_max and _sparse_nan_min_max
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:224:# TODO: Adapt when Pandas > 2.2 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:238:# TODO: remove when SciPy 1.12 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:285:# TODO: remove when SciPy 1.12 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:355:# TODO: Remove when Scipy 1.12 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:200:    # TODO(1.9) remove UserList when the force_int_remainder_cols param
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:315:        # TODO: we should probably use _is_pandas_df_or_series(X) instead but:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:372:            # TODO(1.3): check if the warning is still raised or remove the filter.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:22:# TODO: complete __all__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:572:    # TODO: Update to use `__array_namespace__info__()` from array-api v2023.12
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:673:    # TODO: Remove this once https://github.com/scipy/scipy/issues/21736 is fixed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:682:    # TODO: refactor once nan-aware reductions are standardized:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:702:    # TODO: refactor once nan-aware reductions are standardized:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:722:    # TODO: refactor once nan-aware reductions are standardized:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:850:    # TODO: once sufficiently adopted, we might want to instead rely on the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:986:    # TODO: update if bincount is ever adopted in a future version of the standard:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_testing.py:1373:        # TODO: remove when pyamg > 5.0.1
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/optimize.py:95:        # TODO: It seems that the new check for the sum of absolute gradients above
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:654:    # TODO: Remove when the minimum version of SciPy supported is 1.12
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2408:        # TODO: remove the pandas-specific branch once the minimum supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_extmath.py:226:    # more accurate but slow (TODO find realistic settings here)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_plotting.py:217:# TODO(1.9) : Remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:24:# TODO: add this estimator into the _mocking module in a further refactoring
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:2338:# TODO(1.8): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:40:# TODO(1.8): Update when implementing __sklearn_tags__ is required
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:92:# TODO(1.8): Update this test to check for errors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_array_api.py:297:# TODO: add cupy to the list of libraries once the following upstream issue
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:127:# TODO(1.8): remove force_all_finite and change the default value of ensure_all_finite
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:251:# TODO(1.8): Remove this function
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:327:        # TODO(1.8): turn the warning into an error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/stats.py:116:# TODO: refactor to do the symmetrisation inside _weighted_percentile to avoid
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:292:        # TODO(1.9): remove and switch to quantile_method="averaged_inverted_cdf"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:360:                    # TODO: make _weighted_percentile and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2351:        # TODO: This should be refactored because binarize also calls
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:480:    ## TODO: change to averaged inverted cdf, but that means we only get bin
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:519:    # TODO this check is redundant with common checks and can be removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:957:        # TODO: Remove this condition, once scipy 1.10 is the minimum version.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1120:            # TODO: Remove this conditional error when the minimum supported version of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1144:            # TODO: Remove ones scipy 1.10 is the minimum version. See comments above.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:108:    # TODO: Use loss.fit_intercept_only where appropriate instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:257:            # TODO: Multiply here by learning rate instead of everywhere else.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:449:        # TODO: Without oob, i.e. with self.subsample = 1.0, we could call
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:672:        y = column_or_1d(y, warn=True)  # TODO: Is this still required?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_base.py:23:    # TODO(SLEP6): remove if-condition for unrouted sample_weight when metadata
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:116:    # TODO: (slep6) remove if condition for unrouted sample_weight when metadata
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:155:        # TODO(SLEP6): remove if condition for unrouted sample_weight when metadata
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py:140:        # TODO: consider always using platform agnostic dtypes for fitted
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:15:# TODO(1.8) remove the filterwarnings decorator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:107:        # TODO: We are not entirely satisfied with this lax comparison, but the root
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:125:# TODO(1.8) remove the filterwarnings decorator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:202:# TODO(1.8) remove the filterwarnings decorator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:90:    # TODO: Ideally this should be computed in parallel over the leaves using something
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:125:    TODO: in the future, we could explore the possibility to extend the scorer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:572:            # TODO: remove when PDP supports sample weights
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:682:                # TODO: incorporate sample_weight in sampling here, as well as
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1086:        # TODO: incorporate sample_weights here in `resample`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:2225:        # TODO: This could be done in parallel
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py:327:        # TODO: complexity is O(n_categorical_features * 255). Maybe this is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:490:    # TODO(1.8): remove "algorithm" entry
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:745:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:1129:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_weight_boosting.py:635:# TODO(1.8): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/isotonic.py:164:        # TODO: remove this branch when Scipy 1.12 is the minimum supported version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:655:                # TODO: incorporate sample_weight in sampling here.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neural_network/_base.py:211:    # TODO: Decide what to do with the term `xlogy(y_true, y_true) - y_true`. For now,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:330:            # TODO: systematize this mapping of metric for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:338:                # TODO: Implement efficient multi-output solution
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:363:                    # TODO: adapt the heuristic for `strategy="auto"` for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:36:# TODO: implement a brute force version for testing purposes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:37:# TODO: create a density estimation base class?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:330:        # TODO: implement sampling for other valid kernel shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:378:        # TODO: also test radius_neighbors, but requires different assertion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1623:# TODO: remove when NearestNeighbors methods uses parameter validation mechanism
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1727:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2253:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2488:    # TODO: if score is refactored to evaluate models for other scoring
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_lof.py:252:    # TODO: compare results on dense and sparse data as proposed in:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/calibration.py:329:            # TODO(1.8): Remove this code branch and cv='prefit'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/calibration.py:863:        # TODO: Remove casting to np.float64 when minimum supported SciPy is 1.11.2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:658:    # TODO(1.9): Remove base_estimator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:676:    # TODO(1.8): This is a temporary getter method to validate input wrt deprecation.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:791:            # TODO: remove this condition check when the minimum supported scipy version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1037:    # TODO(1.9): Remove base_estimator from __init__
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:372:        # TODO: for Scipy <= 1.10, `isspmatrix(X)` returns `True` for sparse arrays.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:1060:# TODO this class should fit on either p-values or scores,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:225:    # TODO(1.8) remove this property
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:791:    # TODO(1.8): remove `groups` from the signature after deprecation cycle.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:377:                # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:461:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/_optics.py:621:    # TODO: handle working_memory somehow?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:772:                # TODO: Support np.nan in Cython implementation for precomputed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:834:                # TODO: Benchmark KD vs Ball Tree efficiency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:938:                # TODO: Implement weighted argmin PWD backend
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_birch.py:245:# TODO(1.8): Remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:30:# TODO: AffinityPropagation must preserve dtype for its fitted attributes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:114:    # TODO: we should handle missing values (i.e. `np.nan`) specifically and store them
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:716:            # TODO(1.9): raise a ValueError instead.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:682:    # TODO: extend to HistGradientBoosting once sample_weight is supported
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:705:    # TODO: remove/fix when PDP supports HGBT with sample weights
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:510:    # TODO(1.8): Remove this attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:583:    # TODO(1.8): Remove this attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:659:    # TODO(1.8): Remove this attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:1012:    # TODO(1.8): Remove this attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:1062:    # TODO(1.8): Remove this attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:1202:    # TODO(1.8): Remove this check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:1242:    # TODO(1.8): Remove this check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:1284:    # TODO(1.8): Remove this check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/base.py:1309:    # TODO(1.8): Remove this check
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:551:    # TODO We can do this cheaper; sorted_indices copies the whole matrix.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:570:        # TODO: simplify interfaces and implementations in _svmlight_format_fast.pyx.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/datasets/_arff_parser.py:67:    # TODO: improve for efficiency
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:341:        # TODO: feature request OpenML.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:640:        # TODO (1.8): remove this once the deprecation is removed. In the meantime,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:654:            # TODO (1.8): remove this once the deprecation is removed to keep only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:663:            # TODO (1.8): remove this once the deprecation is removed to keep only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:684:                # TODO (1.8): remove this `if` branch once the following issue is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:468:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:571:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:13:    # TODO: remove this check once the estimator is no longer experimental.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:19:# TODO: remove this check once the estimator is no longer experimental.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:413:# TODO (1.8): check that `keep_empty_features=False` drop the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:429:# TODO (1.8): check that `keep_empty_features=False` drop the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:459:# TODO (1.8): check that `keep_empty_features=False` drop the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:495:# TODO (1.8): check that `keep_empty_features=False` drop the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1550:# TODO (1.8): check that `keep_empty_features=False` drop the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1761:        # TODO(1.8): Remove the condition and still call getattr(imputer, method)(X)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1259:        TODO: Remove when ``set_config(enable_metadata_routing=False)`` is no
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/compose/tests/test_column_transformer.py:975:# TODO(1.9): remove this test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:50:    TODO(1.8): remove this context manager and replace with check_is_fitted.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:406:    # TODO(1.8): Remove this property
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:780:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:896:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:943:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:981:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1027:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1082:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1127:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1178:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1902:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1951:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:2024:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:446:                # TODO: tree shouldn't need this in this case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:624:                # TODO: the tree shouldn't need this param
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:170:        # TODO(slep006): remove when metadata routing is the only way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:239:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:251:        # TODO(slep006): remove when metadata routing is the only way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:296:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:456:                # TODO (1.8): scoring="max_error" has been deprecated in 1.6,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:498:        # TODO(slep006): remove when metadata routing is the only way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:738:# TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2200:    # TODO(1.9): When `raise_warning` is removed, the following changes need to be made:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_supervised.py:1256:    # TODO(1.9): remove the sparse parameter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/tests/test_supervised.py:515:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:398:    TODO: use a float64 accumulator in row_norms to avoid the latter.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1972:        # TODO: do it also for other norms.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:80:            # TODO: implement a stable simultaneous_sort.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:128:                # TODO: support CSR matrices without non-zeros elements
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:131:                # TODO: support CSR matrices with int64 indices and indptr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:476:            # TODO: implement Euclidean specialization using GEMM.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:644:            # TODO: implement Euclidean specialization using GEMM.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1398:    # TODO: remove when enable_metadata_routing is deprecated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1656:# TODO(1.8): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_classification.py:762:# TODO(1.9): remove test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:366:# TODO: Handle multi_class metrics that has a labels argument as well as a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:975:            # TODO those metrics doesn't support string label yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:179:        # TODO Fix manhattan_distances to preserve dtype.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:190:        # TODO Fix manhattan_distances to preserve dtype.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:1672:# TODO(1.8): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:709:    # TODO: support CSR matrices without non-zeros elements
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:716:    # TODO: support CSR matrices with int64 indices and indptr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:913:    # TODO: introduce assertions on UserWarnings once the Euclidean specialisation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:80:            # TODO: Inspect slight numerical discrepancy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:164:            # TODO: Inspect slight numerical discrepancy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/roc_curve.py:581:        # TODO(1.9): remove after the end of the deprecation period of `y_pred`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:325:# TODO(1.9): Remove in 1.9
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:334:# TODO(1.9): Remove in 1.9
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:926:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:939:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_common_curve_display.py:167:# TODO: remove this test once classes moved to using `name` instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:229:        # TODO: if alpha=0 check that X is not rank deficient
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:401:        # TODO: Adapt link to User Guide in the docstring, once
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:405:        # TODO: make D^2 a score function in module metrics (and thereby get
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:398:            # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:47:# TODO: bayesian_ridge_regression and bayesian_regression_ard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:154:        Always an array of ones. TODO: refactor the code base to make it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:205:# TODO: _rescale_data should be factored into _preprocess_data.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:832:            # TODO: instead of warning and recomputing, we could just center
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:16:    # TODO: This "sandwich product" is the main computational bottleneck for solvers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1251:        # TODO(1.8) remove multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1362:        # TODO: Refactor this to avoid joblib parallelism entirely when doing binary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1923:        # TODO(1.8) remove multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:813:        # TODO: better names for these variables: z
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:870:                # TODO: this could be updated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:882:                # Cov_n = Cov_j + x_j * X + increment(betas) TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:888:                # TODO: this could be updated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1685:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1714:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1732:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1750:# TODO(1.9): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_theil_sen.py:298:# TODO(1.8): Remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_common.py:66:        # TODO: FIx SAGA which fails badly with sample_weights.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:150:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:202:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:254:# TODO(1.8): remove whole test with deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:279:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:619:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:705:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1306:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1350:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1486:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1746:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1794:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1833:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1963:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2137:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2182:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2360:# TODO(1.8): remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2427:# TODO(1.8): check for an error instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_sag.py:490:    # TODO: uncomment when sparse Ridge with intercept will be fixed (#4710)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:29:# TODO: use another dataset that has multiple drops
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:120:# TODO: remove warning filter when numpy min version >= 2.0.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:132:# TODO: remove warning filter when numpy min version >= 2.0.0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1500:        # TODO(1.9): remove "warn" and None options.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1607:        # TODO(1.9): remove n_alphas and alphas={"warn", None}; set alphas=100 by
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_omp.py:1065:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:164:        # TODO(1.8) remove None option
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:166:        # TODO(1.8) remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:195:        # TODO(1.8) remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:206:        # TODO(1.8): remove and only keep clone(self.estimator)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:217:        # TODO(1.8) remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:622:        # TODO(1.8): remove the condition check together with base_estimator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/tests/test_self_training.py:349:# TODO(1.8): remove in 1.8
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:60:    # TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:86:# TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:364:                # TODO(SLEP6): also pass metadata to the predict method for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1182:                # TODO(SLEP6): also pass metadata for the predict method.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1637:                # TODO(SLEP6): also pass metadata to the predict method for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1982:                # TODO(SLEP6): also pass metadata to the predict method for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:480:    # TODO(1.8) remove this property
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:862:        # TODO(slep006): remove when metadata routing is the only way
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:46:    # TODO: remove this check once the estimator is no longer experimental.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:90:# TODO: remove this check once the estimator is no longer experimental.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_validation.py:2471:# TODO(1.8): remove `learning_curve`, `validation_curve` and `permutation_test_score`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:1117:    # Test the IID parameter  TODO: Clearly this test does something else???
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:192:# TODO(1.9): change default `n_init` to 1, see PR #31117
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:430:# TODO(1.9): change default `n_init` to 1, see PR #31117
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:341:    # TODO: compare results on dense and sparse data as proposed in:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:1068:        # TODO: re-enable this test if/when `manhattan_distances` is refactored to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:122:# TODO(1.9): remove warning filter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:136:# TODO(1.9): remove warning filter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:175:# TODO(1.9): remove warning filter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:202:# TODO(1.9): remove warning filter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:225:# TODO(1.9): delete this test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:48:    # TODO: rewrite this test to make less sensitive to the random seed,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:121:    # TODO check that it actually does something useful
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_spectral_embedding.py:107:# TODO: investigate why this test is seed-sensitive on 32-bit Python
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:148:    # TODO check that it actually does something useful
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:234:    # TODO: compare results on dense and sparse data as proposed in:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:94:        # TODO(jjerphan): Once SciPy 1.11.3 is the minimum supported version, use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/conftest.py:212:        # TODO: configure numpy to output scalar arrays as regular Python scalars
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:315:            # TODO: add keyword copy to copy on demand
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_helper.c:158:     * TODO: does this provoke memory leaks (we just malloc'ed them)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:84: * TODO: precomputed kernel.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:386: * TODO: merge in the cython layer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_svm.py:4:TODO: remove hard coded numerical results when possible
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_bounds.py:17:# TODO(1.8): remove filterwarnings after the deprecation of liblinear multiclass
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_metaestimators.py:279:# TODO: remove data validation for the following estimators
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstrings.py:191:    # TODO: this detection can be improved. Currently we assume that we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:867:# TODO(1.9):  remove when deprecated `base_estimator` is removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:124:# TODO(1.8): remove test when generate_only is removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:229:                # TODO: FIX MLP to not check validation set during MLP
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:272:# TODO: As more modules support get_feature_names_out they should be removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:2063:# TODO(1.8): change warning to checking for NotFittedError
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:308:    # TODO(1.8): Remove cv="prefit" options here and the @ignore_warnings of the test
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:1119:    # TODO(1.8): remove me once the deprecation period is over.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_metadata_routing.py:912:    # TODO: these test classes can be moved to sklearn.utils._testing once we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_base.py:271:# TODO(1.8): Remove this test when the deprecation is removed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:203:        # TODO(devtools): use _tested_estimators instead of all_estimators in the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:223:    # TODO(1.9) remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:227:    # TODO(1.9) remove
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:171:        # TODO: Does this depend on device?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:233:        # TODO: Does this depend on device?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:63:    # TODO: Should we reject ndarray subclasses?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:95:    # TODO: Should we reject ndarray subclasses?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:123:    # TODO: Should we reject ndarray subclasses?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:238:    # TODO: Account for other backends.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:580:            # TODO: Support Python scalars?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:793:        # TODO: What if our array is on the GPU already?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:277:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:334:    # TODO: np.clip has other ufunc kwargs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:36:# TODO: use the QR wrapper once dask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:60:    # TODO: can't avoid computing U or V for dask
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:67:    # TODO: respect device keyword?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:97:    # TODO: respect device keyword?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:168:    # TODO: respect device keyword?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:229:    # TODO: This won't handle dask unknown shapes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_at.py:21:    # TODO import from typing (requires Python >=3.11)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_utils/_helpers.py:20:    # TODO import from typing (requires Python >=3.13)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/testing.py:20:    # TODO import override from typing (requires Python >=3.12)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:564:        # TODO: remove the following two lines when scikit-learn only depends
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:617:            # TODO: remove the following two lines when scikit-learn only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:778:        # TODO: update this code to either:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:142:        # TODO: Make verbosity argument for Lasso?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:158:            # TODO: move this handling (which is currently too broad)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/_lda.py:462:        # TODO: make Parallel._effective_n_jobs public instead?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:617:    # TODO: explain what this is testing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:634:    # TODO: explain what this is testing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_nmf.py:992:        # TODO: use the provided W when init="custom".
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:116:        # TODO: Explore the choice of using bincount + add.at as it seems sub optimal
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/asyn.py:347:        # TODO: implement on_error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/asyn.py:511:        # TODO: on_error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/asyn.py:998:    # TODO: readahead might still be useful here, but needs async version
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/generic.py:327:        # TODO: special case for one FS being local, which can use get/put
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/generic.py:328:        # TODO: special case for one being memFS, which can use cat/pipe
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/utils.py:302:    # TODO: allow length to be None and read to the end of the file?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:78:            # TODO: tarfile already implements compression with modes like "'r:gz'",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:92:        # TODO: load and set saved index, if exists
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:101:        # TODO: save index to self.index_store here, if set
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:322:            # TODO: action where partial file exists in read-only cache
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:394:        # TODO: use transaction support in SMB protocol
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/cache_metadata.py:158:                # TODO: consolidate blocks here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/http.py:104:        # TODO: Maybe rename `self.kwargs` to `self.request_options` to make
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:147:        # TODO: derive fs from `root`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:473:        # TODO: only save needed columns
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:546:        # TODO: only clear those that we wrote to?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:748:            # TODO: warning here, since this can be very expensive?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:884:        # TODO: if references is lazy, pre-fetch all paths in batch before access
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:985:        # TODO: we make dircache by iterating over all entries, but for Spec >= 1,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:352:    # TODO: if all incoming paths were posix-compliant then separator would
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:393:                # TODO: check if path is writable?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:105:        # TODO: encoding from headers
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:883:    # TODO: not allowed in JS
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:896:    # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/spec.py:493:        # TODO: allow equivalent of -name parameter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/compression.py:13:# TODO: files should also be available as contexts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/caching.py:94:        # TODO: use rich for better formatting
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/fsspec/caching.py:502:        # TODO: only set start/end after fetch, in case it fails?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:214:    # TODO allow pos to be None and use a nice TikZ default
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:277:        # TODO -- handle bending of multiedges
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:2499:        # TODO should this be list or array (as in a numpy array)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:792:            Ai = A.getrowview(i).toarray()  # TODO: revisit w/ sparse 1D container
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:1152:    # TODO: Rm csr_array wrapper in favor of spdiags array constructor when available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:75:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:77:    # TODO: Rm csr_array wrapper when eye array creation becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:128:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:238:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:244:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:341:        # TODO: rm csr_array wrapper when spdiags creates arrays
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:344:        # TODO: rm csr_array wrapper when spdiags creates arrays
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:436:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:498:        # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:503:            # TODO: Rm csr_array wrapper when identity array creation becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:192:        # TODO: rm csr_array wrapper when spdiags array creation becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:279:                # TODO: rm csc_array wrapping when spdiags array becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:296:                # TODO: rm csr_array wrapping when spdiags array becomes available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:129:    # TODO: Remove between the lines when `link` deprecation expires
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:274:    # TODO: Remove between the lines when `link` deprecation expires
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/tests/test_node_link.py:27:    # TODO: To be removed when signature change complete
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:463:    # TODO: csr_array
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/tests/test_connectivity.py:138:        # TODO Is this really the intended behavior for providing a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:94:    # TODO: csr_array
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:173:    # TODO: csr_array
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/dag.py:1175:    # TODO In Python 3, this would be better as `yield from ...`.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/efficiency_measures.py:118:    # TODO This can be made more efficient by computing all pairs shortest
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/distance_regular.py:184:# TODO There is a definition for directed strongly regular graphs.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/dominating_set.py:22:# TODO Why doesn't this algorithm work for directed graphs?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:805:            # TODO: this branch does not restore original_edge_weights of G!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/clique.py:300:# TODO Should this also be not implemented for directed graphs?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/walks.py:72:    # TODO: Use matrix_power from scipy.sparse when available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/coloring/equitable_coloring.py:163:        # TODO: Checking whether a color has been visited can be made faster by
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:686:    # TODO: support DiGraph
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:111:    # TODO This can be trivially parallelized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:206:    # TODO This can be trivially parallelized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:1135:    # TODO This can be trivially parallelized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:181:    # TODO This can be trivially parallelized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:475:    # TODO This can be trivially parallelized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:276:            # TODO - The lines between --- were unused and were thus commented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:282:            #     # TODO Why is extra inner loop necessary?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:287:            # TODO Originally, this function returned a three-tuple:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/redundancy.py:93:    # TODO This can be trivially parallelized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/tests/test_matching.py:110:        # TODO Assert that the vertices are the correct ones.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:124:        # TODO This can be parallelized, both in the outer loop over
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:132:        # TODO This loop can be parallelized, to an extent (the union
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:11:# TODO: Implement method from Gabow, Galil, Spence and Tarjan:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/cycles.py:841:                if thisnode not in B[nextnode]:  # TODO: use set for speedup?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:217:        # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:292:        # TODO: graph and subgraph setter methods that invalidate the caches.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:293:        # TODO: allow for precomputed partitions and colors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_swap.py:40:    # TODO: Rewrite function to explicitly check for impossible swaps and raise error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:97:            # TODO: investigate https://arxiv.org/abs/1412.6466 for k=2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:314:    # @not_implemented_for('multigraph')  # TODO: fix decor for classmethods
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/traversal/beamsearch.py:77:        # TODO The Python documentation states that for small values, it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:19:# TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:322:# TODO What is the generalization to two arguments, S and T? Does the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:362:# TODO What is the generalization to two arguments, S and T? Does the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/conftest.py:102:# TODO: The warnings below need to be dealt with, but for now we silence them.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/generators/geometric.py:190:    # TODO Is this function just a special case of the geographical
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/generators/community.py:1034:    # TODO The original code incremented the number of iterations each
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/generators/tests/test_expanders.py:37:    # TODO The second largest eigenvalue should be smaller than a constant,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/generators/degree_seq.py:671:    # TODO Does this need to be sorted in reverse order?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pynvml/nvml.py:1089:#     # TODO handle the error
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:265:            # TODO: reasonable sign of infinity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/factorials.py:112:    # TODO: fixme, obviously
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/theta.py:926:    # TODO: write _jacobi_theta2a and _jacobi_theta3a using fixed-point
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:18:    # TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:313:        # TODO: something else is required here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:373:    # TODO: correct evaluation at singularities
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:28:        # TODO: the integer special-casing shouldn't be necessary.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:147:    # TODO: avoid cancellation for imaginary arguments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:384:# TODO: do this more generically?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:423:# TODO: could be expressed more elegantly using triple factorials
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:468:        # TODO: limits
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:521:                # TODO: asymptotic series for derivatives
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:562:        # TODO: limits
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:718:    # TODO: check that chop=True chops when and only when it should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:757:    # TODO: check that chop=True chops when and only when it should
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:833:    TODO: this can be optimized, e.g. by reusing evaluation points.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:878:                # TODO: use v <= j'_{v,1} < y_{v,1}?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:238:# TODO: fix the interface wrt contexts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:287:# TODO: for bernpoly and eulerpoly, ensure that all exact zeros are covered
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:385:# TODO: this should be implemented low-level
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:620:    # TODO: implement for derivatives
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:697:            # TODO: the following could perhaps be tidied a bit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:11:        # Avoid division by zero in leading factors (TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:284:            # TODO: handle the all-real case more efficiently!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:285:            # TODO: figure out how much precision is needed (exponential growth)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:404:        # TODO: the following logic can be simplified
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:760:    # TODO: much of the following could be shared with 2F3 instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:832:    # TODO: much of the following could be shared with 2F3 instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1091:    # TODO: continuation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1107:    # TODO: continuation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:174:# TODO: tests; improve implementation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:182:    # TODO: accurately eval the smaller of the real/imag parts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:212:    # TODO: accurately eval the smaller of the real/imag part
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:257:            # TODO: this can be done *much* faster
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:604:    # TODO: the following could be generalized into a perfect
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/identification.py:273:        # slowly (e.g. a factor 1-10) with each step TODO: we could
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:306:    # TODO: add more of these, make consistent, write docstrings, ...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:171:    (TODO: find a better solution to this problem.)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1969:            # TODO: we are evaluating log(1+eps) -> eps, which is
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/differentiation.py:364:    TODO: most exponents are zero, so maybe a sparse representation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/odes.py:219:    **TODO**
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:264:            # TODO: maybe refactoring with function for divided differences
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:289:# TODO: consider raising a ValueError when there's no sign change in a and b
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:418:                # TODO: better condition (when f is very flat)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:457:# TODO: check whether it's possible to combine it with Illinois stuff
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:503:                # TODO: better condition (when f is very flat)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:560:            # TODO: decide not to use convergence acceleration
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:573:# TODO: add Brent
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:601:# TODO: test with user-specified jacobian matrix
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:665:            # damping step size TODO: better strategy (hard task)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:984:        if verify and norm(f(*xl))**2 > tol: # TODO: better condition?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:99:# TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:136:                if current > biggest: # TODO: what if equal?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:218:                    # TODO: necessary to check also b?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:239:            raise RuntimeError("need n*n matrix") # TODO: really?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:372:    # TODO: implement this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:4:# TODO: interpret list as vectors (for multiplication)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:208:        COMMENT: TODO: the above "doctest:+SKIP" may be removed as soon as we
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:3:# TODO: should use diagonalization-based algorithms
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:14:        TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/math2.py:207:        # TODO: sinpi
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/math2.py:221:        # TODO: sinpi
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/math2.py:359:# TODO: could implement complex erf and erfc here. Need
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:273:    # TODO: many more tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:404:    # TODO: need many more tests
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/torture.py:27:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/test_matrices.py:57:    # TODO remove exec() wrapper as soon as we drop support for Python <= 3.5
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/test_gammazeta.py:599:    # TODO: more tests for polyexp
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/test_linalg.py:1:# TODO: don't use round
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/runtests.py:57:# TODO: add a flag for this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:54:TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:199:        # TODO: when there are several real parameters and just a few complex
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:332:# TODO: mpf_erf should call mpf_erfc when appropriate (currently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:355:        # TODO: interval rounding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:617:            # TODO: could return finite imaginary value at -inf
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:911:# TODO: for extremely large x, we could use an asymptotic
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:914:# TODO: recompute at higher precision if the fixed-point mantissa
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1046:    TODO:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1081:    # TODO: for |x| << 1/2, one could use fall back to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:4:TODO: rename, cleanup, perhaps move the gmpy wrapper code
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:129:# TODO: speed up for bases 2, 4, 8, 16, ...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:458:    TODO: speed up using factorization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:342:    # TODO: handle rnd direction of the logarithm carefully
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:711:        # TODO: if close enough to 1, we could use Taylor series
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:876:# TODO: cleanup the special cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1158:        # TODO: the best cutoff depends on both x and the precision.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1249:    # TODO: optimize division precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:179:    # formula to the tail. TODO: choose more intelligently
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:626:TODO: the current estimation of N for m > 0 is *very suboptimal*.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:628:TODO: implement the reflection formula for m > 0, Re(z) << 0.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:633:TODO: maybe use exact algorithms to compute psi for integral
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1160:# TODO: optimize / cleanup interface / unify with list_primes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1383:    TODO: this is currently only used for gamma, but could
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1942:    # a fixed-point value. TODO: determine a precise cutoff of validity
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:498:    # TODO: handle cancellation when c ~=  -1 and ch ~= 1
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:584:# TODO: avoid loss of accuracy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:124:# TODO: optimize
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:367:    # TODO: combine evaluation code to avoid duplicate modulo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:631:    # TODO: optimize for real/imag cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:643:    # TODO: optimize for real/imag cases
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:670:    # TODO: accuracy for small x
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:759:    # TODO: recognize/speed up real cases, integer y
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:848:        # TODO: reflection formula
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:885:            # TODO: reflection formula
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1175:    # TODO: account for precision when doing this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1320:    TODO: the rounding does not work properly for large exponents.
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1024:/* TODO: remove */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1029:/* TODO: move these enums out to the appropriate submodule */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1073:/* TODO: remove */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1024:/* TODO: remove */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1029:/* TODO: move these enums out to the appropriate submodule */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1073:/* TODO: remove */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:81:/* TODO */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:88:/* TODO: Detect UWP, a.k.a. Windows Store app, and set this to 0. */
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cuda_runtime.h:1391: * TODO detail
./core/py/pipeline/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cooperative_groups.h:1173:// TODO: Use a static dispatch to determine appropriate return type
./core/py/pipeline/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:594:        # TODO: Add logic that removes the TransferState if the transfer is
./core/py/pipeline/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:644:        # TODO: Not all exceptions are pickleable so if we are running
./core/py/pipeline/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:899:    # TODO: It may make sense to expose these class variables as configuration
./core/py/pipeline/.venv/lib/python3.12/site-packages/s3transfer/__init__.py:857:                # TODO: we need a way to reset the callback if the
./core/py/pipeline/.venv/lib/python3.12/site-packages/psycopg2/tz.py:158:# TODO: pre-generate some interesting time zones?
./core/py/pipeline/.venv/lib/python3.12/site-packages/psycopg2/_range.py:526:# TODO: probably won't work with infs, nans and other tricky cases.
./core/py/pipeline/.venv/lib/python3.12/site-packages/cv2/__init__.py:19:# TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PdfParser.py:616:            # TODO: support reuse of deleted objects
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:2280:                    raise RuntimeError(msg)  # XXX TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/IcoImagePlugin.py:75:            # TODO: invent a more convenient method for proportional scalings
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:134:    #TODO: Add support for sets provided by the user
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1323:        # TODO : Remove when lambdify accepts 'pymc' as module
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1340:                # TODO: Replace the try-except block with only given_fn(*args)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1366:                    # TODO: Replace the try-except block with only given_fn(*args)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1383:            # TODO: Replace the try-except block with only fn(*args)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1610:            # TODO: do this for drv.py and frv.py if necessary.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1611:            # TODO: add more distributions here if there are more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:114:    ### TODO: Add tests after adding matrix distributions in numpy_rv_map
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/frv.py:460:            #TODO: Implement the mechanism for handling queries for symbolic sized distributions.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/drv.py:152:        # TODO: support discrete sets with non integer stepsizes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:415:            #TODO: Modify to support integration
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1694:    .. TODO - What is the difference between these degrees of freedom?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2986:    .. TODO - what does the parameter mean?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:77:        with ignore_warnings(UserWarning):  # TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:109:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:408:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:677:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1348:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1358:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_compound_rv.py:90:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_finite_rv.py:68:    # TODO: Make iid method!
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_mix.py:80:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/random_matrix_models.py:249:        # TODO : Add support for Lie groups(as extensions of sympy.diffgeom)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:10:# TODO: The code below could be made more granular with something like:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:74:    # TODO: How can we test that the output of a SyntaxError is the original
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:732:                    # TODO: Implement this case
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:868:                # TODO: support for singular initial condition
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:103:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/trigonometry.py:5:# TODO sin(a*x)*cos(b*x) -> sin((a+b)x) + sin((a-b)x) ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:38:# TODO: Add messages to NonElementaryIntegralException errors
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:205:    # TODO: finish writing this and write tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:286:    # TODO: finish writing this and write tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:510:# TODO: better name for this function
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:653:            # TODO: Write a dummy function that does this idiom
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:713:        # TODO: Is this check necessary, and if so, what should it do if it fails?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:772:        # check for regularity conditions (TODO), see issue 4215
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:201:        # TODO handle derivatives etc
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:745:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:119:    # TODO this needs more polar_lift (c/f entry for exp)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:164:    # TODO can do sin^n, sinh^n by expansion ... where?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:170:    # TODO can do t + a. but can also do by expansion... (XXX not really)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:187:    # TODO these only hold for positive p, and can be made more general
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:189:    # TODO also it would be nice to derive them recursively ...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:202:    # TODO log(x)/(x+a) and log(x)/(x-1) can also be done. should they
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:204:    # TODO further formulae in this section seem obscure
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:207:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:230:    # TODO exp(-x)*erf(I*x) does not work
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:256:    # TODO all of the following should be derivable
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:282:    # TODO many more formulas. should all be derivable
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:286:    # TODO many more formulas. should all be derivable
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:524:    # TODO should this be a method of meijerg?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:852:    # TODO altered cases 4-7
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:876:    # TODO This leaves only one case from the three listed by Prudnikov.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:900:    # XXX TODO we should reduce order first
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:972:    # TODO should we try both?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:988:    # XXX TODO this is a testing *nightmare*
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1445:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:2040:            # TODO: This is for future development, as currently
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:333:        # TODO: This probably doesn't need to be completely recomputed at
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:366:                    # TODO: Would there ever be any benefit from just
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:395:            # TODO: Just put it in self.Tfuncs
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:497:                    # TODO: Add something to backsubs to put exp(const*p)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:530:                        # TODO: give algebraic dependence in error string
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:779:    # TODO: Rewrite algorithms below to use this (?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:781:    # TODO: Pass through information about why the integral was nonelementary,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:798:    # TODO: This should go in densetools.py.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:855:    # TODO: Use this on the final result.  That way, we can avoid answers like
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1006:    # TODO: This algorithm appears to be faster in every case
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1007:    # TODO: Verify this and splitfactor() for multiple extensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1250:        # TODO also consider the complex roots which should
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1280:    # TODO: Use log_to_atan() from rationaltools.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1350:    # TODO: check what Lambda does with RootOf
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1365:    # TODO: verify that this is correct for multiple extensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1458:        # TODO: This does not do the right thing when b is False
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1621:    # TODO: Integral from k?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1622:    # TODO: split out nonelementary integral
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1691:    # TODO: This is useful in and of itself, because isinstance(result,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:114:    # TODO: Merge this with the very similar special_denom() in rde.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:158:                        # TODO: Add test
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:822:        # TODO: implement this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:878:    # TODO: finish writing this and write tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:921:        # TODO: We treat this as 'no solution', until the structure
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:952:    # TODO: Write the full algorithm using the structure theorems.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:957:        # TODO: This could be implemented more efficiently.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1035:        # TODO: What should really be done in this case?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1160:        # TODO: What should really be done in this case?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1185:            # TODO: But maybe we can tell if they're not rational, like
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1266:    # TODO: finish writing this and write tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1301:        # TODO: we can use more efficient residue reduction from ratint()
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:400:        # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:466:        # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:875:        # TODO not implemented yet, but also not important
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:977:        #  TODO : This part is quite hacky. Should be made more robust with
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:978:        #  TODO : respect to symbol names and scalable w.r.t higher dimensions.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:235:    # TODO: Skip or make faster
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:250:    # TODO: Add tests for integrate_hyperexponential() from the book
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:374:    # TODO: Add a test where two different parts of the extension use a
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:110:    # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:698:    # TODO sinh/cosh shifted come out a mess. also delayed trig is a mess
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:699:    # TODO should this simplify further?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:714:    # TODO can we make erf(t) work?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:756:    # TODO LT of Si, Shi, Chi is a mess ...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_trigonometry.py:32:    # TODO: remove conds='none' below. For this to work we would have to rule
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:328:    # TODO: Remove conds='none' below, let the assumption take care of it.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1140:    # TODO: Remove conds='none' below, let the assumption take care of it.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1329:    # TODO: How to test risch=False?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:149:    # TODO what simplifications should be done automatically?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:165:    # TODO it would be nice to test the condition
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:245:    # TODO more orthogonality integrals
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:257:    # TODO can do higher powers, but come out as high order ... should they be
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:262:    # TODO more besseli when tables are extended or recursive mellin works
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:273:    # TODO how does besselj(0, a*x)*besselj(0, b*x) work?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:274:    # TODO how does besselj(0, x)**2*besselj(1, x)**2 work?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:275:    # TODO sin(x)*besselj(0, x) etc come out a mess
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:276:    # TODO can x*log(x)*besselj(0, x) be done?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:277:    # TODO how does besselj(1, x)*besselj(0, x+a) work?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:278:    # TODO more indefinite integrals when struve functions etc are implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:374:    # TODO gammasimp cannot prove that the factor is unity
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:517:    # TODO conditions are a mess
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:523:    # TODO gamma, rayleigh
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:579:    # TODO are there other distributions supported on (-oo, oo) that we can do?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:658:    # TODO maybe simplify the inequalities? when the simplification
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:668:    # TODO FT(besselj(0,x)) - conditions are messy (but for acceptable reasons)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:105:    # TODO: when bound_degree() can handle this, test degree bound from that too
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:147:    # TODO: Add test for deg(b) <= 0 with b small
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:262:    # TODO: Add more tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:280:    # TODO: Add more tests, including ones with exponentials
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:80:    # TODO does not work with bneg, argument wrong. Needs changes to matching.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:164:    # TODO we cannot currently do these (needs summation of 3F2(-1))
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:244:    # TODO we can't do any of these (delicate cancellation)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:253:    # TODO bessely(a, x)*besselk(a, x) is a mess
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:264:    # TODO products of besselk are a mess
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:271:    # TODO exp(x/2)*besselk(a, x/2) [etc] cannot currently be done
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:272:    # TODO various strange products of special orders
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:386:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:420:    # TODO this comes out as an amazing mess, but simplifies nicely
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:436:    # TODO this can be further simplified!
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:444:    # TODO more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:466:    # TODO for this to work with real a, need to expand abs(a*x) to abs(a)*abs(x)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:479:    # TODO IFT is a *mess*
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:481:    # TODO IFT
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:492:    # TODO IFT without factoring comes out as meijer g
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:502:    # TODO IFT (comes out as meijer G)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:504:    # TODO besselj(n, x), n an integer > 0 actually can be done...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:506:    # TODO are there other common transforms (no distributions!)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:221:    # TODO: it looks like this used to work just by coincindence and
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:254:    # TODO: heurisch() is off by a constant: -3/4. Possibly different permutation
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:343:# TODO: convert the rest of PMINT tests:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:71:    # TODO: add more tests here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:114:    # TODO: Add test for when the degree bound becomes larger after limited_integrate
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:115:    # TODO: Add test for db == da - 1 case
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:118:    # TODO: Add tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:119:    # TODO: Add test for when the degree becomes larger after parametric_log_deriv()
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:179:    # TODO: Add more exp tests, including tests that require is_deriv_in_field()
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:193:    # TODO: Add more primitive tests, including tests that require is_deriv_in_field()
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:197:    # TODO: Add more tests for rischDE, including ones from the text
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:495:    # TODO: caching is significant factor for why permutations work at all. Change this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:700:        # TODO: Currently it's better to use symbolic expressions here instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:726:                # TODO: Non-polynomial expression. This should have been
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/exprtools.py:1551:            # XXX TODO there should be a way to inspect what order the terms
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:139:       TODO: write about
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:310:        """process a -> b rule"""   # TODO write more?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:398:       # TODO b | c
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:180:# TODO: we should use the warnings module
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:278:# TODO caching with decorator, but not to degrade performance
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1456:                #TODO: this can probably be optimized more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1885:    # TODO make it decorator + bytecodehacks?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/expr.py:3692:        # TODO: Smarter heuristics
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/add.py:292:                seq.extend(o_args)  # TODO zerocopy?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:212:        # TODO: Look at nargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:1416:            #TODO: check if assumption of discontinuous derivatives exist
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:1673:        # TODO: deprecate?  YES, make this 'enumerated_variables' and
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:1675:        # TODO: support for `d^n`?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/symbol.py:637:    # TODO add check against another Wild
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1447:    # TODO: Disable string inputs (https://github.com/sympy/sympy/issues/11003)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_assumptions.py:410:    # TODO Change to x.is_nonzero is None
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_diff.py:138:    # TODO: assert diff(x**2, (x, n)) == x**(2-n)*ff(2, n)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3958:@SKIP("TODO: sympy.physics.quantum.shor: Cmod Not Implemented")
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:208:    # TODO UndefinedFunction does not subclass Expr
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_facts.py:70:# TODO move me to appropriate place
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:917:    # TODO UndefinedFunction does not subclass Expr
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:435:            # TODO: Make non-commutative exponents not combine automatically
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1049:        # TODO: Should these be self.func?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1190:        # TODO: Should this be self.func?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:2758:    # TODO: make this a class like bell()
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:423:        # TODO: extend this to complex numbers?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:283:        if arg.is_Add: # TODO, implement more if deep stuff here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:480:        if arg.is_Add: # TODO, implement more if deep stuff here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/_trigonometric_special.py:3:TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:985:        # TODO new and probably slow
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:578:                # TODO simplify hi <= upto
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:498:        if arg.is_Add:  # TODO, implement more if deep stuff here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:499:            # TODO: Do this more efficiently for more than two terms
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:867:        if arg.is_Add:  # TODO: Do this more efficiently for more than two terms
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1579:    # TODO refactor into TrigonometricFunction common parts of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1223:    # TODO raise error if function is discontinuous at limit of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_complexes.py:938:    # TODO XXX why does abs(x)._eval_evalf() not fall back to global evalf?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/gamma_functions.py:687:                # TODO n == 1 also can do some rational z
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:25:# TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:47:# TODO should __new__ accept **options?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:48:# TODO should constructors should check if parameters are sensible?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:210:        # TODO should we check convergence conditions?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:543:        # TODO should we check convergence conditions?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:980:    # TODO this can be nicer
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:656:            # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:24:# TODO series expansions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:25:# TODO see the "Note:" in Ei
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:1220:        # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:2738:            # TODO: is the series really correct?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:150:        # TODO Add more simplififcation here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:179:        # TODO: Make sure n \in N
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:180:        # TODO: Assert |m| <= n ortherwise we should return 0
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:189:        # TODO: Make sure n \in N
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:190:        # TODO: Assert |m| <= n ortherwise we should return 0
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:197:        # TODO: Make sure theta \in R and phi \in R
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:202:        # TODO: Handle deep and hints
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:150:            # TODO should something be polarified here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:179:        # TODO use minpoly instead of ad-hoc methods when issue 5888 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:181:            # TODO reference?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/setexpr.py:84:        # TODO: this could be implemented straight into `imageset`:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2486:                    know its dimensions. TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2555:    # TODO: check subsets (`func` in `setv`)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2558:    # TODO: support more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:46:        # TODO: handle unevaluated condition.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:49:        # TODO: `s2 > s1` could be unevaluated.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:85:    # TODO: add logic for open intervals?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:34:    # TODO: some intervals containing 0 and oo will fail as 0*oo returns nan.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:41:    # TODO: handle symbolic intervals
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:38:    # TODO: handle functions with infinitely many solutions (eg, sin, tan)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:39:    # TODO: handle multivariate functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:371:            # TODO: Design a technique to handle multiple-inverse
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:29:    # TODO: add support for more functions in the future:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:206:    # TODO: some expressions cannot be calculated due to bugs (currently
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:124:                # TODO: is this break necessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:297:        # TODO: this assumes that all arguments are matrices, it may not be the case:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:448:    # TODO: check if subremoved should be permuted as well...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:542:        # TODO: move this to ElementwiseApplyFunction
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py:189:    # TODO: this is returning a wrong result:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:50:    # TODO: not yet supported:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:54:    # TODO: not yet supported:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:445:    # TODO: reverse operation starting with `PermuteDims` and getting down to `bb`...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:113:        # TODO: check that Kronecker delta is only contracted to one other element:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:605:        # TODO: swap args positions in order to simplify the expression:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:606:        # TODO: this should be in a function
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:641:        # TODO: function in order to permute the args:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:842:        # TODO: add API for total rank and cumulative rank:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1263:        # TODO: add API for total rank and cumulative rank:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1390:        # TODO: check that `expr` has `.subranks`:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/array_derivatives.py:91:        # TODO: this could be done with multiple-dispatching:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:567:        # TODO: add checks for dimensions for `value`?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2208:        # TODO: add possibility of metric after (spinors)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2590:            # TODO: what is the part which is not a coeff?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3064:        # TODO: this could be optimized by only swapping the indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3203:    # TODO: put this into TensExpr?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3209:    # TODO: put this into TensExpr?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3225:        # TODO: inefficient, this should be done at root level only:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3268:        # TODO: check data compatibility with properties of tensor.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3344:        # TODO: replace .args[0] with .name:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3359:            # TODO: if there is no metric present, the derivative should be zero?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3661:    # TODO: this method should be private
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3662:    # TODO: should this method be renamed _from_components_free_dum ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4540:        # TODO: inherit dummies from expr
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4563:        # TODO: can be improved:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5136:    # TODO: add a dum_to_components_map ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:89:#   TODO:  (some ideas for improvement)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:375:         broadcasting.  (TODO)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:497:    # TODO: add check for *get_symmetric_group_sgs(0)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/_compilation/__init__.py:9:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:920:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:956:    # TODO: Replace solve with solveset when it gives Lambert solution
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:966:    # TODO: x = [-1, 2*(+/-asinh(1)*I + n*pi}, 3*(pi/6 + n*pi/3)]
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:967:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1014:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1032:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1038:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1047:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1052:    # TODO: Replace solve with solveset, as of now test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1059:    # TODO: Replace solve with solveset which gives both [+/- current answer]
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1077:    # TODO: Replace solve with solveset, as of now
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1084:    # TODO: Replace solve with solveset, as of now
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1092:    # TODO: Replace solve with solveset, as of now
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1099:    # TODO: Replace solve with solveset, as of now
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1118:    # TODO: Replace solve with solveset, as of now
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1194:    # TODO: Replace solve with solveset, as of now
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2252:    # TODO: Replace solve with solveset, current test fails for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3082:    # TODO: Replace solve with solveset, when it works for solveset
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:382:    # TODO: fix pickling of Options class (see GroebnerBasis._options)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:409:        check(c, exclude=[0, 1], check_attr=False) # TODO: Py3k
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:420:    # TODO: AssertionError: assert id(obj) not in self.memo
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:424:    # TODO: AssertionError: assert id(obj) not in self.memo
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:438:    # TODO: fix pickling of ModularInteger
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:444:    # TODO: fix pickling of RealElement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:448:    # TODO: fix pickling of ComplexElement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:457:    # TODO: fix pickling of ModularInteger
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:472:        # TODO: fix pickling of ModularInteger
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:489:    # TODO: fix pickling of RealElement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:493:    # TODO: fix pickling of ComplexElement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:500:    # TODO: AssertionError
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:504:    # TODO: AttributeError: 'PolyElement' object has no attribute 'ring'
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:526:    # TODO: Argh, Python is so naive. No lambdas nor inner function support in
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:559:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:563:    # TODO: TypeError: can't pickle instancemethod objects
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:612:    # TODO: PicklingError: Can't pickle <function <lambda> at 0x38578c0>: it's not found as __main__.<lambda>
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:622:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:635:    # TODO: fix pickling of `symbols' flag
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:639:# TODO: def test_pickling_polys_rootisolation():
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2494:                # prop is a Symbol.  TODO: Find out why.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:34:    # TODO it would be good to pick the smallest divisible power
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:798:    # TODO: Use solveset here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1072:            # TODO: Hint first order series should match only if d/e is analytic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1783:    # TODO: if two solutions are solved for f(x), we still want to be
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:204:    # TODO: Add methods that can be used by many ODE solvers:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:359:    # TODO: improve solution testing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2902:# TODO: option for calculating J numerically
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:2566:    # TODO: pre-simplification: Not necessary but may simplify
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:3893:        # TODO: Fall back to diop_DN when k = 2
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:175:        # TODO : 'best' hint should be implemented when adequate
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:284:    # TODO : For now pde.py uses support offered by the ode_order function
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:521:    # TODO : For now homogeneous first order linear PDE's having
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:611:    # TODO : For now homogeneous first order linear PDE's having
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:323:    # TODO: Is the above solution set definitely complete?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1862:    # TODO: add more simple testcases when solveset returns
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1727:    # TODO: Investigate why currently solution [0] is preferred over [1].
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:185:    # TODO: does this really have to be so complicated?!
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:694:        # TODO : We should not blindly recurse through all args of arbitrary expressions like this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1662:        # TODO Case: A-> function of symbol, can be extended here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:353:        # TODO: use |G:H| = |G|/|H| (currently H can't be made into a group)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:870:    # TODO:: Sims points out in [Sim94] that performance can be improved by
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:903:            # TODO: this should support input of a list of general words
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/coset_table.py:985:    # TODO: complete the docstring
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/tensor_can.py:1015:    TODO: use baseswap in the case in which if it fails in finding a
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:666:        # TODO: Replace solve with nonlinsolve, when nonlinsolve will be able to solve in real domain
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:919:        # TODO: Replace solve with solveset, when this line is tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:927:                # TODO: Replace solve with solveset, when these lines are tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1290:            # TODO: Replace solve with solveset, when this line is tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/plane.py:412:                # TODO: Replace solve with solveset, when this line is tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/concrete/summations.py:607:        # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1043:    # TODO Implement matrix geometric series summation.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:78:#TODO debugging output
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:403:    #TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:240:        # TODO The 3D stuff
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:304:        #TODO after fixing https://github.com/ipython/ipython/issues/1255
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/utils.py:159:    # TODO: prange check goes here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:128:        # TODO: _process_piecewise check goes here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:204:# TODO: Add color arrays for plots.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:205:# TODO: Add more plotting options for 3d plots.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:206:# TODO: Adaptive sampling for 3D plots.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:381:                # TODO: set cse=True once this issue is solved:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1146:        # TODO: for now, I assume that numpy functions are going to succeed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1156:                # TODO: what if points[k][idx]==e or points[k][idx+1]==e?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1774:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1790:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1871:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1972:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:2094:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:32:# TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1281:        # TODO this can be done more efficiently
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:102:    # TODO more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/polyroots.py:761:    # TODO: This is fragile. Figure out how to make this independent of construct_domain().
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1977:    # TODO Use _parallel_dict_from_expr instead of sring as sring is
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:515:        # TODO better data structure!!!
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:675:        # TODO apply the product criterion?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:683:        # TODO mergesort?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:726:    # (TODO again, better data structures)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:450:        # TODO: implement this in from_ methods
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:459:        else: # TODO: remove this branch
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:9:# TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:142:        # TODO optionally disable reduction?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/polynomialring.py:40:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/fractionfield.py:34:        # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:796:    # TODO: to improve performance, choose the main variable here
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:2129:# TODO: add support for algebraic function fields
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:163:    # TODO: rewrite this so that it doesn't use expand() (see poly()).
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:467:        # TODO: should AlgebraicField be a Composite domain?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:1251:        elif len(self) <= 5: # TODO: use an actual density measure
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:2275:        else: # TODO: don't use dense representation (port PRS algorithms)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:3044:    # TODO: following methods should point to polynomial
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:173:    # TODO: Use a nontrivial pivoting strategy to control intermediate
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:321:    # TODO: Use a non-trivial pivoting strategy. Even just row swapping makes a
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/normalforms.py:11:# TODO (future work):
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:23:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:660:        # TODO: Implement similar algorithms for DDM and SDM.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/rref.py:256:            # TODO: Add partial pivot support to the sparse implementations.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_distributedmodules.py:50:# TODO test to_dict?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_heuristicgcd.py:53:    # TODO: assert heugcd(f, f.diff(x))[0] == g
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/heuristicgcd.py:124:    # TODO: don't expose poly repr implementation details
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:378:        # TODO: Integrate this into expand() itself
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:216:        # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1839:        # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/primes.py:678:    # TODO (future work):
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:327:    # TODO: handle piecewise defined functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:328:    # TODO: handle transcendental functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:329:    # TODO: handle multivariate functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/accumulationbounds.py:688:        # TODO : Devise a better method for Union of AccumBounds
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:702:            # TODO: trigsimp is needed here so that the matrix becomes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/operators.py:214:        # TODO: is case of many coord systems, this gets a random one:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:158:        # TODO: This gets a random coordinate system in case of multiple ones:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:503:        # TODO : The following line introduces a performance issue
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:330:    # TODO: We should be able to support more than 2 elements
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:410:def test_optims_numpy_TODO():
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:442:    NUMBER_OF_DIGITS = 25   # TODO: this should ideally be automatically handled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:526:    #TODO A class Complex may be implemented. The BeamParameter may
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:885:    #TODO add the other possible arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:906:#TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:911:#TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/vector/vector.py:735:        # TODO : Circular dependency if imported at top. Should move
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:47:    # TODO : The unit vectors should print with subscripts but they just
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:50:    # TODO : The pretty print division does not print correctly here:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:35:    TODO: Handle condition such as symbols have subscripts/superscripts
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:94:    # TODO: Need to handle printing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:172:        #TODO: Current version ignores the indices set for partial trace.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:189:        # TODO : improve this implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:192:    #TODO: Review if the permute method is needed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:3:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:428:            # TODO: make sure the hilbert spaces of the bra and ket are
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:491:        # TODO if operands are tensorproducts this may be will be handled
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:36:    TODO: implement a decompose property that returns how to do this in terms
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:3:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:417:            #TODO: Add support for sets of operators
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:451:    TODO (?): Support for Muls and other types of expressions?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cartesian.py:3:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:141:# TODO: Move this into sympy.matrices.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:242:            # TODO: This can be optimized to reduce the number of Qubit
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:104:    # TODO: don't expand the scalars in front of each Mul.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:251:    # TODO: I may need to expand before returning the final result.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:78:        # TODO: explore different sparse formats. But sparse.kron will use
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tensorproduct.py:151:        # TODO: disallow nested TensorProducts.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:145:        # TODO: add methods for uncoupling operators
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:157:    # TODO: move this to qapply_Mul
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:165:        #TODO: use options to use different j values
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:616:        # TODO: move evaluation up to represent function/implement elsewhere
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1017:            # TODO: better way to get angles of rotation
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1487:            # TODO: Need hilbert space fix, see issue 5732
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:1:#TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:486:    #TODO: Improve simplification method
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:675:    # TODO: Check for symmetries
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_trace.py:82:    #TODO: needed while testing reduced density operations, etc.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_density.py:269:    #TODO: test for invalid arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:3:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:678:    # TODO: Fix non-unicode pretty printing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_cartesian.py:113:    # TODO: Add tests for representations
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:13:TODO List:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/density.py:21:    TODO: Density operator support for Qubits
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:351:                # TODO: should this raise a warning?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:522:        #TODO: the inversion will fail if the system is inconsistent, for
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:206:    # TODO: decide whether to allow such expression in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:227:    # TODO: Pow only support structural equality:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:244:    # TODO: need better simplification routine:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:249:    # TODO: need a better way to simplify expressions containing units:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:253:    # TODO: fix this, it should give `m` without `Abs`
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/kane.py:630:    # TODO : Remove `new_method` after 1.1 has been released.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_particle.py:55:    # TODO make the result not be system-dependent
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/series/gruntz.py:633:    # TODO this should not be necessary
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/series/series_class.py:70:        TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:441:    f = x*exp(x)*sin(2*x)  # TODO: rsolve needs improvement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:162:    # TODO : A better output for Order(log(x) + 1/log(x))
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:148:    # TODO zeta function series
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:152:    # TODO 8.35 - 8.37 (bessel, max-min)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:655:        TODO: Implement algorithm for sparse matrices (SFF),
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/hadamard.py:165:# TODO Implement algorithm for rewriting Hadamard product as diagonal matrix
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:52:    # TODO: this is commented because it slows down the tests.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:105:    # TODO: find a way to represent a four-dimensional zero-array:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:225:    # TODO: TensorProduct is not supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:292:    # TODO: no support for TensorProduct.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:407:    # TODO: restore this result (currently returning the transpose):
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:416:    # TODO: restore (currently returning the transpose):
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:435:    # TODO: not implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:444:    # TODO: wrong
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:448:    # TODO: wrong
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:731:    TODO: Implement algorithm for sparse matrices (SFF),
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:1167:    # TODO: currently not working as ``_MinimalMatrix`` cannot be sympified:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3614:        TODO: Implement algorithm for sparse matrices (SFF),
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/matrices.py:70:    # TODO: Add handlers to make these keys work with
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/common.py:17:    # TODO: Add examples
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:238:    # TODO: Add examples
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:337:    # TODO: Add examples
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:394:    # TODO: Add examples
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/calculus.py:57:    # TODO: Add examples
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/refine.py:53:        # TODO: this will probably not work with Integral or Polynomial
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:47:    # TODO: implement sathandlers system for the matrices.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:77:    # TODO: implement sathandlers system for the matrices.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:94:    # TODO: implement sathandlers system for the matrices.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:218:    # TODO: This should be deducible from the nonzero handler
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:103:        # TODO: Run additional checks to see which combination of the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:660:            # TODO: ANTLR refers to ISO 80000-2:2019. should we keep base 10 or base 2?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:520:            #TODO: No string type in AST
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:102:            # TODO: Arithmetic Assignment
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:151:            # TODO: Integer Binary Operations
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:239:            # TODO:Numbers when the LFortran ASR is updated
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:257:            # TODO: Return statement, variable declaration
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:796:            # TODO: Currently only works with symbols. Make it work for dynamicsymbols.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1269:            # TODO** Parse block matrices
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1936:        # TODO parse integers as well ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2023:        # TODO: Should these be protected?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:26:# TODO you are a bit excessive in the use of Dummies
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:27:# TODO dummy point, literal field
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:28:# TODO too often one needs to call doit or simplify on the output, check the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1101:        # TODO: you need a real dummy function for the next line
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1309:                    if c:  # TODO this is ugly - the Commutator can be Zero and
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1438:    # TODO the calculation of signatures is slow
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1439:    # TODO you do not need all these permutations (neither the prefactor)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1594:        # TODO: you need a real dummy function for the next line
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1892:    # TODO Is this a good idea?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1919:    # TODO move some of this to class methods.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1920:    # TODO rewrite using the .as_blah_blah methods
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1965:    # TODO move some of this to class methods.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1966:    # TODO rewrite using the .as_blah_blah methods
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_hyperbolic_space.py:86:    #TODO - it would be nice to have index contraction built-in
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:103:    #TODO assert m == R2_r.transform(R2_p, R2_p.transform(R2_r, [a, b])).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:117:    #TODO assert m == R3_r.transform(R3_c, R3_c.transform(R3_r, m)).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:120:    #TODO assert m == R3_r.transform(R3_s, R3_s.transform(R3_r, m)).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:123:    #TODO assert m == R3_c.transform(R3_s, R3_s.transform(R3_c, m)).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:128:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_c, R3_c.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:131:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:134:        #TODO assert m == R3_c.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_c, m)).applyfunc(simplify)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:19:    #TODO assert point.subs(x, 2) == Point(cs, [2, y])
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:20:    #TODO assert point.free_symbols == set([x, y])
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/str.py:962:        #TODO : Handle indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:107:    # TODO: a better class structure would avoid this mess:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:202:        # TODO: is this necessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:95:    # TODO - assumes all called functions take one double precision argument.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:200:# TODO: Make brackets adjust to height of contents
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:333:    # TODO robustify when no unicodedat available
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1574:        # TODO should exp_polar be printed differently?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1910:            #TODO: Move this code to prettyForm
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2239:        # TODO: the stuff to the left of the | and the stuff to the right of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2602:        # TODO: copy-pasted from _print_Function: can we do better?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2671:                # TODO incorporate order
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2808:        #TODO: Handle indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:10:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4575:    # TODO: The "x in N" parts below should be centered independently of the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7256:    # TODO: add support for ASCII pretty.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7620:    # TODO: TBD polylog(s - 1, z)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:238:    # TODO: merge this with the above, which requires a lot of test changes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:1176:        # TODO should exp_polar be printed differently?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2585:                # TODO incorporate order
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2777:        # TODO: This expression is potentially confusing,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2785:        # TODO nicer fractions for few generators...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2802:        # TODO nicer fractions for few generators...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2850:        # TODO: Handle indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:182:@SKIP  # TODO - this is currently not checked but should be implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:236:    # TODO - matrix broadcasting?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:611:    # assert theq(aesara_code_(sy.Ne(x, y)), aet.neq(xt, yt))  # TODO - implement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:2079:    #TODO: Handle indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:172:@SKIP  # TODO - this is currently not checked but should be implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:226:    # TODO - matrix broadcasting?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:599:    # assert theq(theano_code_(sy.Ne(x, y)), tt.neq(xt, yt))  # TODO - implement
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:93:    # TODO more tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:646:    # TODO: Apply different strategies, considering expression pattern:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1087:        # TODO: see if x*log(a)+x*log(a)*log(b) -> x*log(a)*(1+log(b))?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1247:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:50:#   TODO work this out in detail.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:86:    # TODO see if this can work as Mod(x, 1); this will require
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:253:    # TODO branching
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:736:        # TODO with symbolic parameters, it could be advantageous
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1947:    # TODO tons of more formulae
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1991:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2116:    # TODO for now, we use the following simple heuristic: inverse-shift
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2245:    # TODO the following would be possible:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2250:    # TODO Also, we tend to create combinations of gamma functions that can be
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2443:    # TODO it would be helpful to give conditions under which the integral
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:121:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:116:    # TODO [a+1, aRational(-1, 2)], [2*a]
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:130:    # TODO hyperexpand(hyper([a], [2*a + 1], z))
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:131:    # TODO [S.Half, a], [Rational(3, 2), a+1]
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:135:    # TODO [a], [a - S.Half, 2*a]
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:949:    # TODO polys
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1011:    # TODO LOTS more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1039:    # TODO LOTS more
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:393:                    # TODO is there a better heuristic?
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/gui.py:26:    # TODO: @classmethod: write() on GUI?
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/utils.py:9:# TODO consider using wcswidth third-party package for 0-width characters
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/cli.py:117:# TODO: add custom support for some of the following?
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/cli.py:125:        TODO: find out why this is needed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/rich.py:74:    # TODO: @classmethod: write()?
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/std.py:1442:        # TODO: private method
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/__init__.py:3:from .cli import main  # TODO: remove in v5.0.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/__init__.py:4:from .gui import tqdm as tqdm_gui  # TODO: remove in v5.0.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/__init__.py:5:from .gui import trange as tgrange  # TODO: remove in v5.0.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/tqdm/tk.py:31:    # TODO: @classmethod: write()?
./core/py/pipeline/.venv/lib/python3.12/site-packages/anyio/_core/_fileio.py:416:        def info(self) -> Any:  # TODO: add return type annotation when Typeshed gets it
./core/py/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/backend.py:367:# TODO: Fill in the PR number
./core/py/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py:378:        # TODO: Ensure this primary_metric works as expected, also with bolding the right thing in the model card
./core/py/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:253:        # TODO: This is rather inefficient, as we load all data into memory. We might benefit from a more efficient solution
./core/py/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:323:            # load_best_model_at_end=save_best_model, # <- TODO: Look into a good solution for save_best_model
./core/py/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1405:# TODO: Fill in the PR number
./core/py/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:118:                # TODO: Consider following these steps automatically so we can load PEFT models with other backends
./core/py/pipeline/.venv/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1600:        # TODO: use search_filter once with have an HasVector like condition
./core/py/pipeline/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:238:                # TODO is this the right name for the data attribute ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:305:        # TODO I think there is an edge case here where an annotation's span might not close
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/_utils.py:14:            # TODO: use `add_suggestion` from torchvision.prototype.utils._internal to improve the error message as
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/utils.py:315:    # TODO: There might be a way to vectorize this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/_utils.py:11:    # TODO add back the assert
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/poolers.py:36:# TODO: (eellison) T54974082 https://github.com/pytorch/pytorch/issues/26744/pytorch/issues/26744
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:45:    # TODO: It's possible the masking here is unnecessary if y and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:80:# TODO: this doesn't actually cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:81:# TODO: main library should make this easier to do
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:155:        # TODO: we should change all of this from ground up to simply take
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:190:        # TODO check if stream needs to always be the video stream here or not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:193:        # TODO add some warnings in this case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:206:        # TODO add a warning
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:321:            # TODO raise a warning?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:160:            # TODO: load metadata
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:166:            # TODO: add extradata exception
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/kinetics.py:115:        # TODO: support test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/video_utils.py:388:            # TODO: Revert it once the bug is fixed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:267:# TODO: specify the return type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/celeba.py:173:                # TODO: refactor with utils.verify_str_arg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:39:# TODO: Once torchscript supports Enums with staticmethod
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:1564:    # TODO: if image shape is [N1, N2, ..., C, H, W] and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:70:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:94:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:392:        # TODO: Jit is failing on loading this op when scripted and saved
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:862:    # TODO: we should expect bincount to always be faster than histc, but this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_color.py:36:    # TODO: Maybe move the validation that num_output_channels is 1 or 3 to this function instead of callers.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/__init__.py:93:    hflip,  # TODO: Consider moving all pure alias definitions at the bottom of the file
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:186:    # TODO: Add _xywh_to_cxcywh and _cxcywh_to_xywh to improve performance
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:242:    # TODO: Investigate if it makes sense from a performance perspective to have an implementation for every
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:250:            # TODO: when https://github.com/pytorch/pytorch/issues/68430 is fixed (possibly by https://github.com/pytorch/pytorch/pull/100373),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1239:        # TODO: See https://github.com/pytorch/pytorch/issues/40763
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1259:# TODO: This should be removed once torch_pad supports non-scalar padding values
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1326:        # TODO: add support of other padding modes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1591:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1846:    # TODO: add in docstring about approximation we are doing for grid inversion
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1854:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:107:    # TODO: consider deprecating integers from sigma on the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:221:        # TODO: remove this branch as soon as `dtype.is_floating_point` is supported by JIT
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:360:    # TODO: Do we really need to check for out of bounds here? All
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_utils.py:91:# TODO: let's use torchvision._utils.StrEnum to have the best of both worlds (strings and enums)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:15:# TODO: do we want/need to expose this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:377:                        # TODO: we don't need to enforce tensors, just that entries are indexable as t[bool_mask]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_presets.py:113:        # TODO: we could re-train the video models with antialias=True?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/__init__.py:74:        # TODO: better messages
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/__init__.py:78:        # TODO: better messages
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/mobilenetv3.py:84:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/utils.py:38:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/shufflenetv2.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:51:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:42:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:64:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:86:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:120:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:202:    # TODO: simplify when indexing without rank will be supported by ONNX
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:451:    # TODO : replace below with a dynamic padding when support is added in ONNX
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:744:                # TODO: https://github.com/pytorch/pytorch/issues/26731
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/generalized_rcnn.py:86:        # TODO: Move this to a function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:43:            # TODO change this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:54:    # TODO: https://github.com/pytorch/pytorch/issues/26792
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:609:        # TODO: Move this to a function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:629:        # TODO: Do we want a list or a dict?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/_api.py:177:        # TODO: Replace ann.__args__ with typing.get_args(ann) after python >= 3.8
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/__init__.py:21:# TODO: we could / should document them publicly, but it's not clear where, as
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:154:                # TODO: If we have documentation on how to do that, put a link in the error message.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:200:    # TODO: maybe we should use __getstate__ and __setstate__ instead of __reduce__, as recommended in the docs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/__init__.py:11:# TODO: Fix this. We skip this method as it leads to
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:274:            # TODO: we don't go through the rebuild logic here directly because we don't want
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:55:    # TODO PEP 747: use TypeForm:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:333:        # TODO check for classvar and error?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:411:        # TODO check for classvar and error?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:413:        # TODO infer from the default, this can be done in v3 once we treat final fields with
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:720:            # TODO: properly make use of the protocol (https://rich.readthedocs.io/en/stable/pretty.html#rich-repr-protocol)
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:797:    default: ellipsis,  # noqa: F821  # TODO: use `_typing_extra.EllipsisType` when we drop Py3.9
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/deprecated/json.py:112:# TODO: Add a suggested migration path once there is a way to use custom encoders
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/alias_generators.py:7:# TODO: in V3, change the argument names to be more descriptive
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/functional_validators.py:213:            # TODO if `schema['serialization']` is one of `'include-exclude-dict/sequence',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:124:# TODO: ultimately, make this public, see https://github.com/pydantic/pydantic/pull/9459#discussion_r1628197626
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:592:            # TODO: is there a better way? should we just not do this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/dataclasses.py:277:        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:303:        # TODO: in theory we should check that the schema accepts a serialization key
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:407:            # TODO this is an ugly hack, how do we trigger an Any schema for serialization?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:613:        # TODO: note, this is a fairly common pattern, re lax / strict for attempted type coercion,
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1724:        # TODO: do we really need to resolve type vars here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1743:                # TODO: something like https://github.com/pydantic/pydantic/issues/5952
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2005:        TODO support functional validators once we support them in Config
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2511:# TODO V3: this function is only used for deprecated decorators. It should
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:235:    # TODO: This could be unified with `get_standard_typevars_map` if we stored the generic metadata
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:276:        # TODO remove parentheses when we drop support for Python 3.10:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:91:    # TODO When we drop 3.9, use a match statement to get better type checking and remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:170:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:176:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py:83:    # TODO: this is a bit redundant, we could probably avoid some of these
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_validators.py:44:    # TODO: refactor sequence validation to validate with either a list or a tuple
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:139:# TODO implement `is_finalvar_annotation` as Final can be wrapped with other special forms:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:186:# TODO In 2.12, delete this export. It is currently defined only to not break
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:195:# TODO: Ideally, we should avoid relying on the private `typing` constructs:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:445:        # TODO ideally recursion errors should be checked in `eval_type` above, but `eval_type_backport`
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:230:                # TODO we can also stop there if `__pydantic_fields_complete__` is False.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:29:    TODO: Perhaps we should move this structure to pydantic-core. At the moment, though,
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:32:    TODO: It's unfortunate how functionally oriented JSON schema generation is, especially that which occurs during
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:236:            # TODO: should we merge the parent namespace here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:263:        # TODO `typ.__type_params__` when we drop support for Python 3.11:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:394:                    # TODO: We should probably do something with this so that validate_assignment behaves properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:406:                        # TODO: same note as above re validate_assignment
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:433:            # was already evaluated. TODO: is this method relevant?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:436:        TODO: the nested function definitions here seem like bad practice, I'd like to unpack these
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:505:        # TODO: I dislike that we have to wrap these basic dict updates in callables, is there any way around this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:713:            # TODO: should we add regex flags to the pattern?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1117:        # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1240:        # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1281:                        # TODO: fixme - this is a workaround for the fact that we can't always resolve refs
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1320:        # TODO: Need to read the default value off of model config or whatever
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1321:        use_strict = schema.get('strict', False)  # TODO: replace this default False
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/v1/utils.py:270:            # TODO: replace annotation with actual expected types once #1055 solved
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/v1/networks.py:535:    # TODO: Needed to generic "Parts" for "Replica Set", "Sharded Cluster", and other mongodb deployment modes
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/mypy.py:513:                    # TODO: Only do this if the first argument of the decorated function is `cls`
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/mypy.py:622:                # TODO: We shouldn't be performing type operations during the main
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/mypy.py:785:            # TODO this path should be removed (see https://github.com/pydantic/pydantic/issues/11119)
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/main.py:4:# TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/main.py:1043:                    # TODO - matching error
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/main.py:1689:    # TODO PEP 747: replace `Any` by the TypeForm:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/formatters/terminal256.py:17:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/formatters/latex.py:334:        # TODO: add support for background colors
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/formatters/img.py:548:            # TODO: make sure tab expansion happens earlier in the chain.  It
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:445:            # TODO: these don't match the comments in docs, remove.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:130:                # TODO unsure if ellipses are allowed elsewhere, see
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/textfmts.py:240:    # TODO: Make date regex more ISO 8601 compliant
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:755:            # TODO support other Python syntax like $foo['bar']
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:123:            # TODO: we should probably escape also here ''${ \${
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:135:        # TODO: let/in
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/ada.py:116:            # TODO: use Name.Namespace if appropriate.  This needs
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:150:            # TODO: better logging
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:347:                # TODO: better handle multiline comments at the end with
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:588:            # TODO: Backslash escapes?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mips.py:28:    # TODO: add '*.s' and '*.asm', which will require designing an analyse_text
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:886:    # TODO / should divide keywords/symbols into namespace/rest
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:1341:            (r'\S+\s+', Text)   # TODO: make tests pass without \s+
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:390:            # TODO: Treat context-depedendent names specially
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:396:            # TODO: templates start and end tokens.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/urbi.py:34:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/dns.py:53:            # TODO, $GENERATE https://bind9.readthedocs.io/en/v9.18.14/chapter3.html#soa-rr
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:27:    # TODO String interpolation @VARNAME@ inner matches
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:28:    # TODO keyword_arg: value inner matches
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/perl.py:35:    # TODO: give this to a perl guy who knows how to parse perl...
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/_asy_builtins.py:9:    TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:140:            # TODO: regexes can have other delims
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:191:        # TODO: builtins are only subsequent tokens on lines
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:648:            (r'^(\* )(TODO)( .*)',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:650:            (r'^(\*\*+ )(TODO)( .*)',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:656:            # Unordered lists items, including TODO items and description items
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:672:            # TODO: language-dependent syntax highlighting (see Markdown lexer)
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:701:            (_inline(r'=', r'='), String), # TODO token
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/javascript.py:133:            # TODO: should this include single-line comments and allow nesting strings?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/testing.py:200:            (r'(?i)\bTODO\b', Comment.Preproc),
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:49:            # TODO: highlight references in fandocs
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:85:        'insideUri': [  # TODO: remove copy/paste str/uri
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/c_like.py:212:            # TODO: "correctly" parse complex code attributes
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/modula2.py:474:        'TODO', 'FFI', 'ADDR', 'VARGLIST', 'VARGC',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:24:    TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:85:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:123:                "varname",  # TODO varname the right fit?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:273:                        "async for",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:274:                        "async with",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:702:        # TODO supported?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/parsers.py:396:            # TODO finish implementing other possibilities for scope
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/css.py:555:            # TODO: broken, and prone to infinite loops.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/rnc.py:36:            # TODO single quoted strings and escape sequences outside of
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/scripting.py:1502:            # TODO: JES3 statement
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/oberon.py:50:            # TODO: nested comments (* (* ... *) ... (* ... *) *) not supported!
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/dotnet.py:558:# TODO support multiple languages within the same source file
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexer.py:861:    TODO: clean up the code here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/auto_augment.py:905:        # TODO the results appear in the right ballpark but they differ by more than rounding.
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_dataset.py:5:TODO: 2. NaFlexIterableDatasetWrapper - Iterable dataset that yields batches with variable sequence lengths
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:373:        # TODO: use foreach_pow if/when foreach_pow is added
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:342:        # TODO: use foreach_pow if/when foreach_pow is added
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/norm_act.py:114:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:104:        ValueError: if the string def not properly specified (TODO)
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/tiny_vit.py:626:            # TODO: whether move this func into model for dynamic input resolution? (high risk)
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/regnet.py:128:    # TODO dWr scaling?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:993:        block_fn = cfg.block_fn or Block  # TODO: Support configurable block_fn via string lookup
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:994:        mlp_layer = cfg.mlp_layer or Mlp   # TODO: Support configurable mlp_layer via string lookup
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/davit.py:813:# TODO contact authors to get larger pretrained models
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/resnest.py:49:        assert aa_layer is None  # TODO not yet supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/resnest.py:50:        assert drop_path is None  # TODO not yet supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9:# TODO: remove this check when dropping Python 3.7 support
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:167:    TODO: handle base64 as input
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:173:            yield get_session().get(content).content  # TODO: retrieve as stream and pipe to post request ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:25:# Some TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:259:        # TODO: this should be handled in provider helpers directly
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:257:        # TODO: this should be handled in provider helpers directly
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/mcp_client.py:192:            # ^ TODO: should be handle `get_session_id_callback`? (function to retrieve the current session ID)
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:51:TODO: add support for `huggingface-cli delete-cache aaaaaa bbbbbb cccccc (...)` ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:52:TODO: add "--keep-last" arg to delete revisions that are not on `main` ref
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:53:TODO: add "--filter" arg to filter repositories by name ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:54:TODO: add "--limit" arg to limit to X repos ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:55:TODO: add "-y" arg for immediate deletion ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:85:    # TODO: refactor this + imports in a unified pattern across codebase
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:25:    # TODO: deprecate when adapted in transformers/datasets/gradio
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:43:    # TODO: deprecate when adapted in transformers/datasets/gradio
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:58:    # TODO: deprecate when adapted in transformers/datasets/gradio
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:60:    TODO: could be useful to be able to set a custom error message.
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:91:    # TODO: add an argument to opt-out validation for specific argument?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4726:            # TODO: remove this in v1.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4999:            # TODO: remove this in v1.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:796:                    # TODO: (optimization) download regular files to copy concurrently
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:323:    TODO: factorize logic with `read_download_metadata`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:380:            # TODO: can we do better?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:466:        # TODO - maybe handle this similarly to EvalResult?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:752:    # TODO - Check if there cases where this list is longer than one?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:476:                TODO - Some args above aren't used since we are calling
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:494:        # TODO: change this in a future PR. We are not returning a KerasModelHubMixin instance here...
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_oauth.py:158:    # TODO: handle generic case (handling OAuth in a non-Space environment with custom dev values) (low priority)
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/constants.py:138:hf_cache_home = HF_HOME  # for backward compatibility. TODO: remove this in 1.0.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:121:    >>> from huggingface_hub import load_torch_model  # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:327:        # TODO: use `commit_description` to list all the deleted paths?
./core/py/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:701:                    "tree_id": None,  # TODO: tree_id of the root directory?
./core/py/pipeline/.venv/lib/python3.12/site-packages/jinja2/ext.py:251:    # TODO: the i18n extension is currently reevaluating values in a few
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/quantization/fuse_modules.py:10:# TODO: These functions are not used outside the `fuse_modules.py`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/quantization/__init__.py:42:    # 'fuse_fx', 'quantize_fx',  # TODO: add quantize_dynamic_fx
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/uniform.py:28:    # TODO allow (loc,scale) parameterization to allow independent constraints.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/laplace.py:73:        # TODO: If we ever implement tensor.nextafter, below is what we want ideally.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:249:# TODO define a bijection for LowerCholeskyTransform
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:551:# TODO: Add Beta-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:590:# TODO: Add ContinuousBernoulli-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:649:# TODO: Add Exponential-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:694:# TODO: Add Gamma-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:726:# TODO: Add Gumbel-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:823:# TODO: Add Pareto-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:920:# TODO: Uniform-Laplace KL Divergence
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:105:    # TODO Move this to C++ once the jit has better support for torch.Size.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:1477:    # TODO: type dim as BroadcastingList when
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:1643:            _dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:1646:    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:408:    # TODO(albanD) This needs to be updated when more than one level is supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:434:    # TODO: add an API to map real -> complex dtypes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:590:            # TODO: This implies that ellipses is valid syntax for allocating
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:7:# TODO: Should use `torch._C._get_privateuse1_backend_name()` to get
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:12:# TODO: Limitations and things about enable_torch_dispatch_mode we should fix before exposing it:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:629:                # TODO(https://github.com/pytorch/pytorch/issues/76750)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:650:        # TODO: add limited pickling support for sharing an iterator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/graph.py:22:# TODO(VitalyFedyunin): Make sure it works without dill module installed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:6:# TODO: Caveats
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/decoder.py:320:                # TODO: xinyu, figure out why Nvidia do this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:36:            # TODO(VitalyFedyunin): Replacing with TorchArrow only API, as we are dropping pandas as followup
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:120:        except Exception:  # TODO(VitalyFedyunin): Replace with better iterable exception
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:8:# TODO(VitalyFedyunin): Add error when two different traces get combined
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:53:#  TODO(VitalyFedyunin): Extract this list from the DFIterDataPipe registred functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:61:    # TODO: All operations are shared across entire InitialCapture, need to figure out what if we join two captures
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:78:        # TODO(VitalyFedyunin): Currently can't pickle (why?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:131:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:142:    # TODO(VitalyFedyunin): Add tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:143:    # TODO(VitalyFedyunin): Need to join context if one of them are empty because we used capture
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:146:        # TODO: Check if args or kwargs have more than one different context
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:148:            # TODO: Allow CaptureA to take context from mock
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:190:        # TODO(VitalyFedyunin): Do not use provate function here, copy own implementation instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:220:        # TODO: VitalyFedyunin execute kwargs and maybe nested structures
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:242:    # TODO(VitalyFedyunin): This should be atomic and thread safe
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:261:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:421:    # TODO(VitalyFedyunin): Must implement all special functions of datapipes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:146:            # TODO: Add try-except to in-place reduce traceback from the Exception
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:197:                # TODO: Simplify the traceback message to skip over `response = gen.send(None)`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/gen_pyi.py:227:    TODO: The current implementation of this script only generates interfaces for built-in methods. To generate
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:67:    # TODO: Lambda for picking
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:167:    # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/fileopener.py:54:        # TODO: enforce typing for each instance based on mode, otherwise
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:136:    # TODO(VitalyFedyunin): Verify that item is any sort of batch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:138:        # TODO(VitalyFedyunin): Compact all batch dataframes into one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:155:            # TODO(VitalyFedyunin): Add default collation into df_wrapper
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:166:    # TODO(VitalyFedyunin): We can dynamically extract types from the tuple_values here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:167:    # TODO(VitalyFedyunin): Instead of ignoring mypy error, make sure tuple_names is not empty
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:227:        # TODO(VitalyFedyunin): Replace `Callable[..., Any]` with `Callable[[IColumn], Any]`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:228:        # TODO(VitalyFedyunin): Replace with `Dict[Union[str, IColumn], Union[Callable, Enum]]`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:235:                # TODO(VitalyFedyunin): Validate passed dictionary
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:104:        # TODO: Performance optimization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:15:# TODO: Use TypeAlias when Python 3.6 is deprecated
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:206:# TODO: When PyTorch drops the support for Python 3.6, it can be converted
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:262:        # TODO: the statements below are not reachable by design as there is a bug and typing is low priority for now.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:280:    # TODO: Fix isinstance bug
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:327:    # TODO: Fix isinstance bug
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:336:    # TODO: Fix isinstance bug
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:380:    # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/__init__.py:1:# TODO(VitalyFedyunin): Rearranging this imports leads to crash,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:156:# TODO: Implement `SeedSequence` like object for `torch.random`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:496:    TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py:8517:        # TODO: Undo this special-case; see the header for motivation behind this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:13:            # TODO: Remove this once ScriptModule supports registering None buffer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:54:            # TODO: Remove this once ScriptModule supports registering None buffer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:238:    # TODO(XuehaiPan): remove this condition when we make Python pytree out-of-box support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:110:        # TODO: when the bounds have free variables, this may be
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:180:    # TODO: this doesn't work with bools but arguably it should
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:606:        # TODO: We should tighten value ranges
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:622:        # TODO: We should tighten value ranges
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:768:        # TODO A better way of doing this would be to assign them a range upon creation, as
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:163:# sharing (TODO: considering splitting out a BaseReferenceAnalysis).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:31:# TODO: Dedupe this with SYMPY_INTERP
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:36:    # TODO add CeilDiv (it doesn't appear in the index_expr)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:38:    # TODO default to some decompositions if the interpreter doesn't have them
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:144:                        # TODO if https://github.com/openai/triton/issues/619 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:299:# TODO: As an indicator, this != 0 implies == 1 (and vice versa).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:312:        # TODO: it is possible to make progress evaluating this guard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/weak.py:319:        # TODO, add _fix_weakref type binding
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:103:        # TODO: make storage support buffer protocol so this isn't
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:112:    # TODO: factor this into a random utility
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:153:    # TODO: offer some sort of non-blocking API to speed things up
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:158:        # TODO: consider not using torch.save for this; we don't actually
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:184:        # TODO: Support more advanced snapshotting of requires_grad/grad/etc
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:33:    # TODO(#105471): Rename the count field
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:841:            # TODO: we can probably make this check stricter by checking that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1155:    # TODO: unify _is_compiling across all compile stacks
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:205:    # TODO: expose other parameters in the future.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:45:        # TODO; Specify a __slots__ for this class or potentially
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:114:        # TODO: See if we can remove this in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:216:        # TODO: compute correct memory usage and CPU time once
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:344:    # TODO: See if we can extract GPU vs CPU information from the PyTorch model
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:72:        # TODO: See if we can remove this in the future if we are
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:395:        # TODO: Should we do this even for non-contiguous tensors?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:405:        # TODO: Provide more useful diagnostics.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/dlpack.py:47:# TODO: add a typing.Protocol to be able to tell Mypy that only objects with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:83:                # TODO: This creates a temporary file for every frame, but we
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:174:            # TODO: Maybe indicate that the traceback was elided?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:299:            # TODO: change this warning to an error after OSS/internal stabilize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1407:# TODO(angelayi): remove this function after OSS/internal stabilize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1413:# TODO(angelayi): remove this function after OSS/internal stabilize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:74:      // TODO: Maybe check that compressed_size === file_size.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:81:  // TODO: Better formatting.  Right-align this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:121:      // TODO: Maybe show simple lists and tuples on one line.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:125:      // TODO: Maybe show simple lists and tuples on one line.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:129:      // TODO: Maybe show simple (empty?) dicts on one line.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:217:    // TODO: Check stride and indicate if the tensor is channels-last or non-contiguous
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:218:    // TODO: Check size, stride, offset, and numel and indicate if
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:220:    // TODO: Maybe show key?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:268:        // TODO: Less copy/paste between this and normal dicts.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:308:  // TODO: Add human-readable sizes?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:309:  // TODO: Add sorting options?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:310:  // TODO: Add hierarchical collapsible tree?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:481:// TODO: Maybe track by dtype as well.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:482:// TODO: Maybe distinguish between visible size and storage size.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:48:    - Fix various TODO comments in this file and the JS.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:179:            # TODO: Undo at least that second hack.  We should support string states.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:293:                # TODO: Handle this case better.  TorchScript ranges are in bytes,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:326:                # TODO: handle errors here and just ignore the file?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:278:        # TODO: Make this work with autograd
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:507:    # TODO: Figure out how to handle this better
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1055:    # TODO: Handle inference mode properly.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:170:            # TODO: Don't guard on this!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:236:# TODO: Remove ViewBufferFromNested, ViewNestedFromBuffer, and buffer_from_jagged once the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:327:        # TODO: An alternative way to construct offsets is to use F.pad. This avoids creating
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:64:        # TODO: Figure out whether masks are actually supported for this layout or not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:315:        # TODO: Explore performance impact of copying
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:320:        # TODO: Explore performance impact of copying
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:326:        # TODO: Explore performance impact when compiling
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:370:# TODO: Next iteration should add test cases and check it works
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:550:    # [TODO] K and V have to have the same Nnz, should probably torch_check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:603:# TODO: coalesce with torch/nn/utils/attention.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:605:    # TODO: Investigate why math.sqrt() isn't properly handled by Dynamo?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nested/__init__.py:235:        # TODO: switch to as_nested_tensor(tensor) when it is available
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:78:    # TODO: test the specs match; empirically  sometimes we have a tuple
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:126:                # TODO: suppress guards
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:136:        # TODO: This probably does the wrong thing if you're running other
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:198:            # TODO: support get_autocast_gpu/cpu_dtype
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:271:                    # TODO: is there a way to split by device and dtype without appending in the inner loop?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:643:    # TODO: This feature could be added in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:670:                # TODO: Once we decide to break serialization FC, this case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:708:            # TODO: There's an issue here with FC. It might be impossible to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:786:    # TODO: This feature could be added in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:798:                # TODO: Once we decide to break serialization FC, this case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1138:                    # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1150:                    # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1206:                # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1226:                    # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1387:        # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:3881:    # TODO: handle out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5007:# TODO: Deduplicate this with canonicalize_dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5771:    # TODO: Query cudnnGetRNNTrainingReserveSize (expose to python)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1376:    # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2400:            # TODO: Remove this once script supports type() calls
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2466:    # TODO: make use of reduce like below when JIT is ready with the missing features:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4524:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5412:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5421:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:1284:    # TODO: consider removing this check and allowing users to specify
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:65:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:136:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:20:    # TODO Make return type more specific
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:238:    # TODO allow kwargs such as unsafe and others for parametrization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:653:                        # TODO: Fix this for tensor subclasses that are parameters:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:171:        # TODO: Re-enable this check (.type isn't supported in TorchScript)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:295:# TODO: ContrastiveNorm2d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:296:# TODO: DivisiveNorm2d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:297:# TODO: SubtractiveNorm2d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:286:        padding_mode: str = 'zeros',  # TODO: refine this type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:438:        padding_mode: str = 'zeros',  # TODO: refine this type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1109:# TODO: Deprecate and remove the following alias `_ConvTransposeMixin`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1132:# TODO: Conv2dLocal
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1133:# TODO: Conv2dMap
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1134:# TODO: ConvTranspose2dMap
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1300:        padding_mode: str = 'zeros',  # TODO: refine this type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:# TODO: fail fast on quantization API usage error, then remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:264:# TODO: PartialLinear - maybe in sparse?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/padding.py:10:# TODO: grad_output size asserts in THNN
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1843:    # TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1889:        # TODO: Remove `args` and the parsing logic when BC allows.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:626:# TODO: remove the overriding implementations for LSTM and GRU when TorchScript
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1287:            ret = input  # TODO: remove when jit supports exception flow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:57:        # TODO: check in THNN (if inplace == True, then assert value <= threshold)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:153:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1788:# TODO: L1HingeEmbeddingCriterion
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1789:# TODO: MSECriterion weight
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1790:# TODO: ClassSimplexCriterion
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/_reduction.py:18:        ret = -1  # TODO: remove once JIT exceptions support control flow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/comm.py:122:    # TODO: When `len(inputs) == 1` and all inputs are on `destination`, just
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:89:    # TODO (rohan-varma): keep_low_precision_grads: bool = False
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:90:    # TODO (rohan-varma): APIs to allow users to run batchnorm and layernorm
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:147:        # TODO: Expand to remote RRefs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:290:        # TODO: make DDP uneven inputs context manager support buffer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:840:            # params. TODO (rohan-varma): Make this compose with general
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1039:                        # TODO: when zero_grad(set_to_none=False) or in grad
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1511:            # TODO (rohan-varma) test this codepath.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1548:        # TODO: DDPSink is currently enabled for unused parameter detection and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:126:    # TODO: update notes/cuda.rst when this class handles 8+ GPUs well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/attention/bias.py:230:                    is_causal=True,  # TODO: Flash accepts causal = True and for this particular op it means lower right
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/attention/__init__.py:21:# TODO: Consider using this for sdpa regardless of subclasses
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:969:    # TODO: __name__ not set for submodules in recursive script
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:1368:# TODO support future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/library.py:146:            # TODO: in future, add more info about where the existing function is registered (this info is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/library.py:455:    # TODO(rzou): We're gonna need to stage this change with torchvision,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_script.py:837:                # TODO: we don't have _concrete_type set after load(), and in general we lose constant information.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_script.py:845:                # TODO: it's possible that the following is confusing:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_script.py:996:    # TODO MAKE SURE THAT DISABLING WORKS
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:64:    TODO: To remove this check once Union support lands.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:130:                    # TODO: To remove this check once Union suppport in TorchScript lands.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:443:        # TODO: this is hack to recognize NumberType
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:449:        # TODO: Determine if the other cases need to be fixed as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:539:    # TODO: Consider not exporting these during wildcard import (reserve
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:253:    # TODO: proper overriding analysis when implementing class inheritance
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:382:# TODO: more robust handling of recognizing ignore context manager
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:516:        # TODO: add input, output validator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:755:            # TODO: try to recover the location of else:? Python doesn't give us useful
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:32:# TODO: there should be a more principled way of doing this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:300:            # TODO: We should really error in this case, but its bc-breaking so
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:319:            # TODO: We should really error in this case, but its bc-breaking so
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:400:            # TODO: could add more detail here. For example, what the user should do
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:680:            # TODO: Why skip this? Because @torch.jit._overload_method will
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:686:        # TODO: we don't currently do this functions that are recursively
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:843:    (TODO add a link when the rules are published).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:86:# TODO: replace torch.sigmoid -> aten.sigmoid
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_builtins.py:120:    # TODO: add support for more ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_serialization.py:164:    # TODO: Pretty sure this approach loses ConstSequential status and such
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:159:            # TODO: figure out one liner to .clone() and set requires_grad
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:228:    # TODO: In principle, we track device information in our trace, so it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:232:    # TODO: Consider adding a utility function to torch.jit to test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:272:        # TODO: I'm not sure if the clone here is necessary but it is safer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_check.py:147:        # TODO @ansley: add `Union` once landed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:39:            # TODO: only assertion error is bound in C++ compilation right now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:94:            # TODO: only assertion error is bound in C++ compilation right now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:405:    # TODO: return self
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:611:        # TODO: handling of slice
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:617:        # TODO: handling of slice
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:678:    # TODO: look into rewriting with early return and getting loop unrolling to fire
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:698:    # TODO: assertions could be expanded with the error messages
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1029:        # TODO: return self
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1037:    # TODO: use slicing when slice optimization has landed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1439:# TODO: migrate over all of symbolic_shape_registry_util.cpp
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1454:# quantized_conv_prepack TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:687:                # TODO: handle the other Ju
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:928:            # TODO: To cover more problematic cases, replace stride = 0 check with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1720:    # TODO: properly handle case when u is tuple instead of only taking first element
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1902:    # TODO: replicate https://github.com/pytorch/pytorch/pull/77743 for fast gradcheck as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:2194:    # TODO: do we want to test this too?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/_functions/tensor.py:30:# TODO: deprecate this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:598:        # TODO: TorchScript ignores standard type annotation here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:618:        # TODO: Too slow with __torch_function__ handling enabled
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:655:        # TODO: Too slow with __torch_function__ handling enabled
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:921:        )  # TODO: find in sqlite database
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:71:            # TODO: We can remove this conditional once we uniformly use
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:538:        # TODO: Raise exception instead of converting value.  This is only for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:563:        # TODO: Raise exception instead of converting value.  This is only for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:626:        # TODO: Raise exception instead of converting value.  This is only for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:674:    # TODO: Enable data-dependent checks with debug mode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:675:    # TODO: This check does not work with FakeTensor inputs; See Issue #85834
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:754:    # TODO: raise exception instead of converting value
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:810:# TODO: This ref supports int reduction and out kwarg to be compatible with ATen:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:812:# TODO: Could be rewritten to support complex:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:896:        # TODO: Raise exception instead of converting value.  This is only for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1042:        # TODO: Raise exception instead of converting value.  This is only for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/special/__init__.py:231:# TODO: add docstring
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:114:    "round",  # TODO: model kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:204:    "copy_to",  # TODO: add OpInfo (or implement .to)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:386:    # TODO: make common validations available as utils
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:450:# TODO: add type promotion support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:740:# TODO: if this is special maybe it should be defined there and imported here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:965:# TODO: register this as a real ref/decomposition once TorchInductor supports complex!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1614:# TODO: skip unnecessary conversion of long to float
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1695:# TODO: consider refactoring this with add impl
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1898:# TODO: implement alternate where
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2095:    # TODO: is_pinned is not currently supported in refs or fake_tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2119:    # TODO: non_blocking should be handled by `copy_to`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2151:            # TODO - this is true for eager mode currently, but it's wrong behavior for complex norms
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2782:        # TODO: fix this to work with meta tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2993:    # TODO: we could look at directing collapse_view to skip its meta function here (unsafe_collapse_view)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3058:# TODO: This must return a sparse tensor if the input is sparse, but refs have
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3222:# TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4416:    # TODO: Add sparse support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4544:# TODO: Turn this into a decomposition (currently fails on reshape meta tests)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5343:    requires_grad: bool = False,  # TODO: unused
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5370:    # TODO: Use requires_grad.  All refs taking the requires_grad kwarg must
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5970:    # TODO: fix inductor rand_like for integer, bool dtypes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6004:# TODO: add support for functionalization aten.normal_functional
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6264:    # TODO: this is inaccurate, we actually test PySequence_Check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6305:    # TODO: this is inaccurate, we actually test PySequence_Check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6315:            # TODO: test this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6373:    # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6377:    # TODO: test for numpy input with PyArray_Check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6405:    # TODO (or not): support names kwarg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6415:        {"device": "cpu"},  # TODO: use torch.get_default_tensor_type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:126:        # TODO: This solution is no ideal since we may miss some factory methods. In future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:183:    # TODO: this part is TS backend specific for now and will be generalized to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:9:    TODO: This API is currently ts backend specific. We are working on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:23:    TODO: This API is currently ts backend specific. We are working on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/__init__.py:16:    # TODO(whc) expand this to include backend hooks and align with XLA backend needs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:222:    # TODO: Uhh.... it shouldn't matter, but changing this to true_fn results in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:225:    # TODO Sometimes the operands are not completely FakeTensor, something seems went wrong in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:16:# TODO to figure out a more generic approach
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:48:        # TODO(ydwu4): Subclassing HigherOrderOperator causes __module__ to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:21:# TODO: this is not really sufficient. While passes (hopefully) check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:77:# TODO: currently we just run the C++ implementation with fake tensors.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:290:                # TODO(oulgen): add support for tt.reduce
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:325:    # TODO(oulgen):
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:723:    # TODO(oulgen): Preexisting bug, if two kernel inputs are views of each
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:758:    # TODO(oulgen): For performance reasons, we want to ensure that these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:774:    # TODO(oulgen): For performance reasons, we want to ensure that these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:177:            # TODO: We want to use the same `checkpoint(Interpreter(gmod).run, *args, **kwargs)` here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/map.py:28:# TODO: We add this to prevent dymamo from tracing into map_wrapper,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:176:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:263:                # TODO: Validation currently involves an expensive traversal
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:363:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:855:    TODO(khabinov): we should deprecate this function and use torch.compiler.is_compiling().
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_utils.py:97:            # TODO: there are many flatten/unflatten in IterGraph that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:50:        # TODO: if we do ``deepcopy(_codegen)`` and the input argument contains
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:352:        # TODO: This is a temporary solution. We are going to remove DCE usage
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:598:        # TODO: remove this API after DCE is removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:614:        # TODO: remove this API after DCE is not used with IterGraph
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:739:        # TODO: remove this API once it is not used.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:59:# TODO(@fegin): Support multiple runs of graph optimization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:60:# TODO(@fegin): With this design, circular imports will happen when a pass
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:215:    # TODO: populate all the tensor metadata and remove the default.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:218:        # TODO: support symbolic shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:242:    # TODO: fix the memory_format
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:264:        # TODO: fix these value
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:324:                # TODO(@fegin): support symbolic shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:485:        # TODO: determine the dtype
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:601:# TODO(fegin): Have a template class for all Block class.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:611:    # TODO(fegin): populate/generate the max_exp_avg_sqs if exists
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:927:# TODO(fegin): The API only support fused adam now. Should extend it to support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:165:            # TODO: figure out why turning on cudagraphs cause exceptions.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:193:    # TODO(yifu): apparently having a meta kernel is not a necessary
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/comm_tensor.py:141:                # TODO(ezyang): I don't really understand what's going on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:483:    # TODO(@mrshenli): @yifuwang has a suggestion of conducting expansion and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:496:# TODO: ensure the key is unique.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:553:                    # TODO: SPMD should provid a default and configurable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/log_utils.py:47:        # TODO(anj): Add loggers for MPMD
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:39:        TODO(@wanchaol): some of these arguments are not necessary for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:53:        # TODO: add more necessary arguments to this interface.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:93:        # TODO: what if user passes in a incorrect `input_batch_dim`, how should we
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:100:            # TODO: add a few default passes here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:113:        # TODO: figure out a way to avoid explicit "cuda" mesh.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:132:        # TODO: add more necessary arguments to this interface.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:150:            # TODO: add a few default passes here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:215:        # TODO: move the trasnformation passed to this function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:227:    # TODO: provide schema_suggestions when placements do not match
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:393:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:141:    # TODO: this is broken because it won't redistributed potential tensors on the kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:480:    # TODO(anj): This depends on the call function node -> actual DTensor output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:522:        # TODO(anj): We require mapping of the final DTensor output to the wait
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:540:                # TODO(anj): We are depending on the concrete DTensor output of the dummy add.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:730:            # TODO(anj): Pipe the output schema for the BW pass
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:158:    # TODO: Only NCCL supports AVG so using backend like Gloo would
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:358:                # TODO: Currently this specializes to fused optimizer ops, but we need
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:397:                    # TODO: optimizer parts should follow the dtensor prop logic
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:536:                    # TODO: add support for default mode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:226:            # TODO(yeounoh) implement DeviceMesh backend and register XLA backend.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:246:            # TODO: if user want to pass pg_options, offer a way to do it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:273:            # TODO(yifu): remove tag and ranks once we fully migrate to native
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:304:                        # TODO: Add two tests to cover internal tests scenarios and re-enable reuse subgroup if exists.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/nn/jit/templates/remote_module_template.py:60:# TODO: Merge these two templates together in the future once TorchScript syntax is improved.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:261:            # TODO: We need to change this to rpc.remote, and make it async (see the else branch below).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:204:# TODO assert if ranks has duplicated entries
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:232:    # TODO add dim support?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:280:    # TODO add dim support?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:80:    # TODO: should we use pytree?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:149:                # TODO: support DTensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:89:        # TODO: figure out dynamo support for instance method and switch this to instance method
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:394:                    # TODO: re-enable the check once we fix the compile path
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:471:                    # TODO: re-enable the check once we fix the compile path
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:80:        # TODO: we should allow user to pass in the default seed from a config
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:23:    # TODO: Will follow up with dynamo POC to make warnings.warn working with dynamo.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:40:    # TODO: To add perf optimizations to this iterations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:94:    # TODO: To add test cases and ensure that it works for nested modules
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/fsdp.py:350:            # TODO: this is a short term fix and we should make the get_unflat_views
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:20:        # TODO(@fegin): this variable is originally create for testing, we
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:131:    # TODO(fegin): using kwargs is not a good idea if we would like to make
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_init.py:129:    # TODO: De-duplicate with `_apply` after `swap_tensors` path lands:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:146:        # TODO: Replace the sharded DTensor parameter construction logic with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:148:        # TODO: Simplify the following sharded parameter padding logic after
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:178:            # TODO: Hard code FSDP + TP; need to support HSDP + TP
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:353:        # TODO: Prefer this DTensor to be read-only and generalize the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/fully_shard.py:218:        # TODO: Remove this padding logic once DTensor pads the local tensor:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:18:# TODO: we can add additional info to RegistryItem to share across APIs. E.g.,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:165:            # TODO: a stricter verification should also reject changing module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:168:            # TODO: verify that installed distributed paradigms are compatible with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:176:                {},  # TODO(@yhcharles): this is a temporary fix, need a better way
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:57:        # TODO: Once step_param interface is robust, refactor step to call
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py:71:            # TODO: Remove these attributes once we have a better way of accessing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:58:    TODO: Add tutorial for _NamedOptimizer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:59:    TODO: Add documentation in the docstring for the public attributes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:313:        # TODO(chienchin): This API should be FSDP agnostic and should support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:322:        # TODO(chienchin): This API should be FSDP agnostic and should support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:29:# TODO (wanchaol): remove this once we added TorchScript
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:60:# TODO (wanchaol): remove/merge this with ScriptLocalOptimizer once
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:112:    # TODO: improve error propagation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1535:        # TODO: Manually add `self.param_groups` if using a functional
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:57:        # TODO: no union or any types in TorchScript, make step a scalar tensor instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/pipeline/sync/skip/skippable.py:241:# TODO(sublee): Move to above of Skippable class for better read flow.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_loader.py:33:        # TODO: test returning `load` here instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:9:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:19:# TODO: Update Docstring for nested_dict.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:34:# TODO: update docstring for traverse.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:145:        # TODO: add local offset for _local_tensor in print_nested.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_sharded_tensor_utils.py:15:# TODO: We need to refactor this code.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:384:# TODO: integrate with distributed logging flag
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:60:# TODO: Update docstrings for default_planner.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:46:# TODO: Update docstrings for optimizer.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:189:            # TODO: The ReadItems will have a displaced MetadataIndex, fix it.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:190:            # TODO: we should change _create_sharded_read_items to have more ergonomic API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:77:        # TODO: add logging for the gc details/time
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:373:        # TODO: make this faster.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:573:            # TODO: check if value is the same if exists.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:962:# TODO: correct the state_dict function signature.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:963:# TODO: this API is not yet fully tested. Make it private
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1017:# TODO: correct the load_state_dict function signature.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1018:# TODO: this API is not yet fully tested. Make it private
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:39:    # TODO: test returning `save` here instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_dedup_tensors.py:30:# TODO add docstring for dedup_tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:220:        # TODO replace with headq
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:269:            # TODO: Using the OverlappingCpuLoader with multiple threads creates significant
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:572:                # TODO sort by offset and cache the reading
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/format_utils.py:118:        # TODO: read on each host, instead of only the coordinator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:317:            # But maybe we need to? TODO(voz): Look into this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:579:        # TODO: Do not use the side stream for tensor copies for now; investigate
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:784:    # TODO: Post-backward prefetching does not support the multiple handles
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:961:    # TODO: Investigate why `NO_SHARD` breaks correctness when using
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:963:    # TODO (rohan-varma): When CPU offload and optimizer overlap,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:994:                # TODO (rohan-varma): For CPU offload, this unfortunately
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1084:        # TODO (rohan-varma): this also waits for the overlapped optimizer step to finish
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1127:            # TODO: This already-resharded check is brittle:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:155:    # TODO: need to check if this is always correct for composable FSDP.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:449:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:506:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626:            continue  # TODO: Improve unittesting for state_dict finetuning
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_wrap_utils.py:43:    # TODO: We may relax this no-nested-wrapping constraint to support manual
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:115:        # TODO: Move all the attributes to this class to enable typing for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:195:    # TODO: This is a temporary hack for differentiate between code paths.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:238:    # TODO: Explicitly replacing the checkpoint wrapper prefix is not ideal as
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:337:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:422:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:430:                            # TODO(voz): Don't graph break on this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:511:            # TODO: We need to run this mixed precision ignored module in fp32,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:559:        # TODO(voz): Extend a dynamo util to answer the above, unify the codepaths here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:81:        # TODO: figure out the case for the composable APIs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:96:        # TODO: figure out the case for the composable APIs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:142:        # TODO: Rank 0 can broadcast the `FlatParameter` to allow all ranks to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:253:            # TODO (awgu): The traversal function does not traverse through
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1448:        # TODO: This solution is not general and only apply to PTD TP solution.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1748:                # TODO: it is unclear if we need to do the same check with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:80:        # TODO (awgu): We can broadcast the metadata of rank 0's `all_handles`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:214:            # TODO (awgu): Since every module has at most one handle in the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:218:                # TODO(voz): Don't graph break on this - dynamo hates the n1 != n2
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:244:                # TODO(voz): Don't graph break on this - dynamo hates the i1 != i2
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:39:    # TODO: Add any other composable APIs that are mutually exclusive.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:46:# TODO (awgu): We may be able to remove this function if we retired the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:115:# TODO: Define this for now to avoid circular imports. See if we can remove.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1566:                # TODO (awgu): Gradient accumulation outside `no_sync()`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1607:            # TODO (rohan-varma): test for full precision with keep_low_precision_grads
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1616:        # TODO (awgu): We should replace these conditional checks to encode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1785:                # TODO: Change `_unpadded_unsharded_size` if we change the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2293:        # TODO: If we want to handle shared parameters, we need to re-generate
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:77:# TODO (awgu): Refactor this later
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:321:    # TODO: FSDP's contract for buffers is not well-defined. They are
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:517:    # TODO: we need to add additional check once we support FSDP + PiPPy.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:657:            # TODO: We may relax this by taking the FSDP instance's wrapped
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:832:    # TODO: We need to establish a contract for FSDP and buffers. For now, we
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1052:# TODO: See how to deprecate!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/distributed.py:77:            # TODO properly map the exceptions in pybind (c10d/init.cpp)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:430:        # TODO log_line_prefixes can be exanded too
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:144:        # TODO: look into using weakref here instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:190:# TODO: we should probably handle a few additional errors,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:248:        # TODO: look into using weakref here instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:919:        # TODO: implement timeout
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:84:    # TODO @kiuk - make entrypoint a required field
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:701:        # TODO after stopping workers, wait at least monitor_interval*2 for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py:100:# TODO: create an internal helper function and extract the duplicate code in FP16_compress and BF16_compress.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:72:            # not average. TODO: (rohan-varma) the div factor may be different
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:77:            # TODO (rohan-varma): upcast as needed for DDP mixed precision,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:593:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:814:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:285:    # TODO: Importing inside function to avoid circular import issue between FSDP and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:76:    # TODO: register_fsdp once FSDP supports communication hook.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:241:    # TODO this should be done inside AsyncCollectiveTensor to delay the wait() call
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:698:        # TODO: it should run collective in the whole mesh instead of dim 0
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:967:    group,  # TODO add a type,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:981:    op: str = "sum",  # TODO type is actually c10d ReduceOp. is this ok?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:982:    group=None,  # TODO add a type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/sharding_prop.py:173:        # scalar. TODO: figure out a better way to handle this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:138:            # TODO: by default check tensor metas across rank
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:139:            # TODO: See if we need to make this run_check logic
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:181:            # TODO: return the redistributed local tensor directly without
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:185:        # TODO: backward is also differentiable now, add a test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:248:        # TODO: consider all_gather the local tensors for better debugging
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:561:    # TODO: the value assignment to global variable is not the ideal solution
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_utils.py:16:# TODO: audit existing code base to see if we can safely remove this API.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:154:        # TODO: alltoall/permute reshuffling to change device_mesh if they are not the same
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:212:                # TODO: enable this with all_to_all
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:718:        # TODO: we can avoid forcing the redistribution once we figure out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:735:            # TODO: we can avoid forcing the redistribution once we figure out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:752:            # TODO: we can avoid forcing the redistribution once we figure out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:820:        # TODO: change the strategy to the following rule.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:827:            # TODO: now grad_out spec follows input spec. we may need
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:871:            # TODO: now d_weight spec follows input spec w/ a reduction.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:663:            # TODO: optimize this. we shouldn't simply blindly replicate
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/utils.py:140:        # TODO: maybe we should determine is_shardable based on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/random_ops.py:26:            # TODO: figure out how inplace random op should behave when it's partial
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/matrix_ops.py:151:    # TODO: sdpa might be a good candidate for us to explore decomposed sharding propagation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:98:                # TODO: further merge the sharding properly (i.e. reshard one input to replicate)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:164:            # TODO: consider a more advanced heuristic to pick the best sharding
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:115:            # TODO: see if this is valid for the submesh case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:171:    # TODO: filter out invalid strategies, at this point we generate
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/pointwise_ops.py:527:# TODO: add all for_each ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:178:        aten.new_empty_strided.default,  # TODO: re-think new_empty_strided
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:183:    # TODO: maybe we should generate all possible shardings intead of just stay
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:294:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:500:    TODO: exception: when the dtype of second input is "bool", then a torch.nonzero needs to be triggered first.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:775:    # TODO: tensor to split cannot have _Partial
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:785:    # TODO: just like slice op, split replicates before
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:44:        # TODO: evaluate if we need to release the mask buffer or the buffer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:177:    # TODO: implement rowwise sharding
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:253:    # TODO: implement rowwise sharding backward
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/dispatch.py:238:        # TODO: the op schema should probably just remain flattened so that we can avoid this tree flatten
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/tp_conv.py:13:    # TODO: whether there requires data exchange is currently determined by padding
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/placement_types.py:358:        # TODO: if the reduce_op is min/max, etc. the _partition_value should be a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/op_schema.py:214:    TODO: make this a frozen dataclass
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:26:# TODO: we need to migrate these APIs to be functional collectives
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:53:    # TODO: Ideally we should use the meta tensor way
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:109:    # TODO: Ideally we should use the meta tensor way
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:125:# TODO: test uneven split on GLOO and NCCL
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:142:        # TODO: pull the handle of uneven case in #492
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:207:                # TODO: see if we need to tweak this or offer a way for user
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:268:        # TODO: see if we want to support this once there's cross mesh communication
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/api.py:165:        # TODO: figure out a generic and efficient way to scatter the shards for EnumerableShardingSpec
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:150:        # TODO: Can we improve this error message to point out the gaps?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding.py:287:    # TODO: Make the result a PartialTensor.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding_bag.py:407:    # TODO: Make the result a PartialTensor and move the logic below there.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py:66:        # TODO: support named dimension
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:79:        # TODO: implement state_dict
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:90:        # TODO: implement load_state_dict
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:96:        # TODO: implement add_param_group
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:427:            # TODO make it as a view of out tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:492:        # TODO: make this a __torch_function__ op once ShardedTensor becomes a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:835:        # TODO: figure out what the API should behave when some rank have no shard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/tensor_ops.py:30:# TODO: set grad with a ShardedTensor that consists of all local grads
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:283:            # TODO: make async?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:342:        # TODO: add try-except and destroy _agent in all processes if any fails.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:245:        # TODO: remove this exception once UCC plugin is fully deprecated.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:482:        TODO don't expose the map, expose fine grained ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:492:        TODO don't expose the map, expose fine grained ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:502:        TODO don't expose the map, expose fine grained ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:512:        TODO don't expose the map, expose fine grained ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:522:        TODO don't expose group_count, use something else instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:611:            # TODO moco benchmark on CPU initializes pgnccl backend today, triggered this assert in CI before it was
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:816:# TODO: remove this once the ecosystem moves away from it.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:852:    # TODO(yifu): remove this function once ranks + tag is not a supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1506:            # TODO: remove this check after lazy initialization is supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1537:            # TODO: once UCC plugin is fully deprecated, remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1575:        # TODO: This defaults to the old behavior for PythonProcessGroups which overwrites the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3753:        # TODO(whc) aparently some existing test case for monitored_barrier passes in a timeout in float format?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4225:    # TODO copy settings and timeout from default PG
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_torch_docs.py:5271:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:43:# TODO: implement ref.cast with an option to enforce safe casting
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:172:# TODO: handle tuples of tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:362:            # TODO: There is a subtle bug here: prims like copy_to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:379:# TODO: when tracing this will add torch tensors and not TensorMeta objects
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:381:# TODO: this wrapper is currently untested
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:43:# TODO: Type[torch.SymInt], Type[torch.SymFloat]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:45:# TODO: This needs a lot more type annotations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:107:            # TODO: We should check that the symbols are consistent
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:134:# TODO: look at using torch.testing.assert_close instead with an option
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:164:        # TODO: we should review why this happens and see about fixing it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:440:    # TODO: are these necessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:449:    # TODO: do channels last too
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1034:        # TODO: type error here is real, replace with sym_complex
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1053:    # TODO: sym_complex_float?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1195:# TODO: maybe unify with can_cast_to?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1349:# TODO: when NumberType contains the sym types, can simplify this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1367:# TODO: document type promotion kinds
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1630:    # TODO: maybe inform the user of channels_last_3d if rank of the tensor is 5?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1923:    # TODO: a better way to handle this would be with a new op, "_unsafe_as_strided"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:123:    # TODO: no real reason to restrict multiple outputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:167:        # TODO: file issue
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:195:    # TODO: I think this does the wrong thing if r is inp
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:247:    # TODO: remove me
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:276:        # TODO: consider a memo
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:309:        # TODO: Add a config knob to turn off this unsound behavior
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:559:            # TODO: We can make this a little more faithful with best effort
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:941:            # TODO: Minor optimization: track if the shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:980:            # TODO: we don't need the compute type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:1002:        # TODO: is_non-overlapping_and_dense (not bound from Python
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/schema_check_mode.py:50:                # TODO: This is only OK if can't have NaN quantized; idk if
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_utils.py:109:                # TODO: enable_python_dispatcher() here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:69:    # TODO (tmanlaibaatar) make it a tag
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:103:            # TODO: right now, _make_wrapper_subclass's dynamic shape interaction is not great.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:288:            # TODO (tmanlaibaatar)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:468:    # TODO: pull these from aot autograd
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:82:        # TODO: test if is resizable (no direct query for this atm)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:83:        # TODO: audit AutogradMeta to see if it matches
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:84:        # TODO: test forward AD
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:216:            # TODO: make a dedicated UnknownSource for this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:415:                # TODO: Change this logic to use view replay for consistency?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:593:                    # TODO: Handle this better in Dynamo?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:872:                    # TODO: Use a valid grad-specific symbolic context instead of recycling
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:898:        # TODO: zero tensors?  We appear to have eliminated them by
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:913:                # TODO: sparse should support meta
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:50:# TODO: Hack to unblock https://github.com/pytorch/pytorch/pull/108186
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:416:    # TODO: Generalize this as needed, e.g., into a trie of memos
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1099:        # TODO: support caching sparse outputs?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1386:                    # TODO: Remove these exclusions, so that we can remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1405:        # TODO - we should be use the prim aten impl
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1406:        # TODO - fix prims complex ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1714:    # TODO: also check metadata change on inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:13:# TODO: Add type annotations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:14:# TODO: Check tensor types for ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:150:# TODO: Expose these directly to Python to avoid maintaining this list.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:206:    # TODO: Make this an enum.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:239:    # TODO: Support non-equal-rank broadcast where semantics match.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:264:    # TODO: Handle dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:492:                # TODO: Improve this error message, possibly after converting
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1169:            # TODO: Possibly check scale and zero point.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1171:            # TODO: Possibly support variable-sized inputs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1466:                # TODO: Support this by adding trailing 1 dims.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1496:        # TODO: Validate ceil_mode semantics.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1753:        # TODO: Transform at load time to share weights with CPU model.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1793:        # TODO: Support automatic reshape
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1832:        # TODO: Transform at load time to share weights with CPU model.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:2055:        # TODO: Transform at load time to share weights with CPU model.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:72:            # TODO: See if it's possible to use those directly.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:84:            # TODO: See if it's possible to use those directly.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:139:    # TODO: Maybe make these names match the original.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_custom_op/autograd.py:46:# TODO(#101191): Use the actual C++ autograd not implemented fallback,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:24:# TODO: Maybe we should allow for some sub-hierarchy so you can control which
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:113:    # flattens all the qnames together (TODO: consider memoizing?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:1055:            # TODO: Actually, the rank probably should just be emitted once at
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset13.py:549:    # TODO: So far we don"t have a module using this method. We"ll keep
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1510:        # TODO: remove this as onnx opset 11 spec allows negative axes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1561:    # TODO(justinchuby): Looks like this op is deprecated in torch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2446:    # TODO: remove this as onnx opset 11 spec allows negative axes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3451:# TODO(justinchuby): Support multiple quantized args in output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3477:# TODO(justinchuby): Support multiple quantized args in output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4261:# TODO(justinchuby): Support multiple quantized args in output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4291:# TODO(justinchuby): Support multiple quantized args in output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5376:    # TODO: remove this as onnx opset 11 spec allows negative axes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5856:            # TODO: If indexing is supported natively in ONNX in future opsets,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6311:        # TODO: Might need a fix in torch group_norm module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6820:# TODO: It would be better to export this as a chunk directly, as this is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6822:# TODO: Once we have proper scoping, stop reimplementing chunk, delete this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6884:        # TODO(justinchuby): Use a public method in the helper module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:112:# TODO(justinchuby): Add type checking by narrowing down the return type when input is None
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:252:            # TODO: Remove `check_shape` option once every shape inconsistent issue is addressed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:435:        # TODO: remove this and treat mutating model separately. See #77679
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:619:    # TODO: refactor utils.py to remove duplicated code of context setup. See #78834
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:691:    # TODO: Below is doing aten graph to onnx. It should be abstracted as a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:873:        # TODO(#77679): remove this and treat mutating model separately.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:921:    # TODO: Only copy the argument if mutation is detected in Graph.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1278:            # TODO: A more compact graph printer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1853:    # TODO: Copied from utils.py `export` until `_optimize_graph`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_experimental.py:14:    TODO: Adopt this in `torch.onnx.export` api to replace keyword arguments.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:39:        # TODO(thiagocrepaldi): handle overload_name?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:45:        # TODO(thiagocrepaldi): handle overload_name?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:16:                        TODO: test coverage for mixed types inputs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:19:                        TODO: bfloat16 support.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:22:                        TODO: optional start/end attribute.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:156:    # TODO(justinchuby): Replace insinstance with _is_value once we figure out mypy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:432:            # TODO(justinchuby): Only single output is supported for now. We may want to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1346:        # TODO(justinchuby): Check if dtype is indeed a int.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1718:# TODO: remove these once we support Type's in the JIT IR and we can once again
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:75:# TODO(justinchuby): Remove dependency to this global variable from constant_fold.cpp
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1127:    # TODO: can we simplify this to always return a tuple of Tensor or None?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1379:            # TODO(justinchuby): Create a way to check if an op is fully supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1625:            # TODO: Don't allocate a in-memory string for the protobuf
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1851:        # TODO(justinchuby): Update the module name of GraphContext when it is public
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1952:                # TODO Wrap almost identical attrs assignment or comment the difference.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:134:        # TODO: get opset version from torchlib
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:362:        from torch.onnx._internal.fx import (  # TODO: Prevent circular dep
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1017:            # TODO: Should this be part of the serializer?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1080:        # TODO: Should we populate ONNXProgram with more info, such _model_torch for easier debug?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1119:    # TODO: Design the passes API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1154:        # TODO: https://github.com/pytorch/pytorch/issues/107714
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1164:        # TODO: Defer `import onnxscript` out of `import torch` path
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1174:            # TODO: Defer `import onnxscript` out of `import torch` path
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1451:    # TODO: Import here to prevent circular dependency
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/registration.py:149:    # TODO(justinchuby): Add @functools.lru_cache(maxsize=None) if lookup time becomes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:119:    # TODO: select a good default based on the capabilities of the host
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:683:    # TODO(wschin): Make it to inference session level flag.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:774:        # TODO(wschin): this is a naive implementation of cache without proper guard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:951:            # TODO(wschin): enable external allocators.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1079:                # TODO(wschin): use a better way to identify fused submodule
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:4:# TODO(justinchuby): Move more of the symbolic helper functions here and expose
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:359:# TODO: Expose this to user when migrating symbolic helper functions to here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:7:# TODO: Remove after https://github.com/huggingface/safetensors/pull/318
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:41:    TODO: Should this really be a global patcher? Can we make it a local patcher?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:98:# TODO: generalize to allow more checkpoints formats (torch or gguf)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:39:        # TODO: Figure out how to retrieve commit hash.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:188:    TODO(bowbao): Add more overridable methods in call hierarchy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:189:    TODO(bowbao): Create an example once more overridable methods are added.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:315:            # TODO(titaiwang): aten::sym_size has overload, but fx graph is using
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/op_validation.py:92:            # TODO(titaiwang): How to bound indices/dim: INT64
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:38:# TODO(bowbao): move to type utils.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1267:        # TODO(bowbao): diagnostic.emit and diagnostic.set_message api.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:54:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:109:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/diagnostics.py:129:    # TODO: Compact display of `param_schema`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:56:    TODO(bowbao): Create fx utils module and move this function there.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:321:    # TODO: aten::sym_size has overload, but fx graph is using
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:400:    TODO: Convert methods to @staticmethod when the diagnostic system supports it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:409:        # TODO: Diagnostics API should be revised to get rid of this attribute.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:567:        # TODO: Fix FakeTensorMode limitation asap
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:761:        # TODO(wechi): Support call_method.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:818:        # TODO: We may want to consider other naming styles. The goal is to be stable and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/torch_export_graph_extractor.py:106:        # TODO: Import here to prevent circular dependency
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:125:# TODO: Migrate to `DynamoExporter` after fake model tracing is supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:159:        # TODO: plumb ``concrete_args`` to symbolic_trace call at ``generate_fx``
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:24:# TODO(bowbao): Add diagnostics for IO adapters.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:152:# TODO: make_fx lose stack info https://github.com/pytorch/pytorch/issues/90276
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:182:    # TODO(bowbao): Turn this check into diagnostic. Consider warning instead of error.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:493:                    "markdown": 'This error occurs when the ONNX converter is unable to find a corresponding symbolic function\nto convert a "call_function" node in the input graph to its equivalence in ONNX. The "call_function"\nnode represents a normalized function call in PyTorch, such as "torch.aten.ops.add".\n\nTo resolve this error, you can try one of the following:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/tutorials/beginner/onnx/onnx_registry_tutorial.html#overview) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n',
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:518:                    "markdown": "This error indicates that an FX graph contains one or more unsupported nodes. The error message\nis typically accompanied by a list of the unsupported nodes found during analysis.\n\nTo resolve this error, you can try resolving each individual unsupported node error by following\nthe suggestions by its diagnostic. Typically, options include:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n",
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:104:            # TODO(bowbao): by default diagnostic doesn't have stack.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:158:# TODO(bowbao): decorator to report only when failed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:280:    # TODO(bowbao): Implement this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:406:            # TODO(bowbao): Create builtin-rules and create diagnostic using that.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/_infra.py:264:    # TODO: Implement this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:30:# TODO(After 1.13 release): Remove the deprecated SymbolicContext
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:146:# TODO(justinchuby): Deprecate these logging functions in favor of the new diagnostic module.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset10.py:763:    # TODO(justinchuby): Extract all the cast ops into a helper function.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/utils.py:75:                # TODO(avik): Assert the following property in the IR verifier:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:30:    # TODO(angelayi): remove this in favor of _check_val
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:42:        elif isinstance(val, (FakeTensor, torch.Tensor)):  # TODO(zhxchen17) Remove Tensor.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:161:            # TODO Remove this allowlist.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:170:                # TODO (tmanlaibaatar)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:199:                # TODO(T140410192): should have fake tensor for all dialects
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:247:                # TODO(zhxchen17)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/upgrade.py:109:        # TODO(larryliu0820): Add support for custom ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:234:        storage_offset=serialize_sym_int(0),  # TODO needs to be fixed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:271:        # TODO: this should be fixed by deserialization instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:402:            # TODO(zhxchen17) Maybe provide a function name helper in FX.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:406:        else:  # TODO(zhxchen17) Don't catch all here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:439:                # TODO: create a new tensor_values here, meta might have faketensor info
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:476:                # TODO: This is not ideal, we should fix this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:858:            raise AssertionError("TODO")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1119:        # TODO: Directly serialize exported_program.constants once
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1179:        if serialized_target.startswith("_operator"):  # TODO(zhxchen17) Follow up on this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1185:        else:  # TODO(zhxchen17) Don't catch all here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1886:            # TODO(larryliu0820): Add support for upgrader & downgrader
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:102:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:107:                        # TODO we should allocate static shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:116:                        # TODO: This is just a workaround to get over the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:135:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:143:                        # TODO: This is just a workaround to get over the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:275:        # TODO(angelayi): Update this with what we decide to do for metadata in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py:16:# TODO (tmanlaibaatar) remove this after https://github.com/pytorch/pytorch/pull/100749
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:104:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:181:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:213:        # TODO(avik): Maybe record the constraint violation error instead and replay later?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_export/exported_program.py:8:# TODO(ycao): This is added to avoid breaking existing code temporarily.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/context.py:53:        # TODO: Should these methods be mapped some other way?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:233:        # TODO: This looks wrong, a number that is wrapped into a tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:338:# TODO: implement dtype validation here, too, or on the corresponding refs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:420:    # TODO: fix number type promotion (bool, complex->float)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:950:# TODO: complex needs a special meta to account for its float -> complex behavior
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1456:        # TODO: this is only here to support the unsqueeze ref
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1644:# TODO: make stride SymInt
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1695:# TODO: consider renaming split_dim_view
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1903:# TODO: review stride logic
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2054:        # TODO: update meta objects so this can be acquired directly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2118:# TODO: create a new return type for scalars?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2150:# TODO: create a new return type for scalars?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2182:# TODO: create a new return type for scalars?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2203:    # TODO: move this as an option on the reference
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2225:# TODO: Remove safe casting and implement on reference instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2288:# TODO: review support arbitrary resizes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2438:# TODO: layout, pin_memory, memory_format
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2439:# TODO: model requires_grad on TensorMeta
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2486:# TODO: layout, pin_memory, memory_format
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2487:# TODO: model requires_grad on TensorMeta
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2529:# TODO: add layout, pin_memory
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2584:# TODO: add layout, pin_memory
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2624:# TODO: add layout
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2707:# TODO: add layout and pin_memory support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2748:    # TODO The MAGMA backend returns V, so this is wrong if used with the MAGMA backend
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2875:# TODO: we should more seriously review randomness modeling and prims
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/executor.py:53:        # TODO: caching
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/maskedtensor/reductions.py:127:        # TODO: autograd.Function doesn't support kwarg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:524:    assert mask.dense_dim() == input.dense_dim()  # TODO: eliminate this restriction
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:816:    # TODO: implement sparse CSR specific where operator for efficiency
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1381:            # TODO: compute count analytically
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1605:            # TODO: compute count analytically
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1621:        # TODO: replace torch.subtract/divide/square/maximum with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1785:    # TODO: eliminate mask_input as unnecessary when using masked divide.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1789:        # TODO: replace torch.maximum with masked maximum when available.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1791:        # TODO: replace torch.divide with masked divide when available.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:112:        # TODO(avik): use sympy value range analysis instead?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:126:        # TODO(avik): use sympy value range analysis instead?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:188:    # TODO: We don't need t_id; we can get it off of w_tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:287:        # TODO: A better way is needed. Currently we use 't_id' to map the constraint,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:364:        # TODO(avik): clean this up
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:277:            # TODO(suo): untangle this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:281:                # TODO(suo): The FlatArgsAdapter returns a list of flat args,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_unlift.py:246:    # TODO(suo) this should not be optional, but is since we still ahve
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:129:                # TODO(suo): this is horrible.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:270:        # TODO Make this tuple.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:281:        # TODO Make this tuple.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:302:        # TODO Make this tuple.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:312:        # TODO Make this tuple.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:133:    # TODO properly use the cached fake tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:186:                    # TODO Figure out why sometimes we have root sometimes we don't.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:208:                    except Exception:  # TODO(zhxchen17) Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:413:    transform=lambda x: x,  # TODO(zhxchen17) Revisit if this is needed later.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:446:    # TODO unfortunately preserving graph-level metadata is not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:496:            # TODO: this branch is likely wrong, all permissible ConstantArgument type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:138:        verifier: Optional[Type[Any]] = None,  # TODO Change typing hint to Verifier.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:141:        ] = None,  # TODO: deprecate this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:478:        # TODO(zhxhchen17) Return the new graph_signature directly.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:543:        # TODO unfortunately preserving graph-level metadata is not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:584:        # TODO(zhxchen17) Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:675:    # TODO(zhxchen17) Formalize this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/_unary_ufuncs_impl.py:71:# TODO set __name__ and __qualname__
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/random.py:162:    # TODO: check a.dtype is integer -- cf np.random.choice(3.4) which raises
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/optim/radam.py:466:            # TODO(mlazos): we should try and get a foreach_where op https://github.com/pytorch/pytorch/issues/117884
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/optim/_functional.py:19:# TODO: use foreach API in optim._functional to do all the computation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/optim/adam.py:51:            # TODO(crcrpar): [low prec params & their higher prec copy]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:59:            # TODO(crcrpar): [low prec params & their higher prec copy]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/package/importer.py:81:            # TODO: I guess we should do copyreg too?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/package/package_exporter.py:918:                # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:246:                # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:283:        # TODO from zdevito:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:27:# TODO: The mechanism we are using to register decompositions doesn't
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:97:# TODO: do these also belong here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:27:# TODO - We have to register many more distributions here, and also higher level
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:168:        # TODO: Investigate if there is be a better way to wrap the tuple in a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:59:        # TODO: pretty sure this is not quite right
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:387:# TODO: None of these loss castings are quite correct, see
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1413:# TODO: this doesn't appear to have enough precision in bfloat16
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1591:# TODO: Take a closer look at the type promotion semantics
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1798:# TODO: this decomposition is NOT here to stay. We would much prefer replacing native_batch_norm
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1965:    assert not layout or layout == torch.strided, "TODO"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1966:    assert not pin_memory, "TODO"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2257:            # TODO make minimum accept scalars
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4055:        # TODO: handling of slice
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:23:# TODO: relax key type here; torch registrations should be possible to; but
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/cpu/amp/autocast_mode.py:34:    # TODO: discuss a unified TorchScript-friendly API for autocast
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:293:    # TODO: Handle distinguishing between subclass and non-subclass versions of NT better
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:592:    # TODO: Maybe this should be in tensor_classes? :)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_lobpcg.py:993:        # TODO use torch.linalg.cholesky_solve once it is implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_deploy.py:24:                # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_deploy.py:68:            # TODO: Once we decide to break serialization FC, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_guards.py:60:    # TODO: consider also tracking the recompilation count
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_guards.py:779:# TODO(voz): Consider a toplevel torch/_source.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:32:# TODO(torch_deploy) figure out how to freeze version.py in fbcode build
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:566:                # TODO: fix their module from C++ side
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:651:            # TODO: Call like get_device_index() method corresponding to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:1507:        # TODO: Once the undocumented FC window is passed, remove the line bellow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:1937:# TODO: remove the function for PyTorch v 1.15.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:390:            # TODO: binary search
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:634:            # TODO: type annotations for *args and **kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:132:        # TODO node_name_to_scope will be depreciated in favor of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:479:                # TODO: Define how to symbolically trace HigherOrderOperators
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:73:        # TODO: Figure out if this is safe. It seems like when generating the type signatures for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/meta_tracer.py:194:            # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:141:    TODO: we have to check if this is the case for all HF models
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:370:    # TODO: add the extra check mentioned here:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:393:        # TODO: review this rule; should input = dyn; output = dyn be included here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:519:            # TODO: we should figure out why there is a key-error here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:780:# TODO normalize index
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:884:        # TODO generate add constraints for scalar addition
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/schema_type_annotation.py:48:                # TODO: can we emit the union of these? What are the implications on TorchScript
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:354:                # TODO: add different size support for sparse_nn_partition
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:472:    TODO: Make Dynamo handle this appropriately if this is seen in Dynamo-ed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:477:    TODO: I didn't support min/max because I didn't have a use case where this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:540:    that doesn't have a lot of safety guarantees (TODO: provide higher level
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:580:    # TODO: Shouldn't we install a guard if the symbol is backed?  Or is the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:599:    # TODO: this does not install a deferred runtime assert yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:601:    # TODO: Maybe dedupe this with _maybe_guard_rel?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:610:        # TODO: Actually, we can support this as long as one of them is a symbol.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:657:        # TODO: check perf implications of this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:782:        # TODO: better printing for -oo and oo
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:939:    # TODO: add storage offset and stride symbolic_context
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:967:# TODO(voz): Shape env validation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:991:    # TODO(voz): consider a weakref to the shape_env here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1038:# TODO: Deduplicate this with torch/_prims_common/__init__.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1354:        # TODO(avik): https://github.com/pytorch/pytorch/issues/101093
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1756:                    # TODO(avik) Maybe we should generate an assertion here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1764:                    # TODO(avik) Maybe warn that `arg` in not in `signature`?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2383:        # TODO: make this configurable from outside symbolic_context; we made a symbolic_context
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2388:        # TODO: This should be DYNAMIC, using DUCK for BC
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2904:        # TODO: Make this more efficient by binding all the size/stride/offsets
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3566:        # TODO: when unbacked_only, can sometimes early return even when there
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3603:        # TODO it would seem that this pass is not necessary given the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3667:        # TODO: in a Dynamo context, having user code, and having the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3695:            # TODO: Help text about how to use our runtime tests to fix this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3748:            # TODO: Should we propagate size-like-ness?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4053:        # TODO: split conjunctions and evaluate them separately
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4126:                # TODO: dedupe this with _maybe_evaluate_static
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4175:                # TODO: If we successfully eliminate a symbol via equality, it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4187:                # TODO: deal with duplicate guards somehow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4247:        # TODO: split conjunctions and evaluate them separately
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4285:            # TODO: Do this in a way that is less janky than int(s.name[1:])
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/merge_matmul.py:116:        # TODO: Properly handle aliasing caused by get_attr. For now,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/_sym_dispatch_mode.py:50:        # TODO: properly compute types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:184:    # TODO. We leave it like this till we add a type to represent tensor sizes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/_config.py:30:# TODO: Perhaps consider allowing unions for the configs below (so you can hit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:154:            # TODO: This doesn't properly track storages.  A more robust
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:261:    # TODO: figure out if this API generally makes sense and bake it into the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:306:    # TODO: we could use types to test this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:332:        # TODO: maybe constant SymInts should also be allowed?  Not sure if
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:603:            # TODO(tmanlaibaatar): we should systematically couple it with expoert verifier,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:737:# TODO: I'm not sure what the point of this class is; you can just
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:756:        # TODO handle case where the first character of target is '*'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1042:            # TODO: it would be nice to line these up with the names
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1068:            # TODO: Would be nice to fix this at the source...
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1083:        # TODO: kind of a bad way to do it, should maybe figure out a better way
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:62:# TODO: An incomplete list
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:350:        # TODO: use the file/line for some useful diagnostic on why a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:360:        # TODO: use the file/line for some useful diagnostic on why a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:372:        # TODO: use the file/line for some useful diagnostic on why a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:389:        # TODO: file/line here is very important, because the assert has been
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:420:        # TODO: use the file/line for some useful diagnostic on why a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:444:# TODO: this probably needs the sizes-strides eval functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:817:# NB: There is a TODO in C++ to allow omitting the batch dim.  If that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:882:    # TODO: These could also be done with indicators, maybe it is better
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:914:    # TODO: let C++ also take advantage of this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:957:        # TODO: consider constant prop here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1002:        # TODO: consider constant prop here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1103:            # TODO: Remove the args construction below if a different sentinel is used by FX.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1163:    # TODO: This is technically hotpath, but in the ideal end state
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1184:            # TODO: this is an awful implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:121:# TODO: Determine whether this can be removed after type inference.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:90:        # TODO: assert pattern is a connected graph
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:110:        # TODO(tmanlaibaatar) should probably make this actual API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:212:        # TODO: use a more efficient way to check if gn is matched before: two-way dict
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:133:            # TODO: do we really need copy the get_attr node into the graph?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/fake_tensor_prop.py:49:                # TODO: How is it possible that we get a non fake tensor?  We
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:11:    # TODO: why is submodules passed here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:51:    # TODO: single node partition may be wrong due to the pessimization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:295:        # TODO currently placeholders/parameters aren't put into random partitions,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:210:        # TODO(alexbeloi): add constraint management/validation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:129:# TODO: this should be beefed up to be able to properly re-inplace with:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:132:# TODO: we should also figure this info out using torchgen.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:538:                # TODO: later, add the optimization for handling `copy_()` calls in the graph.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/node.py:42:# TODO: Either refactor this into 2 functions 1 dce for functional graphs and 1 dce for all graphs,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:127:    # TODO: we shold handle __reduce_deploy__ the same way as __reduce_package__,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/hub.py:290:    # TODO: Remove `None` option in 2.0 and change the default to "check"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:280:        # TODO: Instead of always upcasting to int64, it would be sufficient to cast to the next higher dtype to avoid
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:787:        # TODO: Remove this conversion as soon as all operations are supported natively by the MPS backend
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1522:        # TODO: compose all metas into one AssertionError
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:324:        ),  # TODO: Move out to testing in param_group?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:345:# TODO: consider tensor LR! See multi_tensor_optimizer_configs in test_optim.py --> tensor LR should work
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:831:        ),  # TODO: Move out to testing in param_group?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:87:# TODO: due to case sensitivity problems, for now list these files by hand
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:701:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:707:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:733:        # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:29:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1547:            # TODO: now that nccl send/recv is supported, there does not seem to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2546:            # TODO: move this test to use torch.profiler once kineto issues are
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3593:            # TODO: Instead we should probably go through _rank_not_in_group
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6436:            # TODO: NCCL backend does not work correctly for bitwise reduction ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8408:            # TODO: enable this for general training use cases:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8637:            # TODO(#54879): Provide ability to wait and report all failed ranks
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:374:        # TODO: dist tensor need to support quantized and sparse
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:411:        # TODO: add multi mesh choices
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:928:        # TODO, need more investigation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:1152:            # TODO: Can't get a reliable time for this profiling event since
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1566:        # TODO, need more investigation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:548:    # TODO: use torch.futures.collect_all
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:1421:        # TODO: with TCP init, rank 0 raises Address already in use because
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3462:        # TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:5106:        # TODO: Cuda RPC is failing due to:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1037:        raise unittest.SkipTest('TODO: Memory availability checks for XLA?')
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1522:# TODO: the "all" in the name isn't true anymore for quite some time as we have also have for example XLA and MPS now.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:144:    # TODO: reference function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:151:        # TODO(#50743): Figure out the error. "RuntimeError: Unrecognized tensor type ID: Batched"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2519:        # TODO(#50743): figure out the error
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2802:            # TODO: This code can path can be removed if #61309 is resolved
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3174:# TODO : Fix these discrepancies
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3317:            # TODO: compare structure (ensure analytic jacobian has correct shape)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3436:                # TODO: do this with in-memory files as soon as torch.save will support it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3732:                # TODO: torch.complex32 when properly supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3814:    # TODO: check that criterions don't ignore grad_output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:45:# TODO: TensorBase should work
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:61:            # TODO: clone storage aliasing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:105:# TODO: Expand this class to handle abritrary settings in addition to boolean flags?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1261:# TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2349:# TODO: Revisit the relaxed pairs and check how much work it is to fix the tests that would fail without the relaxation.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2715:        # TODO: sure looks like we unconditionally initialize the context here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2788:        # TODO: Remove this; this is grandfathered in because we suppressed errors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3486:    # TODO: add args/kwargs for passing to assertEqual (e.g. rtol, atol)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3547:            # TODO: default this to True
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3621:            # TODO: compose all metas into one AssertionError
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3705:    # TODO: Support context manager interface
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4094:# TODO: consider more complicated noncontiguity schemes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4115:# TODO: remove this (prefer make_symmetric_matrices below)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4165:# TODO: remove this (prefer make_symmetric_pd_matrices below)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:341:    # TODO(future PR): consider combining with skipIfNoQNNPACK,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:975:            # TODO: make img_data a single example instead of a list
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1488:        # TODO: remove this check and define two fuse_modules function on this module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1710:# TODO: self.fc should be self.conv
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1724:# TODO: self.fc should be self.conv
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1741:# TODO: self.fc should be self.conv
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1890:        # TODO: remove this check and define two fuse_modules function on this module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2427:        # TODO: remove this check and define two fuse_model function on this module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:62:    # TODO: FSDP non-recursive wrapping
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1350:        # TODO: Disable checking the parameters for pure FP16 due to floating
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/hypothesis_utils.py:131:    # TODO: Maybe embed the enforced zero_point in the `torch.iinfo`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:166:# TODO: Update all quantization tests to use this decorator.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:532:        # TODO: check gradients for parameters, not just inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:688:# TODO(suo) remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:752:# TODO: Remove me once https://bugs.python.org/issue42666 is resolved
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:821:        # TODO: inplace tests currently fail, fix and add inplace variant
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:825:    # TODO: find better way to standardize on op registration itself..
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:492:    # flaky test - TODO fix
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:530:# TODO: delete this list once we make all nn_tests work
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_cuda.py:53:# TODO(eqy): gate this against a cuDNN version
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:53:        "aliases": None,  # TODO add a check for alias coverage
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:55:        "inplace_variant": None,  # TODO: add a check for inplace coverage
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:754:    # TODO: rename this to supports_bwgrad_bwgrad to be consistent with below
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:835:    # TODO: rename supports_sparse to supports_sparse_coo
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1414:    # TODO(@heitorschueroff) Once all reduction operators are using
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1418:    # TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:2363:# TODO: in the future generalize the reference generators to handle n-ary elementwise operations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1534:        # TODO: backward uses in-place operations that vmap doesn't like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2394:            # TODO: is this really needed?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:150:                # TODO: remove this if-block after gh-98495 is fixed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:215:            # TODO: remove this if-block after gh-98495 is fixed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:248:            # TODO: remove this if-block after gh-98495 is fixed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:42:# TODO: Consolidate `i0e` with sample_inputs_unary when `make_tensor`,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:70:        # TODO: eliminate low after gh-106692 is fixed:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:771:            # TODO Move fftshift to decomps
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:780:            # TODO Move ifftshift to decomps
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/signal.py:302:            # TODO: same as this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:791:        # TODO: we should pipe the exception of the failed subprocess here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:925:        # TODO: get test name from kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1025:        # TODO: figure out a better way to do this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:364:    # TODO: Uncomment when negative weights is supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:1507:        # TODO: add pos_weight to the definition here and corresponding SampleInputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1313:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1320:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1408:# TODO: add reduction kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1870:        # TODO: no layout
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1878:    # TODO: no layout
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2128:        # TODO: fix bug in the documentation for svd_lowrank:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3231:            # TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4405:    # TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5034:    # TODO: can't switch `to.device` overload to use positional arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:7564:# TODO: add reference inputs for where(condition) signature
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8904:        # TODO: remove once the issue is resolved
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10179:                       # TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10821:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10832:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12524:           # TODO: some signatures of median do support out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12532:           # TODO: some signatures of nanmedian do support out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12540:           # TODO: some signatures of var_mean do support out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12553:           # TODO: some signatures of var_mean do support out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12565:           # TODO: some signatures of std_mean do support out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12578:           # TODO: some signatures of var_mean do support out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13032:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13052:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13081:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13246:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13288:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13336:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13386:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13446:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13488:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13521:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13565:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13582:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13603:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13653:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13670:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13687:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13940:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13959:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13987:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14033:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14049:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14077:           # TODO: add shape checks
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14142:           # TODO: add shape checks
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14146:           # TODO: investigate nondeterminism
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14261:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14350:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14400:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14481:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14508:            # TODO: Do not work even on MI200 because of stride mismatching.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14522:            # TODO Need to understand what this is testing and why it doesn't work
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14525:            # TODO skip this for now since we can't skip on runtime arch support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14582:            # TODO: Do not work on MI200 because of stride mismatching.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14603:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14648:    # TODO: combine this with the nn.functional.silu OpInfo when
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14726:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14825:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14831:        # TODO(whc) should not need sample_inputs_func, but without it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14922:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14946:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14965:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15132:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15287:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15889:               # TODO: Investigate this more
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16191:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16266:           # TODO(@heitorschueroff) update SampleInput to handle such cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16379:    # TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17332:               # TODO: same as this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17424:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17510:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17570:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17591:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17607:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17632:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17643:           # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17887:    OpInfo('trapz',  # TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18131:               # TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18315:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18403:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18451:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18478:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18511:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18544:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18569:        # TODO Benchmark again with the new implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18680:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18693:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18830:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18867:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18881:            # TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18908:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18959:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18962:    # TODO: delete this OpInfo once we add meta support for grid_sampler_3d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18970:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19326:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19375:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19450:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19526:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19544:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19639:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19661:        # TODO: Avoid COW materialize
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19838:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19839:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19867:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19868:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19899:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19900:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19926:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19927:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19953:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19954:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19982:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19983:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20012:            # TODO: RuntimeError: no _refs support for torch.rand_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20013:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20946:    PythonRefInfo(  # TODO: Port this to an UnaryOpInfo
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21663:        # TODO: Uses minimum and clamp
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21691:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21699:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21707:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21718:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21748:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21756:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21764:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21772:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21783:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21794:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21805:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21813:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21821:        # TODO: If self already has the correct dtype and device, then self is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22680:# TODO: review porting these to make_tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_subclass.py:7:# TODO: Move LoggingTensor here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:227:        # TODO(future PR): consider designing this better, as the difference
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:233:        # TODO(future PR): consider refactoring this to better reuse the parent
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:260:        # TODO(future PR): make the comparison function configurable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:396:    # TODO(future PR): expose these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:423:    # TODO(future PR): do not observe nodes we do not care
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:509:    # TODO(future PR): expose these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:536:        # TODO(future PR): better check when scripted
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:583:# TODO(future PR): align on naming
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:664:    # TODO(future PR): expose these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:805:    High level TODOs for future PRs:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:840:    # TODO(future PR): deduplicate repeating entries
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:864:# TODO(future PR): we should rethink the names of all the PNP APIs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:940:# TODO(future PR): we should rethink the names of all the PNP APIs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:963:# TODO(future PR): consider aligning API signature with other similar quantization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:973:# TODO(future PR): consider aligning API signature with other similar quantization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:996:        # TODO(future PR): consider matching in a safer way than
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:487:# TODO(future PR): clean this up
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:530:        # TODO(future PR): implement shadowing for binary ops and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:10:    # TODO(future PR): make this work correctly for methods
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:33:# TODO(future PR): reuse existing mapping instead of creating a new one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:112:    # TODO(future PR): try reversed(list(matches.items()))
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:166:            # TODO(future PR): make this code less confusing,  see discussion
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:242:    # TODO(future PR): reconsider the design to make this more intuitive.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:307:            # TODO(future): some graphs could have placeholders which are unrelated
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:346:            # TODO(future PR): handle non-normalized kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:373:            # TODO(future PR): this is not handling complicated graphs correctly, need to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:375:            # TODO(future PR): this is ignoring kwargs, will need to support kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:459:    # TODO(future PR): move logger classes to utils to remove circular dependency
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:491:        # TODO(future PR): deduplicate equivalent qconfigs that come from
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:528:            # TODO(future PR): handle fusion patterns where non-first nodes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:547:                    # TODO(future PR): clarify why we are adding kwargs to args
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:588:    # TODO(future PR): implement this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:609:        # TODO(future PR): add a test case for this once we have an easy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:623:    # TODO(future): consider making this configurable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:702:    # TODO(future PR): move logger classes to utils to remove circular dependency
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:800:                # TODO(future PR): make this support all possible args/kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:815:                        # cur_node_orig.name,  # TODO(future PR): set name explicitly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:992:    # TODO(future PR): move this to config
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1006:        # TODO(future PR, if needed): support kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1007:        # TODO(future PR, if needed): support multiple shadow users
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1011:            # TODO(before land): fix string match
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1086:# TODO(future PR): redesign this to make it easier to consume outputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1172:# TODO(future PR): redesign this to make it easier to consume outputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1252:# TODO(future PR): redesign this to make it easier to consume outputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:23:# TODO(future PR): consider deleting this enum and using the torch types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:30:    # TODO(future PR): while these functions can support multiple dtypes,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:35:    # TODO(future PRs): dynamic quant, fake quant, etc
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:45:    # TODO(future PR): clean this up
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:196:        # TODO(future PR): handle more functionals
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:197:        # TODO(future PR): handle functional ops which inherit qparams from input
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:314:        # TODO(future PR): use relationship map instead of hardcoding
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/ns_types.py:18:# TODO(future PR): see if we can use typing_extensions's TypedDict instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:240:        # TODO(future PR): determine the actual dtype of node_c,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:303:                # TODO(future PR): add handling for quantize_per_tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:320:# TODO(future PR): look into using copy_node API instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:449:    TODO(before land): real docblock
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:480:            # TODO(future PR): enable multiple inputs for nodes which are not at start of subgraph
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:842:                    # TODO: explain this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:72:    # TODO(future PR): make more generic, handle everything
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:149:    # TODO(future PR): why does packed_weight.unpack() not work?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:24:    # TODO(future PR): allow customizations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:25:    # TODO(future PR): reuse existing quantization mappings
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:26:    # TODO(future PR): add the rest of modules and ops here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:69:    # TODO(future PR): allow customizations from default patterns.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:74:        # TODO: this is a temporary hack to flatten the patterns from quantization so
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:90:        # TODO(future PR): if needed, implement matching for a node
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:183:    # TODO(next): make this code handle matching by what is before the base op
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:211:                # TODO(future PR): check for matches start_op_node and base_op_node
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:342:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:474:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:590:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:640:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:691:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:49:    # TODO: deprecated, remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:247:            # TODO: make this compatible with xnnpack constraints
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:368:            # TODO: make this compatible with xnnpack constraints
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:171:        # TODO: keeping self.quant_min/max for BC; remove after a couple releases
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:274:    # TODO: rename observer to observer_ctr
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:395:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:37:# TODO: replace all usages with these constants
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:44:# TODO: derive this map from the BackendConfig
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:112:    # TODO Currently it's required that separate ops in a fused op/module have the same qconfig.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:126:    # TODO: add assert for backend choices
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:294:    # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:321:    # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:20:# TODO(future PR): improve this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:27:# TODO: not sure if typing supports recursive data types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:33:# TODO: maybe rename this to MatchInputNode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:115:# TODO: not used now, remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:117:    # TODO: reuse is_fixed_qparam_node after we move this function to _lower_to_native_backend.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:360:    # TODO(jerryzh): Figure out why custom quant_min/quant_max are still adjusted.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:533:# (last update over 1 year ago) and when torchscript is fully deprecated we can refactor. TODO(jakeszwe, jerryzh168)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:591:        # TODO: switch to scale.item() after adding JIT support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:594:        # TODO: switch to zero_point.item() after adding JIT support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:122:    # TODO: change the value to QuantizationSpec in a separate PR
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:147:        # TODO: qat + per channel?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:272:        # TODO: move this to BoltNNQuantizer?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:379:        # TODO: implement the support for None to be canceling out previous annotations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:396:        # TODO: implement the support for None to be canceling out previous annotations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:129:    # TODO: Add more supported operators here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:502:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:559:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:606:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:641:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:55:    # TODO: remove, since we can use observer_or_fake_quant_ctr to express this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:488:        # TODO: annotate the uses of input, weight, and bias separately instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:902:# TODO: remove Optional in return type, fix annotated_partitions logic
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:918:            # TODO: change this to AnnotationException
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:958:        # TODO: remove?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1002:# TODO: make the list of ops customizable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:32:# TODO remove this once BC is no longer required to avoid a SEV
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:204:        # TODO remove Dropout special after codebase stable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:226:            # TODO: These are the modules that cannot be observed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:304:    # TODO: remove allow_list
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:322:    # TODO: maybe we should change activation_post_process to _activation_post_process
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:342:# TODO: rename to something more general
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:169:# TODO: rename this to _is_conv_node
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:179:# TODO: rename this to _is_conv_transpose_node
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:284:    # TODO: move this information to fx node itself
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:513:# TODO: Handle this in export itself and don't wrap the model in another GraphModule
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:78:    # TODO: change to mul.Scalar
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:83:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:125:    # TODO: use out_dtype(mul, ...) here when the op is ready
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:245:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:288:    # TODO: change this to mul.Scalar?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:328:    # TODO: use out_dtype op
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:398:    # TODO: use out_dtype(mul, ...) here when the op is ready
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:427:    # TODO: use out_dtype op
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:429:    # TODO: debug the implementation later when torchdynamo time out issue is resolved
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:100:    # TODO(Leslie): This function still fails to support custom momentum and eps value.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:162:# TODO: expose these under this namespace?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:27:# TODO: make pt2e folder private?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:125:    # TODO: add assertions for types of root qspecs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:263:            # TODO: maybe edge_or_node_to_qspec should be edge_or_node_to_root_qspec, this will simplify
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:474:        # TODO: simplify logic for inserting observers
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:95:# TODO: merge this with the `no_conv_bias` case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:111:        # TODO: allow setting eps
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:142:        # TODO: allow setting eps
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:196:    # TODO: allow setting eps
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:240:    # TODO: allow setting eps
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:427:# TODO: this is error prone, use the replace_literals_with_placeholders hack instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:555:    # TODO: use the public replace_pattern API once it also returns replacement nodes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:598:    #       TODO: do this for literal args for batchnorm as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:102:    # TODO: check qconfig_mapping to make sure conv and bn are both configured
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:104:    # TODO: (maybe) rewrite this with subgraph_rewriter
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:179:    # TODO: only fuse if conv and bn are both configured to be quantized
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:80:            # TODO: currently it only works for modules,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:82:            # TODO: currently it only works for object_type configurations,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:235:# TODO: correct the namespace for these modules
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:241:# TODO: merge with STATIC_LOWER_MODULE_MAP after we merge
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:268:    # TODO: LinearLeakyReLU is registered as global but it is only fused and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:354:# TODO: add tests for lowering these ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:733:        # TODO: maybe define a WeightedDynamicallyQuantizedModule
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:756:        # TODO: WeightedQuantizedModule is currently assuming static quant apis
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:759:        # TODO: maybe define a WeightedWeightOnlyQuantizedModule
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1021:        # TODO: add safety checks that users for the ref_node and dq_node needs to be one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1024:            # TODO: add a warning or error out here? (bc-breaking if error out)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1032:            # TODO: add a warning or error out here? (bc-breaking if error out)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1054:        # TODO: enable we have patterns that needs to swap the modules
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:47:# TODO: revisit this list. Many helper methods shouldn't be public
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:305:                        # TODO(future PR): remove this entire function  and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:322:                    # TODO(future PR): remove this entire function  and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:726:        TODO: traverse upwards from the output and handle the case when tuple is not a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:802:    # TODO: log warnings only when the user enabled a debug flag
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:810:        # TODO: for now, just use the existing eps value as scale_min. In the future, we should
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:845:            # TODO: handle fp16 qconfigs properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:103:# TODO: remove other variants and keep this one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:173:        # TODO: investigate why
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:213:# TODO: remove other variants and keep this one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:465:        # TODO: investigate why
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:547:# TODO: move this to https://github.com/pytorch/pytorch/blob/main/torch/ao/quantization/fx/_decomposed.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:729:    # TODO: support fp16
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:739:# TODO: dtype is ignored for now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:760:    # TODO: check for dtype, currently we can't express torch.int4 so it's omitted
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:18:# TODO: replace all usages with these constants
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:168:    # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:330:    # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:397:    # TODO: remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:100:        # TODO: change the signature for fuser_method to take matched module patterns
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:118:            # TODO: is this logic right?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:270:    # TODO: instead of instantiating the instance, we can use inspect to get the default args
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:292:    # TODO: support check for standalone module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:300:        # TODO(future PR): remove the cast to bool below after figuring
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:308:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:318:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:333:    # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:335:    # TODO: we should check is_dynamic here as well, the code from _is_input_arg_dtype_supported_by_backend
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:341:    # TODO: this is a hack because we can only specify one activation_obs_or_fq for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:508:        # TODO: refactor the following code in terms of apply a qconfig to a pattern
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:555:    TODO(future PR, if needed): explicitly spell out the non-Tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:759:    # TODO: move this to a separate function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:769:            # TODO: we are assuming "target_dtype_info" exists here, maybe
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:829:        # TODO: this is looking into how the value is used in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1071:            # TODO: this does not handle dynamic quantization yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1128:    # TODO: probably need to remove `is_general_tensor_value_op`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1261:    # TODO(future PR): delete the orphaned observer modules
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1367:    # TODO: we probably don't need this counter since each graph will only have
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1417:            # TODO(future PR): update the output_quantized_idxs API to match
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1422:            # TODO(future PR): support more dtypes in model outputs, if necessary
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1443:        # TODO: we might want to handle these more uniformly with the default path
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1473:    # TODO: reuse placeholder_node_to_input_index and output_node_to_output_index
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1480:    # TODO: change this to insert obs/fq by pattern instead of by node
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1512:            # TODO: take a closer look to see if we can remove this check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1581:                            # TODO: This currently diverges from how custom modules are handled today,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1802:    # TODO: support regex as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:26:# TODO(future PR): the 1st argument is typed as `List[Node]`, but a better type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:141:    # TODO: 1. merge with fuse matcher 2. document the code
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:40:    # TODO: We should make this private in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:80:    # TODO: change this to inplace changes to graph, since we no longer construct
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:109:            # TODO: add validation that root_node is a module and has the same type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:133:    # TODO: dedup with quantization matching function in match_utils.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:141:        # TODO: probably should cleanup this condition check, it's hard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:186:                # TODO: we can add the information of whether a value needs to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:196:                    # TODO: maybe need more complex attr name here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:296:                # TODO: we can add the information of whether a value needs to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:377:        # TODO: probably should cleanup this condition check, it's hard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:402:                # TODO: we can add the information of whether a value needs to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:406:                    # TODO: maybe need more complex attr name here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:424:        # TODO: get reduce range from observer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:447:                # TODO: we can add the information of whether a value needs to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:461:# TODO: DeQuantStubs are currently inserted only after custom module LSTM, while observers are inserted
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:548:    TODO: this logic is hacky, we should think about how to remove it or make it more
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:582:        # TODO: it's not used, so actually we can skip quantization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:633:    # TODO: remove is_reference flag
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:666:    # TODO: allow convert_custom_config to override backend_config
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:723:    # TODO: rename weight_is_statically_quantized to weight_is_int8_quantized
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:738:    # TODO: move this to the reference quantized module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:854:        TODO: maybe we want to redesign this part to align with reference model design
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:880:            # TODO: This is the first step in enabling the full fx custom module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:991:    # TODO refactor this code once we update the prepare logic to have additional information on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1120:    # TODO: maybe move this to quantize_fx.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1124:    # TODO: this looks hacky, we want to check why we need this and see if we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:145:# TODO: remove this class, this is still exposed in torch.ao.quantization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:153:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:157:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:161:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:165:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:169:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:173:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:179:# TODO: remove this class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:183:# TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:187:# TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:191:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:195:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/pattern_utils.py:14:# TODO(future PR): fix the typing on QuantizeHandler (currently a circular dependency)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:19:# TODO: move all LSTM util functions from fx/utils.py to this file
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:92:    # TODO: maybe make this work for layer_bw as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:327:        # TODO(jakeszwe, jerryzh168)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:371:            # TODO: switch to scale.item() after adding JIT support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:374:            # TODO: switch to zero_point.item() after adding JIT support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:392:# TODO(after v1.13): delete this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:479:        # TODO: MinMaxObserver by itself doesn't support dynamic quantization, but
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1239:            # TODO: For some reason, this is required for it to pass torchscript test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1393:        quant_min: minimum value in quantized domain (TODO: align behavior with other observers)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1670:# TODO(future PR): remove these defaults and enforce activation functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1676:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:1:# TODO: rename executorch to qnnpack_executorch since executorch is a general runtime
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:262:        # TODO: we can add fusion for torch.relu as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:306:        # TODO: this is not used right now since we have extra check in prepare
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/native.py:158:    # TODO: express this BackendConfig as a union of the FBGEMM and QNNPACK BackendConfigs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/utils.py:158:# TODO(future PR): move backend_config_dict to use dataclass and move this logic to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/qnnpack.py:80:# TODO: add additional restriction on qscheme to ensure it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/fbgemm.py:25:# TODO: For now, these DTypeConfigs are identical to the ones defined in native.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/tensorrt.py:26:    TODO: add a README when it's more stable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:23:    # TODO: need to fix the way we insert observers for this pattern
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:88:    # TODO: remove when functionalization is supported in PT2 mode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:130:        # TODO: this is not used right now since we have extra check in prepare
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:141:            # TODO: remove when functionalization is supported in pt2_mode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:28:# TODO: rename to be more explicit, e.g. qat_conv_relu
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:86:        # TODO: this is not used right now since we have extra check in prepare
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:323:        # TODO: we can add fusion for torch.relu as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:46:# TODO: maybe rename this to something that's not related to observer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:263:    # TODO: refer to NativeBackendConfig once that is implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quant_type.py:22:# TODO: make this private
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:181:# TODO: merge with default static mapping
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:329:# TODO: merge with get_static_quant_module_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/rnn.py:86:        # TODO: make this tanh a member of the module so its qparams can be configured
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/activation.py:308:        # TODO: This method has some duplicate lines with the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:237:        # TODO: dedup with __init__ of RNNBase
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:924:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:939:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1005:            ret = input  # TODO: remove when jit supports exception flow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:118:    # TODO: maybe change to this when https://github.com/pytorch/pytorch/pull/32958 is landed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/activation.py:221:        # TODO: This is a potential source of accuracy drop.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:144:    # TODO: add an util function for converting qdtype to dtype
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:165:        # TODO: torch.quint4x2 is not supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:191:    # TODO: get the quant_min and quant_max from activation_post_process
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:197:    # TODO: add an util function for converting qdtype to dtype
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:218:        # TODO: torch.quint4x2 is not supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:44:        # TODO(jerryzh168): maybe make this arg a required arg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:66:            # TODO: refactor the duplicated code to utils.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:126:    # TODO: refactor nn.RNNCell to have a _forward that takes weight_ih and weight_hh as input
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:153:            ret = input  # TODO: remove when jit supports exception flow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:292:        # TODO(jerryzh168): maybe make this arg a required arg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:539:        # TODO: maybe we can try inheriting from that class and define get_flat_weights
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/dynamic/modules/linear_relu.py:36:            # TODO check if we should set reduce_rage = True by default here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:41:        # TODO: Add qat support for BNReLU2d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:77:        # TODO: Add qat support for BNReLU3d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:18:# TODO: factor out the common parts to ConvNd
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:220:        # TODO(jerryzh): extend
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:102:        # TODO: Need to add options to qconfig to avoid the calibration.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:103:        # TODO: Add calibration for the sparsity
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:117:        # TODO (zaf): Mask might not be part of the qconfig (T83295194)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:8:# TODO (zaf): Inherit from `quantized.LinearPackedParams` (T83294430)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:66:# TODO (zaf): Inherit from `quantized.Linear` (T83294430)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:155:        TODO(zaf): Need to add the sparse params to the qconfig
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:165:        # TODO: Need to add options to qconfig to avoid the calibration.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:166:        # TODO: Add calibration for the sparsity
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:28:# TODO update desc with new config args
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:95:        TODO: Need a clean way of loading the state of the "prepared" module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:165:        self.model = model  # TODO: Need to figure out how to load without this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:172:        # TODO: Remove the configuration by reference ('module')
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:297:                # TODO handle multiple tensor being quantized on a single module, where to store sparse_params?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:40:        # TODO Fix this typing, as Type[Module] has no attribute "from_dense"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/base_structured_sparsifier.py:108:        # TODO LSTM Structured pruning does not support returned state currently.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:320:        TODO: Might have to treat functions (reduce_fn, mask_fn etc) in a different manner while serializing.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/cuda/amp/autocast_mode.py:43:    # TODO: discuss a unified TorchScript-friendly API for autocast
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:225:        # TODO(torch_deploy): this accesses linecache, which attempts to read the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_library/utils.py:104:    TODO: torchgen/model.py's FunctionSchema.parse is the source of truth for this,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/pytree_hacks.py:9:# TODO: remove this file when the migration of the pytree utility is done
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:175:        # TODO: Resolve this so we always have matching real / symbolic tensors / metadata.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:251:    # TODO: we should kill this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:301:        # TODO: we should apply the below "detach inputs if their gradients are statically known to be None"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:777:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:856:                        # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:884:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:915:        # TODO: Check aliasing relationships
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:916:        # TODO: Check strides for metadata mutation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:193:# TODO: UNUSED. delete?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:225:    #   TODO: add a test case to assert we error when this happens, instead of getting silent correctness
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:117:    # TODO: should factor this into a separate function for export that always only returns just the graph.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:184:    # TODO: in AOTAutograd, we create metadata like _indices_of_inps_to_detach to detect
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:115:            # TODO: Please remove soon
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:515:    # TODO (tmanlaibaatar) revisit this if we ever need to turn on non-strict joint graph export
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:562:    # TODO: add subclass guards (later PR).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:652:        # TODO: handle Tensor returns
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:155:                    #     TODO: discuss on the PR and decide if we want to tr to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:261:                # TODO: handle the custom autograd function case here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:524:    # TODO: Can avoid the zip here too, probably
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:540:        # TODO(voz): This structure is 1:1, we could consider an alternate structure like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:608:        # TODO: work out how to setup this assert correctly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:15:# TODO: It would be nice to reset the numbering every time aot_id goes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:47:    # TODO: Don't shove the aot_id in here; set it in the context
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:74:    # TODO: refactor to kill this flag
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:174:            #     TODO: discuss this in the PR. Both supporting this, and detecting + erroring out,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:319:    # isn't actually true.  (TODO: Could this cause problems for Inductor?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:96:        # TODO: Remove the following hack for namedtuples
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:162:            # TODO: There is some sort of problem where we record that an
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:181:        # TODO: update following link from master to stable once that's out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:274:            # TODO: Update link to stable once that's out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:286:        # TODO: Update link to stable once that's out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:346:        # TODO: What is to_size_hint suppose to be?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:808:            # TODO: Investigate why this hack helps.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:809:            # TODO: Investigate the interaction with compiler assisted
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:279:        # TODO: We don't need to copy the model to create a stateless copy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:330:        # TODO: We don't need to copy the model to create a stateless copy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:438:    # TODO: Chillee argues that dynamo itself should pass in fake tensors to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:513:                    # TODO: Ensure that this codepath is never exercised from
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:549:                    # TODO: refactor the subclass path of run_functionalized_fw_and_collect_metadata
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:612:        # TODO: Do this properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:909:    # TODO: There is something deeply wrong here; compiled_fn running with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1167:    # TODO: we might have to temporarily patch config.functionalize_rng
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__config__.py:12:# TODO: In principle, we could provide more structured version/config
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:96:            # TODO: skipping storage copy is wrong for meta, as meta
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:149:                    # TODO: Once we decide to break serialization FC, no longer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:316:            # TODO: Once we decide to break serialization FC, no longer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:372:                # Ideally, we'd use a private API for this instead. TODO: Switch to this if
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:413:                # TODO: Once we decide to break serialization FC, no longer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:1130:            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:247:            # TODO(jansel): explore this further normalization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:116:# TODO(jansel): ezyang says we won't need this in the future, try removing it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:132:    # TODO(jansel): add quantized types?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:275:        # TODO maybe we need to use pytrees here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:837:        # TODO: It would be better to realize the input if any of its sizes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1144:        # TODO <leslie> Remove this fallback when we support vectorization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1206:    # TODO: We observed negative performance impact of pointwise_cat optimization on CPU so disabled it.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1315:        # TODO: We don't have to guard on sizes per se, but the number
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1400:    # TODO: don't guard on static shape here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2182:# TODO(jansel): we should implement decomps or lowerings for these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2457:    # TODO(jansel): memory format
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3448:            # TODO: Need to support more reduction type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3672:            # TODO(Lezcano) Here we may not need to set-up a device_size
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4025:    # TODO(jansel): should we force these to be realized?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4059:        # TODO will need a better way of determining if inputs are channels-last
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4323:    # TODO: should we force these to be realized?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4685:            # TODO(jansel): optimize to do `int(x<h)` rather than `x<h?1:0`
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4694:    # TODO(jansel): should we force these to be realized?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:41:    TODO will it be necessary to tune multiple fields simultaneously.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:44:    TODO: what if both increasing and decreasing a field can improve perf.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:319:        TODO(ezyang): I think, in principle, every IRNode should have an
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:743:            # TODO the best heuristic currently has XBLOCK (corresponding to numel_hint) 128
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:842:            # TODO this will fail for something like ((1, N) * (N, 1)).sum()
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:867:            # TODO determine splits when all inputs are broadcast
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1257:        # TODO(jansel): realize the reduction so we can do dynamic indexing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1422:        # TODO: Unrolled reduction
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1592:        # TODO: Can combine_fn/reindex close over unbacked symbols? If so, we
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1655:            # TODO: CPU support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1720:        # TODO: custom splitting heuristic for scan
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2115:        # TODO: a new class for FixedTransferLayout that output layout is constrained by input layout
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3148:        TODO(jansel): A better algorithm here would look at downstream consumers of this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3802:        # TODO(jansel): replace this with dynamic shape formulas
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3829:        # TODO: Unconditionally do this, not just when example_output has
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3905:            # TODO(jansel): impose layout preference on realized buffer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3949:        # TODO - Storage to InputBuffer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4456:        assert isinstance(new_size, int), "TODO: dynamic shapes"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4661:    # TODO: handle bools carefully
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5399:        # TODO <Leslie> cleaned up the fake_tensor trace as Linear implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5693:        # TODO: op.call: input[0] should be at::Tensor&
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7318:        # TODO(whc) i'm not sure what's going on here, this probably means I missed something upstream
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7382:            # TODO: avoid more than one ref of the same pg (even though they are cached inside the api)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7429:        # TODO: A better fix is to figure out how to propagate the aliases properly,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7798:# TODO(yifu): replace the CollectiveKernel IR hierarchy with _CollectiveKernel.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7879:    # TODO(yifu): add a pre-grad pass to validate the correctness of collective
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:8056:        # TODO: might be necessary to do some pretty printing on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:545:                # TODO: migrate all disable reasons to stack trace, refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:601:    # TODO: Should we actually dump this?  It should be redundant with the aot
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:864:    # TODO(jansel): figure out why this version doesn't work:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:948:                    # TODO - could make one single op of multiple slices
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1303:    # TODO: can add logging before/after the call to create_aot_dispatcher_function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1344:    # TODO(voz): It would be nice to enable this assert, but there are lots of tests that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1357:    # TODO(voz): Should we always have one anyway?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:39:# TODO: A superclass that does desugaring for operations like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:180:    # TODO: Better explain how the "collective" semantics of these ops;
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:202:    # TODO: in practice, this seems to actually return None, but not returning
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:218:        # TODO: Improve the description with some pseudocode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:465:    # TODO(ezyang): Is this really the best way to do this?  What if we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/index_propagation.py:80:            # TODO: Inductor doesn't handle floating point in sympy expressions well at the moment
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/utils.py:218:    # TODO: There is a bug in a call to this function, to repro:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:45:    # TODO (tmanlaibaatar) figure out why this is different
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:105:    # TODO - further restrict cse ? right now needed to dedup aliasing ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1078:    # TODO: Revisit the functionalize_rng_ops for lowmem dropout
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1357:    # TODO - look into using aot autograd, asserting no mutating ops here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/triton_helpers.py:340:    # TODO(isuruf): use inline_asm_elementwise here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:60:    # TODO when we drop support for Python < 3.10, we can use
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:143:# TODO(xmfan): reuse an existing mapping for this if it exists, or formalize this into ir.py:ExternKernel
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:385:                            # but TODO this might be a convenient place to signal to the Collective kernels to inplace
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:453:            # TODO(voz): Should the pragma be constant somewhere?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:474:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:625:                    # TODO(xmfan): find a better heuristic to model FLOPS/latency relationship
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:665:            # TODO make this a property of the IR
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1597:        # TODO: ideally, we should deduplicate .users and .node_users,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1724:            # TODO support benchmarking epilogue fusion
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:156:            # TODO: this should not be needed once #93059 lands
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:158:            # TODO: make a dedicated UnknownSource for this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:419:            # TODO - get different values per hardware
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:746:        # TODO(jansel): handle input aliasing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:948:                # TODO: this is sus, it probably should be handled in the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1049:                # TODO(jansel): introduce a store vs inline choice
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1124:            # TODO(Eikan): Only support mixing cpu and other device now.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1191:            # TODO: reuse self.scheduler from the first pass to speed up the second pass
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1262:        # TODO. Revisit this once the logging API is more mature
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:423:        # TODO: These tensors don't currently pickle, so we can't cache a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:654:    # TODO(masnesral): Investigate whether it's beneficial to store compiled graphs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:920:    # TODO: When making an API that can save compiled models e2e to disk
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:179:    - 8 gpus per node  # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:187:    # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:553:    # we could also generate all these patterns in 3d.. TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:685:            # TODO: Enable CUDA after solving Bert accuracy issue of calling efficient attention
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:55:        # TODO: remove the need to run fake_tensor_prop on the whole model.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:59:        # TODO - decompose/type promote to avoid this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:85:        # TODO handle Tensor-Scalar adds, it's a different schema
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:182:        # TODO - we could also Tensors which get replaced with arange here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:127:        # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:22:# TODO: need a better strategy for decomposing mm
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:173:            # TODO: support scalar case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:191:        # TODO: support scalar case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:269:                # TODO: support linear?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/serialized_patterns/central_index.py:111:    # TODO - could add more validation that the same set of decomps used when
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:762:                # TODO: Haozhe investigate how add guard here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:890:            # TODO: Support dynamic shape case for MKLDNN conv transpose.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1186:        # TODO: aarch64: enable op fusion for acl once it supports fused operators. Disabling it for now.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:313:                # TODO: support kwargs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:475:                # TODO(yifu): this doesn't properly remove copy epilogues for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:249:    # TODO - finetune coefficient here. As a reference point, Triton mm model assumes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:402:        # TODO: Build a learned model which would be better than this heuristic
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:377:    # TODO(jansel): rewrite this as a bmm?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cuda.py:195:        # TODO: only works for constant now, need type info
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:470:                        # TODO: input shape checking for regular tensor interface as well?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1077:        # TODO: support other overload for cpp wrapper and remove the below assertions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1204:            # TODO: Add buf name directly into check_inf_and_nan.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1647:        # TODO: Only support tensor(s) returns for now, SymInt is not implemented yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1302:    # TODO: these look dead, but with all the getattr it's hard to tell...
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1429:        # TODO: hoist this to top level
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:587:        # TODO(jgong5): A more accurate way of deciding the dtype of the variables is to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1280:    # TODO: this seems to be dead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1393:        # TODO(jgong5): support conversion for other types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2427:            self._load_mask is None  # TODO: support transposition with mask
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2773:            # TODO(Eikan): To record, deduce and propagate the data type of every expression.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3059:                # TODO(Eikan): Regarding get_index and index_expr, we should conclude the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3380:            # TODO(jgong5): support alternative tiling factors and data types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3546:        # TODO(jansel): allow fusion pointwise (vars1, ()) suffix?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3565:        # TODO: we can extend fusion support with compatible ranges for FusedSchedulerNode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3589:        # TODO: we can fix if it allows us to CSE at least one of the variables
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3682:        # TODO: support kernel profile on other platforms
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3713:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3912:            # TODO(jansel): look into chunk size and other schedules
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:210:                # TODO mlazos: support dynamic shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:243:            # TODO: refactor generate_kernel_call
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:284:            # TODO(jansel): we could try harder here by merging overlapping in space
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:677:                # TODO(jansel): we should support reusing buffers created via ExternKernelAlloc
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:51:    # TODO(ipiszy): remove this hack when CUTLASS solves Python scripts packaging structure issues.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:122:    # TODO: these three look dead?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_epilogue_gen.py:135:        # of a previous epilogue node, a constant or (TODO) an auxiliary input.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:219:        TODO: Will add needed args to pass it in if it is dynamic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:243:        TODO: Will add needed args to pass it in if it is dynamic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:263:        TODO: Will add needed args to pass it in if it is dynamic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:319:        )  # @TODO: Hack for ensuring that Cutlass Kernel is preferred
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:400:        # TODO(ipiszy): Check whether it's necessary to swap X/W.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:482:        # TODO: update epilogue functor according to epilogues.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:682:            # TODO: Support split_k.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1628:        # TODO instead of trying to blindly find complicated exprs, we should hoist the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1701:            # TODO(jansel): it is sometimes possible to do higher dimensional block_ptrs with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1800:            # TODO(jansel): do we need a reshape here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2904:        # TODO(jansel): if there are constants, we shouldn't bother passing them as args
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3504:                    # TODO - use split ranges ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3533:            # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3582:            # TODO: Maybe unify CUDATemplateKernel to also use PartialRender for flexible epilogue fusion.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3737:            # TODO(jansel): should we tile reductions?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:136:# TODO: Move to a well known place
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:705:        # TODO: Add check for python too.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:725:                # TODO: integrate memory planning & stack allocation?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:778:            # TODO: this seems legit, NullLine has no node
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1068:            # TODO(aakhundov): add None args to constants, too. currently, this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1187:        # This is handled in `generate_args_decl` which has a correct comment of: TODO: only works for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:13:        # TODO: Remove fp8 special handling when Triton supports PyTorch fp8 dtypes.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:90:            # TODO(voz): These are kinda redundant, if we can solve out statically_known_multiple_of with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:186:    # TODO - remove, prevents cleanup
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:207:    TODO: in the future, we would like to do the following once storage weak refs land
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:253:        # TODO - when issue #91395 is landed, we can set a weakref on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:924:        # TODO - one jit kernel across multiple inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1452:        # TODO: - should we make the storage resizable ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1535:            lambda: "TODO: graph recording observed an input tensor deallocate during graph "
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1659:    # TODO: make generation increment configurable, warn on overwrite.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:2078:        # TODO: we could also allow the these weak refs to continue to be allocated,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:506:                # TODO(jansel): should we use sympy.diff here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1293:        # TODO: this may only be beneficial when each iteration of the reduction
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1348:    # TODO(jansel): we should be able to improve these heuristics
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:114:        # TODO - fix errors with this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:121:        # TODO - constant folding triton kernel returns the inputs -- fix this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:130:        # TODO - more complicated strategy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:509:                # TODO(nmacchioni): fix sympy division by zero
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:820:        # TODO(nmacchioni): remove once CI tests are fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:377:    # TODO: check if it's beneficial to convert Conv1d to Conv2d and then
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:382:        # TODO maybe we can convert weights to channels last just once before
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:454:                # TODO(jansel): try unroll for bigger kernels once fixed:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm.py:170:        # TODO: Re-enable eager mode implementation once cuBLAS is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm_plus_mm.py:208:        # TODO(jansel): support different K values when this is fixed:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:329:# TODO: fork is not safe in a multithreaded environment, we should evaluate changing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:406:# TODO: remove later
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:510:    # TODO - need to debug why this prevents cleanup
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:624:        # TODO: Support non-zero workspace_size.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:637:            None,  # set workspace ptr, TODO: update it to a real ptr if workspace_size > 0
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:97:# TODO: for now, inductor doesn't handle asserts
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:324:    assert not self.is_complex(), "TODO: implement this"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:386:    # TODO: _to_copy tensor to stride permutation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:50:    # TODO - there are dominated uses whose dtype does not depend on whether
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:71:                    # TODO - not sure if we should be doing int/float casts while tracing,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:109:    # TODO - if dominated node of one to_dtype is not expressible in int32,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:39:   TODO: Define a parent class / protocol that defines all of the operations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:128:            # TODO: To be honest, I feel we probably should just error in this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:159:)  # TODO: improve type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:43:    TODO: We might want to adjust this in the future to account for memory limitations.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:99:    TODO: Come up with a better approach
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:259:                # TODO: Smarter heuristics here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:331:        # TODO - Running exec generated frame seems propagates f_globals to the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:354:                assert recompile_reasons, "TODO(whc) any other recompile reasons?"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:832:# TODO mlazos: add support for same args, or record them
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:877:            # TODO: the first condition is not covered by any test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:214:            # TODO: replace `same` function with the one in testing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:269:        # TODO: maybe should just pass the entire f_code in here?  Not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:306:            # TODO (tmanlaibaatar) Remove this once we always lift params and buffers
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:461:    # TODO(rzou): can delete after we refactor speculate_subgraph to use nested GraphTracer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:538:        # TODO - Consider having a torch level API for torch_function_state. As
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:658:            # TODO: don't readd symint if we already have it in graph
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1158:            # TODO(voz): The way export uses gm, and fake tensors, is not supported with us resetting
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1162:            # TODO(voz): Ostensibily, this should be scoped and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1206:            # TODO: Why isn't this stored in meta :think:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1324:    # TODO: this is a generic pass that should live outside of Dynamo
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1334:        # TODO: Request simplification on runtime asserts before emitting them
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1496:                            # TODO: Remove relaxing assert on unbacked_symint https://github.com/pytorch/pytorch/issues/119689
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1507:                                # TODO: use ra.msg here, but it's pretty
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:237:                # TODO(whc)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:350:            # TODO - better way of doing this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:58:                    # TODO: not correct for args that contain tensors in a struct
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:64:        # TODO: error on unrecognized nodes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/tvm.py:86:            # TODO(shingjan): This could be replaced by tvm.contrib.torch.optimize_torch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:733:    # TODO: this is questionable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1467:     * (TODO)confirming which functions got compiled/skipped
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1956:            from tabulate import tabulate  # TODO: Check that this is installed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2172:    # TODO - This is a temporary situation where we have two versions of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:112:            # TODO: Maybe complain if this isn't a int/bool/float variable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:129:        # TODO: The default repr is pretty bad, do better
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:132:    # TODO: API for adding a custom guard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:217:        # TODO: improve printing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:228:        # TODO: improve by improving the VariableTracker printing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:259:        # TODO: improve print format, current guard format is extremely
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:11:    # TODO(jansel): double check exception handling
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/types.py:85:        # TODO(whc) how do I annotate a _RecordFunction here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/source.py:538:# TODO: can probably write a generic "test this on everything in the chain"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:91:    # TODO(jansel): we should move guarded_backend_cache to C++
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:687:# TODO(voz): Consider making "explain" output alongside a run / part of a run
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:691:        # TODO(voz): Do we want a decorator for this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:727:        # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:748:        # TODO(voz): Do we want a decorator for this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:803:                    # TODO(zhxchen17) Also preserve all the user constraints here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:903:            # TODO: option to print ALL of the stack traces at once
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1309:            # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:52:# TODO(jansel): need to ensure this does not get DCEed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/test_minifier_common.py:129:            # TODO: return a more appropriate data structure here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:802:                # TODO(voz):
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:833:                # TODO(jansel): returning None here is wrong, it should be
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:912:        # TODO: Should we allow non SymTypes here?  Today it is allowed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1024:            unimplemented(f"TODO: add support for ndarray.{name}")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:179:    # TODO: storing a SymInt here but not a FakeTensor is a pretty strange
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:656:            # TODO: this doing it manually is bad
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:665:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:669:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:673:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:769:            # TODO(whc): Why do we limit this to methods on NNModules?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:797:                # TODO(jansel): combine this case with the one above
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:929:            # TODO(whc) We could add a guard on the opposite case, where a user compiled/ran
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1227:                # TODO: This should be dynamic, as we in general do not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1236:                    # TODO: dynamic_dim = DimDynamic.STATIC should work but
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1460:        # TODO: not sure about this fake mode test
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1722:    # TODO: index export_constraints ahead of time so we don't have to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:218:    TODO: make it possible to use ProcessGroupVariable as input to simple functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:223:    TODO: should we make this inherit VT instead of UDOV? Do we want any of the default behaviors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:251:        # TODO should this just raise unimplemented?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:417:            # TODO: support pytree output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:569:        # TODO(voz): Support fake tensor dispatch for recursive
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:636:            # TODO: Support kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:924:        # TODO: Support kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1020:        # TODO: Support `fn` with kwargs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1056:        # TODO: Support kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1300:        # TODO (tmanlaibaatar) support pytree here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1597:        # TODO: assert that bwd_graph didn't capture values that were
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1600:        # TODO(oulgen): Ideally, we would not do a linear search for output
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:287:                # TODO: If we expand this to handle tensor args, we need to manually
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1331:                    # TODO(voz): Make it work properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:471:            # TODO(voz): This is rewritten as a call_method because
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:481:        # TODO: These special cases shouldn't be necessary; we should
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:606:            # TODO: this probably should be folded somewhere else but I'm not
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:608:            # TODO: some of the other symbolic_shapes special tools can also
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:641:            # TODO(voz): Replace w/ dynamic shape rewrite table.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:660:                    # TODO: there maybe other recursive structures you need to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:270:                # TODO: Use named_children when it supports remove_duplicate=False.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:323:                    # TODO: do we want to support __call__ for GM's?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:91:        # TODO(jansel): there is a small chance this could trigger user code, prevent that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:209:        # TODO: support an expression form as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:739:            # TODO Add all the functions that go from constants to constants to can_constant_fold_through
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:72:            # TODO Temorarily remove to figure out what keys are we breaking on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:98:            # TODO: Put this in utils and share it between variables/builtin.py and here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:579:            # TODO(jansel): implement unpacking logic in ModelOutput.__post_init__
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:779:    # TODO(voz): Upstream to transformers lib
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:299:            )  # TODO(voz): These can invoke user code!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:302:            )  # TODO(voz): These can invoke user code!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:305:            and len(kwargs) == 0  # TODO(ybliang): support kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:575:                # TODO(jansel): add a guard to check for monkey patching?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:880:        # TODO this should probably be merged with the dict handling
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:169:        # TODO: shouldn't this be f_locals/f_globals from frame?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:159:        # TODO - Assuming that all modules can be safely repr'd. Check if that assumption is correct.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:214:        # TODO - Keep this code for now. But, I don't think we will need this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:531:# TODO: Support bundling the entire repro into a zip file for ease of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:558:                    # TODO: transfer it to the right device?  But failing this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:620:        # TODO: consider ensuring tensor and storage counters line up?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:654:        # TODO: being optional on device is kind of pointless as the default
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:699:    # TODO: this doesn't actually symint atm
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/cache_size.py:74:    TODO(janimesh) - Consider adding a map from tuple_of_match_ids to count -
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3120:    # TODO: Once we require py3.9 use removesuffix instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:856:# TODO use the actual object instead, can interface from eval_frame.c
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/resume_execution.py:467:            # TODO(jansel): add dead code elimination here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:266:        # TODO: something here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:367:            # TODO(janimesh) - This is currently restricted to nn.Module objects
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:474:        # the internal types match.  (TODO: what about nested lists?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:494:        # TODO: It feels like it would be better to just implement our own
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:574:    # TODO(voz): Deduplicate w/ AOTAutograd dupe input guards
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:748:            # TODO(voz): Either populate a dispatch_key check into the guards, or error on users passing in an unsupported
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:752:            # TODO(voz): We are missing storage offset in all our tensor guards?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1041:                # TODO: we could make use of 'DefaultsSource' and offer a .guard.is_defaults() API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1053:        # TODO(janimesh) - Currently this information is stored as an attr on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1187:        # TODO: the "guard" here is actually just the top level SHAPE_ENV
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1232:        # TODO(whc) maybe '.code_parts' was only kept around for the guard callback? so we don't need both
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1481:        # TODO(voz): Combine local and global guard builders.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:21:    TODO(khabinov): we should deprecate this function and use one of these two:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:159:    TODO(voz): We now have allow_in_graph, disallow_in_graph, forbid_in_graph - some more robust
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:222:        # TODO: Make this configurable via a supported public API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:231:        # TODO(voz): Should we bounds check?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:249:        # TODO: Make this configurable via a supported public API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:255:        # TODO(voz): Should we bounds check?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:286:        # TODO: Make this configurable via a supported public API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:292:        # TODO(voz): Should we bounds check?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:321:# TODO: we should delete this whole _allow_in_graph_einops logic by approximately 2024 Q2
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:86:        # TODO(jansel): are all these modes needed?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:330:            # TODO maybe should respect DtoH sync intention of users later??
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:463:                # TODO link the torch.cond doc later
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:504:                # TODO: Also report the traceback from the parent frame
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2157:        # TODO(jansel): check the id of the cell rather than the contents
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2357:        # TODO: mlazos, add support for enabling multiple artifact logs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2555:        # TODO(jansel): figure out why this is needed, it isn't in the docs for YIELD_VALUE
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2578:                    # TODO(voz): Unclear if we need the push None in YIELD_VALUE?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:150:    # TODO: Figure out why torch.compile'd hash isn't work on this codepath
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:156:            # TODO: improve these names with FQN
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:236:    # TODO: factor this out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:263:    # TODO: It's inconsistent to pass SymInt inputs but REAL tensors.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:424:            # TODO: disable clone
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:76:        # TODO: why do we need to deepcopy the original graph?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:85:            # TODO: Failures here are troublesome because no real inputs,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:236:            # TODO: improve these names with FQN
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:315:    # TODO: factor this out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:480:    # TODO: speed this up
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:555:    # TODO: The logic for cloning inputs/models here is intentionally
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:644:    # TODO: check eager determinism
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:711:# TODO: lazily load the inputs or something, rather than cloning them
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:860:    # TODO: make this an option for --analyze too
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:102:# TODO(janimesh, voz): Remove both of these flags (or atleast guard_nn_modules)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:180:# TODO: Detect this situation automatically so the user doesn't need
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/contrib/_tensorboard_vis.py:137:        # TODO: handle attrs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:58:        # TODO: The cache is NOT currently used by HigherOrderOperator, but it should!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:103:                # TODO(voz): Should we replace setting torch._C.DispatchKey.Python entirely with setting mode keys?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:276:        # TODO (tmanlaibaatar) Make it generic fallback mechanism
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:660:                # TODO: We also need to handle tensor subclasses here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:661:                # TODO(voz): We should walk all the nodes here / turn it into a list, topmode is ok for now.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:667:                    # TODO: This path is slow, should generally encourage this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:670:                # TODO(voz): The idea behind this is that we do not yet support dispatch by key + mode, only key.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:705:                            # TODO: need to double check the semantics of the "types" argument to torch_dispatch.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:713:                        # TODO: check that I got these args correct (in C++, we pass in "0000"??)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:731:        # TODO: We could potentially have lots of debugging wrappers against
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:766:    # TODO: add more methods to expose information about input and output arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:828:            # TODO: disallow access to overloads registered by JIT
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:856:    # TODO: use this to make a __dir__
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:91:        # TODO: investigate if contiguity along other axes than the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:261:            # TODO in the future we can add in padding to support sparse dimensions that aren't perfect multiples
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/xpu/XPUEvent.h:112:    // TODO: provides the ability to time the execution of commands in a SYCL
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CUDAFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:29:// TODO: Add constructors for all of the descriptors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:99:  // TODO: Figure out why const-correctness doesn't work here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:369:        "TODO: support more cuDNN activation modes");
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradNestedTensorFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:62:// [TODOs]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:111:// TODO: move this from `at::` to `jit::torch::` after
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/Utils.h:93:    // TODO: is this necessary?  We used to treat nullptr-vs-not in IntList
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CPUFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/quantized/QTensorImpl.h:33:  // TODO: Expose in PyTorch Frontend
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:35:// TODO: try to remove this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/symbol.h:77:  // TODO: eliminate me
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/DispatchKeyExtractor.h:41:  // TODO: It's a bit irritating that we have to do logical ORs here, it would
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/Dispatcher.h:187:  // TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:256:  // TODO Use list_element_from?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:282:  // TODO Use list_element_from?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:69:  // TODO(jerryzh): add a Get(c10::DeviceType) function?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:78:    // TODO: after we add Get<Tensor>(c10::DeviceType)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:108:      // TODO Re-enable logging
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TransformationHelper.h:129:  // TODO: must be investigated and unified!!!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:13:// TODO: consider storing namespace separately too
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:20:  // TODO: These two functions below are slow!  Fix internal data structures so
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PythonOpRegistrationTrampoline.h:5:// TODO: this can probably live in c10
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/stack.h:9:// TODO move this to c10 namespace
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:132:    // TODO(min-jean-cho) change to Polar method, a more efficient version of Box-Muller method
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:133:    // TODO(voz) We use std:: below, and thus need a separate impl for CUDA.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:1764:// TODO this is deprecated but we don't throw a warning because a lot of ops in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:196:  // TODO: temporarily disabled
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:235:  // TODO: Deprecate me
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:1368:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:273:   * TODO: need to support customizing equality
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:345:    // TODO: Find way to expose alias info for opaque tensors.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:465:    // TODO (after Tensor merge) If we pass in a Blob holding a Tensor, extract
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1085:        // TODO: Find way to expose alias info for opaque tensors.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1120:  // TODO: There are several places that recurse over IValue. This is fragile.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dynamic_type.h:133:  // TODO Change Ptr to DynamicTypePtr when all migrations are done.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:506:  // TODO remove the mutation here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List.h:457:  // TODO Test use_count
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:576:// TODO: investigate making this SingletonOrSharedTypePtr<TensorType>
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2098:  // TODO: static_assert that a templated function exists, and throw a friendly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2105:  // TODO: static_assert that a templated function exists, and throw a friendly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/Generator.h:51: * TODO: Look into changing the threading semantics of Generators in ATen (e.g., making
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/BoxedKernel.h:130:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:15:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:209:  // TODO: it probably would be good to tighten this up quite a bit more with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:268:    // TODO static_assert(AllowDeprecatedTypes, "You tried to register a kernel with an unsupported output type: std::vector<T>. Please use List<T> instead.");
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:432:  // TODO Delete this once kernels don't do that anymore
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/test_helpers.h:29:  // TODO: We add this to simulate the ideal case where we only have Autograd backend keys
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/boxing.h:80:  // TODO Reuse stack vector instead of allocating?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:13:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:157:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:404:  // TODO: once modules support arbitrary ivalue attributes, we don't need this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:406:  // TODO: This is better represented as an OrderedDict, but alas it is not yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:551:  /// TODO: it's not in native_functions.yaml yet as it's not exposed to python
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:589:  // TODO(#97856) Make this return a const pointer. This currently
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:612:  // TODO(#97856) Make this return a const pointer. This is currently
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:9:// TODO: Clean up what remains here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:70:// TODO: AutoNonVariableTypeMode should be removed in release 1.10.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/adaption.h:49:  // TODO: Remove this once the following issue is addressed:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:249:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:278:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:293:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:308:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:349:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:390:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:528:       // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:559:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:576:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_allowlist.h:3:// TODO: unify to C10_MOBILE. In theory this header could be used in OSS.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/NestedIntSymNodeImpl.h:40:  // the higher-level API in python instead (TODO: actually introduce that).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/detail/CUDAHooksInterface.h:59:// TODO: Consider putting the stub definitions in another class, so that one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/FunctionalTensorWrapper.h:207:  // TODO: maybe it's possible to arrange for that to happen automatically
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:31:// TODO: Move the MPSGuardImpl to inherit from NoOpDeviceGuardImpl
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:64:    // TODO: Currently setting only device 0
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:81:      //TODO: extend it for multi-device case
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:19:// TODO: Unify the logic with CUDACachingAllocator and remove redundant code.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:119:    // TODO: check the caching performance of write-combined mode
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:316:  // TODO: make a common function to do size unit conversions in PyTorch.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:46:  // TODO: don't expose private implementation details like this; in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:52:  // TODO: don't expose private implementation details like this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:112:  // TODO: numel_custom and is_contiguous_custom can be profitably overridden
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:170:  // TODO: maybe we can remove this metadata since
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradNonFunctionalFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpp_custom_type_hack.h:93:  at::AutoDispatchBelowADInplaceOrView guard; // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_int.h:747:      // TODO<leslie> We can use _mm512_zextsi128_si512 in the furture,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_double.h:159:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_float.h:574:// TODO(jgong5): rewrite with ATEN vectorized (need to add unpack and shuffle)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_bfloat16.h:1053:// TODO(Leslie): Add the AVX2 Version of transpose_mxn for BFloat16 and Float16
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_float.h:654:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:118:    // TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:273:  // this should be removed. TODO (kimishpatel)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_int.h:686:      // TODO<leslie> We can use _mm256_zextsi128_si256 in the furture,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:196:  // TODO: can we support caching this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:240:  // TODO: can we support caching this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/MetaFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/utils/Factory.h:13:// TODO: Remove this function when at::native::empty() is modified to accept a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:47:// TODO: Figure out if we need a non-moving wrap_buffer()
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:287:// TODO: Add static assert to verify lambda arguments match nested_node types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:15:// TODO: make all operations that resize given outputs use this function
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/AffineQuantizerBase.h:11:// TODO combine this with quantize_val once the numerics for ARM are aligned
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/fbgemm_utils.h:312:// TODO: Remove functions below when ChannelsLast3d is ready.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:339:// TODO: Move it to third_party/ideep
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:394:  // TODO Support more OSs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/OperationUtils.h:194:// TODO: Improve the overall design of MPSGraphCache.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/MPSGraphVenturaOps.h:4:// TODO: Remove me when moved to MacOS 13
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:19:// TODO: This file only supports AVX2. We could split the AVX kernels into
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:178:  // TODO: we may want to merge that into the fallback code (currently called
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:254:  // TODO: we may want to merge that into the fallback code (currently called
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:293:// future improvement that can be done: look for the TODOs in this file.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:1197:  // TODO: Do we also need block 4 ???
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:55:// TODO: put this into the public API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:67:// TODO: Expose this for real in ATen, some day?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:36:// TODO: CPU instruction set selection should be folded into whatever
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:212:    // TODO: make this point at hip_dispatch_ptr
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:296:// TODO: cut this over to HIP dispatch once we stop pretending that CUDA
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/MaxPooling.h:64:// TODO(Heitor) Template by dimension
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:350:  // TODO: instead of variable name 'sigma', use 'gamma' or 'scale'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:384:  // TODO: Fix resize_as_. See pytorch/pytorch#11665.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:27:  // TODO: remove this special case for HIP when issue is fixed:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:38:  // TODO: remove this special case for HIP when issue is fixed:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:17:// TODO: update and add a usage example after https://github.com/pytorch/pytorch/pull/58092 lands.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:25:            // TODO: figure out how to make compiler happy without dynamic casts
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:33:            // TODO: get std::forward<> to work
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:302:    // TODO: Our current linear mode impls use unbound indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:202:  // TODO: check that output->size() matches output_sizes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:203:  // TODO: check that weight matches output->sizes()
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:362:  // TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:209:  // TODO: implement negative step
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:314:  // TODO: check scalarType
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/DynamicLayer.h:39:// TODO: we can excise DynamicLayer in favor of Interpreter,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/LegacyVmapTransforms.h:102:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/PlumbingHelper.h:59:  // TODO: should really check this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/BatchedTensorImpl.h:156:// TODO: should probably contain more (or all?) backend keys
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/LegacyVmapTransforms.h:95:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cuda/detail/CUDAHooks.h:8:// TODO: No need to have this whole header, we can just put it all in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:58:// TODO: Consider generalizing this into a call stack.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/caffe2/serialize/versions.h:92:// risk of breaking existing clients. TODO: A better way would be to allow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/GeneratorImpl.h:44: * TODO: Look into changing the threading semantics of Generators in ATen (e.g.,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:214:  /// TODO: This function encourages bad behavior (assuming CUDA is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:403:  // TODO: Deprecate this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:436:  // TODO remove after TensorOptions rationalization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:545:  // TODO: MemoryFormat is not implemented in this way
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Storage.h:92:  // TODO: remove later
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Scalar.h:138:  // TODO: Support ComplexHalf accessor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymBool.h:81:  // TODO: optimize to union
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymbolicShapeMeta.h:162:  // TODO: should the SymBool cases avoid the short circuit?  Need to reason
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/StorageImpl.h:107:  // TODO: remove later
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:251:  // TODO: Consider reading Tensor and TensorList constructors here, when
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/SizesAndStrides.h:25:  // TODO: different iterator types for sizes & strides to prevent
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:72:    // TODO: make a version that takes an impl argument.  Unfortunately,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:179:  // TODO: put this in BackendComponents
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:183:  // TODO: put this in BackendComponents
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:192:  Vulkan, // TODO: put this in BackendComponents
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:193:  Metal, // TODO: put this in BackendComponents
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:209:  // TODO: Make Mkldnn a functionality key, so we can give it Meta
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:236:  // TODO: delete this in favor of Python-implemented fake tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:262:  // TODO: delete this once torchdim lands in functorch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:354:  // TODO: make Autocast a functionality key
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/CPUAllocator.h:12:// TODO: rename to c10
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:255:      // TODO dim == 3 case will be enabled once it is fully tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:271:      // TODO dim == 4 case will be enabled once it is fully tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarTypeToTypeMeta.h:8:// TODO move to typeid.h (or codemod away) when TypeMeta et al
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:98:// TODO: To add unsigned int types here, we must define accumulate type.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:167:    /* TODO: remove once the bug is fixed. */                                \
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:380:    // TODO: Replace the link to the documentation once it's available.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:534:  // TODO: When Variable is added, delete these constructors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:637:  // TODO: does C++14 have a stdlib template for this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:743:    // TODO: maybe this should be toggled by strides
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:911:      // TODO: provide stride_custom, symmetrically with size_custom.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:968:    // TODO: We could add support to Python dispatch here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:969:    // TODO: We could call into aten::size.int instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:976:    // TODO: We could add support to Python dispatch here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:977:    // TODO: We could call into aten::size.int instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1218:  // TODO: remove this once we don't automatically enabled Autograd dispatch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1285:      // TODO: implement layout() as native function/method so that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1748:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1767:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1794:    // TODO: this should probably consult policy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1891:    // TODO: at some point, we should kill this field completely.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:2140:    // TODO: A useful internal assert would be to show that device_opt_ is null
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:3050://    strong refcount           TODO: pack these into one word
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymFloat.h:107:  // TODO: optimize to union
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:57:      // TODO dim == 3 case will be enabled once it is fully tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:86:      // TODO dim == 4 case will be enabled once it is fully tested
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymInt.h:55:  // TODO: these implementations are not optimal because they allocate a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymIntArrayRef.h:16:// TODO: a SymIntArrayRef containing a heap allocated large negative integer
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Backend.h:284:// TODO: This probably shouldn't actually be static inline
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DeviceGuard.h:49:  /// TODO: The consistency check here is inconsistent with StreamGuard's
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/ApproximateClock.h:79:// TODO: We should use
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Deprecated.h:27:// TODO Is there some way to implement this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:345:// TODO: Brian Vaughan observed that we might be able to get this to work on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:563:// TODO: We're going to get a lot of similar looking string literals
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeList.h:158:  // TODO Direct implementation might be faster
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:14:// TODO Make it work for more compilers
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:67:  // TODO Disallow this and rather use std::unordered_map/set everywhere
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeCast.h:169:// Trigger tests for D25440771. TODO: Remove this line any time you want.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:622:  // TODO: Use std::bit_cast once C++20 becomes available.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/C++17.h:92:// TODO This is an incomplete implementation of std::apply, not working for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:43:// TODO(xiaofeng): Define GOOGLE_PROTOBUF_HAS_CONSTEXPR when constexpr is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:143:// TODO: perhaps it would be nice to have int128, a signed 128-bit type?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:46:  // TODO Making operator== noexcept if underlying type is noexcept equality
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:55:  // TODO Making operator!= noexcept if operator== is noexcept doesn't work with
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Half.h:395:// TODO : move to complex.h
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/intrusive_ptr.h:572:   * TODO: https://github.com/pytorch/pytorch/issues/56482
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/MathConstants.h:13:// TODO: Replace me with inline constexpr variable when C++17 becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:110:    // TODO: split out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:530:    // TODO At some point this should probably be done, including tricks
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex_utils.h:20:// TODO: Write in more idiomatic C++17
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:140:// TODO(@zasdfgbnm): c10::complex<c10::Half> is not currently supported,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:581:// TODO(@zasdfgbnm): implement them as c10::conj
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:589:// TODO(@zasdfgbnm): implement it by ourselves
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/ArrayRef.h:75:  // TODO Make this explicit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/hash.h:58:// TODO: Compare vs OpenSSL and/or CryptoPP implementations
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:37:// TODO: This file is still in the caffe2 namespace, despite living
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:87:// TODO Disallow this and rather use std::unordered_map/set everywhere
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/cuda/CUDACachingAllocator.h:36:// TODO: Turn this into an honest to goodness class. I briefly attempted to do
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/macros/Macros.h:125:// TODO: It's possible this is still triggering
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class_detail.h:137:  // TODO We shouldn't use c10::impl stuff directly here. We should use the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class.h:401:      // TODO: we need to figure out how to profile calls to custom functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:108:  // TODO: This is morally the same thing as KernelRegistrationConfig, but it's
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:167:        // TODO: Don't go through WrapRuntimeKernelFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:184:        // TODO: Don't go through WrapRuntimeKernelFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:201:        // TODO: Don't go through WrapRuntimeKernelFunctor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:681:    // TODO: need to raise an error when you impl a function that has a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:702:    // TODO: need to raise an error when you impl a function that has a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/throughput_benchmark-inl.h:57:  // TODO: add GUARDED_BY once it is available
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:388:// TODO: this can return MaybeOwned
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:1168: * TODO: we could use different names for the following 'handle_torch_function'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/model.h:249:    // TODO: Handle shared storage case.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/arrayref_tensor.h:40:  // TODO Make this explicit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/interface.h:22:// TODO: Deprecate this API. This was kept for BC compatibility.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runner/model_container_runner.h:78:  // TODO: need an OSS proxy executor implementation. For now,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/tensor.h:40:    // TODO(alanwaketan): Remove this ctor. This is a
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:109:  // TODO: even though this API is currently used **only** in codegen to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:136:  // TODO(alanwaketan): Revisit if all of them need to be accessible to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:264:  // TODO(alanwaketan): Add a registry such that we don't need to make all
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_metadata.h:35:// TODO(whc) is this going to be used outside of in IR decompositions?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/trie.h:46:  // TODO: Because we don't expect user to explicitly call this function via
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:19:// TODO(alanwaketan): Consolidate it with c10::scope_exit.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:68:// TODO(alanwaketan): This is clever, but is there really no std or c10
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_builder.h:140:// TODO: this should return Value
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir.h:209:  // TODO: Some IR classes share the same opkind, such as Mean and MeanDim, so
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/helpers.h:16:// TODO: Consolidate this file with util.h
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_node.h:85:// TODO(whc) once Shape() API is moved to Node base, also make it virtual, and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/config.h:4:// TODO(whc) unclear if this is useful, has only been tested as true
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:21:  // TODO: Scalar node is not currently used by ts_backend. Enable reusing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:55:  // TODO: verify if IR node reusing works for Dynamic shape ops
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:31:        "TODO(whc) implement TS computation shapes or change interface");
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:41:        "TODO(whc) implement TS computation shapes or change interface");
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:82:  // TODO(whc) need to keep this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:131:  // TODO(whc)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/instruction.h:89:  // TODO: check for overflow
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:53: * TODO Instead of doing it this way, we should only have pure-jit ops in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:146:    // TODO: some sort of caching mechanism?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:178:                  // TODO What if it gets set later?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/register_ops_utils.h:360:    // TODO: remove when possible, since it just slows down
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/flatbuffer_loader.h:132:// no op, TODO(qihan) delete
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/observer.h:39:  // TODO: Kimish
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/code.h:27:  // TODO After we actually export CALL instructions we can remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:583:// TODO: supports only single comprehension for now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:597:  // TODO: no ifs for now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:607:// TODO: supports only single comprehension for now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:624:  // TODO: no ifs for now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/source_range.h:368:    // TODO: c10::optional<>::value returns an rvalue ref so can't use it here??
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:74:  // TODO @wconstab refactor to use ModuleValue::asTuple instead of new API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:425:  // TODO holding this thing is creepy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/graph_opt.h:104:// TODO: add error reporting for graphs that can't be converted.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/reduction.h:268:  // TODO possible to remove this arg by deferring the init value until we
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:393:  // TODO: add memory types.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:841:// TODO: move to this an internal IR.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:842:// TODO: make IR nodes extensible.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:141:  //     loop variable. TODO: Remove this constraint.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:144:  //     TODO: Remove this constraint.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:473:  // TODO: Add an IR verifier check to detect invalidly compressed buffers.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:584:// TODO: Revisit this once we decide on how dependencies analysis should look
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/external_functions_registry.h:20:// case we need to run aten ops (TODO: support different devices). The first
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/codegen.h:69:  // TODO: Figure out how to unify these call interfaces.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/mem_dependency_checker.h:245:  // TODO: this will return only the AccessInfo for A. It's included for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:171:  // TODO: unique_name
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:215:  // TODO: unique_name
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:263:// TODO: add TORCH_API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:287:// TODO: add TORCH_API
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/python_list.h:39:  // TODO: Do these make sense?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind.h:140:    // TODO: Is there a way to py::cast that doesn't raise an exception on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:635:      // TODO: this message is not correct anymore, since this InferredType is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:971:// TODO: Remove once we clean up the GraphExecutor usage.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:1105:  // TODO: we could add __torch_function__ dispatch here but I don't know
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/quantization_patterns.h:553:  // TODO: add %dtype after when https://github.com/pytorch/pytorch/issues/34351
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:138:// TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:142:// TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:148:// TODO: refactor all current uses of this function to the Opt one
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:186:// TODO: add a macro to declare the filters
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/symbolic_shape_cache.h:10:  // TODO: Consider in the future if it is reasonable to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/value_refinement_utils.h:18:// TODO: vector may be faster
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickle.h:39:///  // TODO: when tensors are stored in the pickle, delete this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickler.h:249:  // TODO: only use this if necessary (add a pass to find all shared ivalues,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/flatbuffer_serializer.h:90:// TODO(qihan): delete
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/export.h:258:// TODO remove these switches once interface call is rolled out.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:41: *  - Pattern graph nodes cannot alias. TODO: the check not implemented yet.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:43: * found matches, no nodes in the subgraph alias with each other). TODO: check
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:249:  // TODO: make this more const correct
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1746:  // TODO: return iterator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1822:  // TODO: return iterator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/function_impl.h:141:  // TODO: add more executors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/compilation_unit.h:173:    // TODO: class types cannot be redefined because we have no way right now
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:22:    // TODO: Nested Tensor does not have an implementation of detach. The
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:44:        // TODO: Actually detect views in the accumulateGrad function so that
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/VariableTypeUtils.h:134:// TODO: Blegh, bare references
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function.h:561:  /// TODO: it might be possible to handle cases where backward is
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/custom_function.h:271:  // TODO Add tracing here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/forward_grad.h:205:  // TODO(albanD): replace this with a SmallVector
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:167:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:185:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:204:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:220:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:853:/// TODO: Eliminate this function as much as possible, as it can be expressed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/dynamo/compiled_autograd.h:141:    // TODO(jansel): Here we unpack the SavedVariable exactly once.  This might
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:491:    // TODO: HACK for backend name to get sequence number for that backend.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:512:    // TODO: HACK for backend name to get sequence number for that backend.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:581:    // TODO: if nccl was specified then use it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:626:    // TODO: should we add these entries after the backend setting succeeds?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/logger.hpp:70:  // TODO to support single process multiple devices and multi device modules,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:124:  // TODO this function makes broadcast communication call and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:396:    // TODO(@pietern)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/Utils.hpp:537:    // TODO: see if we should add overflow protection for offset
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/tensorpipe_agent.h:314:  // TODO: To achieve better performance we can have a pipe pool per
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_proto.h:15:// TODO: Remove all these messages and use rpc + registered functions instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_context.h:201:  // TODO: make this a context guard
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:75:// TODO: current RRef implementation does not tolerate failures
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:88:// TODO: RRef internal messages are not yet idempotent
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:186:// TODO: make RRef an IValue, and edit createStackForSchema accordingly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:187:// TODO: make RRef system messages idempotent and retry on failures.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/tensor/python_tensor.h:27:// TODO: This is nuts!  There is no reason to let the default tensor type id
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/CudaIPCTypes.h:71:  // TODO: Can be changed to FIFO in order to avoid full traverse on every
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/parallel/data_parallel.h:89:      // TODO: use nccl reduce
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:10:// TODO: These don't really belong here but torchvision builds in CI need them
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/util.h:17:// TODO: replace with pytorch/rfcs#43 when it is ready.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/containers.h:180:  // TODO: cbegin and cend()
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/collection.h:476:    TensorListBegin, // TODO: generalize to other lists.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:188:    // TODO PYBIND11_DEPRECATED(
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:1365:// TODO: After the deprecated constructors are removed, this macro can be simplified by
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/common.h:357:/// Compatibility macros for Python 2 / Python 3 versions TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/type_caster_base.h:482:        // TODO: is this still true for pure Python 3.6?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/tensor.h:503:    // TODO: Move to std::optional once std::optional has more support
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/matrix.h:94:          // TODO: when Eigen bug #747 is fixed, remove the tests for non-negativity.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1295:    using module_def = PyModuleDef; // TODO: Can this be removed (it was needed only for Python 2)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1322:        // TODO: Should be reinterpret_steal for Python 3, but Python also steals it again when
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2346:                    // TODO consolidate the erasure code in pybind11_meta_dealloc() in class.h
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2433:    // TODO: state captures only the types of Extra, not the values
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:141:            # TODO: find a better way to identify cudaLaunchKernel
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:145:            # TODO: find a better way to identify CUDA Kernel
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:367:# TODO(dberard) - deprecate / remove workaround for CUDA >= 12, when
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:167:        # TODO(robieta): Move away from load bearing names
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:305:        # TODO(robieta):
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:1061:        # TODO: Write a faster serialize (orjson not available in CI)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:181:        # TODO: We should also check tensor identities
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:216:        # TODO: Check if tensor is reused
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:418:        # TODO: fixme! Due to lifetime issues of the function name, this field might
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:437:        # TODO: We should also check if the loader is bottleneck.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:483:        # TODO: We should also check if the optimizer's numerical behavior will change.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/beta/_client_adaptations.py:85:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:43:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:413:                return None  # TODO(nathaniel): call the multimethod.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_auth.py:37:    # TODO(xuanwn): Give credentials an actual type.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_server.py:1182:        # TODO(https://github.com/grpc/grpc/issues/6597): eliminate these fields.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_server.py:1238:# TODO(https://github.com/grpc/grpc/issues/6597): delete this function.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_server.py:1463:        # TODO(xuanwn): We should validate method_handlers first.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_channel.py:257:# TODO(xuanwn): Create a base class for IntegratedCall and SegregatedCall.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_channel.py:1835:    # TODO(xuanwn): Refactor this: https://github.com/grpc/grpc/issues/31704
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_channel.py:2253:        # TODO(https://github.com/grpc/grpc/issues/12531): Several releases
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/_observability.py:271:    # TODO(xuanwn): use channel args to exclude those metrics.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_server.py:87:        # TODO(xuanwn): Implement this for AsyncIO.
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:409:                # TODO(lidiz) drop this hack after 3.8 deprecation
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:484:    # TODO(xuanwn): Implement this method after we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:489:    # TODO(xuanwn): Implement _registered_method after we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:509:    # TODO(xuanwn): Implement _registered_method after we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:529:    # TODO(xuanwn): Implement _registered_method after we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:549:    # TODO(xuanwn): Implement _registered_method after we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:56:    cext.SSWAP: _common.STATUS_RUNNING,  # TODO what status is this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:180:    # TODO - the filtering logic should be better checked so that
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:256:        # TODO: rewrite this in C (entstat forks, so use truss -f to follow.
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:531:        # TODO rewrite without using procfiles (stat /proc/pid/fd/* and then
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_pswindows.py:866:                # TODO: the C ext can probably be refactored in order
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:230:    # TODO - the filtering logic should be better checked so that
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:288:        # TODO: refactor and use _common.conn_to_ntuple.
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:639:        # TODO: rewrite this in C (...but the damn netstat source code
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1004:    # TODO: #595
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1041:    # TODO: #595
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:564:    # TODO: remove this once 1892 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:841:                        # TODO: skip AF_INET6 for now because I get:
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_osx.py:122:    # TODO: remove this once 1892 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:254:        # TODO: UNIX sockets are temporarily implemented by parsing
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:368:    # TODO: remove this once 1892 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:386:    # TODO: remove this skip when this gets fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_unicode.py:116:        # TODO - this is quite random and I'm not sure why it happens,
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_aix.py:60:        # TODO maybe try to use "swap -l" to check "used" too, but its units
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_bsd.py:7:# TODO: (FreeBSD) add test for comparing connections with 'sockstat' cmd.
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:2028:    # TODO: re-enable this test.
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:284:        # TODO: check ntuple fields
./core/py/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_contracts.py:235:    # TODO: remove this once 1892 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/click/_termui_impl.py:525:    # TODO: This never terminates if the passed generator never terminates.
./core/py/pipeline/.venv/lib/python3.12/site-packages/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./core/py/pipeline/.venv/lib/python3.12/site-packages/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./core/py/pipeline/.venv/lib/python3.12/site-packages/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./core/py/pipeline/.venv/lib/python3.12/site-packages/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./core/py/pipeline/.venv/lib/python3.12/site-packages/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./core/py/pipeline/.venv/lib/python3.12/site-packages/yaml/scanner.py:187:        # TODO: support for BOM within a stream.
./core/py/pipeline/.venv/lib/python3.12/site-packages/yaml/scanner.py:761:        # TODO: We need to make tab handling rules more sane. A good rule is
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic_core/core_schema.py:1135:            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/client.py:95:        # TODO: Migrate things away from scoped_config in favor of the
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/client.py:680:            # TODO: fallback partition_name should be configurable in the
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/client.py:758:        # TODO: This normalization logic is duplicated from the
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/utils.py:2314:                # TODO: Update message to reflect use_arn_region
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/docs/bcdoc/style.py:321:        # TODO: Need to control the bullets used for LI items
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/discovery.py:276:        # TODO: Improve eviction behavior to only evict the bad endpoint if
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/handlers.py:976:# TODO: Remove this class as it is no longer used
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/auth.py:245:            # TODO: We should set the host ourselves, instead of relying on our
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/auth.py:943:        TODO: Do we need this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/serialize.py:71:    # TODO: Unknown protocols.
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/retryhandler.py:157:        # TODO: send a signal.
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/response.py:102:            # TODO: the url will be None as urllib3 isn't setting it yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/response.py:119:            # TODO: the url will be None as urllib3 isn't setting it yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/response.py:203:    # TODO: Unfortunately, we have to have error logic here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/retries/special.py:17:# TODO: This is an ideal candidate for the retryable trait once that's
./core/py/pipeline/.venv/lib/python3.12/site-packages/botocore/endpoint.py:346:        # TODO: avoid naming conflicts with ResponseMetadata and Error
./core/py/pipeline/.venv/lib/python3.12/site-packages/h2/windows.py:116:        # TODO: Can the window be smaller than 1024 bytes? If not, we can
./core/py/pipeline/.venv/lib/python3.12/site-packages/h2/utilities.py:417:    # TODO: We should also guard against receiving duplicate Host headers,
./core/py/pipeline/.venv/lib/python3.12/site-packages/httpx/_auth.py:267:        # TODO: implement auth-int
./core/py/pipeline/.venv/lib/python3.12/site-packages/typing_extensions.py:3267:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:26:  # TODO: Remove this import after fix api_implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:271:    # TODO: Add function to calculate full_name instead of having it in
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:474:# TODO: We should have aggressive checking here,
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:480:# TODO: for this and other *Descriptor classes, we
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:539:  # TODO: Find a way to eliminate this repetition.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:563:  # TODO: Find a way to eliminate this repetition.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:600:  # TODO: Find a way to eliminate this repetition.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:139:    # TODO: implement this API.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:143:    # TODO: implement this API.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_pool.py:1360:  # TODO: This pool could be constructed from Python code, when we
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/pyext/cpp_message.py:21:# TODO: Remove this import after fix api_implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:100:        # TODO: Remove this check here. Duplicate extension
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:140:      # TODO: Remove this check here. Duplicate extension
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:88:    # TODO: fail back to python
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:135:# TODO: Remove the API, it returns a constant. b/228102101
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:10:# TODO: Helpers for verbose, common checks like seeing if a
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:215:  # TODO: Escape Python keywords (e.g., yield), and test this support.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:230:  # TODO:  Remove this method entirely if/when everyone agrees with my
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:464:    # TODO: This may be broken since there may not be
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:717:    # TODO: This may be broken since there may not be
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:767:  # TODO: Remove duplication with similar method
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:824:  # TODO: Migrate all users of these attributes to functions like
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:827:    # TODO: Use cls.MESSAGE_FACTORY.pool when available.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:977:  # TODO: Don't use the factory of generated messages.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:989:  # TODO: For now we just strip the hostname.  Better logic will be
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:1035:    # TODO: Fix UnknownFieldSet to consider MessageSet extensions,
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/builder.py:96:  # TODO: Remove this on-op
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:37:# TODO: Unify error handling of "unknown extension" crap.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:38:# TODO: Support iteritems()-style iteration over all
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:98:# TODO: Remove this. BaseContainer does *not* conform to
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:214:# TODO: Constrain T to be a subtype of Message.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/symbol_database.py:136:    # TODO: Fix the differences with MessageFactory.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:22:# TODO Import thread contention leads to test failures.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:477:          # TODO: refactor and optimize if this becomes an issue.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1081:        # TODO: Change to _allow_singular_overwrites.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1637:# TODO: Migrate violators to textformat_tokenizer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:8:# TODO: We should just make these methods all "pure-virtual" and move
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:43:  # TODO: Link to an HTML document here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:45:  # TODO: Document that instances of this class will also
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:49:  # TODO: Document these fields and methods.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:66:    # TODO: Remove this once the UPB implementation is improved.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:182:  # TODO: MergeFromString() should probably return None and be
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:217:    # TODO: Document handling of unknown fields.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:218:    # TODO: When we switch to a helper, this will return None.
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:263:  # TODO: Decide whether we like these better
./core/py/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:269:  # TODO: Be sure to document (and test) exactly
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578:        # TODO: Add optional support for socket.gethostbyname checking.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095:        # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38:    # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144:        # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234:                # TODO: Arbitrary read value.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282:            # TODO this is often present from upstream.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325:    # TODO: This is a woefully incomplete response object, but works for non-streaming.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332:        decode_content: bool = False,  # TODO: support decoding
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/exceptions.py:306:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/util/url.py:454:    # TODO: Remove this when we break backwards compatibility.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/util/request.py:229:    # File-like object, TODO: use seek() and tell() for length?
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/connection.py:330:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/connection.py:436:        # object later. TODO: Remove this in favor of a real
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/connection.py:561:        # TODO should we implement it everywhere?
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:1005:                # TODO make sure to initially read enough data to get past the headers
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20:    # TODO: Remove this in favor of a better
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499:        # TODO should we eliminate the recursion?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503:                    # TODO check whether we need to call `list_hook`
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511:            # TODO is the interaction between `list_hook` and `use_list` ok?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516:                    # TODO check whether we need to call hooks
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863:    TODO: clean up the code here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558:            # TODO: Not sure if we need the SecTrustResultType for anything?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:839:            # TODO version verification
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:922:                # TODO SHA256 digest
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401:        # TODO check k, v for valid values
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:560:    # TODO could add iter* variants
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:984:        # TODO: any other fields wanted
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:1020:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:3568:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522:        # TODO: Add optional support for socket.gethostbyname checking.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659:        # TODO: should I do clean shutdown here? Do I have to?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819:        # TODO: Well, crap.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829:        # TODO: Update in line with above.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1:# TODO: Add Generic type annotations to initialized collections.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122:_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598:        # TODO: Add a deadline?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227:        # TODO: There is an assumption that the result will be a
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/cache.py:278:                # TODO: use DirectUrl.equivalent when
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:227:        # TODO performance: this means we iterate the dependencies at least twice,
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:362:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:201:        # TODO: Check already installed candidate, and use it if the link and
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:622:        # TODO: Are there more cases this needs to return True? Editable?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:344:        # TODO: In the future, it would be nice if pip supported PEP 691
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:204:        # TODO: Try to get these passing down from the command?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6:# TODO: This needs Python 3.10's improved slots support for dataclasses
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:107:    # TODO: replace this with slots=True when dropping Python 3.9 support.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:526:    # TODO: handle space after '\'.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:285:        # TODO: The is_installable_dir test here might not be necessary
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:75:        TODO remove this property together with the legacy resolver, since the new
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:167:        # TODO: this property is relatively costly to compute, memoize it ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:177:                # TODO: get project location from second line of egg_link file
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:557:        # TODO: separate this part out from RequirementPreparer when the v1
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:36:    BaseTy.float: "double",  # TODO: how about other floating point types?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:97:            # TODO: BaseTy.Dimname, BaseTy.Generator, etc.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:98:            raise NotImplementedError(f"TODO: add support for arg type {repr(typ)}")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:203:                f"TODO: add support for return type {repr(ret.type)}"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:316:        # TODO: No need to generate C shim for Inductor lowered ops.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:48:    # TODO: Matching on CType seems wrong; should be matching on Type
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:60:                # TODO: I don't understand when you should put lazy_ in the name
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:72:                f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:447:                # TODO(alanwaketan): Maybe we want to apply GetLtcTensorOrCreateForWrappedNumber here, but hold it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:455:                    f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:540:            # TODO: this is trolling
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:581:            # TODO(whc) remove this if XLA switches to using static method for creation
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:39:# TODO: use BackendIndex
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:75:        # TODO: don't hardcode; return type will be inferred based on tags on
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:501:        # TODO: don't hardcode ufunc:: namespace here, should be centralized smh
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:160:      // TODO: avoid the redispatch here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:428:            # TODO: dedupe this with the structured codegen
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:453:                    # TODO: handle in place on tensor list
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:662:            # TODO: Make sure out argument is guaranteed to be self
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:708:            # TODO: Move to OptionalMPSGuard.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:720:            f"      return {output_value};\n",  # type: ignore[possibly-undefined]  # TODO: audit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:722:            f"    std::array<{output_type}, {len(f.func.returns)}> outputs_;",  # type: ignore[possibly-undefined]  # TODO: audit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:723:            f"{textwrap.indent(proxy_field, indent)}",  # type: ignore[possibly-undefined]  # TODO: audit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:739:        # TODO: Now, there is something interesting going on here.  In the code below,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:762:        # (e.g., at::cpu::add).  We don't generate methods (TODO: do this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:815:                # TODO: dedup this branch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:893:                        # TODO: Stop hardcoding that the output type is a Tensor.  Note
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:908:                # TODO: https://github.com/pytorch/pytorch/issues/53023
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:918:                # TODO: I think this means structured won't work with method
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:947:            # TODO: Do this in translate instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:965:            sig_body.append(f"return {ret_expr};")  # type: ignore[possibly-undefined]  # TODO: audit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:342:        # TODO: for ops with structured_delegate it should check the dispatch table of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:786:# TODO: This was historically used to help some JIT interop code
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:1041:# TODO: Get rid of dynamic_type, after getting tools/autograd
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:1310:        # TODO: What exactly is the semantics of the 'dispatch' field?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:1424:    # TODO: how come ValuesView isn't a Sequence lol
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:2227:                    # TODO: this condition is a bit questionable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:2723:    # TODO: --op-registration-whitelist will be removed when all call-sites
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:2790:    # TODO: stop generating CUDA kernels for non-CUDA builds
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_backend_stubs.py:139:            # TODO: allow structured external backends later.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:789:        # TODO: The below ops all have "problematic" schemas that prevent them from
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:60:# TODO: Use a real parser here; this will get bamboozled
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:98:        # TODO: this does the wrong thing with KeyError
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:108:# TODO: put this somewhere else, maybe
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:159:            # TODO: Update the comment reference to the correct location
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:272:        # TODO: remove the skip after these two operators schemas are fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:327:            # TODO: remove the skip after these two operators schemas are fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:23:# TODO: Duplicated Subset from codegen.tool.gen_oplist, remove declaration in codegen
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:64:        type_alias_map: Dict[str, List[str]],  # TODO: Support unwrapped str val
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:91:            # TODO: Support inlined arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:130:                )  # TODO: fix this discrepancy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:140:        # TODO: keeping these special cases for Tensor[] and Tensor?[] so that we can hookup with ATen kernels.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:215:        # TODO: Consider incorporating this into the data model
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/custom_ops.py:94:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_executorch.py:368:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:149:    # TODO(whc) add a check for shape inference functions that have meta kernels implement and should be retired.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:368:        TODO(alanwaketan): Remove this sorting hack once all ops are grouped properly.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:75:        # TODO: these ones got added recently and need manual inspection
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:252:        # TODO: stop doing type tests by converting to C++ and then testing
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:278:    # TODO: stop type testing by converting to C++
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:476:    # TODO: figure out what this does
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:684:            # TODO: verify that the tag is valid and has an entry in tags.yaml
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:763:                # TODO: maybe it's better to test the return
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:926:        # TODO: probably better to accumulate these errors and report them all
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1293:            # TODO: This discrepancy isn't required; we could also generated
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1359:    # TODO: Need to handle collisions with argument names at some point
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1733:        # TODO: implement a proper parser if this gets more ugly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1856:    ConstQuantizerPtr = auto()  # TODO: rename
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1996:        # TODO: deduplicate annotation matching with Return
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:2281:        # TODO: Use a real parser here; this will get bamboozled
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:2400:        # TODO: These invariants are weirdly asymmetric?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:2401:        # TODO: Fancier types?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:228:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:251:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:298:    # TODO: maybe don't need keep scattered out fields for python signature?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:322:                # TODO: shouldn't this be OptionalType[ListType[...]], since it defaults to None?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:337:    # TODO: create a dedicated SelfArgument type for 'self'?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:354:    # TODO: maybe create a PythonTensorOptionsArgument?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:723:        # TODO: directly translate a.default to python default
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:775:    # [old codegen] TODO: because these aren't guaranteed to be 100% faithful
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:946:            # TODO: this doesn't seem right...
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1095:# TODO: This is to keep same byte-for-byte result as the old codegen - maybe unnecessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1127:            # TODO: avoid this special handling?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1405:            # TODO: why this needs to be special case?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1426:            # TODO: make this part of something more general, or get rid of it.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1480:    # TODO: maybe move to the generator side as it's not related to binding.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/native.py:47:    # TODO: delete this!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/native.py:114:        # TODO: Not sure why the arguments assigned here are for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:149:        # TODO: My kingdom for a pattern matcher
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:152:        # TODO: This could get us in recomputation trouble if b.expr is nontrivial.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:253:        # TODO: These are referentially equal, shouldn't have to do this;
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:368:            # TODO: You might also want to solve this from longSymVec_ctype or
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:120:            raise AssertionError(f"TODO add support for type {repr(typ)}")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:125:            # TODO(whc) is this actually correct? or should it use a Vector like above
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:131:            # TODO: return a value type.  The problem here is analogous to
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:146:# TODO: Determining this based off of CType is bad; this should be computed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:166:        # TODO: report True for this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:192:# TODO: dedupe with Type.is_generator_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:209:    # TODO: this is lies, it is false for symint list
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:229:            # TODO: lists of symints are not currently treated as value types
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:306:# TODO: This is not idiomatic with how other torchgen APIs transform on schema.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:314:    # TODO: Need to handle collisions with argument names at some point
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:164:                )  # TODO: fix this discrepancy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:181:        # TODO: remove these special cases, ArrayRef fallthrough works fine
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:285:        # TODO: Consider incorporating this into the data model
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:422:                default = "at::kLong"  # TODO: this is wrong
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:114:    # TODO: maybe the logic to search for all variants is no longer necessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:233:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:241:#   TODO: some cpp naming logic (e.g. resolving name conflict) might be irrelevant?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:250:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:261:# TODO: Update comment below since it is out of date.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:348:# TODO(crcrpar): Avoid hard coding "Default" ideally.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:632:            # TODO(crcrpar): Avoid hard coding "Default" ideally.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:85:    # TODO: Kill this when we eventually remove it!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:188:    # TODO: Kill this when we eventually remove it!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:211:    # TODO: maybe don't represent default here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:246:    # TODO: Kill this when we eventually remove it!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/structured.py:76:        # TODO: delete these special cases; see torchgen.api.cpp--these
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/RegisterBackendSelect.cpp:31:  // TODO: fetch scalar type from Tensor? But it doesn't really matter...
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:196:  // TODO: temporarily disabled
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:235:  // TODO: Deprecate me
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:539:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:19:// TODO: rename this file to something more generic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:50:// TODO: this doesn't handle restriding empty tensors correctly; see
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/DispatchKeyFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/FunctionalInverses.h:26:// TODO: Change codegen to generate these. See the following link:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/Functions.cpp:10:   AutoDispatchBelowADInplaceOrView guard{}; // TODO: Remove.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:110:    # TODO: byte-for-byte compatible with old codegen behavior - should clean up
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:302:    # TODO: clean up old codegen behavior
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:256:    # TODO: Should handle optional here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:261:    # TODO: Should handle optional here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:338:    return f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:355:    # TODO: Clean this logic up if we get rid of reverse view funcs or reify them.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:174:# TODO: Why is this going through CppSignatureGroup, that doesn't make sense...
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:395:            # TODO we are trolling
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:592:        # TODO: do we need eagerly calculate and save it here? Can it be derived
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:653:    # TODO: maybe the logic to handle the legacy schema is no longer necessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:943:            # TODO: it would be nice to not have these special cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1079:        # TODO: `cpp_type` is only to keep it byte-for-byte compatible with the old codegen, should remove.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1100:                    # TODO(crcrpar): Make it simpler.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1221:            # TODO: process all derivative formulas!!!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1345:            # TODO: should be `arg.type.is_tensor_like()`?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1605:            base_name = f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1729:        # TODO: flatten allocates a std::vector, which could be expensive
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1857:                # TODO update this when inplace namings are unified
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1967:                    # TODO(crcrpar): Should this (= the foreach specific logic) be refactored somehow?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py:441:# TODO: This is probably not exhaustive, but it's a start
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1250:        # TODO: should use some canonical form instead of 'str(arg.type)' - see comments
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1338:        # TODO: Checking `ps.method and ('requires_grad' in parser_outputs)` is a hacky
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_factories.py:22:# TODO: maybe update the cpp argument API to take optional namespace argument?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:73:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:91:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:110:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:126:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:156:    // TODO: consider factoring this out
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:371:  // TODO: change the condition to `self_.dim() != 0` once we expose scalars
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:416:  // TODO: Make this call the TensorOptions version, maybe?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:422:  // TODO: Make this call the TensorOptions version, maybe?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./core/py/pipeline/.venv/lib/python3.12/site-packages/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./core/py/pipeline/.venv/lib/python3.12/site-packages/requests/hooks.py:19:# TODO: response is the only one
./core/py/pipeline/.venv/lib/python3.12/site-packages/einops/einops.py:52:    # TODO add support for added_axes
./core/py/pipeline/.venv/lib/python3.12/site-packages/einops/tests/test_einsum.py:352:    # TODO: Include check for giving normal einsum pattern rather than einops.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:167:# TODO: add support for `axis` tuples
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_correlation.py:10:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:44:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1262:    # TODO: properly avoid NaN when y is negative infinity
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1263:    # TODO: silence warning with taking log of complex nan
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1264:    # TODO: deal with x == y better
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3015:    # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3453:        # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:4442:    # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_morestats.py:2627:    # TODO: calculate exact distribution considering ties
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_qmc.py:456:        # TODO consider returning both the mean and the standard deviation
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_page_trend_test.py:322:    if ranks.ndim != 2:  # TODO: relax this to accept 3d arrays?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:193:    # TODO: add more where possible with test coverage,
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:321:    # TODO: add more where possible with test coverage,
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_fast_gen_inversion.py:144:# TODO: add more distributions
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous_basic.py:136:        # TODO: multiple checks in this function are not robust, tweaking the
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:26:    # Check that `var` keyword returns a value.  TODO: check whether returned
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:43:    # TODO: check that implementation is correct.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2367:    # TODO: add method "pearsonr" after fix overflow issue
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2387:    # TODO: add method "pearsonr" after fix overflow issue
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_basic.py:1260:# TODO: for all ttest functions, add tests with masked array inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:5780:        # These are excluded by the filters below. TODO: Rewrite tests so that
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous.py:890:    # TODO: add `supported` method and check here
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_stats.py:79:    # TODO: write these tests to handle missing values properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs.py:221:    # TODO use a better error approximation
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:38:#TODO renovate or move this class when scipy operators are more mature
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:73:#TODO renovate or move this function when SciPy operators are more mature
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_lapack.py:1941:                # TODO: Add a test for ONB?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/pyprima/cobyla/geometry.py:24:    TODO: Check whether it improves the performance if JDROP = NUM_VARS is allowed when
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:181:        # TODO: Does this depend on device?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:243:        # TODO: Does this depend on device?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/torch/_aliases.py:833:    # TODO: is the return type a list or a tuple
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:42:    # TODO: import from typing (requires Python >=3.13)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:119:    # TODO: Should we reject ndarray subclasses?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:264:    # TODO: Account for other backends.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:293:        # TODO: drop support for numpy<2 which didn't have __array_namespace__
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:300:        # TODO: drop support for jax<0.4.32 which didn't have __array_namespace__
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:642:            # TODO: Support Python scalars?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:876:        # TODO: What if our array is on the GPU already?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:16:    # TODO: import from typing (requires Python >=3.13)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:309:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:381:    # TODO: np.clip has other ufunc kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:32:# TODO: use the QR wrapper once dask
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:59:    # TODO: can't avoid computing U or V for dask
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:65:    # TODO: respect device keyword?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:96:    # TODO: respect device keyword?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:163:    # TODO: respect device keyword?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:224:    # TODO: This won't handle dask unknown shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_at.py:23:    # TODO import from typing (requires Python >=3.11)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:36:    # TODO import from typing (requires Python >=3.12 and >=3.13)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:307:    TODO this helper should be eventually removed once all the special cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/testing.py:23:    # TODO import override from typing (requires Python >=3.12)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/differentiate/_differentiate.py:372:    # TODO (followup):
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/cluster/hierarchy.py:1385:        # TODO ARRAY_API complex indexing not supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_direct_py.py:256:    # TODO: fix disp argument
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py:349:        # TODO: Use more advanced strategies from [2]_
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py:54:    # TODO: Use a symmetric indefinite factorization
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:61:    # TODO: revert this once the warning bug fix in sksparse is merged/released
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:101:    # TODO: Use a symmetric indefinite factorization
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_ip.py:92:                # TODO: revert this suppress_warning once the warning bug fix in
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2050:    # TODO: add hessp (callable or FD) to ScalarFunction?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_chandrupatla.py:7:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:72:    # TODO: test redundant row removal better
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:73:    # TODO: make solve more efficient with BGLU? This could take a while.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:376:        # TODO: cythonize?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:477:        pass  # TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:716:                    # self.n #TODO: Should always be self.n, this is
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1176:        # TODO: Only do this if global mode
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1502:            # TODO: Uncertain if n_prc needs to add len(self.LMC.xl_maps)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_chandrupatla.py:970:        # # TODO: Test zero tolerance
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_optimize.py:3063:        # TODO this test should really be equivalent to factorized version
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__remove_redundancy.py:5:# TODO: add tests for:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:579:        # TODO: Make default n higher for faster tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:715:        # TODO: This test doesn't cover anything new, it is unknown what the
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1179:            sign_det_A_11 = -1  # TODO: Choose another det of j instead?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1180:            # TODO: Unlikely to work in many cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1187:            # TODO: Note that scipy might be faster to add as an optional
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1191:            # TODO: Note if sign_det_A_j0 == then the point is coplanar to the
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1217:        # TODO: Is checking the projection of one vertex against faces of other
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1220:        # TODO: Literature seems to suggest using proj.T, but why is this
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1222:        if np.linalg.det(proj) == 0.0:  # TODO: Replace with tolerance?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_remove_redundancy.py:423:        v = U[:, -1]  # TODO: return these so user can eliminate from problem?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:862:        if rr and A_eq.size > 0:  # TODO: Fast sparse rank check?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:876:        try:  # TODO: use results of first SVD in _remove_redundancy_svd
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/special/_support_alternative_backends.py:125:            # TODO use xpx.lazy_apply to add jax.jit support
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/special/_lambertw.py:146:    # TODO: special expert should inspect this
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/special/tests/test_sf_error.py:34:    # TODO: special expert should correct
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/special/tests/test_basic.py:2448:        # TODO: cannot use N itself yet; factorial uses `gamma(N+1)` resp. `(hi+lo)//2`
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/io/_harwell_boeing/hb.py:12:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:21:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:842:        # TODO: this is where we are spending time (~80%). I think things
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/io/_netcdf.py:20:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/interpolate/_fitpack_impl.py:19:TODO: Make interfaces to the following fitpack functions:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_legendre.py:56:        # TODO: current converting to/from numpy
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:78:        # TODO: Currently only support for degree 7 Genz-Malik cubature, should aim to
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:134:        # TODO: Currently only support for the degree 5 lower rule, in the future it
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_kronrod.py:83:        # TODO: nodes and weights are currently hard-coded for values 15 and 21, but in
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:82:    # TODO: Optimize for hermitian and real?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:194:    # TODO: Optimize for hermitian and real?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/tests/test_basic.py:865:# TODO: Is this test actually valuable? The behavior it's testing shouldn't be
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/tests/test_real_transforms.py:110:    # TODO write an array-agnostic pad
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:885:    # TODO: Why are we using _as_euler_from_matrix here? As a sanity check? It is not
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:920:    # TODO: Same as before: Remove _as_euler_from_matrix?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:2083:    # TODO: Do we want to support this for all Array API frameworks?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:412:    # TODO: delete next 15 lines [combine with _eye()] once spmatrix removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:541:    # TODO: delete next 10 lines and replace _sparse with _array when spmatrix removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:627:    # TODO: delete next 8 lines and replace _sparse with _array when spmatrix removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:684:    # TODO remove this if-structure when sparse matrices removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:134:                # TODO infer shape here
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:346:        # TODO eliminate zeros
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/tests/test_svds.py:626:            # TODO: arpack crashes when v0=v0, which="SM"
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/minres.py:357:            break  # TODO check this
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:20:# TODO check that method preserve shape and type
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:21:# TODO test both preconditioner methods
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:366:    # TODO: minres / tfqmr. It didn't historically use absolute tolerances, so
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:369:        pytest.skip("TODO: Add atol to minres/tfqmr")
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:145:        #TODO this test seems to give estimates that match the table,
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:146:        #TODO even though no attempt has been made to deal with
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:147:        #TODO complex numbers in the one-norm estimation.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_dok.py:474:            # TODO implement resize across dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:227:        # TODO check for duplicates?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:700:        # TODO: don't fall back to fancy indexing here
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:967:            # TODO: only sort where necessary
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_base.py:656:            # TODO sparse broadcasting
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_csr.py:229:        # TODO: uncomment this once it's faster:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_data.py:18:# TODO implement all relevant operations
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:238:                # TODO: make sparse matrix indexing work for sparray
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:303:            # TODO: handle this for nD (adjacent arrays stay, separated move to start)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_construct.py:23:#TODO check whether format=XXX is respected
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:297:# TODO test prune
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:298:# TODO test has_sorted_indices
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:4733:        # TODO: properly handle this assertion on ppc64le
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:5469:        # TODO check that NC has duplicates (which are not explicit zeros)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_spfuncs.py:16:        #TODO expose through function
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:516:                and n_fft > 0):  # TODO: review threshold acc. to benchmark?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:1643:    # TODO in the near future:
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:4886:# TODO: Make this a real public function scipy.misc.ff
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_ltisys.py:1996:    # TODO: This could use some more work.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:604:        # TODO: add meaningful test where X0 is a list
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:676:        # TODO: add meaningful test where X0 is a list
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2565:        # TODO: Why so inaccurate?  Is reference flawed?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2570:        # TODO: Why so inaccurate?  Is reference flawed?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2580:        # TODO: Why so inaccurate?  Is reference flawed?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2585:        # TODO: Why so inaccurate?  Is reference flawed?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_windows.py:820:    @xfail_xp_backends(np_only=True, reason='TODO: make resample array API ready')
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:211:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:884:    @xfail_xp_backends(np_only=True, reason="TODO: swapaxes")
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:290:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:305:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:319:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./core/py/pipeline/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:221:# TODO at some point, we could switch to an enum flag, so that multiple sources
./core/py/pipeline/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:224:    # TODO if/when https://peps.python.org/pep-0767/ is accepted, add 'read_only'
./core/py/pipeline/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:319:        # TODO use a match statement when Python 3.9 support is dropped.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/_typing/_dtype_like.py:61:_DTypeLikeNested = Any  # TODO: wait for support for recursive types
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/_typing/_array_like.py:56:# TODO: Wait until mypy supports recursive objects in combination with typevars
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1795:    # TODO: are there no other tests for cholesky?
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/getlimits.py:367:    TODO: MachAr should be retired completely ideally.  We currently only
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs.py:2312:        assignment examples; TODO).
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/arrayprint.py:1466:        # TODO: Custom repr for user DTypes, logic should likely move.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:170:        # TODO: this path can never be reached
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:179:    # TODO: this duplicates the C metastr_to_unicode functionality
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs_scalars.py:320:# TODO: work out how to put this on the base class, np.floating
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:80:        # TODO: Optimize case when `where` is broadcast along a non-reduction
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_scalarmath.py:97:        # TODO: It would be nice to resolve this issue.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:7434:# TODO: test for multidimensional
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:452:        # TODO: This discrepancy _should_ be resolved, either by relaxing the
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:892:    # TODO: This is arguably weird/wrong, but seems old:
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:12:# TODO: branch cuts (use Pauli code)
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:13:# TODO: conj 'symmetry'
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:14:# TODO: FPU exceptions
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:23:# TODO: replace with a check on whether platform-provided C99 funcs are used
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:26:# TODO This can be xfail when the generator functions are got rid of.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:122:    # TODO This can be xfail when the generator functions are got rid of.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:479:    # TODO This can be xfail when the generator functions are got rid of.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_casting_unittests.py:782:        # TODO: While this test is fairly thorough, right now, it does not
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_api.py:163:# TODO: remove when fastCopyAndTranspose deprecation expires
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:1544:        # TODO: Allowing unsafe casting by
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:2520:        # TODO: add absolute (gold standard) time span limit strings
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/numeric.py:480:    # TODO: this works around .astype(bool) not working properly (gh-9847)
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1873:    /* TODO: Make this definition public in the API, as soon as its settled */
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:221: * TODO: Due to the fact that `resolve_descriptors` is also used for `can_cast`
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:366:// TODO: These slots probably still need some thought, and/or a way to "grow"?
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:398: * TODO: These two functions are currently only used for experimental DType
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:821:        // TODO: do something better than 128 bit math
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:855:        // TODO: do something better than 128 bit math
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/mixins.py:163:    # TODO: handle the optional third argument for __pow__?
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:73:# TODO: .zip support, .tar support?
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:335:        # TODO: Doesn't handle compressed files!
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:401:        # TODO:  This should be more robust.  Handles case where path includes
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:515:        # TODO: There is no support for opening a file for writing which
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:518:        # TODO: Add a ``subdir`` parameter for specifying the subdirectory
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:3543:        # TODO: Note that times have dubious rounding as of fixing NaTs!
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:4101:        # TODO: Median does not support Datetime, due to `mean`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:311:                sup.filter(ResourceWarning)  # TODO: specify exact message
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/core.py:207:        # TODO: This is probably a mess, but should best preserve behavior?
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/core.py:4673:        # TODO: We don't actually support K, so use A instead.  We could
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5430:    # TODO: Test masked_object, masked_equal, ...
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/_isocbind.py:55:# TODO: See gh-25229
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:134:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2066:    TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2505:                    # TODO: test .eq., .neq., etc replacements.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2551:                outmess(f'get_parameters[TODO]: '
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2594:        # TODO: use symbolic from PR #19805
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:723:        /* TODO: change the type of `len` so that we can remove this */
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:783:            // TODO: update when numpy will support 1-byte and
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:808:        /* TODO: This error (and most other) error handling needs cleaning. */
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:830:# TODO: These should be dynamically generated, too many mapped to int things,
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:248:    # TODO: support Fortran `len` function with optional kind parameter
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:504:        # TODO: Evaluate intent_flags here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:23:# TODO: support logical constants (Op.BOOLEAN)
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:24:# TODO: support logical operators (.AND., ...)
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:25:# TODO: support defined operators (.MYOP., ...)
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:520:                # TODO: other kind not used
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:570:        # TODO: implement a method for deciding when __call__ should
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:811:            # TODO: determine correct kind
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:846:            # TODO: determine correct kind
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:896:            # TODO: denom kind not used
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:1108:            # TODO: find common divisor of coefficients
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/src/fortranobject.c:1358:  // TODO: detect the size of buf and make sure that size(buf) >= size(localbuf).
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:395:    # TODO: Clean up to prevent passing --overwrite-signature
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:494:    TODO: Test to ensure this has no effect without --latex-doc
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:638:    TODO: Document this in the help string
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:662:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:671:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:727:    # TODO: f2py2e should not call sys.exit() after printing the version
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:752:# TODO: These should be tested separately
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:759:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:767:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:775:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:783:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:791:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:799:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:807:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:815:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:823:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:831:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:839:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:847:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:855:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:863:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:871:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:879:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:887:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:895:    # TODO: populate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_docs.py:55:    # TODO: implement test methods for other example Fortran codes
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:448:    # TODO: Remove all this when scaninputline is replaced
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/_set_functions.py:15:# TODO in this implementation as this behavior may be reverted in np.unique().
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/__init__.py:98:Still TODO in this module are:
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/_creation_functions.py:69:        # to an object array. TODO: This won't handle large integers in lists.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_array_object.py:387:    TODO: Find and use appropriate __setitem__() case.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_data_type_functions.py:29:    # TODO: These will require https://github.com/numpy/numpy/issues/23883
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:436:        # TODO: we're stuck with disabling math formatting until we handle
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/random/tests/test_random.py:1062:    # TODO: Include test for randint once it can broadcast
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:688:    # TODO: Find some kind of fallback if there is no _CHECKPOINT_FOR_DOC in any of the modeling file.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:41:# TODO: This doesn't work for all packages (`bs4`, `faiss`, etc.) Talk to Sylvain to see how to do with it better.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:48:            # TODO: Once python 3.9 support is dropped, `importlib.metadata.packages_distributions()`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:71:                # TODO: remove once `importlib.metadata.packages_distributions()` is supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:401:    # TODO check if some bugs cause push backs on the exact version
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:578:        # TODO: more precise exception matching, if possible.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:602:        # TODO: more precise exception matching, if possible.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1048:        # TODO: Bump the requirement to 2.1.0 once released in https://github.com/ROCmSoftwarePlatform/flash-attention
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/attention_visualizer.py:188:            if "token_type_ids" in inputs:  # TODO inspect signature of update causal mask
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1803:                # TODO: Remove this check once configuration version is handled natively by Quark.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:93:# TODO: clean this for v5?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:530:# TODO cyril: Deprecated and should be removed in 4.51
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:197:    # TODO: add support for them as it should be quite easy to do so (small blocking issues).
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:389:    # TODO: infer shape without performing the computation, this might be quite hard.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:582:        # TODO: infer shape without performing the computation.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:1351:            # TODO: solves GraphModule creation.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:336:        # TODO: remove this hack when the legacy code that initializes generation_config from a model config is
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:1117:                    # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:371:        # TODO (Joao): this function might trigger XLA retracing as `cur_len` increases. Fix it if it becomes
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:428:        # TODO (joao): enable XLA on this logits processor. See discussion and attempts in
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:1942:        # TODO(Patrick): Make sure that official models have max_initial_timestamp_index set to 50
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:317:# TODO (joao): remove the equivalent classes and typing shortcuts below in v5
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:519:        # 8. Remove unexpected `generate` inputs (TODO @joao: fix trainer and examples)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:800:                # TODO (joao): remove output/input mismatch when these old models (xlnet, reformer) are deprecated
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1082:            # TODO (sanchit): move this exception to GenerationConfig.validate() when TF & FLAX are aligned with PT
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1088:        # TODO (joao): find a strategy to specify the order of the processors
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1353:        # TODO(joao): remove this function in v4.50, i.e. when we remove the inheritance of `GenerationMixin` from
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1428:            # TODO: A better way to handle this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1564:        # TODO (joao): per-model generation config classes.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1821:        # TODO(joao): support static caches in assisted generation. assisted generation needs to roll back caches,
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2135:            # TODO (joao): generalize this check with other types of inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3331:                # TODO (joao): this OP throws "skipping cudagraphs due to ['incompatible ops']", find solution
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3386:        TODO: standardize cache formats and make all models compatible with `Cache`. It would remove the need
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3505:        # TODO (joao): This function should take an optional beam scorer function, to manipulate the scores after
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3669:        # TODO (joao): standardize special cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1627:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1911:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2254:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2789:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:537:        # TODO joao: find out a way of not depending on external fields (e.g. `assistant_model`), then make this a
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:54:# TODO: Move BatchFeature to be imported by both image_processing_utils and image_processing_utils
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:71:# TODO: (Amy) - factor out the common parts of this and the feature extractor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/image_utils.py:1325:        # TODO raise a warning here instead of simply logging?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1496:            # TODO Matt: This is a workaround for older versions of datasets that are missing the `cols_to_retain`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2025:        # TODO (joao): flagged for replacement (by `_v2_resized_token_embeddings`) due to embeddings refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2065:        # TODO (joao): flagged for delection due to embeddings refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2096:        # TODO (joao): flagged for replacement (by `_v2_resize_token_embeddings`) due to embeddings refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2133:            # TODO (joao): this one probably needs a v2 version with other models
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2156:        # TODO (joao): flagged for replacement (by `_v2_get_resized_lm_head_bias`) due to embeddings refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2283:        # TODO (joao): flagged for replacement (by `_v2_get_resized_embeddings`) due to embeddings refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2954:            # TODO Matt: This is a temporary workaround to allow weight renaming, but requires a method
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3335:    # TODO (joao): flagged for delection due to embeddings refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:197:        # TODO use valid to mask invalid areas due to padding in loss
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:210:        # TODO: randomness could apply a random seed, ex. rng = random.Random(random_seed)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/data/processors/squad.py:179:        encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:201:        # TODO: The default inputs only work for text models. We need to add support for vision/audio models.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:227:        # TODO: figure out dynamo support for instance method and switch this to instance method
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:261:        # TODO: figure out dynamo support for instance method and switch this to instance method
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:876:        # TODO clean this up at some point (probably by switching to fast tokenizers)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/audio_utils.py:381:# TODO This method does not support batching yet as we are mainly focused on inference.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:279:        # TODO: Remove the `query_length != 1` check once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/onnx/convert.py:141:            # TODO: Check when exporting QA we provide "is_pair=True"
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:516:        # TODO: should we set seq_length = 1 when self.use_past = True?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:702:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/tf_utils.py:70:    # TODO: When the issue linked above gets sorted, add a check on TF version here and use the original function if
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:271:    # TODO: @AjayP13, @younesbelkada replace this check with version check at the next `accelerate` release
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:1542:                # TODO Change dtypes back to M=FP32, Var = BF16, Kahan = False once they can be cast together in torchdistx.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:2865:            # TODO: in the future support only specific min PEFT versions
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:2959:                    # TODO: in the future support only specific min PEFT versions
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:3785:        # TODO: this needs to be fixed and made cleaner later.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:4561:                    # TODO: this needs to be fixed and made cleaner later.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:545:        # TODO this is fairly slow to improve!
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:1103:        # TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_string
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:213:    TODO(Patrick): Delete safety argument `_enable=True` at next major version. .
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1760:# TODO (joao): remove `GenerationMixin` inheritance in v4.50
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4065:            # TODO: we can relax this check when we support taking tp_plan from a json file, for example.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:160:        # TODO try and retrieve it in a nicer way from _sanitize_parameters.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:103:    # TODO: Update task_summary docs to include an example with document QA and then update the first sentence
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:379:            # TODO: check why slower `LayoutLMTokenizer` and `LayoutLMv2Tokenizer` don't have this key in outputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:467:        # TODO: A lot of this logic is specific to Donut and should probably be handled in the tokenizer
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1301:        # TODO hack by collating feature_extractor and image_processor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1344:        # TODO make the get_iterator work also for `tf` (and `flax`).
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1419:        # TODO hack by collating feature_extractor and image_processor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:103:    # TODO  Use a faster algorithm this can probably be done in O(n)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:969:    # TODO: we need to make `NO_IMAGE_PROCESSOR_TASKS` and `NO_FEATURE_EXTRACTOR_TASKS` more robust to avoid such issue.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:341:# TODO need to add the __repr__ that shows that it is a colwise parallel
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/sagemaker/training_args_sm.py:29:# TODO: should be moved to `utils` after refactoring of SageMakerTrainer
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:61:        # TODO: deprecate this function in favor of `cache_position`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:453:        # TODO: deprecate this function in favor of `cache_position`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:596:    # TODO (tmanlaibaatar) This won't be needed in torch 2.7.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1021:        # TODO: deprecate this function in favor of `cache_position`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1172:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1276:        # TODO: deprecate this function in favor of `cache_position`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1356:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1567:    # TODO(gante, sanchit-gandhi): move following functionality into `.generate`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1659:    # TODO (joao): dive deeper into gemma2 and paligemma -- there are reports of speed loss with compilation. Revert
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1663:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1806:        # TODO: deprecate this function in favor of `cache_position`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1865:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1866:    # TODO (joao): add layer_device_map arg and update code in `generate` accordingly
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2044:        # TODO(gante): Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2078:            # TODO(gante): Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2136:        # TODO(gante): Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2148:        # TODO(gante): Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2160:        # TODO(gante): Remove this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/training_args.py:223:# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/training_args.py:2162:        # those deprecated arguments are removed from TrainingArguments. (TODO: v5)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/image_transforms.py:791:# TODO (Amy): Accept 1/3/4 channel numpy array as input and return np.array as default
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:133:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:261:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:414:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:459:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1218:                # TODO: Remove once eetq releases a fix and this release is used in CI
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1506:    # TODO (if possible): Avoid exceptional cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/agents/agents.py:1094:                # TODO: observation naming could allow for different names of same type
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:269:            # TODO: When tracing with TorchDynamo with fullgraph=True, the model is recompiled depending on the input
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:297:                # TODO: maybe revisit this with https://github.com/pytorch/pytorch/pull/114823 in PyTorch 2.3.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:375:    # TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:66:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/helium/modeling_helium.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/shieldgemma2/processing_shieldgemma2.py:153:        # TODO(ryanmullins): Support images from PIL or URLs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:274:    # TODO: maybe jit, otherwise move inside forward
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/pegasus/tokenization_pegasus.py:33:# TODO ArthurZ refactor this to only use the added_tokens_encoder
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/emu3/modeling_emu3.py:1234:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:279:        # TODO: remove the redundant computation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:394:        # TODO replace this with
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:467:        # TODO: This code is most likely not very efficient and should be improved
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2473:        # TODO (Joao): investigate why LED has numerical issues in XLA generate
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmo/modeling_olmo.py:311:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:188:            # TODO: figure this case out.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:287:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:317:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:251:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granite/modeling_granite.py:346:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:99:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:356:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:461:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:525:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:300:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:428:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:203:            # TODO: figure this case out.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:302:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/processing_grounding_dino.py:319:                    # TODO: @pavel, set labels to None since v4.51.0 or find a way to extract ids
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1582:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:26:# TODO Update this
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:364:# TODO: ^ interpret this
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:418:    # TODO: this file should be downloaded in a setup script
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:2007:# TODO Add information to the docstring about any methods that convert to PDB format, or otherwise prepare
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/tokenization_esm.py:65:        # TODO, all the tokens are added? But they are also part of the vocab... bit strange.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:330:        # `sqrt` in order to prevent NaNs during training in bfloat16. TODO a bit annoying
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:347:    # TODO refactor
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:709:        if use_cache and inputs_embeds.shape[1] != 1:  # TODO let's maybe only call in the `generate`?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:776:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->RECURRENTGEMMA,Llama->RecurrentGemma,llama->gemma
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:866:        # Soft-cap the logits TODO remove if always done.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:324:        # TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:971:        # TODO: deal with head_mask
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:1046:        # TODO: deal with head_mask
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:344:        # TODO check if the t5/llama PR also applies here
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:156:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:629:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:210:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:239:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:310:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:424:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:612:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:685:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:740:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:307:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:431:        # TODO: @yoni, change in v4.48 (use_fast set to True by default)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:496:        # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:262:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:270:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:608:        # TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1295:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py:504:                # TODO: Should we use the pre-trained projection as well ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:669:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:487:        # TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:346:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:475:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:687:        # TODO Matt: What is going on here? Why is a non-trainable weight randomly initialized?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama_fast.py:244:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:117:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:268:# TODO: (Amy) Move to image_transforms
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:661:        # TODO: (Amy)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:618:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:747:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1577:        >>> # TODO: Add full pretraining example
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1594:        # TODO(PVP) - add pretraining logic and add to tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:338:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:562:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:573:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:622:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:679:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:700:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:203:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1709:        # TODO (joao):workaround until nested generation config is compatible with PreTrained Model
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bark/generation_configuration_bark.py:245:    # TODO (joao): nested from_dict
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:462:        # TODO: (amy) add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py:628:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:158:        # TODO ArthurZ fairseq_ids_to_tokens should be removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:423:        # TODO fix this
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:516:        # TODO find a better way of exposing other arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1152:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:216:            # TODO: Support arbitrary patch sizes.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:931:                # TODO can we simplify this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:1345:        # TODO (Qian): is it possible to revert the original cell if it is in the final answer?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:388:        self.t2u_variance_predictor_embed_dim = t2u_variance_predictor_embed_dim  # TODO: add to docstrings
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:389:        self.t2u_variance_predictor_hidden_dim = t2u_variance_predictor_hidden_dim  # TODO: add to docstrings
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:390:        self.t2u_variance_predictor_kernel_size = t2u_variance_predictor_kernel_size  # TODO: add to docstrings
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:391:        self.t2u_variance_pred_dropout = t2u_variance_pred_dropout  # TODO: add to docstrings
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:354:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:483:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/configuration_m2m_100.py:274:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:197:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:399:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:412:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:510:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:531:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:313:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere2/modeling_cohere2.py:78:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:504:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:461:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:664:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:793:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt2/configuration_gpt2.py:202:            # TODO: how to do that better?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:300:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:388:            # TODO add support for MLM
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:572:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:170:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:637:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:839:            # TODO(PVP): need to verify if below code is correct
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/byt5/tokenization_byt5.py:97:            additional_special_tokens=additional_special_tokens,  # TODO extra ids are not used :sweatywmile:
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:414:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:506:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1446:        # TODO: As is this currently fails with saved_model=True, because
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bridgetower/configuration_bridgetower.py:279:        # TODO: remove this once the Hub files are updated.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:287:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:504:    _supports_static_cache = False  # TODO: needs a HybridCache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:330:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:458:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:63:# TODO: Update before the merge
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1263:    _supports_static_cache = False  # TODO: @raushan more involved due to local/global attn
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:2227:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:696:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:390:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:595:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:817:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:936:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1830:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py:248:        # TODO: @raushan update config in the hub
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:216:            # TODO: Support arbitrary patch sizes.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:129:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:232:        # TODO support align_corners=True in image_transforms.resize
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:457:        # TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:307:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:414:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:651:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:176:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:230:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:337:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmo2/modeling_olmo2.py:312:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:73:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:96:# TODO(joao): add me back asap :)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:149:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: this may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:280:    # TODO(joao): add me back asap :)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:374:# TODO(joao): add me back asap :)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:385:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:437:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim].
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:511:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:593:# TODO(joao): add me back asap :)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:124:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:313:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:324:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:371:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:428:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:450:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:1010:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->NEMOTRON,Llama->Nemotron,llama->nemotron
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/ijepa/modeling_ijepa.py:585:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:140:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:266:        # TODO (raushan): remove in v4.46 (RoPE is computed in the model, not in the decoder layers)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:472:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:511:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1024:        # TODO: As of torch==2.2.0, the `attention_mask` passed to the model in `generate` is 2D and of dynamic length even when the static
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:306:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:258:        # TODO check if the t5/llama PR also applies here
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:342:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:434:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:51:# TODO @ArthurZucker bring copied from back
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:262:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:303:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:305:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:413:        # TODO find a better way of exposing other arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:287:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:391:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:496:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:352:    # TODO add a deprecation cycle as this can have different behaviour from our API
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:188:            # TODO: figure this case out.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:287:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:297:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:426:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py:213:                # TODO: Check if this is needed, as it ensures that decode(encode(doc)) != doc by adding extra whitespace in the decoded document
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:131:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:630:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:749:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:941:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1707:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py:237:        # TODO: @raushan update config in the hub
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:594:        # TODO: We should check if the opset_version being used to export
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1967:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py:103:    # TODO: make it with torch instead of numpy
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gptj/configuration_gptj.py:148:            # TODO: how to do that better?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deit/modeling_deit.py:595:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:34:# TODO this class is useless. This is the most standard sentencpiece model. Let's find which one is closest and nuke this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:353:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:82:        # TODO maybe make it torch compatible later on. We can also just slice
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:112:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:863:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:874:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:168:        # TODO(enijkamp): factor out number of logical TPU-v4 cores or make forward pass agnostic
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/codegen/configuration_codegen.py:159:            # TODO: how to do that better?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:345:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1672:        # TODO: Implement `WhisperTimeStampLogitsProcessor`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:366:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:423:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:491:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1005:                    # TODO Handle when language is different from the previous
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:93:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:762:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1436:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:251:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:208:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:243:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/vit/modeling_vit.py:604:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py:2349:            # TODO (joao, raushan): refactor `generate` to avoid these operations with VLMs
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:348:# TODO: Implement attention with SDPA for PLBart.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:375:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:638:            # TODO(PVP): need to verify if below code is correct
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:210:            # TODO: figure this case out.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:309:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:422:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:292:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:323:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:194:        # TODO decode outputs do not match between fast and slow
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1289:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:263:# TODO: (Amy) Move to image_transforms
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:660:        # TODO: (Amy)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:607:        # TODO: Check fp32 layer norm possiblity
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:454:        # TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:49:# TODO: Replace all occurrences of the checkpoint with the final one
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:242:        # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:545:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:754:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:1012:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:2202:        # TODO: we have no attention_mask so this won't work, check if we really won't need attention mask and find another way
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:265:            TODO: add aspect_ratio_ids and aspect_ratio_mask and cross_attention_mask
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:537:        # TODO Come up with footnote formatting inside a table
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:661:        # TODO: (Amy)
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:659:        # TODO: remove the redundant computation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:774:        # TODO replace this with
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1031:        # TODO: This code is most likely not very efficient and should be improved
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:394:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:593:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:604:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:648:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:705:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:726:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1415:        # TODO (Joao): investigate why Speech2Text has numerical issues in XLA generate
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:317:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:40:# TODO(PVP) - this should be removed in Transformers v5
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:38:# TODO(PVP) - this should be removed in Transformers v5
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1942:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:188:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:404:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:448:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:522:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:865:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaModel with Llama->Olmoe
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:58:# TODO: Could have better fused kernels depending on scaling, dropout and head mask.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:284:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:521:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:636:# TODO - (Amy) make compatible with other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:659:# TODO - (Amy) make compatible with other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1039:    # TODO (Amy) - update to use `rescale_factor` instead of `scale`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1500:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:475:        # TODO find a better way of exposing other arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:495:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:624:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:601:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:730:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1560:        >>> # TODO: Add full pretraining example
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1597:        # TODO(PVP) - add negative sampling & loss computation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:400:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:411:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:450:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:508:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:530:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:783:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1261:                # TODO(ls): Add cross attention values to respective lists
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1434:                # TODO(ls): Add cross attention values to respective lists
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:2127:        # TODO: As is this currently fails with saved_model=True, because
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:451:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:543:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:107:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:1247:            # TODO(SS): do we need to ignore pad tokens in labels?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:188:            # TODO: figure this case out.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:288:            # TODO: test this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bloom/configuration_bloom.py:156:            # TODO: how to do that better?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:64:    TODO @thomasw21 this doesn't work as nicely due to the masking strategy, and so masking varies slightly.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bloom/tokenization_bloom_fast.py:113:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/starcoder2/modeling_starcoder2.py:305:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/perceiver/tokenization_perceiver.py:182:    # TODO @ArthurZ refactor this as well....
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:193:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:523:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:534:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:573:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:631:# TODO cyril: modular
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:653:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:153:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:502:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere/modeling_cohere.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:505:            # TODO(Patrick): if we train more RAG models, I want to put the input first to take advantage of effortless truncation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:506:            # TODO(piktus): better handling of truncation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:415:            # TODO: make sure we are using `FacebookAI/xlm-mlm-enro-1024`, since XLM-100 doesn't have this step
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:431:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:331:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:385:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:458:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:579:        # TODO refer to https://github.com/ArthurZucker/transformers/blob/0f0a3fe5ca5697ee58faeb5b53f049af720b5e98/src/transformers/models/vit_mae/modeling_vit_mae.py#L871
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:120:        # TODO Remove this logic in a subsequent release since subsequences are not supported.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:353:        self.max_position_embeddings = 16384  # TODO Can't derive this from model files: where to set it?
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:375:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:445:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:526:            qlen: TODO Lysandre didn't fill
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:527:            mlen: TODO Lysandre didn't fill
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:526:        # TODO find a better way of exposing other arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1123:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1525:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1527:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:489:        # TODO find a better way of exposing other arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:272:        # Tokenizer arguments TODO: eventually tokenizer and models should share the same config
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:396:            # TODO (joao): this should be an exception if the user has modified the loaded config. See #33886
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:62:                # TODO: Update message once eetq releases a fix
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:317:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_awq.py:125:            model._awq_is_fused = True  # TODO: consider storing this flag in model.config instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:274:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./core/py/pipeline/.venv/lib/python3.12/site-packages/mdurl/_parse.py:168:            # v0.12 TODO(isaacs): This is not quite how Chrome does things.
./core/py/pipeline/.venv/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py:26:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/markdown_it/parser_inline.py:96:            # TODO: remove this workaround when CM standard will allow nested links
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/numpy_pickle_utils.py:237:    TODO python2_drop: is it still needed? The docstring mentions python 2.6
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/pool.py:49:    TODO python2_drop : can this be simplified ?
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/memory.py:44:# TODO: The following object should have a data store object as a sub
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/memory.py:53:# TODO: Same remark for the logger, and probably use the Python logging
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/memory.py:583:            # TODO (pierreglaser): do the same with get_func_name?
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/_store_backends.py:209:                        # TODO(1.5) turn into error
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/_memmapping_reducer.py:164:        # TODO: check scipy sparse datastructure if scipy is installed
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/parallel.py:2054:            # TODO: this iterator should be batch_size * n_jobs
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/test/common.py:18:# TODO straight removal since in joblib.test.common?
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/test/common.py:44:# TODO: Turn this back on after refactoring yield based tests in test_hashing
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:146:    # TODO: test that the cache related to the function cache persists across
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:170:            # TODO when Python 3.11 is the minimum supported version, use
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/compressor.py:235:    TODO python2_drop: is it still needed since we dropped Python 2 support A
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/externals/cloudpickle/cloudpickle.py:1342:        # TODO: decorrelate reducer_override (which is tied to CPython's
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/externals/loky/_base.py:20:# TODO investigate why using `concurrent.futures.Future` directly does not
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py:11:# TODO: investigate which Python version is required to be able to use
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/func_inspect.py:168:        # TODO: Maybe add a warning here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./core/py/pipeline/.venv/lib/python3.12/site-packages/boto3/resources/factory.py:586:                    # TODO: Make this configurable in the future?
./core/py/pipeline/.venv/lib/python3.12/site-packages/boto3/resources/response.py:151:        # TODO: Remove the '$' check after JMESPath supports it
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/rrule.py:1182:                    # TODO: Check -numweeks for next year.
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:55:# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:265:                ("Tue", "Tuesday"),     # TODO: "Tues"
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:267:                ("Thu", "Thursday"),    # TODO: "Thurs"
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:272:              ("Feb", "February"),      # TODO: "Febr"
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:291:    # TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:777:                                # TODO: not hit in tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:815:                    # TODO: check that l[i + 1] is integer?
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:823:                        min_offset = int(l[i + 3])  # TODO: Check that l[i+3] is minute-like?
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:910:                # TODO: Check if res attributes already set.
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:934:                # TODO: checking that hour/minute/second are not
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:941:            value = self._to_decimal(tokens[idx + 2])  # TODO: try/except for this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1032:            # TODO: Are we sure this is the right condition here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1100:        # TODO: Every usage of this function sets res.second to the return
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1112:        # TODO: Is this going to admit a lot of false-positives for when we
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:25:    except IOError as e:  # TODO  switch to FileNotFoundError?
./core/py/pipeline/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:76:# TODO: Remove after deprecation period.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:839:            # TODO: What could we test if loss.approx_hessian?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:874:                # TODO: What could we test if loss.approx_hessian?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_plotting.py:167:        # TODO(1.9): Remove deprecated **kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:258:    # TODO: test with intercept
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:259:    # TODO: test with multiple responses
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:789:            TODO(1.8): remove return value
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:831:    # TODO(1.8): remove generate_only
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:1117:        # TODO There are a few errors in SearchCV with array-api-strict because
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3454:    # TODO: find out why PLS and CCA fail. RANSAC is random
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3795:        # TODO(devtools): this should be a separate check.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3827:                    # TODO(devtools): separately check that the constructor doesn't
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:499:# TODO(devtools): allow third-party developers to pass test specific params to checks
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:501:    # TODO(devtools): check that function names here exist in checks for the estimator
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:565:    # TODO(1.9) simplify when averaged_inverted_cdf is the default
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:604:            # TODO: dual=True is a stochastic solver: we cannot rely on
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:824:    # TODO(devtools): enable this behavior for third party estimators as well
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:853:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:862:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:871:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:880:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:893:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:902:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:941:        # TODO: investigate failure see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:950:        # TODO: investigate failure see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:983:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:992:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1001:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1015:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1027:        # TODO: replace by a statistical test when _dual=True, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1039:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1048:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1057:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1067:        # TODO: fix sample_weight handling of this estimator when probability=False
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1068:        # TODO: replace by a statistical test when probability=True
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1081:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1095:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1104:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1126:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1135:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1148:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1157:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1179:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1188:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1197:        # TODO: replace by a statistical test, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1229:        # TODO: fix sample_weight handling of this estimator when probability=False
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1230:        # TODO: replace by a statistical test when probability=True
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1240:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1258:# TODO: remove when scipy min version >= 1.11
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1285:        # TODO: remove when scipy min version >= 1.16
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:35:# TODO: We can consider removing the containers and importing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:58:# TODO: Remove when SciPy 1.11 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:71:# TODO: Remove when Scipy 1.12 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:84:# TODO : remove this when required minimum version of scipy >= 1.9.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:116:# TODO: Fuse the modern implementations of _sparse_min_max and _sparse_nan_min_max
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:224:# TODO: Adapt when Pandas > 2.2 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:238:# TODO: remove when SciPy 1.12 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:285:# TODO: remove when SciPy 1.12 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:355:# TODO: Remove when Scipy 1.12 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:200:    # TODO(1.9) remove UserList when the force_int_remainder_cols param
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:315:        # TODO: we should probably use _is_pandas_df_or_series(X) instead but:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:372:            # TODO(1.3): check if the warning is still raised or remove the filter.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:22:# TODO: complete __all__
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:572:    # TODO: Update to use `__array_namespace__info__()` from array-api v2023.12
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:673:    # TODO: Remove this once https://github.com/scipy/scipy/issues/21736 is fixed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:682:    # TODO: refactor once nan-aware reductions are standardized:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:702:    # TODO: refactor once nan-aware reductions are standardized:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:722:    # TODO: refactor once nan-aware reductions are standardized:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:850:    # TODO: once sufficiently adopted, we might want to instead rely on the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:986:    # TODO: update if bincount is ever adopted in a future version of the standard:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_testing.py:1373:        # TODO: remove when pyamg > 5.0.1
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/optimize.py:95:        # TODO: It seems that the new check for the sum of absolute gradients above
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:654:    # TODO: Remove when the minimum version of SciPy supported is 1.12
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2408:        # TODO: remove the pandas-specific branch once the minimum supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_extmath.py:226:    # more accurate but slow (TODO find realistic settings here)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_plotting.py:217:# TODO(1.9) : Remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:24:# TODO: add this estimator into the _mocking module in a further refactoring
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:2338:# TODO(1.8): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:40:# TODO(1.8): Update when implementing __sklearn_tags__ is required
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:92:# TODO(1.8): Update this test to check for errors
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_array_api.py:297:# TODO: add cupy to the list of libraries once the following upstream issue
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:127:# TODO(1.8): remove force_all_finite and change the default value of ensure_all_finite
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:251:# TODO(1.8): Remove this function
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:327:        # TODO(1.8): turn the warning into an error
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/stats.py:116:# TODO: refactor to do the symmetrisation inside _weighted_percentile to avoid
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:292:        # TODO(1.9): remove and switch to quantile_method="averaged_inverted_cdf"
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:360:                    # TODO: make _weighted_percentile and
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2351:        # TODO: This should be refactored because binarize also calls
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:480:    ## TODO: change to averaged inverted cdf, but that means we only get bin
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:519:    # TODO this check is redundant with common checks and can be removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:957:        # TODO: Remove this condition, once scipy 1.10 is the minimum version.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1120:            # TODO: Remove this conditional error when the minimum supported version of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1144:            # TODO: Remove ones scipy 1.10 is the minimum version. See comments above.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:108:    # TODO: Use loss.fit_intercept_only where appropriate instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:257:            # TODO: Multiply here by learning rate instead of everywhere else.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:449:        # TODO: Without oob, i.e. with self.subsample = 1.0, we could call
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:672:        y = column_or_1d(y, warn=True)  # TODO: Is this still required?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_base.py:23:    # TODO(SLEP6): remove if-condition for unrouted sample_weight when metadata
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:116:    # TODO: (slep6) remove if condition for unrouted sample_weight when metadata
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:155:        # TODO(SLEP6): remove if condition for unrouted sample_weight when metadata
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py:140:        # TODO: consider always using platform agnostic dtypes for fitted
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:15:# TODO(1.8) remove the filterwarnings decorator
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:107:        # TODO: We are not entirely satisfied with this lax comparison, but the root
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:125:# TODO(1.8) remove the filterwarnings decorator
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:202:# TODO(1.8) remove the filterwarnings decorator
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:90:    # TODO: Ideally this should be computed in parallel over the leaves using something
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:125:    TODO: in the future, we could explore the possibility to extend the scorer
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:572:            # TODO: remove when PDP supports sample weights
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:682:                # TODO: incorporate sample_weight in sampling here, as well as
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1086:        # TODO: incorporate sample_weights here in `resample`
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:2225:        # TODO: This could be done in parallel
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py:327:        # TODO: complexity is O(n_categorical_features * 255). Maybe this is
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:490:    # TODO(1.8): remove "algorithm" entry
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:745:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:1129:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_weight_boosting.py:635:# TODO(1.8): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/isotonic.py:164:        # TODO: remove this branch when Scipy 1.12 is the minimum supported version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:655:                # TODO: incorporate sample_weight in sampling here.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neural_network/_base.py:211:    # TODO: Decide what to do with the term `xlogy(y_true, y_true) - y_true`. For now,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:330:            # TODO: systematize this mapping of metric for
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:338:                # TODO: Implement efficient multi-output solution
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:363:                    # TODO: adapt the heuristic for `strategy="auto"` for
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:36:# TODO: implement a brute force version for testing purposes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:37:# TODO: create a density estimation base class?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:330:        # TODO: implement sampling for other valid kernel shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:378:        # TODO: also test radius_neighbors, but requires different assertion
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1623:# TODO: remove when NearestNeighbors methods uses parameter validation mechanism
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1727:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2253:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2488:    # TODO: if score is refactored to evaluate models for other scoring
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_lof.py:252:    # TODO: compare results on dense and sparse data as proposed in:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/calibration.py:329:            # TODO(1.8): Remove this code branch and cv='prefit'
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/calibration.py:863:        # TODO: Remove casting to np.float64 when minimum supported SciPy is 1.11.2
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:658:    # TODO(1.9): Remove base_estimator
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:676:    # TODO(1.8): This is a temporary getter method to validate input wrt deprecation.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:791:            # TODO: remove this condition check when the minimum supported scipy version
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1037:    # TODO(1.9): Remove base_estimator from __init__
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:372:        # TODO: for Scipy <= 1.10, `isspmatrix(X)` returns `True` for sparse arrays.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:1060:# TODO this class should fit on either p-values or scores,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:225:    # TODO(1.8) remove this property
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:791:    # TODO(1.8): remove `groups` from the signature after deprecation cycle.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:377:                # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:461:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_optics.py:621:    # TODO: handle working_memory somehow?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:772:                # TODO: Support np.nan in Cython implementation for precomputed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:834:                # TODO: Benchmark KD vs Ball Tree efficiency
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:938:                # TODO: Implement weighted argmin PWD backend
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_birch.py:245:# TODO(1.8): Remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:30:# TODO: AffinityPropagation must preserve dtype for its fitted attributes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:114:    # TODO: we should handle missing values (i.e. `np.nan`) specifically and store them
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:716:            # TODO(1.9): raise a ValueError instead.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:682:    # TODO: extend to HistGradientBoosting once sample_weight is supported
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:705:    # TODO: remove/fix when PDP supports HGBT with sample weights
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:510:    # TODO(1.8): Remove this attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:583:    # TODO(1.8): Remove this attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:659:    # TODO(1.8): Remove this attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1012:    # TODO(1.8): Remove this attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1062:    # TODO(1.8): Remove this attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1202:    # TODO(1.8): Remove this check
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1242:    # TODO(1.8): Remove this check
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1284:    # TODO(1.8): Remove this check
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1309:    # TODO(1.8): Remove this check
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:551:    # TODO We can do this cheaper; sorted_indices copies the whole matrix.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:570:        # TODO: simplify interfaces and implementations in _svmlight_format_fast.pyx.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_arff_parser.py:67:    # TODO: improve for efficiency
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:341:        # TODO: feature request OpenML.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:640:        # TODO (1.8): remove this once the deprecation is removed. In the meantime,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:654:            # TODO (1.8): remove this once the deprecation is removed to keep only
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:663:            # TODO (1.8): remove this once the deprecation is removed to keep only
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:684:                # TODO (1.8): remove this `if` branch once the following issue is
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:468:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:571:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:13:    # TODO: remove this check once the estimator is no longer experimental.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:19:# TODO: remove this check once the estimator is no longer experimental.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:413:# TODO (1.8): check that `keep_empty_features=False` drop the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:429:# TODO (1.8): check that `keep_empty_features=False` drop the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:459:# TODO (1.8): check that `keep_empty_features=False` drop the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:495:# TODO (1.8): check that `keep_empty_features=False` drop the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1550:# TODO (1.8): check that `keep_empty_features=False` drop the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1761:        # TODO(1.8): Remove the condition and still call getattr(imputer, method)(X)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1259:        TODO: Remove when ``set_config(enable_metadata_routing=False)`` is no
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/compose/tests/test_column_transformer.py:975:# TODO(1.9): remove this test
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:50:    TODO(1.8): remove this context manager and replace with check_is_fitted.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:406:    # TODO(1.8): Remove this property
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:780:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:896:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:943:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:981:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1027:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1082:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1127:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1178:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1902:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1951:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:2024:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:446:                # TODO: tree shouldn't need this in this case
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:624:                # TODO: the tree shouldn't need this param
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:170:        # TODO(slep006): remove when metadata routing is the only way
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:239:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:251:        # TODO(slep006): remove when metadata routing is the only way
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:296:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:456:                # TODO (1.8): scoring="max_error" has been deprecated in 1.6,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:498:        # TODO(slep006): remove when metadata routing is the only way
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:738:# TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2200:    # TODO(1.9): When `raise_warning` is removed, the following changes need to be made:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_supervised.py:1256:    # TODO(1.9): remove the sparse parameter
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/tests/test_supervised.py:515:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:398:    TODO: use a float64 accumulator in row_norms to avoid the latter.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1972:        # TODO: do it also for other norms.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:80:            # TODO: implement a stable simultaneous_sort.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:128:                # TODO: support CSR matrices without non-zeros elements
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:131:                # TODO: support CSR matrices with int64 indices and indptr
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:476:            # TODO: implement Euclidean specialization using GEMM.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:644:            # TODO: implement Euclidean specialization using GEMM.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1398:    # TODO: remove when enable_metadata_routing is deprecated
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1656:# TODO(1.8): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_classification.py:762:# TODO(1.9): remove test
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:366:# TODO: Handle multi_class metrics that has a labels argument as well as a
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:975:            # TODO those metrics doesn't support string label yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:179:        # TODO Fix manhattan_distances to preserve dtype.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:190:        # TODO Fix manhattan_distances to preserve dtype.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:1672:# TODO(1.8): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:709:    # TODO: support CSR matrices without non-zeros elements
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:716:    # TODO: support CSR matrices with int64 indices and indptr
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:913:    # TODO: introduce assertions on UserWarnings once the Euclidean specialisation
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:80:            # TODO: Inspect slight numerical discrepancy
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:164:            # TODO: Inspect slight numerical discrepancy
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/roc_curve.py:581:        # TODO(1.9): remove after the end of the deprecation period of `y_pred`
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:325:# TODO(1.9): Remove in 1.9
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:334:# TODO(1.9): Remove in 1.9
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:926:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:939:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_common_curve_display.py:167:# TODO: remove this test once classes moved to using `name` instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:229:        # TODO: if alpha=0 check that X is not rank deficient
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:401:        # TODO: Adapt link to User Guide in the docstring, once
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:405:        # TODO: make D^2 a score function in module metrics (and thereby get
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:398:            # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:47:# TODO: bayesian_ridge_regression and bayesian_regression_ard
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:154:        Always an array of ones. TODO: refactor the code base to make it
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:205:# TODO: _rescale_data should be factored into _preprocess_data.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:832:            # TODO: instead of warning and recomputing, we could just center
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:16:    # TODO: This "sandwich product" is the main computational bottleneck for solvers
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1251:        # TODO(1.8) remove multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1362:        # TODO: Refactor this to avoid joblib parallelism entirely when doing binary
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1923:        # TODO(1.8) remove multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:813:        # TODO: better names for these variables: z
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:870:                # TODO: this could be updated
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:882:                # Cov_n = Cov_j + x_j * X + increment(betas) TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:888:                # TODO: this could be updated
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1685:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1714:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1732:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1750:# TODO(1.9): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_theil_sen.py:298:# TODO(1.8): Remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_common.py:66:        # TODO: FIx SAGA which fails badly with sample_weights.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:150:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:202:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:254:# TODO(1.8): remove whole test with deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:279:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:619:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:705:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1306:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1350:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1486:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1746:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1794:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1833:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1963:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2137:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2182:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2360:# TODO(1.8): remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2427:# TODO(1.8): check for an error instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_sag.py:490:    # TODO: uncomment when sparse Ridge with intercept will be fixed (#4710)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:29:# TODO: use another dataset that has multiple drops
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:120:# TODO: remove warning filter when numpy min version >= 2.0.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:132:# TODO: remove warning filter when numpy min version >= 2.0.0
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1500:        # TODO(1.9): remove "warn" and None options.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1607:        # TODO(1.9): remove n_alphas and alphas={"warn", None}; set alphas=100 by
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_omp.py:1065:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:164:        # TODO(1.8) remove None option
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:166:        # TODO(1.8) remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:195:        # TODO(1.8) remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:206:        # TODO(1.8): remove and only keep clone(self.estimator)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:217:        # TODO(1.8) remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:622:        # TODO(1.8): remove the condition check together with base_estimator
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/tests/test_self_training.py:349:# TODO(1.8): remove in 1.8
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:60:    # TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:86:# TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:364:                # TODO(SLEP6): also pass metadata to the predict method for
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1182:                # TODO(SLEP6): also pass metadata for the predict method.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1637:                # TODO(SLEP6): also pass metadata to the predict method for
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1982:                # TODO(SLEP6): also pass metadata to the predict method for
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:480:    # TODO(1.8) remove this property
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:862:        # TODO(slep006): remove when metadata routing is the only way
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:46:    # TODO: remove this check once the estimator is no longer experimental.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:90:# TODO: remove this check once the estimator is no longer experimental.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_validation.py:2471:# TODO(1.8): remove `learning_curve`, `validation_curve` and `permutation_test_score`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:1117:    # Test the IID parameter  TODO: Clearly this test does something else???
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:192:# TODO(1.9): change default `n_init` to 1, see PR #31117
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:430:# TODO(1.9): change default `n_init` to 1, see PR #31117
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:341:    # TODO: compare results on dense and sparse data as proposed in:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:1068:        # TODO: re-enable this test if/when `manhattan_distances` is refactored to
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:122:# TODO(1.9): remove warning filter
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:136:# TODO(1.9): remove warning filter
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:175:# TODO(1.9): remove warning filter
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:202:# TODO(1.9): remove warning filter
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:225:# TODO(1.9): delete this test
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:48:    # TODO: rewrite this test to make less sensitive to the random seed,
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:121:    # TODO check that it actually does something useful
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_spectral_embedding.py:107:# TODO: investigate why this test is seed-sensitive on 32-bit Python
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:148:    # TODO check that it actually does something useful
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:234:    # TODO: compare results on dense and sparse data as proposed in:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:94:        # TODO(jjerphan): Once SciPy 1.11.3 is the minimum supported version, use
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/conftest.py:212:        # TODO: configure numpy to output scalar arrays as regular Python scalars
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:315:            # TODO: add keyword copy to copy on demand
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_helper.c:158:     * TODO: does this provoke memory leaks (we just malloc'ed them)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:84: * TODO: precomputed kernel.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:386: * TODO: merge in the cython layer
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_svm.py:4:TODO: remove hard coded numerical results when possible
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_bounds.py:17:# TODO(1.8): remove filterwarnings after the deprecation of liblinear multiclass
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_metaestimators.py:279:# TODO: remove data validation for the following estimators
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstrings.py:191:    # TODO: this detection can be improved. Currently we assume that we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:867:# TODO(1.9):  remove when deprecated `base_estimator` is removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:124:# TODO(1.8): remove test when generate_only is removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:229:                # TODO: FIX MLP to not check validation set during MLP
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:272:# TODO: As more modules support get_feature_names_out they should be removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:2063:# TODO(1.8): change warning to checking for NotFittedError
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:308:    # TODO(1.8): Remove cv="prefit" options here and the @ignore_warnings of the test
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:1119:    # TODO(1.8): remove me once the deprecation period is over.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_metadata_routing.py:912:    # TODO: these test classes can be moved to sklearn.utils._testing once we
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_base.py:271:# TODO(1.8): Remove this test when the deprecation is removed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:203:        # TODO(devtools): use _tested_estimators instead of all_estimators in the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:223:    # TODO(1.9) remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:227:    # TODO(1.9) remove
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:171:        # TODO: Does this depend on device?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:233:        # TODO: Does this depend on device?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:63:    # TODO: Should we reject ndarray subclasses?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:95:    # TODO: Should we reject ndarray subclasses?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:123:    # TODO: Should we reject ndarray subclasses?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:238:    # TODO: Account for other backends.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:580:            # TODO: Support Python scalars?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:793:        # TODO: What if our array is on the GPU already?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:277:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:334:    # TODO: np.clip has other ufunc kwargs
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:36:# TODO: use the QR wrapper once dask
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:60:    # TODO: can't avoid computing U or V for dask
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:67:    # TODO: respect device keyword?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:97:    # TODO: respect device keyword?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:168:    # TODO: respect device keyword?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:229:    # TODO: This won't handle dask unknown shapes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_at.py:21:    # TODO import from typing (requires Python >=3.11)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_utils/_helpers.py:20:    # TODO import from typing (requires Python >=3.13)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/testing.py:20:    # TODO import override from typing (requires Python >=3.12)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:564:        # TODO: remove the following two lines when scikit-learn only depends
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:617:            # TODO: remove the following two lines when scikit-learn only
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:778:        # TODO: update this code to either:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:142:        # TODO: Make verbosity argument for Lasso?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:158:            # TODO: move this handling (which is currently too broad)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_lda.py:462:        # TODO: make Parallel._effective_n_jobs public instead?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:617:    # TODO: explain what this is testing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:634:    # TODO: explain what this is testing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_nmf.py:992:        # TODO: use the provided W when init="custom".
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:116:        # TODO: Explore the choice of using bincount + add.at as it seems sub optimal
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/asyn.py:347:        # TODO: implement on_error
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/asyn.py:511:        # TODO: on_error
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/asyn.py:998:    # TODO: readahead might still be useful here, but needs async version
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/generic.py:327:        # TODO: special case for one FS being local, which can use get/put
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/generic.py:328:        # TODO: special case for one being memFS, which can use cat/pipe
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/utils.py:302:    # TODO: allow length to be None and read to the end of the file?
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:78:            # TODO: tarfile already implements compression with modes like "'r:gz'",
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:92:        # TODO: load and set saved index, if exists
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:101:        # TODO: save index to self.index_store here, if set
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:322:            # TODO: action where partial file exists in read-only cache
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:394:        # TODO: use transaction support in SMB protocol
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/cache_metadata.py:158:                # TODO: consolidate blocks here
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http.py:104:        # TODO: Maybe rename `self.kwargs` to `self.request_options` to make
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:147:        # TODO: derive fs from `root`
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:473:        # TODO: only save needed columns
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:546:        # TODO: only clear those that we wrote to?
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:748:            # TODO: warning here, since this can be very expensive?
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:884:        # TODO: if references is lazy, pre-fetch all paths in batch before access
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:985:        # TODO: we make dircache by iterating over all entries, but for Spec >= 1,
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:352:    # TODO: if all incoming paths were posix-compliant then separator would
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:393:                # TODO: check if path is writable?
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:105:        # TODO: encoding from headers
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:883:    # TODO: not allowed in JS
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:896:    # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/spec.py:493:        # TODO: allow equivalent of -name parameter
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/compression.py:13:# TODO: files should also be available as contexts
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/caching.py:94:        # TODO: use rich for better formatting
./core/py/pipeline/.venv/lib/python3.12/site-packages/fsspec/caching.py:502:        # TODO: only set start/end after fetch, in case it fails?
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:214:    # TODO allow pos to be None and use a nice TikZ default
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:277:        # TODO -- handle bending of multiedges
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:2499:        # TODO should this be list or array (as in a numpy array)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:792:            Ai = A.getrowview(i).toarray()  # TODO: revisit w/ sparse 1D container
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:1152:    # TODO: Rm csr_array wrapper in favor of spdiags array constructor when available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:75:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:77:    # TODO: Rm csr_array wrapper when eye array creation becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:128:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:238:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:244:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:341:        # TODO: rm csr_array wrapper when spdiags creates arrays
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:344:        # TODO: rm csr_array wrapper when spdiags creates arrays
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:436:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:498:        # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:503:            # TODO: Rm csr_array wrapper when identity array creation becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:192:        # TODO: rm csr_array wrapper when spdiags array creation becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:279:                # TODO: rm csc_array wrapping when spdiags array becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:296:                # TODO: rm csr_array wrapping when spdiags array becomes available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:129:    # TODO: Remove between the lines when `link` deprecation expires
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:274:    # TODO: Remove between the lines when `link` deprecation expires
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/tests/test_node_link.py:27:    # TODO: To be removed when signature change complete
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:463:    # TODO: csr_array
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/tests/test_connectivity.py:138:        # TODO Is this really the intended behavior for providing a
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:94:    # TODO: csr_array
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:173:    # TODO: csr_array
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/dag.py:1175:    # TODO In Python 3, this would be better as `yield from ...`.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/efficiency_measures.py:118:    # TODO This can be made more efficient by computing all pairs shortest
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/distance_regular.py:184:# TODO There is a definition for directed strongly regular graphs.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/dominating_set.py:22:# TODO Why doesn't this algorithm work for directed graphs?
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:805:            # TODO: this branch does not restore original_edge_weights of G!
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/clique.py:300:# TODO Should this also be not implemented for directed graphs?
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/walks.py:72:    # TODO: Use matrix_power from scipy.sparse when available
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/coloring/equitable_coloring.py:163:        # TODO: Checking whether a color has been visited can be made faster by
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:686:    # TODO: support DiGraph
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:111:    # TODO This can be trivially parallelized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:206:    # TODO This can be trivially parallelized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:1135:    # TODO This can be trivially parallelized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:181:    # TODO This can be trivially parallelized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:475:    # TODO This can be trivially parallelized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:276:            # TODO - The lines between --- were unused and were thus commented
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:282:            #     # TODO Why is extra inner loop necessary?
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:287:            # TODO Originally, this function returned a three-tuple:
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/redundancy.py:93:    # TODO This can be trivially parallelized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/tests/test_matching.py:110:        # TODO Assert that the vertices are the correct ones.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:124:        # TODO This can be parallelized, both in the outer loop over
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:132:        # TODO This loop can be parallelized, to an extent (the union
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:11:# TODO: Implement method from Gabow, Galil, Spence and Tarjan:
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cycles.py:841:                if thisnode not in B[nextnode]:  # TODO: use set for speedup?
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:217:        # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:292:        # TODO: graph and subgraph setter methods that invalidate the caches.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:293:        # TODO: allow for precomputed partitions and colors
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_swap.py:40:    # TODO: Rewrite function to explicitly check for impossible swaps and raise error
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:97:            # TODO: investigate https://arxiv.org/abs/1412.6466 for k=2
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:314:    # @not_implemented_for('multigraph')  # TODO: fix decor for classmethods
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/traversal/beamsearch.py:77:        # TODO The Python documentation states that for small values, it
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:19:# TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:322:# TODO What is the generalization to two arguments, S and T? Does the
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:362:# TODO What is the generalization to two arguments, S and T? Does the
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/conftest.py:102:# TODO: The warnings below need to be dealt with, but for now we silence them.
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/geometric.py:190:    # TODO Is this function just a special case of the geographical
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/community.py:1034:    # TODO The original code incremented the number of iterations each
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/tests/test_expanders.py:37:    # TODO The second largest eigenvalue should be smaller than a constant,
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/degree_seq.py:671:    # TODO Does this need to be sorted in reverse order?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pynvml/nvml.py:1089:#     # TODO handle the error
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:265:            # TODO: reasonable sign of infinity
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/factorials.py:112:    # TODO: fixme, obviously
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/theta.py:926:    # TODO: write _jacobi_theta2a and _jacobi_theta3a using fixed-point
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:18:    # TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:313:        # TODO: something else is required here
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:373:    # TODO: correct evaluation at singularities
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:28:        # TODO: the integer special-casing shouldn't be necessary.
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:147:    # TODO: avoid cancellation for imaginary arguments
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:384:# TODO: do this more generically?
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:423:# TODO: could be expressed more elegantly using triple factorials
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:468:        # TODO: limits
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:521:                # TODO: asymptotic series for derivatives
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:562:        # TODO: limits
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:718:    # TODO: check that chop=True chops when and only when it should
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:757:    # TODO: check that chop=True chops when and only when it should
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:833:    TODO: this can be optimized, e.g. by reusing evaluation points.
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:878:                # TODO: use v <= j'_{v,1} < y_{v,1}?
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:238:# TODO: fix the interface wrt contexts
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:287:# TODO: for bernpoly and eulerpoly, ensure that all exact zeros are covered
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:385:# TODO: this should be implemented low-level
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:620:    # TODO: implement for derivatives
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:697:            # TODO: the following could perhaps be tidied a bit
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:11:        # Avoid division by zero in leading factors (TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:284:            # TODO: handle the all-real case more efficiently!
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:285:            # TODO: figure out how much precision is needed (exponential growth)
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:404:        # TODO: the following logic can be simplified
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:760:    # TODO: much of the following could be shared with 2F3 instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:832:    # TODO: much of the following could be shared with 2F3 instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1091:    # TODO: continuation
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1107:    # TODO: continuation
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:174:# TODO: tests; improve implementation
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:182:    # TODO: accurately eval the smaller of the real/imag parts
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:212:    # TODO: accurately eval the smaller of the real/imag part
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:257:            # TODO: this can be done *much* faster
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:604:    # TODO: the following could be generalized into a perfect
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/identification.py:273:        # slowly (e.g. a factor 1-10) with each step TODO: we could
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:306:    # TODO: add more of these, make consistent, write docstrings, ...
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:171:    (TODO: find a better solution to this problem.)
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1969:            # TODO: we are evaluating log(1+eps) -> eps, which is
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/differentiation.py:364:    TODO: most exponents are zero, so maybe a sparse representation
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/odes.py:219:    **TODO**
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:264:            # TODO: maybe refactoring with function for divided differences
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:289:# TODO: consider raising a ValueError when there's no sign change in a and b
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:418:                # TODO: better condition (when f is very flat)
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:457:# TODO: check whether it's possible to combine it with Illinois stuff
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:503:                # TODO: better condition (when f is very flat)
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:560:            # TODO: decide not to use convergence acceleration
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:573:# TODO: add Brent
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:601:# TODO: test with user-specified jacobian matrix
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:665:            # damping step size TODO: better strategy (hard task)
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:984:        if verify and norm(f(*xl))**2 > tol: # TODO: better condition?
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:99:# TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:136:                if current > biggest: # TODO: what if equal?
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:218:                    # TODO: necessary to check also b?
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:239:            raise RuntimeError("need n*n matrix") # TODO: really?
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:372:    # TODO: implement this
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:4:# TODO: interpret list as vectors (for multiplication)
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:208:        COMMENT: TODO: the above "doctest:+SKIP" may be removed as soon as we
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:3:# TODO: should use diagonalization-based algorithms
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:14:        TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/math2.py:207:        # TODO: sinpi
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/math2.py:221:        # TODO: sinpi
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/math2.py:359:# TODO: could implement complex erf and erfc here. Need
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:273:    # TODO: many more tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:404:    # TODO: need many more tests
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/torture.py:27:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_matrices.py:57:    # TODO remove exec() wrapper as soon as we drop support for Python <= 3.5
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_gammazeta.py:599:    # TODO: more tests for polyexp
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_linalg.py:1:# TODO: don't use round
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/runtests.py:57:# TODO: add a flag for this
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:54:TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:199:        # TODO: when there are several real parameters and just a few complex
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:332:# TODO: mpf_erf should call mpf_erfc when appropriate (currently
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:355:        # TODO: interval rounding
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:617:            # TODO: could return finite imaginary value at -inf
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:911:# TODO: for extremely large x, we could use an asymptotic
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:914:# TODO: recompute at higher precision if the fixed-point mantissa
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1046:    TODO:
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1081:    # TODO: for |x| << 1/2, one could use fall back to
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:4:TODO: rename, cleanup, perhaps move the gmpy wrapper code
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:129:# TODO: speed up for bases 2, 4, 8, 16, ...
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:458:    TODO: speed up using factorization
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:342:    # TODO: handle rnd direction of the logarithm carefully
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:711:        # TODO: if close enough to 1, we could use Taylor series
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:876:# TODO: cleanup the special cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1158:        # TODO: the best cutoff depends on both x and the precision.
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1249:    # TODO: optimize division precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:179:    # formula to the tail. TODO: choose more intelligently
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:626:TODO: the current estimation of N for m > 0 is *very suboptimal*.
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:628:TODO: implement the reflection formula for m > 0, Re(z) << 0.
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:633:TODO: maybe use exact algorithms to compute psi for integral
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1160:# TODO: optimize / cleanup interface / unify with list_primes
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1383:    TODO: this is currently only used for gamma, but could
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1942:    # a fixed-point value. TODO: determine a precise cutoff of validity
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:498:    # TODO: handle cancellation when c ~=  -1 and ch ~= 1
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:584:# TODO: avoid loss of accuracy
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:124:# TODO: optimize
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:367:    # TODO: combine evaluation code to avoid duplicate modulo
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:631:    # TODO: optimize for real/imag cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:643:    # TODO: optimize for real/imag cases
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:670:    # TODO: accuracy for small x
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:759:    # TODO: recognize/speed up real cases, integer y
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:848:        # TODO: reflection formula
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:885:            # TODO: reflection formula
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1175:    # TODO: account for precision when doing this
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1320:    TODO: the rounding does not work properly for large exponents.
./utilities/ts/node_modules/@cspotcode/source-map-support/source-map-support.js:138:// TODO un-copy these from resolve-uri; see if they can be exported from that lib
./utilities/ts/node_modules/@cspotcode/source-map-support/source-map-support.js:392:      // TODO Remove now that windows path support was added to resolve-uri and thus trace-mapping?
./utilities/ts/node_modules/@cspotcode/source-map-support/source-map-support.js:629:  // TODO is there a better way to reliably get an instance of NodeError?
./utilities/ts/node_modules/undici-types/webidl.d.ts:193:  // TODO(@KhafraDev): a type could likely be implemented that can infer the return type
./utilities/ts/node_modules/undici-types/client.d.ts:24:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:34:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:50:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:58:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:60:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:62:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:64:    /** TODO */
./utilities/ts/node_modules/undici-types/client.d.ts:66:    /** TODO */
./utilities/ts/node_modules/typescript/lib/protocol.d.ts:209:     * A request to get TODO comments from the file
./utilities/ts/node_modules/typescript/lib/protocol.d.ts:220:         * Array of target TodoCommentDescriptors that describes TODO comments to be found
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:859:        return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:7039:    // TODO: GH#18217 this is used as if it's certainly defined in many places.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:10398:            // TODO: Somehow track edits between file as it was during the creation of sourcemap we have and the current file and
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:12798:            // TODO: Add codePage support for readFile?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:14342:    // TODO: determine what this does before making it public.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:14358:    // TODO: GH#19856 Would like to return `node is Node & { jsDoc: JSDoc[] }` but it causes long compile times
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:15777:                        // TODO (drosen): TaggedTemplateExpressions may eventually support type arguments.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:16266:            // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:16317:            && nodeCanBeDecorated(node, parent, grandparent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:16321:        return nodeIsDecorated(node, parent, grandparent) || childIsDecorated(node, parent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:16327:                return ts.some(node.members, function (m) { return nodeOrChildIsDecorated(m, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:16331:                return ts.some(node.parameters, function (p) { return nodeIsDecorated(p, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:17977:        // UpdateExpression:            // TODO: Do we need to investigate the precedence here?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:18010:        // TODO: JSXElement?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:18066:            // TODO: Should prefix `++` and `--` be moved to the `Update` precedence?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:18768:        // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:20398:        // TODO: Should this callback be cached?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22025:                        : expression; // TODO(rbuckton): Verify this assertion holds
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22044:                // TODO(rbuckton): Verify whether this assertion holds.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22047:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22051:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22055:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22066:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22075:                    // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22082:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:22089:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:27272:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:29225:    // TODO(rbuckton): Rename to 'isParameterDeclaration'
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:29813:    // TODO(rbuckton): isUnparsedPrologue
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:29818:    // TODO(rbuckton): isUnparsedText
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:29819:    // TODO(rbuckton): isUnparsedInternalText
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:29820:    // TODO(rbuckton): isUnparsedSyntheticReference
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:29834:    // TODO(rbuckton): isInputFiles
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30121:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30126:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30136:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30140:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30155:                /*type*/ undefined, getAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30161:                /*type*/ undefined, setAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:30179:        /*type*/ undefined, method.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:31915:            // TODO: should we separate these branches out?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:33979:                // TODO(rbuckton): Do we need to call `parseExpectedToken` or can we just call `createMissingNode` directly?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:34124:            // TODO(rbuckton): JSDoc parameters don't have names (except `this`/`new`), should we manufacture an empty identifier?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:34133:                // TODO(rbuckton): We never set the type for a JSDocNamepathType. What should we put here?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:36574:                // TODO(rbuckton): Consider manufacturing this when we need to report an error as it is otherwise not useful.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:36866:        // TODO: Review for error recovery
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:37238:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:39139:                    // TODO: Determine whether we should enforce this in the checker.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:39140:                    // TODO: Consider moving the `constraint` to the first type parameter as we could then remove `getEffectiveConstraintOfTypeParameter`.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:39141:                    // TODO: Consider only parsing a single type parameter if there is a constraint.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:39757:            // TODO: The below should be strongly type-guarded and not need casts/explicit annotations, since entryOrList is related to
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:39794:                                // TODO: It's probably fine to issue this diagnostic on all instances of the pragma
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:42198:                            result.set(name, value.map(function (element) { return getNameOfCompilerOptionValue(element, customTypeMap_1); })); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:42645:                // TODO extend type typeAcquisition
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:43262:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:45078:                // TODO: Assert that `resolvedTarget` is actually within the package directory? That's what the spec says.... but I'm not sure we need
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:46059:                //      TODO: Make this a more specific error and decouple it from the exclusion logic.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:46971:                // TODO: bindLogicalExpression is recursive - if we want to handle deeply nested `&&` expressions
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:47441:            var symbol = createSymbol(131072 /* SymbolFlags.Signature */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:48680:                    bindAnonymousDeclaration(node, 262144 /* SymbolFlags.TypeParameter */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:51030:                            !checkAndReportErrorForMissingPrefix(errorLocation, name, nameArg) && // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:51207:                        var instanceType = getDeclaredTypeOfSymbol(classSymbol).thisType; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:51699:            var moduleSymbol = resolveExternalModuleName(node, moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:53029:                        // TODO: the below is shared with similar code in `resolveName` - in fact, rephrasing all this symbol
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:53035:                        // TODO: Should this filtered table be cached in some way?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:53438:                var entity = builder(symbol, meaning, enclosingDeclaration, nodeFlags); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:53460:                printer.writeNode(4 /* EmitHint.Unspecified */, sig, /*sourceFile*/ sourceFile, ts.getTrailingSemicolonDeferringWriter(writer)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:53635:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:53825:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:54165:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:54642:                context.tracker.trackSymbol(symbol, context.enclosingDeclaration, meaning); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:55357:                // TODO: Use `setOriginalNode` on original declaration names where possible so these declarations see some kind of
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:55575:                        // TODO: Issue error via symbol tracker?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:55824:                    // TODO: `suppressNewPrivateContext` is questionable -we need to simply be emitting privates in whatever scope they were declared in, rather
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:55856:                        // TODO: Handle computed names
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:55901:                        // prop in the outermost scope (TODO: a namespace within a namespace would need to be appropriately handled by this)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:55927:                        // TODO: implement handling for the localVsRemoteMap.get("remote") - should be difficult to trigger (see comment above), as only interesting cross-file js merges should make this possible
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:56134:                            // TODO: Not part of a file's local or export symbol tables
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:56300:                        !ts.length(getSignaturesOfType(typeToSerialize, 1 /* SignatureKind.Construct */)) && // TODO: could probably serialize as function + ns + class, now that that's OK
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:56347:                            // TODO: https://github.com/microsoft/TypeScript/pull/32372#discussion_r328386357
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:56536:                var predicate = ts.factory.createTypePredicateNode(typePredicate.kind === 2 /* TypePredicateKind.AssertsThis */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createToken(129 /* SyntaxKind.AssertsKeyword */) : undefined, typePredicate.kind === 1 /* TypePredicateKind.Identifier */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createIdentifier(typePredicate.parameterName) : ts.factory.createThisTypeNode(), typePredicate.type && nodeBuilder.typeToTypeNode(typePredicate.type, enclosingDeclaration, toNodeBuilderFlags(flags) | 70221824 /* NodeBuilderFlags.IgnoreErrors */ | 512 /* NodeBuilderFlags.WriteTypeParametersInQualifiedName */) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:57408:                    var sourceTypes = ts.some(constructorTypes, function (t) { return !!(t.flags & ~98304 /* TypeFlags.Nullable */); }) ? constructorTypes : types; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:57696:                // TODO: If back compat with pre-3.0/4.0 libs isn't required, remove the following SymbolConstructor special case transforming `symbol` into `unique symbol`
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:58147:        // TODO: GH#18217 If `checkBase` is undefined, we should not call this because this will always return false.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:58174:                node = node.parent; // TODO: GH#18217 Use SourceFile kind check instead
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:58492:            // TODO: Given that we allow type parmeters here now, is this `!isGenericMappedType(type)` check really needed?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:59877:            var constraintDeclaration = getConstraintDeclarationForMappedType(type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:61183:                return getTypeFromTypeNode(declaration.parameters[0].type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:61575:                        // TODO: Adopt same permissive behavior in TS as in JS to reduce follow-on editing experience failures (requires editing fillMissingTypeArguments)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:64000:                result.aliasTypeArguments = aliasSymbol ? aliasTypeArguments : instantiateTypes(root.aliasTypeArguments, mapper); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:64112:                // TODO: Future work: support unions/generics/whatever via a deferred import-type
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:64520:                    // TODO(rbuckton): `NullKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:64530:                    // TODO(rbuckton): `ThisKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service and because of `isPartOfTypeNode`.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:64588:                // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:65184:            // TODO(anhans): A block should be context-sensitive if it has a context-sensitive return value.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:65726:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:67014:                            // TODO: Stack errors so we get a pyramid for the "normal" comparison above, _and_ a second for this
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:67330:                        // TODO: Find a nice way to include potential conditional type breakdowns in error output, if they seem good (they usually don't)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:68721:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:69672:                        // TODO: remove this when we support static private identifier fields and find other solutions to get privateNamesAndStaticFields test to pass
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:70125:                            // TODO: The `allowComplexConstraintInference` flag is a hack! This forbids inference from complex constraints within constraints!
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:73593:                    // TODO: Maybe issue a better error than 'object is possibly undefined'
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:75639:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:75641:            return s; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:76048:                containingType = containingType.isThisType ? getConstraintOfTypeParameter(containingType) : getBaseConstraintOfType(containingType); // TODO: GH#18217 Use a different variable that's allowed to be undefined
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:76435:                error(errorNode, ts.Diagnostics.Property_0_is_used_before_being_assigned, symbolToString(prop)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:78918:            var resolvedRequire = resolveName(node.expression, node.expression.escapedText, 111551 /* SymbolFlags.Value */, /*nameNotFoundMessage*/ undefined, /*nameArg*/ undefined, /*isUse*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:81849:            // TODO (yuisu): Remove this check in else-if when SyntaxKind.Construct is moved and ambient context is handled
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:81874:            // TODO(rbuckton): Should we start checking JSDoc types?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:82679:                            // TODO: GH#17345: These are methods, so handle computed name case. (`Always allowing computed property names is *not* the correct behavior!)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:82969:            var thenFunction = getTypeOfPropertyOfType(type, "then"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:83687:                // TODO: GH#22580
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:83813:                        //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:83820:                    //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:84736:                reportTypeNotIterableError(errorNode, inputType, allowAsyncIterables); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:85460:            // TODO: Check that target label is valid
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:88876:                var target = getSymbolLinks(symbol).aliasTarget; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:89259:                    accessor = ts.getParseTreeNode(accessor, ts.isGetOrSetAccessorDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:89414:            var moduleSymbol = resolveExternalModuleNameWorker(specifier, specifier, /*moduleNotFoundError*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:89916:                    return grammarErrorOnNode(lastOverride, ts.Diagnostics._0_modifier_cannot_appear_on_a_constructor_declaration, "override"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:90999:            // TODO: The spec needs to be amended to reflect this grammar.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:91284:        JsxNames.ElementAttributesPropertyNameContainer = "ElementAttributesProperty"; // TODO: Deprecate and remove support
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:91368:            // TODO(rbuckton): Remove dependency on `ts.factory` in favor of a provided factory.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:92701:        return !getImportNeedsImportStarHelper(node) && (ts.isDefaultImport(node) || (!!node.importClause && ts.isNamedImports(node.importClause.namedBindings) && containsDefaultReference(node.importClause.namedBindings))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:93212:        var target = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:93330:        var bindingTarget = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:93358:            flattenContext.emitBindingOrAssignment(bindingTarget, value, location, /*original*/ element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:94618:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:94621:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:95166:            //      // TODO, blah
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:95178:            //             // TODO, blah
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:97028:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:98408:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:98577:            recordDeclarationName(node.variableDeclaration, catchClauseNames); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:98617:            var initializer = node.initializer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:100511:                ? ts.createJsxFactoryExpression(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:100532:            var element = ts.createExpressionForJsxFragment(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), context.getEmitResolver().getJsxFragmentFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:102037:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:102072:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:102290:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:104549:            default: return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:105240:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:105897:            // TODO(rbuckton): `expression` should be required on `throw`.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:105935:                    beginCatchBlock(node.catchClause.variableDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:105981:                            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:107234:            var name = ts.getLocalNameForExternalImport(factory, node, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:108640:            var exportStarFunction = addExportStarIfNeeded(statements); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:108763:                    var importVariableName = ts.getLocalNameForExternalImport(factory, entry, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:108863:                hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:108887:            hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:110357:                // TODO(jfreeman): Deal with computed properties in error reporting.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:110766:                // TODO: Do all these accessibility checks inside/after the first pass in the checker when declarations are enabled, if possible
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:110875:                        return undefined; // Omit declaration files from bundle results, too // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111072:            return canHaveLiteralInitializer(node) && resolver.isLiteralConstDeclaration(ts.getParseTreeNode(node)); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111076:                return resolver.createLiteralConstValue(ts.getParseTreeNode(node), symbolTracker); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111174:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111178:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111234:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111649:                                return undefined; // TODO GH#33569: Handle element access expressions that created late bound names (rather than silently omitting them)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111734:                        var id = ts.getOriginalNodeId(inner); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:111813:                        return [statement, cleanup(factory.updateClassDeclaration(input, modifiers, input.name, typeParameters, heritageClauses, members))]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:112314:                // TODO: Remove check and unconditionally use onEmitNode when API is breakingly changed
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:113602:            writer = _writer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:117323:            var expr = ts.getExternalModuleName(node); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118217:        // TODO(rbuckton): Should be a `Set` but that requires changing the below code that uses `mutateMap`
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118707:            var _a = ts.getLineAndCharacterOfPosition(diagnostic.file, diagnostic.start), line = _a.line, character = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118793:        var _a = ts.getLineAndCharacterOfPosition(file, start), firstLine = _a.line, firstLineChar = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118810:                output += formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118818:                output += formatCodeSpan(diagnostic.file, diagnostic.start, diagnostic.length, "", getCategoryFormat(diagnostic.category), host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118826:                        output += halfIndent + formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:118827:                        output += formatCodeSpan(file, start, length_9, indent, ForegroundColorEscapeSequences.Cyan, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:119315:        var createProgramOptions = ts.isArray(rootNamesOrOptions) ? createCreateProgramOptions(rootNamesOrOptions, _options, _host, _oldProgram, _configFileParsingDiagnostics) : rootNamesOrOptions; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:119377:            var loader_1 = function (moduleName, resolverMode, containingFileName, redirectedReference) { return ts.resolveModuleName(moduleName, containingFileName, options, host, moduleResolutionCache, redirectedReference, resolverMode).resolvedModule; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:119386:            var loader_2 = function (typesRef, containingFile, redirectedReference, resolutionMode) { return ts.resolveTypeReferenceDirective(typesRef, containingFile, options, host, redirectedReference, typeReferenceDirectiveResolutionCache, resolutionMode).resolvedTypeReferenceDirective; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:119959:                    : host.getSourceFile(oldSourceFile.fileName, sourceFileOptions, /*onError*/ undefined, shouldCreateNewSourceFile || sourceFileOptions.impliedNodeFormat !== oldSourceFile.impliedNodeFormat); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:120408:            var line = ts.computeLineAndCharacterOfPosition(lineStarts, start).line - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:120871:            getSourceFileFromReferenceWorker(fileName, function (fileName) { return findSourceFile(fileName, isDefaultLib, ignoreNoDefaultLib, reason, packageId); }, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:121216:                    processSourceFile(resolvedTypeReferenceDirective.resolvedFileName, /*isDefaultLib*/ false, /*ignoreNoDefaultLib*/ false, resolvedTypeReferenceDirective.packageId, reason); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:122393:                    var fileName = resolvedTypeReferenceDirective.resolvedFileName; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:122950:                var affectedFilesIndex = state.affectedFilesIndex; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:123521:            newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:123536:        newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:124051:        var getCurrentDirectory = ts.memoize(function () { return resolutionHost.getCurrentDirectory(); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:124076:        var rootPath = (rootDir && resolutionHost.toPath(rootDir)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:124510:                setDirectoryWatcher(rootDir, rootPath, /*nonRecursive*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:125039:                // TODO: maybe useful to keep around as an alternative option for certain contexts where the mode is overridable
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:125763:            diagnostics[0] = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:125831:        host.onUnRecoverableConfigFileDiagnostic = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:126888:            setConfigFileParsingResult(ts.getParsedCommandLineOfConfigFile(configFileName, optionsToExtendForConfigFile, parseConfigFileHost, extendedConfigCache || (extendedConfigCache = new ts.Map()), watchOptionsToExtend, extraFileExtensions)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:127429:        // TODO(rbuckton): Should be a `Set`, but that requires changing the code below that uses `mutateMapSkippingNewValues`
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:129176:                    inferredTypings.set(typingName, undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:130205:                // case SyntaxKind.ThisType: TODO: GH#9267
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:133678:                return undefined; // TODO: GH#18217 Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:133940:            default: return undefined; // TODO: GH#18217 throw Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:134019:                        // TODO: Maybe we should classify these.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:134032:                    // TODO: This should be predicated on `token["kind"]` being compatible with `HasJSDoc["kind"]`
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:134331:                // TODO: we should get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:134335:                // TODO (drosen): we should *also* get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:135006:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:136057:            // TODO(drosen): Right now we just permit *all* semantic meanings when calling
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:136083:            // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:136676:                    return createCompletionDetailsForSymbol(symbol, typeChecker, sourceFile, location, cancellationToken, codeActions, sourceDisplay); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:136780:                            return checker.getContextualType(parent.initializer); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:136820:            var currentToken = ts.getTokenAtPosition(sourceFile, position); // TODO: GH#15853
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:136821:            // We will check for jsdoc comments with insideComment and getJsDocTagAtPosition. (TODO: that seems rather inefficient to check the same thing so many times.)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:137641:                // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:137922:                var moduleSpecifierSymbol = typeChecker.getSymbolAtLocation(moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:138323:                        // TODO: Account for computed property name
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:138482:                var contextToken = ts.findPrecedingToken(previousToken.getFullStart(), sourceFile, /*startNode*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:138522:                    // TODO: GH#18169
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:138790:                    return (isValidKeyword(contextToken.kind) || contextToken.kind === 41 /* SyntaxKind.AsteriskToken */ || ts.isIdentifier(contextToken) && isValidKeyword(ts.stringToToken(contextToken.text))) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:138832:        // TODO: GH#19856 Would like to return `node is Node & { parent: (ClassElement | TypeElement) & { parent: ObjectTypeDeclaration } }` but then compilation takes > 10 minutes
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:139285:                        // TODO: GH#20090
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:139679:                    entry.sourceFile = ts.updateLanguageServiceSourceFile(entry.sourceFile, scriptSnapshot, version, scriptSnapshot.getChangeRange(entry.sourceFile.scriptSnapshot)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:139858:                                break; // TODO: GH#23879
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:139935:                indirectUserDeclarations.push(sourceFileLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:141559:                return exposedByParent ? scope.getSourceFile() : scope; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:141643:                /// TODO: Cache symbol existence for files to save text search
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:143154:                    // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:143223:        for (var _i = 0, _a = sourceFile.referencedFiles || ts.emptyArray; _i < _a.length; _i++) { // TODO: GH#26162
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:143276:                return label ? [createDefinitionInfoFromName(typeChecker, label, "label" /* ScriptElementKind.label */, node.text, /*containerName*/ undefined)] : undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:143443:                var file = reference && program.getSourceFile(reference.resolvedFileName); // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:143642:            return __assign(__assign({ fileName: sourceFile.fileName, textSpan: textSpan, kind: symbolKind, name: symbolName, containerKind: undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:144006:                if (jsdoc.tags.some(function (t) { return t !== tag && ts.isJSDocParameterTag(t) && ts.isIdentifier(t.name) && t.name.escapedText === name; }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:144083:            // * TODO: other tags.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:144255:                    var importer = checker.getSymbolAtLocation(declaration.name); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:144297:            // TODO(cyrusn): get the gamut of comparisons that VS already uses here.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:144313:                // TODO(jfreeman): What should be the containerName when the container has a computed name?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:144930:            return ts.compareStringsCaseSensitiveUI(tryGetName(child1.node), tryGetName(child2.node)) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:145435:                    coalescedImports.push(updateImportDeclarationAndClause(defaultImport, defaultImport.importClause.name, namespaceImports[0].importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:145440:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:145444:                    coalescedImports.push(updateImportDeclarationAndClause(namespaceImport, /*name*/ undefined, namespaceImport.importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:145457:                        newImportSpecifiers.push(ts.factory.createImportSpecifier(/*isTypeOnly*/ false, ts.factory.createIdentifier("default"), defaultImport.importClause.name)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:145471:                        : ts.factory.updateNamedImports(namedImports[0].importClause.namedBindings, sortedImportSpecifiers); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:145584:            return ts.factory.updateImportDeclaration(importDeclaration, importDeclaration.modifiers, ts.factory.updateImportClause(importDeclaration.importClause, importDeclaration.importClause.isTypeOnly, name, namedBindings), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:146279:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:146292:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:146320:        // TODO: find a way to compute this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:146325:        // TODO(cyrusn): Find a way to support this for unicode digits.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:147429:                    var resolvedSignature = checker.getResolvedSignatureForSignatureHelp(invocation.node, candidates, argumentCount); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148338:            var file = getSourceFileLike(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148630:        // TODO(drosen): use contextual SemanticMeaning.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148760:        // TODO(drosen): Currently completion entry details passes the SemanticMeaning.All instead of using semanticMeaning of location
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148824:                    signature = typeChecker.getResolvedSignature(callExpressionLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148899:                            signature = typeChecker.getSignatureFromDeclaration(functionDeclaration_1); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148996:                            var signature = typeChecker.getSignatureFromDeclaration(declaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:150354:                // TODO
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:150876:                .filter(function (d) { return ts.rangeOverlapsWithStartEnd(originalRange, d.start, d.start + d.length); }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:151337:                                listDynamicIndentation = getDynamicIndentation(parent, parentStartLine, indentationOnListStartToken, options.indentSize); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:151950:                    return getActualIndentationForListStartLine(containerList, sourceFile, options) + indentSize; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:151997:                        return getIndentationForNodeWorker(current, currentStart, /*ignoreActualIndentationRange*/ undefined, indentationDelta, sourceFile, /*isNextChild*/ true, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:152313:                    return getActualIndentationForListStartLine(containingList, sourceFile, options) + (listIndentsChild ? options.indentSize : 0); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:152421:                        if (!settings.indentMultiLineObjectLiteralBeginningOnBlankLine && sourceFile && childKind === 207 /* SyntaxKind.ObjectLiteralExpression */) { // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:153410:                // TODO: this emits the file, parses it back, then formats it that -- may be a less roundabout way to do this
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:153749:                || ts.isStatementButNotDeclaration(a) && ts.isStatementButNotDeclaration(b); // TODO: only if b would start with a `(` or `[`
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:153871:                    // TODO: There's currently no unused diagnostic for this, could be a suggestion
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:153897:        // Exported for tests only! (TODO: improve tests to not need this)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:154854:            // TODO: This does not properly handle `function(new:C, string)` per https://github.com/google/closure-compiler/wiki/Types-in-the-Closure-Type-System#the-javascript-type-language
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:154860:            var isRest = node.type.kind === 321 /* SyntaxKind.JSDocVariadicType */ && index === node.parent.parameters.length - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:156116:                    // TODO: Maybe we should handle this? See fourslash test `refactorConvertToEs6Module_export_object_shorthand.ts`.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:156183:        // TODO: GH#22492 this will cause an error if a change has been made inside the body of the node.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:156206:                return makeConst(modifiers, ts.factory.createIdentifier(name), replaceImportUseSites(exported, useSitesToUnqualify)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:156590:        var fixId = "fixClassIncorrectlyImplementsInterface"; // TODO: share a group with fixClassDoesntImplementInheritedAbstractMember?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:159748:            // TODO (https://github.com/Microsoft/TypeScript/issues/21246): use shared helper
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:160432:            changes.replaceNode(sourceFile, oldTypeNode, checker.typeToTypeNode(newType, /*enclosingDeclaration*/ oldTypeNode, /*flags*/ undefined)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:160717:                    return ts.isSetAccessorDeclaration(ts.getContainingFunction(token)) ? ts.Diagnostics.Infer_type_of_0_from_usage : ts.Diagnostics.Infer_parameter_types_from_usage; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:161307:                            // TODO: use getFalsyflagsOfType
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:162218:                // TODO Handle auto quote preference.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:162373:            var leftHead = isStatic ? container.name : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:162431:            /*parameters*/ undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:162591:            var relatedImport = type.symbol.originatingImport; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:162704:            return getDefaultValueFromType(checker, checker.getTypeFromTypeNode(propertyDeclaration.type)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:164389:                var targetRange = rangeToExtract.targetRange; // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:164527:                return { targetRange: { range: getStatementOrExpressionRange(node), facts: rangeFacts, thisNode: thisNode } }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:164636:                                // TODO: GH#18217 Silly to use `errors ||` since it's definitely not defined (see top of `visit`)
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:164638:                                // Also TODO: GH#19956
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:164851:                context.cancellationToken.throwIfCancellationRequested(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165017:                    returnType = checker.typeToTypeNode(contextualType, scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165082:                        /*modifiers*/ undefined, ts.factory.createVariableDeclarationList([ts.factory.createVariableDeclaration(ts.getSynthesizedDeepClone(variableDeclaration.name), /*exclamationToken*/ undefined, /*type*/ ts.getSynthesizedDeepClone(variableDeclaration.type), /*initializer*/ call)], // TODO (acasey): test binding patterns
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165213:                    : checker.typeToTypeNode(checker.getContextualType(node), scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165229:                        ? ts.factory.createIdentifier(scope.name.getText()) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165387:                    var lhs = range.facts & RangeFacts.InStaticRegion ? ts.factory.createIdentifier(scope.name.text) : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165459:                    var body = scope.body; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165540:                // TODO: GH#18217 `variableAssignments` not possibly undefined!
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165610:                        // TODO (https://github.com/Microsoft/TypeScript/issues/18924): allow this
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:165624:                    var contextualType = checker.getContextualType(targetRange.range); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:166414:                                : ts.skipAlias(checker.getSymbolAtLocation(name), checker); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:166516:                    defaultImport = ts.factory.createIdentifier(ts.symbolNameNoDefault(symbol)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:166974:                    return [decl.name.text]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:167126:                    return ts.emptyArray; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:167147:                return { edits: [] }; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:167460:                return ts.isVariableDeclaration(node) && ts.isVarConst(node) && ts.isIdentifier(node.name) && !node.type; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:168719:                // TODO: GH#16312 Return a ReadonlyArray, avoid copying inheritedDocs
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:169240:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:169443:        // TODO: GH#18217 frequently asserted as defined
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:169512:            program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:169521:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:169565:            return ts.Completions.getCompletionEntryDetails(program, log, getValidSourceFile(fileName), position, { name: name, source: source, data: data }, host, (formattingOptions && ts.formatting.getFormatContext(formattingOptions, host)), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170218:                    //  i.e. 'undefined' in position 3 above means TODO(jason) didn't match.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170237:                    // We don't want to match something like 'TODOBY', so we make sure a non
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170253:                // TODO comments can appear in one of the following forms:
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170255:                //  1)      // TODO     or  /////////// TODO
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170257:                //  2)      /* TODO     or  /********** TODO
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170260:                //           *   TODO
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170263:                // The following three regexps are used to match the start of the text up to the TODO
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170268:                // Match any of the above three TODO comment start regexps.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170270:                // so that we can determine the starting position of the TODO comment match.
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170273:                // For example, if the descriptors are "TODO(jason)" and "HACK", then this will be:
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170275:                //      (?:(TODO\(jason\))|(HACK))
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170285:                // This is the portion of the match we'll return as part of the TODO comment result. We
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170290:                // /((?:\/\/+\s*)|(?:\/\*+\s*)|(?:^(?:\s|\*)*))((?:(TODO\(jason\))|(HACK))(?:.*?))(?:$|\*\/)/gim
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170295:                //  'i' is for case insensitivity (We do this to match C# TODO comment code).
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:170484:        return sourceFile.nameTable; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171227:        compilerOptions = ts.fixupCompilerOptions(compilerOptions, diagnostics); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171278:                return null; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171281:            var decoded = JSON.parse(encoded); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171288:                this.scriptSnapshotShim.dispose(); // TODO: GH#18217 Can we just use `if (this.scriptSnapshotShim.dispose)`?
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171303:                    var resolutionsInFile = JSON.parse(_this.shimHost.getModuleResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171315:                    var typeDirectivesForFile = JSON.parse(_this.shimHost.getTypeReferenceDirectiveResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171336:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171370:                return this.shimHost.getScriptKind(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171408:            var pattern = ts.getFileMatcherPatterns(path, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171429:                this.directoryExists = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171432:                this.realpath = function (path) { return _this.shimHost.realpath(path); }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171435:                this.realpath = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:171439:            var pattern = ts.getFileMatcherPatterns(rootDir, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:172092:    /// TODO: this is used by VS, clean this up on both sides of the interface
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:172100:    // TODO: it should be moved into a namespace though.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:849:        return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:7029:    // TODO: GH#18217 this is used as if it's certainly defined in many places.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:10388:            // TODO: Somehow track edits between file as it was during the creation of sourcemap we have and the current file and
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:12788:            // TODO: Add codePage support for readFile?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:14332:    // TODO: determine what this does before making it public.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:14348:    // TODO: GH#19856 Would like to return `node is Node & { jsDoc: JSDoc[] }` but it causes long compile times
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:15767:                        // TODO (drosen): TaggedTemplateExpressions may eventually support type arguments.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:16256:            // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:16307:            && nodeCanBeDecorated(node, parent, grandparent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:16311:        return nodeIsDecorated(node, parent, grandparent) || childIsDecorated(node, parent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:16317:                return ts.some(node.members, function (m) { return nodeOrChildIsDecorated(m, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:16321:                return ts.some(node.parameters, function (p) { return nodeIsDecorated(p, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:17967:        // UpdateExpression:            // TODO: Do we need to investigate the precedence here?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:18000:        // TODO: JSXElement?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:18056:            // TODO: Should prefix `++` and `--` be moved to the `Update` precedence?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:18758:        // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:20388:        // TODO: Should this callback be cached?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22015:                        : expression; // TODO(rbuckton): Verify this assertion holds
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22034:                // TODO(rbuckton): Verify whether this assertion holds.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22037:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22041:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22045:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22056:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22065:                    // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22072:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:22079:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:27262:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:29215:    // TODO(rbuckton): Rename to 'isParameterDeclaration'
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:29803:    // TODO(rbuckton): isUnparsedPrologue
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:29808:    // TODO(rbuckton): isUnparsedText
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:29809:    // TODO(rbuckton): isUnparsedInternalText
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:29810:    // TODO(rbuckton): isUnparsedSyntheticReference
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:29824:    // TODO(rbuckton): isInputFiles
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30111:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30116:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30126:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30130:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30145:                /*type*/ undefined, getAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30151:                /*type*/ undefined, setAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:30169:        /*type*/ undefined, method.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:31905:            // TODO: should we separate these branches out?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:33969:                // TODO(rbuckton): Do we need to call `parseExpectedToken` or can we just call `createMissingNode` directly?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:34114:            // TODO(rbuckton): JSDoc parameters don't have names (except `this`/`new`), should we manufacture an empty identifier?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:34123:                // TODO(rbuckton): We never set the type for a JSDocNamepathType. What should we put here?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:36564:                // TODO(rbuckton): Consider manufacturing this when we need to report an error as it is otherwise not useful.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:36856:        // TODO: Review for error recovery
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:37228:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:39129:                    // TODO: Determine whether we should enforce this in the checker.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:39130:                    // TODO: Consider moving the `constraint` to the first type parameter as we could then remove `getEffectiveConstraintOfTypeParameter`.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:39131:                    // TODO: Consider only parsing a single type parameter if there is a constraint.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:39747:            // TODO: The below should be strongly type-guarded and not need casts/explicit annotations, since entryOrList is related to
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:39784:                                // TODO: It's probably fine to issue this diagnostic on all instances of the pragma
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:42188:                            result.set(name, value.map(function (element) { return getNameOfCompilerOptionValue(element, customTypeMap_1); })); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:42635:                // TODO extend type typeAcquisition
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:43252:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:45068:                // TODO: Assert that `resolvedTarget` is actually within the package directory? That's what the spec says.... but I'm not sure we need
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:46049:                //      TODO: Make this a more specific error and decouple it from the exclusion logic.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:46961:                // TODO: bindLogicalExpression is recursive - if we want to handle deeply nested `&&` expressions
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:47431:            var symbol = createSymbol(131072 /* SymbolFlags.Signature */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:48670:                    bindAnonymousDeclaration(node, 262144 /* SymbolFlags.TypeParameter */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:51020:                            !checkAndReportErrorForMissingPrefix(errorLocation, name, nameArg) && // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:51197:                        var instanceType = getDeclaredTypeOfSymbol(classSymbol).thisType; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:51689:            var moduleSymbol = resolveExternalModuleName(node, moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:53019:                        // TODO: the below is shared with similar code in `resolveName` - in fact, rephrasing all this symbol
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:53025:                        // TODO: Should this filtered table be cached in some way?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:53428:                var entity = builder(symbol, meaning, enclosingDeclaration, nodeFlags); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:53450:                printer.writeNode(4 /* EmitHint.Unspecified */, sig, /*sourceFile*/ sourceFile, ts.getTrailingSemicolonDeferringWriter(writer)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:53625:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:53815:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:54155:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:54632:                context.tracker.trackSymbol(symbol, context.enclosingDeclaration, meaning); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:55347:                // TODO: Use `setOriginalNode` on original declaration names where possible so these declarations see some kind of
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:55565:                        // TODO: Issue error via symbol tracker?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:55814:                    // TODO: `suppressNewPrivateContext` is questionable -we need to simply be emitting privates in whatever scope they were declared in, rather
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:55846:                        // TODO: Handle computed names
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:55891:                        // prop in the outermost scope (TODO: a namespace within a namespace would need to be appropriately handled by this)
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:55917:                        // TODO: implement handling for the localVsRemoteMap.get("remote") - should be difficult to trigger (see comment above), as only interesting cross-file js merges should make this possible
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:56124:                            // TODO: Not part of a file's local or export symbol tables
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:56290:                        !ts.length(getSignaturesOfType(typeToSerialize, 1 /* SignatureKind.Construct */)) && // TODO: could probably serialize as function + ns + class, now that that's OK
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:56337:                            // TODO: https://github.com/microsoft/TypeScript/pull/32372#discussion_r328386357
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:56526:                var predicate = ts.factory.createTypePredicateNode(typePredicate.kind === 2 /* TypePredicateKind.AssertsThis */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createToken(129 /* SyntaxKind.AssertsKeyword */) : undefined, typePredicate.kind === 1 /* TypePredicateKind.Identifier */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createIdentifier(typePredicate.parameterName) : ts.factory.createThisTypeNode(), typePredicate.type && nodeBuilder.typeToTypeNode(typePredicate.type, enclosingDeclaration, toNodeBuilderFlags(flags) | 70221824 /* NodeBuilderFlags.IgnoreErrors */ | 512 /* NodeBuilderFlags.WriteTypeParametersInQualifiedName */) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:57398:                    var sourceTypes = ts.some(constructorTypes, function (t) { return !!(t.flags & ~98304 /* TypeFlags.Nullable */); }) ? constructorTypes : types; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:57686:                // TODO: If back compat with pre-3.0/4.0 libs isn't required, remove the following SymbolConstructor special case transforming `symbol` into `unique symbol`
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:58137:        // TODO: GH#18217 If `checkBase` is undefined, we should not call this because this will always return false.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:58164:                node = node.parent; // TODO: GH#18217 Use SourceFile kind check instead
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:58482:            // TODO: Given that we allow type parmeters here now, is this `!isGenericMappedType(type)` check really needed?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:59867:            var constraintDeclaration = getConstraintDeclarationForMappedType(type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:61173:                return getTypeFromTypeNode(declaration.parameters[0].type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:61565:                        // TODO: Adopt same permissive behavior in TS as in JS to reduce follow-on editing experience failures (requires editing fillMissingTypeArguments)
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:63990:                result.aliasTypeArguments = aliasSymbol ? aliasTypeArguments : instantiateTypes(root.aliasTypeArguments, mapper); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:64102:                // TODO: Future work: support unions/generics/whatever via a deferred import-type
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:64510:                    // TODO(rbuckton): `NullKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:64520:                    // TODO(rbuckton): `ThisKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service and because of `isPartOfTypeNode`.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:64578:                // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:65174:            // TODO(anhans): A block should be context-sensitive if it has a context-sensitive return value.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:65716:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:67004:                            // TODO: Stack errors so we get a pyramid for the "normal" comparison above, _and_ a second for this
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:67320:                        // TODO: Find a nice way to include potential conditional type breakdowns in error output, if they seem good (they usually don't)
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:68711:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:69662:                        // TODO: remove this when we support static private identifier fields and find other solutions to get privateNamesAndStaticFields test to pass
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:70115:                            // TODO: The `allowComplexConstraintInference` flag is a hack! This forbids inference from complex constraints within constraints!
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:73583:                    // TODO: Maybe issue a better error than 'object is possibly undefined'
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:75629:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:75631:            return s; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:76038:                containingType = containingType.isThisType ? getConstraintOfTypeParameter(containingType) : getBaseConstraintOfType(containingType); // TODO: GH#18217 Use a different variable that's allowed to be undefined
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:76425:                error(errorNode, ts.Diagnostics.Property_0_is_used_before_being_assigned, symbolToString(prop)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:78908:            var resolvedRequire = resolveName(node.expression, node.expression.escapedText, 111551 /* SymbolFlags.Value */, /*nameNotFoundMessage*/ undefined, /*nameArg*/ undefined, /*isUse*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:81839:            // TODO (yuisu): Remove this check in else-if when SyntaxKind.Construct is moved and ambient context is handled
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:81864:            // TODO(rbuckton): Should we start checking JSDoc types?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:82669:                            // TODO: GH#17345: These are methods, so handle computed name case. (`Always allowing computed property names is *not* the correct behavior!)
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:82959:            var thenFunction = getTypeOfPropertyOfType(type, "then"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:83677:                // TODO: GH#22580
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:83803:                        //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:83810:                    //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:84726:                reportTypeNotIterableError(errorNode, inputType, allowAsyncIterables); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:85450:            // TODO: Check that target label is valid
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:88866:                var target = getSymbolLinks(symbol).aliasTarget; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:89249:                    accessor = ts.getParseTreeNode(accessor, ts.isGetOrSetAccessorDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:89404:            var moduleSymbol = resolveExternalModuleNameWorker(specifier, specifier, /*moduleNotFoundError*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:89906:                    return grammarErrorOnNode(lastOverride, ts.Diagnostics._0_modifier_cannot_appear_on_a_constructor_declaration, "override"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:90989:            // TODO: The spec needs to be amended to reflect this grammar.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:91274:        JsxNames.ElementAttributesPropertyNameContainer = "ElementAttributesProperty"; // TODO: Deprecate and remove support
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:91358:            // TODO(rbuckton): Remove dependency on `ts.factory` in favor of a provided factory.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:92691:        return !getImportNeedsImportStarHelper(node) && (ts.isDefaultImport(node) || (!!node.importClause && ts.isNamedImports(node.importClause.namedBindings) && containsDefaultReference(node.importClause.namedBindings))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:93202:        var target = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:93320:        var bindingTarget = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:93348:            flattenContext.emitBindingOrAssignment(bindingTarget, value, location, /*original*/ element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:94608:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:94611:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:95156:            //      // TODO, blah
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:95168:            //             // TODO, blah
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:97018:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:98398:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:98567:            recordDeclarationName(node.variableDeclaration, catchClauseNames); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:98607:            var initializer = node.initializer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:100501:                ? ts.createJsxFactoryExpression(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:100522:            var element = ts.createExpressionForJsxFragment(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), context.getEmitResolver().getJsxFragmentFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:102027:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:102062:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:102280:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:104539:            default: return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:105230:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:105887:            // TODO(rbuckton): `expression` should be required on `throw`.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:105925:                    beginCatchBlock(node.catchClause.variableDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:105971:                            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:107224:            var name = ts.getLocalNameForExternalImport(factory, node, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:108630:            var exportStarFunction = addExportStarIfNeeded(statements); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:108753:                    var importVariableName = ts.getLocalNameForExternalImport(factory, entry, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:108853:                hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:108877:            hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:110347:                // TODO(jfreeman): Deal with computed properties in error reporting.
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:110756:                // TODO: Do all these accessibility checks inside/after the first pass in the checker when declarations are enabled, if possible
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:110865:                        return undefined; // Omit declaration files from bundle results, too // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111062:            return canHaveLiteralInitializer(node) && resolver.isLiteralConstDeclaration(ts.getParseTreeNode(node)); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111066:                return resolver.createLiteralConstValue(ts.getParseTreeNode(node), symbolTracker); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111164:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111168:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111224:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111639:                                return undefined; // TODO GH#33569: Handle element access expressions that created late bound names (rather than silently omitting them)
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111724:                        var id = ts.getOriginalNodeId(inner); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:111803:                        return [statement, cleanup(factory.updateClassDeclaration(input, modifiers, input.name, typeParameters, heritageClauses, members))]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:112304:                // TODO: Remove check and unconditionally use onEmitNode when API is breakingly changed
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:113592:            writer = _writer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:117313:            var expr = ts.getExternalModuleName(node); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118207:        // TODO(rbuckton): Should be a `Set` but that requires changing the below code that uses `mutateMap`
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118697:            var _a = ts.getLineAndCharacterOfPosition(diagnostic.file, diagnostic.start), line = _a.line, character = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118783:        var _a = ts.getLineAndCharacterOfPosition(file, start), firstLine = _a.line, firstLineChar = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118800:                output += formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118808:                output += formatCodeSpan(diagnostic.file, diagnostic.start, diagnostic.length, "", getCategoryFormat(diagnostic.category), host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118816:                        output += halfIndent + formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:118817:                        output += formatCodeSpan(file, start, length_9, indent, ForegroundColorEscapeSequences.Cyan, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:119305:        var createProgramOptions = ts.isArray(rootNamesOrOptions) ? createCreateProgramOptions(rootNamesOrOptions, _options, _host, _oldProgram, _configFileParsingDiagnostics) : rootNamesOrOptions; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:119367:            var loader_1 = function (moduleName, resolverMode, containingFileName, redirectedReference) { return ts.resolveModuleName(moduleName, containingFileName, options, host, moduleResolutionCache, redirectedReference, resolverMode).resolvedModule; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:119376:            var loader_2 = function (typesRef, containingFile, redirectedReference, resolutionMode) { return ts.resolveTypeReferenceDirective(typesRef, containingFile, options, host, redirectedReference, typeReferenceDirectiveResolutionCache, resolutionMode).resolvedTypeReferenceDirective; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:119949:                    : host.getSourceFile(oldSourceFile.fileName, sourceFileOptions, /*onError*/ undefined, shouldCreateNewSourceFile || sourceFileOptions.impliedNodeFormat !== oldSourceFile.impliedNodeFormat); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:120398:            var line = ts.computeLineAndCharacterOfPosition(lineStarts, start).line - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:120861:            getSourceFileFromReferenceWorker(fileName, function (fileName) { return findSourceFile(fileName, isDefaultLib, ignoreNoDefaultLib, reason, packageId); }, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:121206:                    processSourceFile(resolvedTypeReferenceDirective.resolvedFileName, /*isDefaultLib*/ false, /*ignoreNoDefaultLib*/ false, resolvedTypeReferenceDirective.packageId, reason); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:122383:                    var fileName = resolvedTypeReferenceDirective.resolvedFileName; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:122940:                var affectedFilesIndex = state.affectedFilesIndex; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:123511:            newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:123526:        newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:124041:        var getCurrentDirectory = ts.memoize(function () { return resolutionHost.getCurrentDirectory(); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:124066:        var rootPath = (rootDir && resolutionHost.toPath(rootDir)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:124500:                setDirectoryWatcher(rootDir, rootPath, /*nonRecursive*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:125029:                // TODO: maybe useful to keep around as an alternative option for certain contexts where the mode is overridable
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:125753:            diagnostics[0] = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:125821:        host.onUnRecoverableConfigFileDiagnostic = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:126878:            setConfigFileParsingResult(ts.getParsedCommandLineOfConfigFile(configFileName, optionsToExtendForConfigFile, parseConfigFileHost, extendedConfigCache || (extendedConfigCache = new ts.Map()), watchOptionsToExtend, extraFileExtensions)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:127419:        // TODO(rbuckton): Should be a `Set`, but that requires changing the code below that uses `mutateMapSkippingNewValues`
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:129166:                    inferredTypings.set(typingName, undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:129549:                        var npmConfig = JSON.parse(this.installTypingHost.readFile(packageJson)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:129550:                        var npmLock = JSON.parse(this.installTypingHost.readFile(packageLockJson)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typingsInstaller.js:129679:                            // TODO: watch project directory
./utilities/ts/node_modules/typescript/lib/typescript.js:859:        return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/typescript.js:7039:    // TODO: GH#18217 this is used as if it's certainly defined in many places.
./utilities/ts/node_modules/typescript/lib/typescript.js:10398:            // TODO: Somehow track edits between file as it was during the creation of sourcemap we have and the current file and
./utilities/ts/node_modules/typescript/lib/typescript.js:12798:            // TODO: Add codePage support for readFile?
./utilities/ts/node_modules/typescript/lib/typescript.js:14342:    // TODO: determine what this does before making it public.
./utilities/ts/node_modules/typescript/lib/typescript.js:14358:    // TODO: GH#19856 Would like to return `node is Node & { jsDoc: JSDoc[] }` but it causes long compile times
./utilities/ts/node_modules/typescript/lib/typescript.js:15777:                        // TODO (drosen): TaggedTemplateExpressions may eventually support type arguments.
./utilities/ts/node_modules/typescript/lib/typescript.js:16266:            // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/typescript.js:16317:            && nodeCanBeDecorated(node, parent, grandparent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:16321:        return nodeIsDecorated(node, parent, grandparent) || childIsDecorated(node, parent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:16327:                return ts.some(node.members, function (m) { return nodeOrChildIsDecorated(m, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:16331:                return ts.some(node.parameters, function (p) { return nodeIsDecorated(p, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:17977:        // UpdateExpression:            // TODO: Do we need to investigate the precedence here?
./utilities/ts/node_modules/typescript/lib/typescript.js:18010:        // TODO: JSXElement?
./utilities/ts/node_modules/typescript/lib/typescript.js:18066:            // TODO: Should prefix `++` and `--` be moved to the `Update` precedence?
./utilities/ts/node_modules/typescript/lib/typescript.js:18768:        // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:20398:        // TODO: Should this callback be cached?
./utilities/ts/node_modules/typescript/lib/typescript.js:22025:                        : expression; // TODO(rbuckton): Verify this assertion holds
./utilities/ts/node_modules/typescript/lib/typescript.js:22044:                // TODO(rbuckton): Verify whether this assertion holds.
./utilities/ts/node_modules/typescript/lib/typescript.js:22047:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:22051:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:22055:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:22066:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:22075:                    // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:22082:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:22089:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/typescript.js:27272:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:29225:    // TODO(rbuckton): Rename to 'isParameterDeclaration'
./utilities/ts/node_modules/typescript/lib/typescript.js:29813:    // TODO(rbuckton): isUnparsedPrologue
./utilities/ts/node_modules/typescript/lib/typescript.js:29818:    // TODO(rbuckton): isUnparsedText
./utilities/ts/node_modules/typescript/lib/typescript.js:29819:    // TODO(rbuckton): isUnparsedInternalText
./utilities/ts/node_modules/typescript/lib/typescript.js:29820:    // TODO(rbuckton): isUnparsedSyntheticReference
./utilities/ts/node_modules/typescript/lib/typescript.js:29834:    // TODO(rbuckton): isInputFiles
./utilities/ts/node_modules/typescript/lib/typescript.js:30121:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:30126:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:30136:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:30140:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:30155:                /*type*/ undefined, getAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:30161:                /*type*/ undefined, setAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:30179:        /*type*/ undefined, method.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:31915:            // TODO: should we separate these branches out?
./utilities/ts/node_modules/typescript/lib/typescript.js:33979:                // TODO(rbuckton): Do we need to call `parseExpectedToken` or can we just call `createMissingNode` directly?
./utilities/ts/node_modules/typescript/lib/typescript.js:34124:            // TODO(rbuckton): JSDoc parameters don't have names (except `this`/`new`), should we manufacture an empty identifier?
./utilities/ts/node_modules/typescript/lib/typescript.js:34133:                // TODO(rbuckton): We never set the type for a JSDocNamepathType. What should we put here?
./utilities/ts/node_modules/typescript/lib/typescript.js:36574:                // TODO(rbuckton): Consider manufacturing this when we need to report an error as it is otherwise not useful.
./utilities/ts/node_modules/typescript/lib/typescript.js:36866:        // TODO: Review for error recovery
./utilities/ts/node_modules/typescript/lib/typescript.js:37238:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:39139:                    // TODO: Determine whether we should enforce this in the checker.
./utilities/ts/node_modules/typescript/lib/typescript.js:39140:                    // TODO: Consider moving the `constraint` to the first type parameter as we could then remove `getEffectiveConstraintOfTypeParameter`.
./utilities/ts/node_modules/typescript/lib/typescript.js:39141:                    // TODO: Consider only parsing a single type parameter if there is a constraint.
./utilities/ts/node_modules/typescript/lib/typescript.js:39757:            // TODO: The below should be strongly type-guarded and not need casts/explicit annotations, since entryOrList is related to
./utilities/ts/node_modules/typescript/lib/typescript.js:39794:                                // TODO: It's probably fine to issue this diagnostic on all instances of the pragma
./utilities/ts/node_modules/typescript/lib/typescript.js:42198:                            result.set(name, value.map(function (element) { return getNameOfCompilerOptionValue(element, customTypeMap_1); })); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:42645:                // TODO extend type typeAcquisition
./utilities/ts/node_modules/typescript/lib/typescript.js:43262:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:45078:                // TODO: Assert that `resolvedTarget` is actually within the package directory? That's what the spec says.... but I'm not sure we need
./utilities/ts/node_modules/typescript/lib/typescript.js:46059:                //      TODO: Make this a more specific error and decouple it from the exclusion logic.
./utilities/ts/node_modules/typescript/lib/typescript.js:46971:                // TODO: bindLogicalExpression is recursive - if we want to handle deeply nested `&&` expressions
./utilities/ts/node_modules/typescript/lib/typescript.js:47441:            var symbol = createSymbol(131072 /* SymbolFlags.Signature */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:48680:                    bindAnonymousDeclaration(node, 262144 /* SymbolFlags.TypeParameter */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:51030:                            !checkAndReportErrorForMissingPrefix(errorLocation, name, nameArg) && // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:51207:                        var instanceType = getDeclaredTypeOfSymbol(classSymbol).thisType; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:51699:            var moduleSymbol = resolveExternalModuleName(node, moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:53029:                        // TODO: the below is shared with similar code in `resolveName` - in fact, rephrasing all this symbol
./utilities/ts/node_modules/typescript/lib/typescript.js:53035:                        // TODO: Should this filtered table be cached in some way?
./utilities/ts/node_modules/typescript/lib/typescript.js:53438:                var entity = builder(symbol, meaning, enclosingDeclaration, nodeFlags); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:53460:                printer.writeNode(4 /* EmitHint.Unspecified */, sig, /*sourceFile*/ sourceFile, ts.getTrailingSemicolonDeferringWriter(writer)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:53635:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:53825:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:54165:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:54642:                context.tracker.trackSymbol(symbol, context.enclosingDeclaration, meaning); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:55357:                // TODO: Use `setOriginalNode` on original declaration names where possible so these declarations see some kind of
./utilities/ts/node_modules/typescript/lib/typescript.js:55575:                        // TODO: Issue error via symbol tracker?
./utilities/ts/node_modules/typescript/lib/typescript.js:55824:                    // TODO: `suppressNewPrivateContext` is questionable -we need to simply be emitting privates in whatever scope they were declared in, rather
./utilities/ts/node_modules/typescript/lib/typescript.js:55856:                        // TODO: Handle computed names
./utilities/ts/node_modules/typescript/lib/typescript.js:55901:                        // prop in the outermost scope (TODO: a namespace within a namespace would need to be appropriately handled by this)
./utilities/ts/node_modules/typescript/lib/typescript.js:55927:                        // TODO: implement handling for the localVsRemoteMap.get("remote") - should be difficult to trigger (see comment above), as only interesting cross-file js merges should make this possible
./utilities/ts/node_modules/typescript/lib/typescript.js:56134:                            // TODO: Not part of a file's local or export symbol tables
./utilities/ts/node_modules/typescript/lib/typescript.js:56300:                        !ts.length(getSignaturesOfType(typeToSerialize, 1 /* SignatureKind.Construct */)) && // TODO: could probably serialize as function + ns + class, now that that's OK
./utilities/ts/node_modules/typescript/lib/typescript.js:56347:                            // TODO: https://github.com/microsoft/TypeScript/pull/32372#discussion_r328386357
./utilities/ts/node_modules/typescript/lib/typescript.js:56536:                var predicate = ts.factory.createTypePredicateNode(typePredicate.kind === 2 /* TypePredicateKind.AssertsThis */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createToken(129 /* SyntaxKind.AssertsKeyword */) : undefined, typePredicate.kind === 1 /* TypePredicateKind.Identifier */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createIdentifier(typePredicate.parameterName) : ts.factory.createThisTypeNode(), typePredicate.type && nodeBuilder.typeToTypeNode(typePredicate.type, enclosingDeclaration, toNodeBuilderFlags(flags) | 70221824 /* NodeBuilderFlags.IgnoreErrors */ | 512 /* NodeBuilderFlags.WriteTypeParametersInQualifiedName */) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:57408:                    var sourceTypes = ts.some(constructorTypes, function (t) { return !!(t.flags & ~98304 /* TypeFlags.Nullable */); }) ? constructorTypes : types; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:57696:                // TODO: If back compat with pre-3.0/4.0 libs isn't required, remove the following SymbolConstructor special case transforming `symbol` into `unique symbol`
./utilities/ts/node_modules/typescript/lib/typescript.js:58147:        // TODO: GH#18217 If `checkBase` is undefined, we should not call this because this will always return false.
./utilities/ts/node_modules/typescript/lib/typescript.js:58174:                node = node.parent; // TODO: GH#18217 Use SourceFile kind check instead
./utilities/ts/node_modules/typescript/lib/typescript.js:58492:            // TODO: Given that we allow type parmeters here now, is this `!isGenericMappedType(type)` check really needed?
./utilities/ts/node_modules/typescript/lib/typescript.js:59877:            var constraintDeclaration = getConstraintDeclarationForMappedType(type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:61183:                return getTypeFromTypeNode(declaration.parameters[0].type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:61575:                        // TODO: Adopt same permissive behavior in TS as in JS to reduce follow-on editing experience failures (requires editing fillMissingTypeArguments)
./utilities/ts/node_modules/typescript/lib/typescript.js:64000:                result.aliasTypeArguments = aliasSymbol ? aliasTypeArguments : instantiateTypes(root.aliasTypeArguments, mapper); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:64112:                // TODO: Future work: support unions/generics/whatever via a deferred import-type
./utilities/ts/node_modules/typescript/lib/typescript.js:64520:                    // TODO(rbuckton): `NullKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service.
./utilities/ts/node_modules/typescript/lib/typescript.js:64530:                    // TODO(rbuckton): `ThisKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service and because of `isPartOfTypeNode`.
./utilities/ts/node_modules/typescript/lib/typescript.js:64588:                // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/typescript.js:65184:            // TODO(anhans): A block should be context-sensitive if it has a context-sensitive return value.
./utilities/ts/node_modules/typescript/lib/typescript.js:65726:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/typescript.js:67014:                            // TODO: Stack errors so we get a pyramid for the "normal" comparison above, _and_ a second for this
./utilities/ts/node_modules/typescript/lib/typescript.js:67330:                        // TODO: Find a nice way to include potential conditional type breakdowns in error output, if they seem good (they usually don't)
./utilities/ts/node_modules/typescript/lib/typescript.js:68721:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/typescript.js:69672:                        // TODO: remove this when we support static private identifier fields and find other solutions to get privateNamesAndStaticFields test to pass
./utilities/ts/node_modules/typescript/lib/typescript.js:70125:                            // TODO: The `allowComplexConstraintInference` flag is a hack! This forbids inference from complex constraints within constraints!
./utilities/ts/node_modules/typescript/lib/typescript.js:73593:                    // TODO: Maybe issue a better error than 'object is possibly undefined'
./utilities/ts/node_modules/typescript/lib/typescript.js:75639:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:75641:            return s; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:76048:                containingType = containingType.isThisType ? getConstraintOfTypeParameter(containingType) : getBaseConstraintOfType(containingType); // TODO: GH#18217 Use a different variable that's allowed to be undefined
./utilities/ts/node_modules/typescript/lib/typescript.js:76435:                error(errorNode, ts.Diagnostics.Property_0_is_used_before_being_assigned, symbolToString(prop)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:78918:            var resolvedRequire = resolveName(node.expression, node.expression.escapedText, 111551 /* SymbolFlags.Value */, /*nameNotFoundMessage*/ undefined, /*nameArg*/ undefined, /*isUse*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:81849:            // TODO (yuisu): Remove this check in else-if when SyntaxKind.Construct is moved and ambient context is handled
./utilities/ts/node_modules/typescript/lib/typescript.js:81874:            // TODO(rbuckton): Should we start checking JSDoc types?
./utilities/ts/node_modules/typescript/lib/typescript.js:82679:                            // TODO: GH#17345: These are methods, so handle computed name case. (`Always allowing computed property names is *not* the correct behavior!)
./utilities/ts/node_modules/typescript/lib/typescript.js:82969:            var thenFunction = getTypeOfPropertyOfType(type, "then"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:83687:                // TODO: GH#22580
./utilities/ts/node_modules/typescript/lib/typescript.js:83813:                        //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/typescript.js:83820:                    //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/typescript.js:84736:                reportTypeNotIterableError(errorNode, inputType, allowAsyncIterables); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:85460:            // TODO: Check that target label is valid
./utilities/ts/node_modules/typescript/lib/typescript.js:88876:                var target = getSymbolLinks(symbol).aliasTarget; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:89259:                    accessor = ts.getParseTreeNode(accessor, ts.isGetOrSetAccessorDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:89414:            var moduleSymbol = resolveExternalModuleNameWorker(specifier, specifier, /*moduleNotFoundError*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:89916:                    return grammarErrorOnNode(lastOverride, ts.Diagnostics._0_modifier_cannot_appear_on_a_constructor_declaration, "override"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:90999:            // TODO: The spec needs to be amended to reflect this grammar.
./utilities/ts/node_modules/typescript/lib/typescript.js:91284:        JsxNames.ElementAttributesPropertyNameContainer = "ElementAttributesProperty"; // TODO: Deprecate and remove support
./utilities/ts/node_modules/typescript/lib/typescript.js:91368:            // TODO(rbuckton): Remove dependency on `ts.factory` in favor of a provided factory.
./utilities/ts/node_modules/typescript/lib/typescript.js:92701:        return !getImportNeedsImportStarHelper(node) && (ts.isDefaultImport(node) || (!!node.importClause && ts.isNamedImports(node.importClause.namedBindings) && containsDefaultReference(node.importClause.namedBindings))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:93212:        var target = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:93330:        var bindingTarget = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:93358:            flattenContext.emitBindingOrAssignment(bindingTarget, value, location, /*original*/ element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:94618:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:94621:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:95166:            //      // TODO, blah
./utilities/ts/node_modules/typescript/lib/typescript.js:95178:            //             // TODO, blah
./utilities/ts/node_modules/typescript/lib/typescript.js:97028:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:98408:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:98577:            recordDeclarationName(node.variableDeclaration, catchClauseNames); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:98617:            var initializer = node.initializer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:100511:                ? ts.createJsxFactoryExpression(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:100532:            var element = ts.createExpressionForJsxFragment(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), context.getEmitResolver().getJsxFragmentFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:102037:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:102072:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:102290:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:104549:            default: return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:105240:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:105897:            // TODO(rbuckton): `expression` should be required on `throw`.
./utilities/ts/node_modules/typescript/lib/typescript.js:105935:                    beginCatchBlock(node.catchClause.variableDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:105981:                            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/typescript.js:107234:            var name = ts.getLocalNameForExternalImport(factory, node, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:108640:            var exportStarFunction = addExportStarIfNeeded(statements); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:108763:                    var importVariableName = ts.getLocalNameForExternalImport(factory, entry, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:108863:                hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:108887:            hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:110357:                // TODO(jfreeman): Deal with computed properties in error reporting.
./utilities/ts/node_modules/typescript/lib/typescript.js:110766:                // TODO: Do all these accessibility checks inside/after the first pass in the checker when declarations are enabled, if possible
./utilities/ts/node_modules/typescript/lib/typescript.js:110875:                        return undefined; // Omit declaration files from bundle results, too // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:111072:            return canHaveLiteralInitializer(node) && resolver.isLiteralConstDeclaration(ts.getParseTreeNode(node)); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/typescript.js:111076:                return resolver.createLiteralConstValue(ts.getParseTreeNode(node), symbolTracker); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/typescript.js:111174:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:111178:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:111234:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:111649:                                return undefined; // TODO GH#33569: Handle element access expressions that created late bound names (rather than silently omitting them)
./utilities/ts/node_modules/typescript/lib/typescript.js:111734:                        var id = ts.getOriginalNodeId(inner); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:111813:                        return [statement, cleanup(factory.updateClassDeclaration(input, modifiers, input.name, typeParameters, heritageClauses, members))]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:112314:                // TODO: Remove check and unconditionally use onEmitNode when API is breakingly changed
./utilities/ts/node_modules/typescript/lib/typescript.js:113602:            writer = _writer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:117323:            var expr = ts.getExternalModuleName(node); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:118217:        // TODO(rbuckton): Should be a `Set` but that requires changing the below code that uses `mutateMap`
./utilities/ts/node_modules/typescript/lib/typescript.js:118707:            var _a = ts.getLineAndCharacterOfPosition(diagnostic.file, diagnostic.start), line = _a.line, character = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:118793:        var _a = ts.getLineAndCharacterOfPosition(file, start), firstLine = _a.line, firstLineChar = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:118810:                output += formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:118818:                output += formatCodeSpan(diagnostic.file, diagnostic.start, diagnostic.length, "", getCategoryFormat(diagnostic.category), host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:118826:                        output += halfIndent + formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:118827:                        output += formatCodeSpan(file, start, length_9, indent, ForegroundColorEscapeSequences.Cyan, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:119315:        var createProgramOptions = ts.isArray(rootNamesOrOptions) ? createCreateProgramOptions(rootNamesOrOptions, _options, _host, _oldProgram, _configFileParsingDiagnostics) : rootNamesOrOptions; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:119377:            var loader_1 = function (moduleName, resolverMode, containingFileName, redirectedReference) { return ts.resolveModuleName(moduleName, containingFileName, options, host, moduleResolutionCache, redirectedReference, resolverMode).resolvedModule; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:119386:            var loader_2 = function (typesRef, containingFile, redirectedReference, resolutionMode) { return ts.resolveTypeReferenceDirective(typesRef, containingFile, options, host, redirectedReference, typeReferenceDirectiveResolutionCache, resolutionMode).resolvedTypeReferenceDirective; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:119959:                    : host.getSourceFile(oldSourceFile.fileName, sourceFileOptions, /*onError*/ undefined, shouldCreateNewSourceFile || sourceFileOptions.impliedNodeFormat !== oldSourceFile.impliedNodeFormat); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:120408:            var line = ts.computeLineAndCharacterOfPosition(lineStarts, start).line - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:120871:            getSourceFileFromReferenceWorker(fileName, function (fileName) { return findSourceFile(fileName, isDefaultLib, ignoreNoDefaultLib, reason, packageId); }, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:121216:                    processSourceFile(resolvedTypeReferenceDirective.resolvedFileName, /*isDefaultLib*/ false, /*ignoreNoDefaultLib*/ false, resolvedTypeReferenceDirective.packageId, reason); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:122393:                    var fileName = resolvedTypeReferenceDirective.resolvedFileName; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:122950:                var affectedFilesIndex = state.affectedFilesIndex; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:123521:            newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:123536:        newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:124051:        var getCurrentDirectory = ts.memoize(function () { return resolutionHost.getCurrentDirectory(); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:124076:        var rootPath = (rootDir && resolutionHost.toPath(rootDir)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:124510:                setDirectoryWatcher(rootDir, rootPath, /*nonRecursive*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:125039:                // TODO: maybe useful to keep around as an alternative option for certain contexts where the mode is overridable
./utilities/ts/node_modules/typescript/lib/typescript.js:125763:            diagnostics[0] = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:125831:        host.onUnRecoverableConfigFileDiagnostic = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:126888:            setConfigFileParsingResult(ts.getParsedCommandLineOfConfigFile(configFileName, optionsToExtendForConfigFile, parseConfigFileHost, extendedConfigCache || (extendedConfigCache = new ts.Map()), watchOptionsToExtend, extraFileExtensions)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:127429:        // TODO(rbuckton): Should be a `Set`, but that requires changing the code below that uses `mutateMapSkippingNewValues`
./utilities/ts/node_modules/typescript/lib/typescript.js:129176:                    inferredTypings.set(typingName, undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:130205:                // case SyntaxKind.ThisType: TODO: GH#9267
./utilities/ts/node_modules/typescript/lib/typescript.js:133678:                return undefined; // TODO: GH#18217 Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/typescript.js:133940:            default: return undefined; // TODO: GH#18217 throw Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/typescript.js:134019:                        // TODO: Maybe we should classify these.
./utilities/ts/node_modules/typescript/lib/typescript.js:134032:                    // TODO: This should be predicated on `token["kind"]` being compatible with `HasJSDoc["kind"]`
./utilities/ts/node_modules/typescript/lib/typescript.js:134331:                // TODO: we should get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/typescript.js:134335:                // TODO (drosen): we should *also* get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/typescript.js:135006:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:136057:            // TODO(drosen): Right now we just permit *all* semantic meanings when calling
./utilities/ts/node_modules/typescript/lib/typescript.js:136083:            // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/typescript.js:136676:                    return createCompletionDetailsForSymbol(symbol, typeChecker, sourceFile, location, cancellationToken, codeActions, sourceDisplay); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:136780:                            return checker.getContextualType(parent.initializer); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:136820:            var currentToken = ts.getTokenAtPosition(sourceFile, position); // TODO: GH#15853
./utilities/ts/node_modules/typescript/lib/typescript.js:136821:            // We will check for jsdoc comments with insideComment and getJsDocTagAtPosition. (TODO: that seems rather inefficient to check the same thing so many times.)
./utilities/ts/node_modules/typescript/lib/typescript.js:137641:                // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/typescript.js:137922:                var moduleSpecifierSymbol = typeChecker.getSymbolAtLocation(moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:138323:                        // TODO: Account for computed property name
./utilities/ts/node_modules/typescript/lib/typescript.js:138482:                var contextToken = ts.findPrecedingToken(previousToken.getFullStart(), sourceFile, /*startNode*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:138522:                    // TODO: GH#18169
./utilities/ts/node_modules/typescript/lib/typescript.js:138790:                    return (isValidKeyword(contextToken.kind) || contextToken.kind === 41 /* SyntaxKind.AsteriskToken */ || ts.isIdentifier(contextToken) && isValidKeyword(ts.stringToToken(contextToken.text))) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:138832:        // TODO: GH#19856 Would like to return `node is Node & { parent: (ClassElement | TypeElement) & { parent: ObjectTypeDeclaration } }` but then compilation takes > 10 minutes
./utilities/ts/node_modules/typescript/lib/typescript.js:139285:                        // TODO: GH#20090
./utilities/ts/node_modules/typescript/lib/typescript.js:139679:                    entry.sourceFile = ts.updateLanguageServiceSourceFile(entry.sourceFile, scriptSnapshot, version, scriptSnapshot.getChangeRange(entry.sourceFile.scriptSnapshot)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:139858:                                break; // TODO: GH#23879
./utilities/ts/node_modules/typescript/lib/typescript.js:139935:                indirectUserDeclarations.push(sourceFileLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:141559:                return exposedByParent ? scope.getSourceFile() : scope; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:141643:                /// TODO: Cache symbol existence for files to save text search
./utilities/ts/node_modules/typescript/lib/typescript.js:143154:                    // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:143223:        for (var _i = 0, _a = sourceFile.referencedFiles || ts.emptyArray; _i < _a.length; _i++) { // TODO: GH#26162
./utilities/ts/node_modules/typescript/lib/typescript.js:143276:                return label ? [createDefinitionInfoFromName(typeChecker, label, "label" /* ScriptElementKind.label */, node.text, /*containerName*/ undefined)] : undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:143443:                var file = reference && program.getSourceFile(reference.resolvedFileName); // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:143642:            return __assign(__assign({ fileName: sourceFile.fileName, textSpan: textSpan, kind: symbolKind, name: symbolName, containerKind: undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:144006:                if (jsdoc.tags.some(function (t) { return t !== tag && ts.isJSDocParameterTag(t) && ts.isIdentifier(t.name) && t.name.escapedText === name; }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:144083:            // * TODO: other tags.
./utilities/ts/node_modules/typescript/lib/typescript.js:144255:                    var importer = checker.getSymbolAtLocation(declaration.name); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:144297:            // TODO(cyrusn): get the gamut of comparisons that VS already uses here.
./utilities/ts/node_modules/typescript/lib/typescript.js:144313:                // TODO(jfreeman): What should be the containerName when the container has a computed name?
./utilities/ts/node_modules/typescript/lib/typescript.js:144930:            return ts.compareStringsCaseSensitiveUI(tryGetName(child1.node), tryGetName(child2.node)) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:145435:                    coalescedImports.push(updateImportDeclarationAndClause(defaultImport, defaultImport.importClause.name, namespaceImports[0].importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:145440:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:145444:                    coalescedImports.push(updateImportDeclarationAndClause(namespaceImport, /*name*/ undefined, namespaceImport.importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:145457:                        newImportSpecifiers.push(ts.factory.createImportSpecifier(/*isTypeOnly*/ false, ts.factory.createIdentifier("default"), defaultImport.importClause.name)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:145471:                        : ts.factory.updateNamedImports(namedImports[0].importClause.namedBindings, sortedImportSpecifiers); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:145584:            return ts.factory.updateImportDeclaration(importDeclaration, importDeclaration.modifiers, ts.factory.updateImportClause(importDeclaration.importClause, importDeclaration.importClause.isTypeOnly, name, namedBindings), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:146279:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/typescript.js:146292:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/typescript.js:146320:        // TODO: find a way to compute this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/typescript.js:146325:        // TODO(cyrusn): Find a way to support this for unicode digits.
./utilities/ts/node_modules/typescript/lib/typescript.js:147429:                    var resolvedSignature = checker.getResolvedSignatureForSignatureHelp(invocation.node, candidates, argumentCount); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:148338:            var file = getSourceFileLike(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:148630:        // TODO(drosen): use contextual SemanticMeaning.
./utilities/ts/node_modules/typescript/lib/typescript.js:148760:        // TODO(drosen): Currently completion entry details passes the SemanticMeaning.All instead of using semanticMeaning of location
./utilities/ts/node_modules/typescript/lib/typescript.js:148824:                    signature = typeChecker.getResolvedSignature(callExpressionLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:148899:                            signature = typeChecker.getSignatureFromDeclaration(functionDeclaration_1); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:148996:                            var signature = typeChecker.getSignatureFromDeclaration(declaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:150354:                // TODO
./utilities/ts/node_modules/typescript/lib/typescript.js:150876:                .filter(function (d) { return ts.rangeOverlapsWithStartEnd(originalRange, d.start, d.start + d.length); }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:151337:                                listDynamicIndentation = getDynamicIndentation(parent, parentStartLine, indentationOnListStartToken, options.indentSize); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:151950:                    return getActualIndentationForListStartLine(containerList, sourceFile, options) + indentSize; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:151997:                        return getIndentationForNodeWorker(current, currentStart, /*ignoreActualIndentationRange*/ undefined, indentationDelta, sourceFile, /*isNextChild*/ true, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:152313:                    return getActualIndentationForListStartLine(containingList, sourceFile, options) + (listIndentsChild ? options.indentSize : 0); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:152421:                        if (!settings.indentMultiLineObjectLiteralBeginningOnBlankLine && sourceFile && childKind === 207 /* SyntaxKind.ObjectLiteralExpression */) { // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:153410:                // TODO: this emits the file, parses it back, then formats it that -- may be a less roundabout way to do this
./utilities/ts/node_modules/typescript/lib/typescript.js:153749:                || ts.isStatementButNotDeclaration(a) && ts.isStatementButNotDeclaration(b); // TODO: only if b would start with a `(` or `[`
./utilities/ts/node_modules/typescript/lib/typescript.js:153871:                    // TODO: There's currently no unused diagnostic for this, could be a suggestion
./utilities/ts/node_modules/typescript/lib/typescript.js:153897:        // Exported for tests only! (TODO: improve tests to not need this)
./utilities/ts/node_modules/typescript/lib/typescript.js:154854:            // TODO: This does not properly handle `function(new:C, string)` per https://github.com/google/closure-compiler/wiki/Types-in-the-Closure-Type-System#the-javascript-type-language
./utilities/ts/node_modules/typescript/lib/typescript.js:154860:            var isRest = node.type.kind === 321 /* SyntaxKind.JSDocVariadicType */ && index === node.parent.parameters.length - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:156116:                    // TODO: Maybe we should handle this? See fourslash test `refactorConvertToEs6Module_export_object_shorthand.ts`.
./utilities/ts/node_modules/typescript/lib/typescript.js:156183:        // TODO: GH#22492 this will cause an error if a change has been made inside the body of the node.
./utilities/ts/node_modules/typescript/lib/typescript.js:156206:                return makeConst(modifiers, ts.factory.createIdentifier(name), replaceImportUseSites(exported, useSitesToUnqualify)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:156590:        var fixId = "fixClassIncorrectlyImplementsInterface"; // TODO: share a group with fixClassDoesntImplementInheritedAbstractMember?
./utilities/ts/node_modules/typescript/lib/typescript.js:159748:            // TODO (https://github.com/Microsoft/TypeScript/issues/21246): use shared helper
./utilities/ts/node_modules/typescript/lib/typescript.js:160432:            changes.replaceNode(sourceFile, oldTypeNode, checker.typeToTypeNode(newType, /*enclosingDeclaration*/ oldTypeNode, /*flags*/ undefined)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:160717:                    return ts.isSetAccessorDeclaration(ts.getContainingFunction(token)) ? ts.Diagnostics.Infer_type_of_0_from_usage : ts.Diagnostics.Infer_parameter_types_from_usage; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:161307:                            // TODO: use getFalsyflagsOfType
./utilities/ts/node_modules/typescript/lib/typescript.js:162218:                // TODO Handle auto quote preference.
./utilities/ts/node_modules/typescript/lib/typescript.js:162373:            var leftHead = isStatic ? container.name : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:162431:            /*parameters*/ undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:162591:            var relatedImport = type.symbol.originatingImport; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:162704:            return getDefaultValueFromType(checker, checker.getTypeFromTypeNode(propertyDeclaration.type)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:164389:                var targetRange = rangeToExtract.targetRange; // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:164527:                return { targetRange: { range: getStatementOrExpressionRange(node), facts: rangeFacts, thisNode: thisNode } }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:164636:                                // TODO: GH#18217 Silly to use `errors ||` since it's definitely not defined (see top of `visit`)
./utilities/ts/node_modules/typescript/lib/typescript.js:164638:                                // Also TODO: GH#19956
./utilities/ts/node_modules/typescript/lib/typescript.js:164851:                context.cancellationToken.throwIfCancellationRequested(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:165017:                    returnType = checker.typeToTypeNode(contextualType, scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:165082:                        /*modifiers*/ undefined, ts.factory.createVariableDeclarationList([ts.factory.createVariableDeclaration(ts.getSynthesizedDeepClone(variableDeclaration.name), /*exclamationToken*/ undefined, /*type*/ ts.getSynthesizedDeepClone(variableDeclaration.type), /*initializer*/ call)], // TODO (acasey): test binding patterns
./utilities/ts/node_modules/typescript/lib/typescript.js:165213:                    : checker.typeToTypeNode(checker.getContextualType(node), scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:165229:                        ? ts.factory.createIdentifier(scope.name.getText()) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:165387:                    var lhs = range.facts & RangeFacts.InStaticRegion ? ts.factory.createIdentifier(scope.name.text) : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:165459:                    var body = scope.body; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:165540:                // TODO: GH#18217 `variableAssignments` not possibly undefined!
./utilities/ts/node_modules/typescript/lib/typescript.js:165610:                        // TODO (https://github.com/Microsoft/TypeScript/issues/18924): allow this
./utilities/ts/node_modules/typescript/lib/typescript.js:165624:                    var contextualType = checker.getContextualType(targetRange.range); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:166414:                                : ts.skipAlias(checker.getSymbolAtLocation(name), checker); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:166516:                    defaultImport = ts.factory.createIdentifier(ts.symbolNameNoDefault(symbol)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:166974:                    return [decl.name.text]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:167126:                    return ts.emptyArray; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/typescript.js:167147:                return { edits: [] }; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/typescript.js:167460:                return ts.isVariableDeclaration(node) && ts.isVarConst(node) && ts.isIdentifier(node.name) && !node.type; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/typescript.js:168719:                // TODO: GH#16312 Return a ReadonlyArray, avoid copying inheritedDocs
./utilities/ts/node_modules/typescript/lib/typescript.js:169240:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:169443:        // TODO: GH#18217 frequently asserted as defined
./utilities/ts/node_modules/typescript/lib/typescript.js:169512:            program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:169521:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:169565:            return ts.Completions.getCompletionEntryDetails(program, log, getValidSourceFile(fileName), position, { name: name, source: source, data: data }, host, (formattingOptions && ts.formatting.getFormatContext(formattingOptions, host)), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:170218:                    //  i.e. 'undefined' in position 3 above means TODO(jason) didn't match.
./utilities/ts/node_modules/typescript/lib/typescript.js:170237:                    // We don't want to match something like 'TODOBY', so we make sure a non
./utilities/ts/node_modules/typescript/lib/typescript.js:170253:                // TODO comments can appear in one of the following forms:
./utilities/ts/node_modules/typescript/lib/typescript.js:170255:                //  1)      // TODO     or  /////////// TODO
./utilities/ts/node_modules/typescript/lib/typescript.js:170257:                //  2)      /* TODO     or  /********** TODO
./utilities/ts/node_modules/typescript/lib/typescript.js:170260:                //           *   TODO
./utilities/ts/node_modules/typescript/lib/typescript.js:170263:                // The following three regexps are used to match the start of the text up to the TODO
./utilities/ts/node_modules/typescript/lib/typescript.js:170268:                // Match any of the above three TODO comment start regexps.
./utilities/ts/node_modules/typescript/lib/typescript.js:170270:                // so that we can determine the starting position of the TODO comment match.
./utilities/ts/node_modules/typescript/lib/typescript.js:170273:                // For example, if the descriptors are "TODO(jason)" and "HACK", then this will be:
./utilities/ts/node_modules/typescript/lib/typescript.js:170275:                //      (?:(TODO\(jason\))|(HACK))
./utilities/ts/node_modules/typescript/lib/typescript.js:170285:                // This is the portion of the match we'll return as part of the TODO comment result. We
./utilities/ts/node_modules/typescript/lib/typescript.js:170290:                // /((?:\/\/+\s*)|(?:\/\*+\s*)|(?:^(?:\s|\*)*))((?:(TODO\(jason\))|(HACK))(?:.*?))(?:$|\*\/)/gim
./utilities/ts/node_modules/typescript/lib/typescript.js:170295:                //  'i' is for case insensitivity (We do this to match C# TODO comment code).
./utilities/ts/node_modules/typescript/lib/typescript.js:170484:        return sourceFile.nameTable; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171227:        compilerOptions = ts.fixupCompilerOptions(compilerOptions, diagnostics); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171278:                return null; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171281:            var decoded = JSON.parse(encoded); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171288:                this.scriptSnapshotShim.dispose(); // TODO: GH#18217 Can we just use `if (this.scriptSnapshotShim.dispose)`?
./utilities/ts/node_modules/typescript/lib/typescript.js:171303:                    var resolutionsInFile = JSON.parse(_this.shimHost.getModuleResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171315:                    var typeDirectivesForFile = JSON.parse(_this.shimHost.getTypeReferenceDirectiveResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171336:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171370:                return this.shimHost.getScriptKind(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171408:            var pattern = ts.getFileMatcherPatterns(path, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171429:                this.directoryExists = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171432:                this.realpath = function (path) { return _this.shimHost.realpath(path); }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171435:                this.realpath = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:171439:            var pattern = ts.getFileMatcherPatterns(rootDir, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/typescript.js:172092:    /// TODO: this is used by VS, clean this up on both sides of the interface
./utilities/ts/node_modules/typescript/lib/typescript.js:172100:    // TODO: it should be moved into a namespace though.
./utilities/ts/node_modules/typescript/lib/tsserver.js:869:        return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/tsserver.js:7049:    // TODO: GH#18217 this is used as if it's certainly defined in many places.
./utilities/ts/node_modules/typescript/lib/tsserver.js:10408:            // TODO: Somehow track edits between file as it was during the creation of sourcemap we have and the current file and
./utilities/ts/node_modules/typescript/lib/tsserver.js:12808:            // TODO: Add codePage support for readFile?
./utilities/ts/node_modules/typescript/lib/tsserver.js:14352:    // TODO: determine what this does before making it public.
./utilities/ts/node_modules/typescript/lib/tsserver.js:14368:    // TODO: GH#19856 Would like to return `node is Node & { jsDoc: JSDoc[] }` but it causes long compile times
./utilities/ts/node_modules/typescript/lib/tsserver.js:15787:                        // TODO (drosen): TaggedTemplateExpressions may eventually support type arguments.
./utilities/ts/node_modules/typescript/lib/tsserver.js:16276:            // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/tsserver.js:16327:            && nodeCanBeDecorated(node, parent, grandparent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:16331:        return nodeIsDecorated(node, parent, grandparent) || childIsDecorated(node, parent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:16337:                return ts.some(node.members, function (m) { return nodeOrChildIsDecorated(m, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:16341:                return ts.some(node.parameters, function (p) { return nodeIsDecorated(p, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:17987:        // UpdateExpression:            // TODO: Do we need to investigate the precedence here?
./utilities/ts/node_modules/typescript/lib/tsserver.js:18020:        // TODO: JSXElement?
./utilities/ts/node_modules/typescript/lib/tsserver.js:18076:            // TODO: Should prefix `++` and `--` be moved to the `Update` precedence?
./utilities/ts/node_modules/typescript/lib/tsserver.js:18778:        // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:20408:        // TODO: Should this callback be cached?
./utilities/ts/node_modules/typescript/lib/tsserver.js:22035:                        : expression; // TODO(rbuckton): Verify this assertion holds
./utilities/ts/node_modules/typescript/lib/tsserver.js:22054:                // TODO(rbuckton): Verify whether this assertion holds.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22057:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22061:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22065:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22076:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22085:                    // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22092:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:22099:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserver.js:27282:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:29235:    // TODO(rbuckton): Rename to 'isParameterDeclaration'
./utilities/ts/node_modules/typescript/lib/tsserver.js:29823:    // TODO(rbuckton): isUnparsedPrologue
./utilities/ts/node_modules/typescript/lib/tsserver.js:29828:    // TODO(rbuckton): isUnparsedText
./utilities/ts/node_modules/typescript/lib/tsserver.js:29829:    // TODO(rbuckton): isUnparsedInternalText
./utilities/ts/node_modules/typescript/lib/tsserver.js:29830:    // TODO(rbuckton): isUnparsedSyntheticReference
./utilities/ts/node_modules/typescript/lib/tsserver.js:29844:    // TODO(rbuckton): isInputFiles
./utilities/ts/node_modules/typescript/lib/tsserver.js:30131:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:30136:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:30146:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:30150:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:30165:                /*type*/ undefined, getAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:30171:                /*type*/ undefined, setAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:30189:        /*type*/ undefined, method.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:31925:            // TODO: should we separate these branches out?
./utilities/ts/node_modules/typescript/lib/tsserver.js:33989:                // TODO(rbuckton): Do we need to call `parseExpectedToken` or can we just call `createMissingNode` directly?
./utilities/ts/node_modules/typescript/lib/tsserver.js:34134:            // TODO(rbuckton): JSDoc parameters don't have names (except `this`/`new`), should we manufacture an empty identifier?
./utilities/ts/node_modules/typescript/lib/tsserver.js:34143:                // TODO(rbuckton): We never set the type for a JSDocNamepathType. What should we put here?
./utilities/ts/node_modules/typescript/lib/tsserver.js:36584:                // TODO(rbuckton): Consider manufacturing this when we need to report an error as it is otherwise not useful.
./utilities/ts/node_modules/typescript/lib/tsserver.js:36876:        // TODO: Review for error recovery
./utilities/ts/node_modules/typescript/lib/tsserver.js:37248:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:39149:                    // TODO: Determine whether we should enforce this in the checker.
./utilities/ts/node_modules/typescript/lib/tsserver.js:39150:                    // TODO: Consider moving the `constraint` to the first type parameter as we could then remove `getEffectiveConstraintOfTypeParameter`.
./utilities/ts/node_modules/typescript/lib/tsserver.js:39151:                    // TODO: Consider only parsing a single type parameter if there is a constraint.
./utilities/ts/node_modules/typescript/lib/tsserver.js:39767:            // TODO: The below should be strongly type-guarded and not need casts/explicit annotations, since entryOrList is related to
./utilities/ts/node_modules/typescript/lib/tsserver.js:39804:                                // TODO: It's probably fine to issue this diagnostic on all instances of the pragma
./utilities/ts/node_modules/typescript/lib/tsserver.js:42208:                            result.set(name, value.map(function (element) { return getNameOfCompilerOptionValue(element, customTypeMap_1); })); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:42655:                // TODO extend type typeAcquisition
./utilities/ts/node_modules/typescript/lib/tsserver.js:43272:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:45088:                // TODO: Assert that `resolvedTarget` is actually within the package directory? That's what the spec says.... but I'm not sure we need
./utilities/ts/node_modules/typescript/lib/tsserver.js:46069:                //      TODO: Make this a more specific error and decouple it from the exclusion logic.
./utilities/ts/node_modules/typescript/lib/tsserver.js:46981:                // TODO: bindLogicalExpression is recursive - if we want to handle deeply nested `&&` expressions
./utilities/ts/node_modules/typescript/lib/tsserver.js:47451:            var symbol = createSymbol(131072 /* SymbolFlags.Signature */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:48690:                    bindAnonymousDeclaration(node, 262144 /* SymbolFlags.TypeParameter */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:51040:                            !checkAndReportErrorForMissingPrefix(errorLocation, name, nameArg) && // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:51217:                        var instanceType = getDeclaredTypeOfSymbol(classSymbol).thisType; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:51709:            var moduleSymbol = resolveExternalModuleName(node, moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:53039:                        // TODO: the below is shared with similar code in `resolveName` - in fact, rephrasing all this symbol
./utilities/ts/node_modules/typescript/lib/tsserver.js:53045:                        // TODO: Should this filtered table be cached in some way?
./utilities/ts/node_modules/typescript/lib/tsserver.js:53448:                var entity = builder(symbol, meaning, enclosingDeclaration, nodeFlags); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:53470:                printer.writeNode(4 /* EmitHint.Unspecified */, sig, /*sourceFile*/ sourceFile, ts.getTrailingSemicolonDeferringWriter(writer)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:53645:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:53835:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:54175:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:54652:                context.tracker.trackSymbol(symbol, context.enclosingDeclaration, meaning); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:55367:                // TODO: Use `setOriginalNode` on original declaration names where possible so these declarations see some kind of
./utilities/ts/node_modules/typescript/lib/tsserver.js:55585:                        // TODO: Issue error via symbol tracker?
./utilities/ts/node_modules/typescript/lib/tsserver.js:55834:                    // TODO: `suppressNewPrivateContext` is questionable -we need to simply be emitting privates in whatever scope they were declared in, rather
./utilities/ts/node_modules/typescript/lib/tsserver.js:55866:                        // TODO: Handle computed names
./utilities/ts/node_modules/typescript/lib/tsserver.js:55911:                        // prop in the outermost scope (TODO: a namespace within a namespace would need to be appropriately handled by this)
./utilities/ts/node_modules/typescript/lib/tsserver.js:55937:                        // TODO: implement handling for the localVsRemoteMap.get("remote") - should be difficult to trigger (see comment above), as only interesting cross-file js merges should make this possible
./utilities/ts/node_modules/typescript/lib/tsserver.js:56144:                            // TODO: Not part of a file's local or export symbol tables
./utilities/ts/node_modules/typescript/lib/tsserver.js:56310:                        !ts.length(getSignaturesOfType(typeToSerialize, 1 /* SignatureKind.Construct */)) && // TODO: could probably serialize as function + ns + class, now that that's OK
./utilities/ts/node_modules/typescript/lib/tsserver.js:56357:                            // TODO: https://github.com/microsoft/TypeScript/pull/32372#discussion_r328386357
./utilities/ts/node_modules/typescript/lib/tsserver.js:56546:                var predicate = ts.factory.createTypePredicateNode(typePredicate.kind === 2 /* TypePredicateKind.AssertsThis */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createToken(129 /* SyntaxKind.AssertsKeyword */) : undefined, typePredicate.kind === 1 /* TypePredicateKind.Identifier */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createIdentifier(typePredicate.parameterName) : ts.factory.createThisTypeNode(), typePredicate.type && nodeBuilder.typeToTypeNode(typePredicate.type, enclosingDeclaration, toNodeBuilderFlags(flags) | 70221824 /* NodeBuilderFlags.IgnoreErrors */ | 512 /* NodeBuilderFlags.WriteTypeParametersInQualifiedName */) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:57418:                    var sourceTypes = ts.some(constructorTypes, function (t) { return !!(t.flags & ~98304 /* TypeFlags.Nullable */); }) ? constructorTypes : types; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:57706:                // TODO: If back compat with pre-3.0/4.0 libs isn't required, remove the following SymbolConstructor special case transforming `symbol` into `unique symbol`
./utilities/ts/node_modules/typescript/lib/tsserver.js:58157:        // TODO: GH#18217 If `checkBase` is undefined, we should not call this because this will always return false.
./utilities/ts/node_modules/typescript/lib/tsserver.js:58184:                node = node.parent; // TODO: GH#18217 Use SourceFile kind check instead
./utilities/ts/node_modules/typescript/lib/tsserver.js:58502:            // TODO: Given that we allow type parmeters here now, is this `!isGenericMappedType(type)` check really needed?
./utilities/ts/node_modules/typescript/lib/tsserver.js:59887:            var constraintDeclaration = getConstraintDeclarationForMappedType(type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:61193:                return getTypeFromTypeNode(declaration.parameters[0].type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:61585:                        // TODO: Adopt same permissive behavior in TS as in JS to reduce follow-on editing experience failures (requires editing fillMissingTypeArguments)
./utilities/ts/node_modules/typescript/lib/tsserver.js:64010:                result.aliasTypeArguments = aliasSymbol ? aliasTypeArguments : instantiateTypes(root.aliasTypeArguments, mapper); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:64122:                // TODO: Future work: support unions/generics/whatever via a deferred import-type
./utilities/ts/node_modules/typescript/lib/tsserver.js:64530:                    // TODO(rbuckton): `NullKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service.
./utilities/ts/node_modules/typescript/lib/tsserver.js:64540:                    // TODO(rbuckton): `ThisKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service and because of `isPartOfTypeNode`.
./utilities/ts/node_modules/typescript/lib/tsserver.js:64598:                // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/tsserver.js:65194:            // TODO(anhans): A block should be context-sensitive if it has a context-sensitive return value.
./utilities/ts/node_modules/typescript/lib/tsserver.js:65736:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/tsserver.js:67024:                            // TODO: Stack errors so we get a pyramid for the "normal" comparison above, _and_ a second for this
./utilities/ts/node_modules/typescript/lib/tsserver.js:67340:                        // TODO: Find a nice way to include potential conditional type breakdowns in error output, if they seem good (they usually don't)
./utilities/ts/node_modules/typescript/lib/tsserver.js:68731:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/tsserver.js:69682:                        // TODO: remove this when we support static private identifier fields and find other solutions to get privateNamesAndStaticFields test to pass
./utilities/ts/node_modules/typescript/lib/tsserver.js:70135:                            // TODO: The `allowComplexConstraintInference` flag is a hack! This forbids inference from complex constraints within constraints!
./utilities/ts/node_modules/typescript/lib/tsserver.js:73603:                    // TODO: Maybe issue a better error than 'object is possibly undefined'
./utilities/ts/node_modules/typescript/lib/tsserver.js:75649:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:75651:            return s; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:76058:                containingType = containingType.isThisType ? getConstraintOfTypeParameter(containingType) : getBaseConstraintOfType(containingType); // TODO: GH#18217 Use a different variable that's allowed to be undefined
./utilities/ts/node_modules/typescript/lib/tsserver.js:76445:                error(errorNode, ts.Diagnostics.Property_0_is_used_before_being_assigned, symbolToString(prop)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:78928:            var resolvedRequire = resolveName(node.expression, node.expression.escapedText, 111551 /* SymbolFlags.Value */, /*nameNotFoundMessage*/ undefined, /*nameArg*/ undefined, /*isUse*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:81859:            // TODO (yuisu): Remove this check in else-if when SyntaxKind.Construct is moved and ambient context is handled
./utilities/ts/node_modules/typescript/lib/tsserver.js:81884:            // TODO(rbuckton): Should we start checking JSDoc types?
./utilities/ts/node_modules/typescript/lib/tsserver.js:82689:                            // TODO: GH#17345: These are methods, so handle computed name case. (`Always allowing computed property names is *not* the correct behavior!)
./utilities/ts/node_modules/typescript/lib/tsserver.js:82979:            var thenFunction = getTypeOfPropertyOfType(type, "then"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:83697:                // TODO: GH#22580
./utilities/ts/node_modules/typescript/lib/tsserver.js:83823:                        //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/tsserver.js:83830:                    //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/tsserver.js:84746:                reportTypeNotIterableError(errorNode, inputType, allowAsyncIterables); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:85470:            // TODO: Check that target label is valid
./utilities/ts/node_modules/typescript/lib/tsserver.js:88886:                var target = getSymbolLinks(symbol).aliasTarget; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:89269:                    accessor = ts.getParseTreeNode(accessor, ts.isGetOrSetAccessorDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:89424:            var moduleSymbol = resolveExternalModuleNameWorker(specifier, specifier, /*moduleNotFoundError*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:89926:                    return grammarErrorOnNode(lastOverride, ts.Diagnostics._0_modifier_cannot_appear_on_a_constructor_declaration, "override"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:91009:            // TODO: The spec needs to be amended to reflect this grammar.
./utilities/ts/node_modules/typescript/lib/tsserver.js:91294:        JsxNames.ElementAttributesPropertyNameContainer = "ElementAttributesProperty"; // TODO: Deprecate and remove support
./utilities/ts/node_modules/typescript/lib/tsserver.js:91378:            // TODO(rbuckton): Remove dependency on `ts.factory` in favor of a provided factory.
./utilities/ts/node_modules/typescript/lib/tsserver.js:92711:        return !getImportNeedsImportStarHelper(node) && (ts.isDefaultImport(node) || (!!node.importClause && ts.isNamedImports(node.importClause.namedBindings) && containsDefaultReference(node.importClause.namedBindings))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:93222:        var target = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:93340:        var bindingTarget = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:93368:            flattenContext.emitBindingOrAssignment(bindingTarget, value, location, /*original*/ element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:94628:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:94631:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:95176:            //      // TODO, blah
./utilities/ts/node_modules/typescript/lib/tsserver.js:95188:            //             // TODO, blah
./utilities/ts/node_modules/typescript/lib/tsserver.js:97038:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:98418:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:98587:            recordDeclarationName(node.variableDeclaration, catchClauseNames); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:98627:            var initializer = node.initializer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:100521:                ? ts.createJsxFactoryExpression(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:100542:            var element = ts.createExpressionForJsxFragment(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), context.getEmitResolver().getJsxFragmentFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:102047:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:102082:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:102300:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:104559:            default: return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:105250:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:105907:            // TODO(rbuckton): `expression` should be required on `throw`.
./utilities/ts/node_modules/typescript/lib/tsserver.js:105945:                    beginCatchBlock(node.catchClause.variableDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:105991:                            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserver.js:107244:            var name = ts.getLocalNameForExternalImport(factory, node, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:108650:            var exportStarFunction = addExportStarIfNeeded(statements); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:108773:                    var importVariableName = ts.getLocalNameForExternalImport(factory, entry, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:108873:                hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:108897:            hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:110367:                // TODO(jfreeman): Deal with computed properties in error reporting.
./utilities/ts/node_modules/typescript/lib/tsserver.js:110776:                // TODO: Do all these accessibility checks inside/after the first pass in the checker when declarations are enabled, if possible
./utilities/ts/node_modules/typescript/lib/tsserver.js:110885:                        return undefined; // Omit declaration files from bundle results, too // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:111082:            return canHaveLiteralInitializer(node) && resolver.isLiteralConstDeclaration(ts.getParseTreeNode(node)); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/tsserver.js:111086:                return resolver.createLiteralConstValue(ts.getParseTreeNode(node), symbolTracker); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/tsserver.js:111184:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:111188:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:111244:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:111659:                                return undefined; // TODO GH#33569: Handle element access expressions that created late bound names (rather than silently omitting them)
./utilities/ts/node_modules/typescript/lib/tsserver.js:111744:                        var id = ts.getOriginalNodeId(inner); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:111823:                        return [statement, cleanup(factory.updateClassDeclaration(input, modifiers, input.name, typeParameters, heritageClauses, members))]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:112324:                // TODO: Remove check and unconditionally use onEmitNode when API is breakingly changed
./utilities/ts/node_modules/typescript/lib/tsserver.js:113612:            writer = _writer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:117333:            var expr = ts.getExternalModuleName(node); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:118227:        // TODO(rbuckton): Should be a `Set` but that requires changing the below code that uses `mutateMap`
./utilities/ts/node_modules/typescript/lib/tsserver.js:118717:            var _a = ts.getLineAndCharacterOfPosition(diagnostic.file, diagnostic.start), line = _a.line, character = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:118803:        var _a = ts.getLineAndCharacterOfPosition(file, start), firstLine = _a.line, firstLineChar = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:118820:                output += formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:118828:                output += formatCodeSpan(diagnostic.file, diagnostic.start, diagnostic.length, "", getCategoryFormat(diagnostic.category), host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:118836:                        output += halfIndent + formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:118837:                        output += formatCodeSpan(file, start, length_9, indent, ForegroundColorEscapeSequences.Cyan, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:119325:        var createProgramOptions = ts.isArray(rootNamesOrOptions) ? createCreateProgramOptions(rootNamesOrOptions, _options, _host, _oldProgram, _configFileParsingDiagnostics) : rootNamesOrOptions; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:119387:            var loader_1 = function (moduleName, resolverMode, containingFileName, redirectedReference) { return ts.resolveModuleName(moduleName, containingFileName, options, host, moduleResolutionCache, redirectedReference, resolverMode).resolvedModule; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:119396:            var loader_2 = function (typesRef, containingFile, redirectedReference, resolutionMode) { return ts.resolveTypeReferenceDirective(typesRef, containingFile, options, host, redirectedReference, typeReferenceDirectiveResolutionCache, resolutionMode).resolvedTypeReferenceDirective; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:119969:                    : host.getSourceFile(oldSourceFile.fileName, sourceFileOptions, /*onError*/ undefined, shouldCreateNewSourceFile || sourceFileOptions.impliedNodeFormat !== oldSourceFile.impliedNodeFormat); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:120418:            var line = ts.computeLineAndCharacterOfPosition(lineStarts, start).line - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:120881:            getSourceFileFromReferenceWorker(fileName, function (fileName) { return findSourceFile(fileName, isDefaultLib, ignoreNoDefaultLib, reason, packageId); }, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:121226:                    processSourceFile(resolvedTypeReferenceDirective.resolvedFileName, /*isDefaultLib*/ false, /*ignoreNoDefaultLib*/ false, resolvedTypeReferenceDirective.packageId, reason); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:122403:                    var fileName = resolvedTypeReferenceDirective.resolvedFileName; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:122960:                var affectedFilesIndex = state.affectedFilesIndex; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:123531:            newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:123546:        newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:124061:        var getCurrentDirectory = ts.memoize(function () { return resolutionHost.getCurrentDirectory(); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:124086:        var rootPath = (rootDir && resolutionHost.toPath(rootDir)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:124520:                setDirectoryWatcher(rootDir, rootPath, /*nonRecursive*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:125049:                // TODO: maybe useful to keep around as an alternative option for certain contexts where the mode is overridable
./utilities/ts/node_modules/typescript/lib/tsserver.js:125773:            diagnostics[0] = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:125841:        host.onUnRecoverableConfigFileDiagnostic = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:126898:            setConfigFileParsingResult(ts.getParsedCommandLineOfConfigFile(configFileName, optionsToExtendForConfigFile, parseConfigFileHost, extendedConfigCache || (extendedConfigCache = new ts.Map()), watchOptionsToExtend, extraFileExtensions)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:127439:        // TODO(rbuckton): Should be a `Set`, but that requires changing the code below that uses `mutateMapSkippingNewValues`
./utilities/ts/node_modules/typescript/lib/tsserver.js:129796:                // case SyntaxKind.ThisType: TODO: GH#9267
./utilities/ts/node_modules/typescript/lib/tsserver.js:133269:                return undefined; // TODO: GH#18217 Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/tsserver.js:133531:            default: return undefined; // TODO: GH#18217 throw Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/tsserver.js:133610:                        // TODO: Maybe we should classify these.
./utilities/ts/node_modules/typescript/lib/tsserver.js:133623:                    // TODO: This should be predicated on `token["kind"]` being compatible with `HasJSDoc["kind"]`
./utilities/ts/node_modules/typescript/lib/tsserver.js:133922:                // TODO: we should get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/tsserver.js:133926:                // TODO (drosen): we should *also* get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/tsserver.js:134597:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:135648:            // TODO(drosen): Right now we just permit *all* semantic meanings when calling
./utilities/ts/node_modules/typescript/lib/tsserver.js:135674:            // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/tsserver.js:136267:                    return createCompletionDetailsForSymbol(symbol, typeChecker, sourceFile, location, cancellationToken, codeActions, sourceDisplay); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:136371:                            return checker.getContextualType(parent.initializer); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:136411:            var currentToken = ts.getTokenAtPosition(sourceFile, position); // TODO: GH#15853
./utilities/ts/node_modules/typescript/lib/tsserver.js:136412:            // We will check for jsdoc comments with insideComment and getJsDocTagAtPosition. (TODO: that seems rather inefficient to check the same thing so many times.)
./utilities/ts/node_modules/typescript/lib/tsserver.js:137232:                // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/tsserver.js:137513:                var moduleSpecifierSymbol = typeChecker.getSymbolAtLocation(moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:137914:                        // TODO: Account for computed property name
./utilities/ts/node_modules/typescript/lib/tsserver.js:138073:                var contextToken = ts.findPrecedingToken(previousToken.getFullStart(), sourceFile, /*startNode*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:138113:                    // TODO: GH#18169
./utilities/ts/node_modules/typescript/lib/tsserver.js:138381:                    return (isValidKeyword(contextToken.kind) || contextToken.kind === 41 /* SyntaxKind.AsteriskToken */ || ts.isIdentifier(contextToken) && isValidKeyword(ts.stringToToken(contextToken.text))) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:138423:        // TODO: GH#19856 Would like to return `node is Node & { parent: (ClassElement | TypeElement) & { parent: ObjectTypeDeclaration } }` but then compilation takes > 10 minutes
./utilities/ts/node_modules/typescript/lib/tsserver.js:138876:                        // TODO: GH#20090
./utilities/ts/node_modules/typescript/lib/tsserver.js:139270:                    entry.sourceFile = ts.updateLanguageServiceSourceFile(entry.sourceFile, scriptSnapshot, version, scriptSnapshot.getChangeRange(entry.sourceFile.scriptSnapshot)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:139449:                                break; // TODO: GH#23879
./utilities/ts/node_modules/typescript/lib/tsserver.js:139526:                indirectUserDeclarations.push(sourceFileLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:141150:                return exposedByParent ? scope.getSourceFile() : scope; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:141234:                /// TODO: Cache symbol existence for files to save text search
./utilities/ts/node_modules/typescript/lib/tsserver.js:142745:                    // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:142814:        for (var _i = 0, _a = sourceFile.referencedFiles || ts.emptyArray; _i < _a.length; _i++) { // TODO: GH#26162
./utilities/ts/node_modules/typescript/lib/tsserver.js:142867:                return label ? [createDefinitionInfoFromName(typeChecker, label, "label" /* ScriptElementKind.label */, node.text, /*containerName*/ undefined)] : undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:143034:                var file = reference && program.getSourceFile(reference.resolvedFileName); // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:143233:            return __assign(__assign({ fileName: sourceFile.fileName, textSpan: textSpan, kind: symbolKind, name: symbolName, containerKind: undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:143597:                if (jsdoc.tags.some(function (t) { return t !== tag && ts.isJSDocParameterTag(t) && ts.isIdentifier(t.name) && t.name.escapedText === name; }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:143674:            // * TODO: other tags.
./utilities/ts/node_modules/typescript/lib/tsserver.js:143846:                    var importer = checker.getSymbolAtLocation(declaration.name); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:143888:            // TODO(cyrusn): get the gamut of comparisons that VS already uses here.
./utilities/ts/node_modules/typescript/lib/tsserver.js:143904:                // TODO(jfreeman): What should be the containerName when the container has a computed name?
./utilities/ts/node_modules/typescript/lib/tsserver.js:144521:            return ts.compareStringsCaseSensitiveUI(tryGetName(child1.node), tryGetName(child2.node)) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145026:                    coalescedImports.push(updateImportDeclarationAndClause(defaultImport, defaultImport.importClause.name, namespaceImports[0].importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145031:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145035:                    coalescedImports.push(updateImportDeclarationAndClause(namespaceImport, /*name*/ undefined, namespaceImport.importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145048:                        newImportSpecifiers.push(ts.factory.createImportSpecifier(/*isTypeOnly*/ false, ts.factory.createIdentifier("default"), defaultImport.importClause.name)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145062:                        : ts.factory.updateNamedImports(namedImports[0].importClause.namedBindings, sortedImportSpecifiers); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145175:            return ts.factory.updateImportDeclaration(importDeclaration, importDeclaration.modifiers, ts.factory.updateImportClause(importDeclaration.importClause, importDeclaration.importClause.isTypeOnly, name, namedBindings), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:145870:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/tsserver.js:145883:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/tsserver.js:145911:        // TODO: find a way to compute this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/tsserver.js:145916:        // TODO(cyrusn): Find a way to support this for unicode digits.
./utilities/ts/node_modules/typescript/lib/tsserver.js:147020:                    var resolvedSignature = checker.getResolvedSignatureForSignatureHelp(invocation.node, candidates, argumentCount); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:147929:            var file = getSourceFileLike(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:148221:        // TODO(drosen): use contextual SemanticMeaning.
./utilities/ts/node_modules/typescript/lib/tsserver.js:148351:        // TODO(drosen): Currently completion entry details passes the SemanticMeaning.All instead of using semanticMeaning of location
./utilities/ts/node_modules/typescript/lib/tsserver.js:148415:                    signature = typeChecker.getResolvedSignature(callExpressionLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:148490:                            signature = typeChecker.getSignatureFromDeclaration(functionDeclaration_1); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:148587:                            var signature = typeChecker.getSignatureFromDeclaration(declaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:149945:                // TODO
./utilities/ts/node_modules/typescript/lib/tsserver.js:150467:                .filter(function (d) { return ts.rangeOverlapsWithStartEnd(originalRange, d.start, d.start + d.length); }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:150928:                                listDynamicIndentation = getDynamicIndentation(parent, parentStartLine, indentationOnListStartToken, options.indentSize); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:151541:                    return getActualIndentationForListStartLine(containerList, sourceFile, options) + indentSize; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:151588:                        return getIndentationForNodeWorker(current, currentStart, /*ignoreActualIndentationRange*/ undefined, indentationDelta, sourceFile, /*isNextChild*/ true, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:151904:                    return getActualIndentationForListStartLine(containingList, sourceFile, options) + (listIndentsChild ? options.indentSize : 0); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:152012:                        if (!settings.indentMultiLineObjectLiteralBeginningOnBlankLine && sourceFile && childKind === 207 /* SyntaxKind.ObjectLiteralExpression */) { // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:153001:                // TODO: this emits the file, parses it back, then formats it that -- may be a less roundabout way to do this
./utilities/ts/node_modules/typescript/lib/tsserver.js:153340:                || ts.isStatementButNotDeclaration(a) && ts.isStatementButNotDeclaration(b); // TODO: only if b would start with a `(` or `[`
./utilities/ts/node_modules/typescript/lib/tsserver.js:153462:                    // TODO: There's currently no unused diagnostic for this, could be a suggestion
./utilities/ts/node_modules/typescript/lib/tsserver.js:153488:        // Exported for tests only! (TODO: improve tests to not need this)
./utilities/ts/node_modules/typescript/lib/tsserver.js:154445:            // TODO: This does not properly handle `function(new:C, string)` per https://github.com/google/closure-compiler/wiki/Types-in-the-Closure-Type-System#the-javascript-type-language
./utilities/ts/node_modules/typescript/lib/tsserver.js:154451:            var isRest = node.type.kind === 321 /* SyntaxKind.JSDocVariadicType */ && index === node.parent.parameters.length - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:155707:                    // TODO: Maybe we should handle this? See fourslash test `refactorConvertToEs6Module_export_object_shorthand.ts`.
./utilities/ts/node_modules/typescript/lib/tsserver.js:155774:        // TODO: GH#22492 this will cause an error if a change has been made inside the body of the node.
./utilities/ts/node_modules/typescript/lib/tsserver.js:155797:                return makeConst(modifiers, ts.factory.createIdentifier(name), replaceImportUseSites(exported, useSitesToUnqualify)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:156181:        var fixId = "fixClassIncorrectlyImplementsInterface"; // TODO: share a group with fixClassDoesntImplementInheritedAbstractMember?
./utilities/ts/node_modules/typescript/lib/tsserver.js:159339:            // TODO (https://github.com/Microsoft/TypeScript/issues/21246): use shared helper
./utilities/ts/node_modules/typescript/lib/tsserver.js:160023:            changes.replaceNode(sourceFile, oldTypeNode, checker.typeToTypeNode(newType, /*enclosingDeclaration*/ oldTypeNode, /*flags*/ undefined)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:160308:                    return ts.isSetAccessorDeclaration(ts.getContainingFunction(token)) ? ts.Diagnostics.Infer_type_of_0_from_usage : ts.Diagnostics.Infer_parameter_types_from_usage; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:160898:                            // TODO: use getFalsyflagsOfType
./utilities/ts/node_modules/typescript/lib/tsserver.js:161809:                // TODO Handle auto quote preference.
./utilities/ts/node_modules/typescript/lib/tsserver.js:161964:            var leftHead = isStatic ? container.name : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:162022:            /*parameters*/ undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:162182:            var relatedImport = type.symbol.originatingImport; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:162295:            return getDefaultValueFromType(checker, checker.getTypeFromTypeNode(propertyDeclaration.type)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:163980:                var targetRange = rangeToExtract.targetRange; // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:164118:                return { targetRange: { range: getStatementOrExpressionRange(node), facts: rangeFacts, thisNode: thisNode } }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:164227:                                // TODO: GH#18217 Silly to use `errors ||` since it's definitely not defined (see top of `visit`)
./utilities/ts/node_modules/typescript/lib/tsserver.js:164229:                                // Also TODO: GH#19956
./utilities/ts/node_modules/typescript/lib/tsserver.js:164442:                context.cancellationToken.throwIfCancellationRequested(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:164608:                    returnType = checker.typeToTypeNode(contextualType, scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:164673:                        /*modifiers*/ undefined, ts.factory.createVariableDeclarationList([ts.factory.createVariableDeclaration(ts.getSynthesizedDeepClone(variableDeclaration.name), /*exclamationToken*/ undefined, /*type*/ ts.getSynthesizedDeepClone(variableDeclaration.type), /*initializer*/ call)], // TODO (acasey): test binding patterns
./utilities/ts/node_modules/typescript/lib/tsserver.js:164804:                    : checker.typeToTypeNode(checker.getContextualType(node), scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:164820:                        ? ts.factory.createIdentifier(scope.name.getText()) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:164978:                    var lhs = range.facts & RangeFacts.InStaticRegion ? ts.factory.createIdentifier(scope.name.text) : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:165050:                    var body = scope.body; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:165131:                // TODO: GH#18217 `variableAssignments` not possibly undefined!
./utilities/ts/node_modules/typescript/lib/tsserver.js:165201:                        // TODO (https://github.com/Microsoft/TypeScript/issues/18924): allow this
./utilities/ts/node_modules/typescript/lib/tsserver.js:165215:                    var contextualType = checker.getContextualType(targetRange.range); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:166005:                                : ts.skipAlias(checker.getSymbolAtLocation(name), checker); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:166107:                    defaultImport = ts.factory.createIdentifier(ts.symbolNameNoDefault(symbol)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:166565:                    return [decl.name.text]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:166717:                    return ts.emptyArray; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/tsserver.js:166738:                return { edits: [] }; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/tsserver.js:167051:                return ts.isVariableDeclaration(node) && ts.isVarConst(node) && ts.isIdentifier(node.name) && !node.type; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/tsserver.js:168310:                // TODO: GH#16312 Return a ReadonlyArray, avoid copying inheritedDocs
./utilities/ts/node_modules/typescript/lib/tsserver.js:168831:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:169034:        // TODO: GH#18217 frequently asserted as defined
./utilities/ts/node_modules/typescript/lib/tsserver.js:169103:            program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:169112:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:169156:            return ts.Completions.getCompletionEntryDetails(program, log, getValidSourceFile(fileName), position, { name: name, source: source, data: data }, host, (formattingOptions && ts.formatting.getFormatContext(formattingOptions, host)), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:169809:                    //  i.e. 'undefined' in position 3 above means TODO(jason) didn't match.
./utilities/ts/node_modules/typescript/lib/tsserver.js:169828:                    // We don't want to match something like 'TODOBY', so we make sure a non
./utilities/ts/node_modules/typescript/lib/tsserver.js:169844:                // TODO comments can appear in one of the following forms:
./utilities/ts/node_modules/typescript/lib/tsserver.js:169846:                //  1)      // TODO     or  /////////// TODO
./utilities/ts/node_modules/typescript/lib/tsserver.js:169848:                //  2)      /* TODO     or  /********** TODO
./utilities/ts/node_modules/typescript/lib/tsserver.js:169851:                //           *   TODO
./utilities/ts/node_modules/typescript/lib/tsserver.js:169854:                // The following three regexps are used to match the start of the text up to the TODO
./utilities/ts/node_modules/typescript/lib/tsserver.js:169859:                // Match any of the above three TODO comment start regexps.
./utilities/ts/node_modules/typescript/lib/tsserver.js:169861:                // so that we can determine the starting position of the TODO comment match.
./utilities/ts/node_modules/typescript/lib/tsserver.js:169864:                // For example, if the descriptors are "TODO(jason)" and "HACK", then this will be:
./utilities/ts/node_modules/typescript/lib/tsserver.js:169866:                //      (?:(TODO\(jason\))|(HACK))
./utilities/ts/node_modules/typescript/lib/tsserver.js:169876:                // This is the portion of the match we'll return as part of the TODO comment result. We
./utilities/ts/node_modules/typescript/lib/tsserver.js:169881:                // /((?:\/\/+\s*)|(?:\/\*+\s*)|(?:^(?:\s|\*)*))((?:(TODO\(jason\))|(HACK))(?:.*?))(?:$|\*\/)/gim
./utilities/ts/node_modules/typescript/lib/tsserver.js:169886:                //  'i' is for case insensitivity (We do this to match C# TODO comment code).
./utilities/ts/node_modules/typescript/lib/tsserver.js:170075:        return sourceFile.nameTable; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170818:        compilerOptions = ts.fixupCompilerOptions(compilerOptions, diagnostics); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170869:                return null; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170872:            var decoded = JSON.parse(encoded); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170879:                this.scriptSnapshotShim.dispose(); // TODO: GH#18217 Can we just use `if (this.scriptSnapshotShim.dispose)`?
./utilities/ts/node_modules/typescript/lib/tsserver.js:170894:                    var resolutionsInFile = JSON.parse(_this.shimHost.getModuleResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170906:                    var typeDirectivesForFile = JSON.parse(_this.shimHost.getTypeReferenceDirectiveResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170927:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170961:                return this.shimHost.getScriptKind(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:170999:            var pattern = ts.getFileMatcherPatterns(path, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:171020:                this.directoryExists = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:171023:                this.realpath = function (path) { return _this.shimHost.realpath(path); }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:171026:                this.realpath = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:171030:            var pattern = ts.getFileMatcherPatterns(rootDir, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:171683:    /// TODO: this is used by VS, clean this up on both sides of the interface
./utilities/ts/node_modules/typescript/lib/tsserver.js:171691:    // TODO: it should be moved into a namespace though.
./utilities/ts/node_modules/typescript/lib/tsserver.js:171909:                    inferredTypings.set(typingName, undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:172129:        // TODO: Use a const enum (https://github.com/Microsoft/TypeScript/issues/16804)
./utilities/ts/node_modules/typescript/lib/tsserver.js:172216:            return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/tsserver.js:172286:                var before = log && self.host.getMemoryUsage(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:172287:                self.host.gc(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:172289:                    var after = self.host.getMemoryUsage(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:172763:                // TODO: assert this offset is actually on the line
./utilities/ts/node_modules/typescript/lib/tsserver.js:172913:                                project.projectService.realpathToScriptInfos.add(this.realpath, this); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173187:            globalTypingsCacheLocation: undefined // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173224:            // TODO: add more relevant properties
./utilities/ts/node_modules/typescript/lib/tsserver.js:173487:                var result = host.require(resolvedPath, moduleName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173600:                return (info && info.scriptKind); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173605:                return (info && info.getLatestVersion()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173654:                return this.directoryStructureHost.directoryExists(path); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173657:                return this.directoryStructureHost.getDirectories(path); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:173661:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:174217:                this.program = this.languageService.getProgram(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:174911:                // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:175674:                return result; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:175992:                    var fileContent = this.host.readFile(this.typesMapLocation); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:176617:                    this.realpathToScriptInfos.remove(realpath, info); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:177361:                    // TODO(rbuckton): Should we add the file as a root to these as well?
./utilities/ts/node_modules/typescript/lib/tsserver.js:177401:                var compilerOptions = projectRootPath && this.compilerOptionsForInferredProjectsPerProjectRoot.get(projectRootPath) || this.compilerOptionsForInferredProjects; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:177639:                    info = new server.ScriptInfo(this.host, fileName, scriptKind, !!hasMixedContent, path, this.filenameToScriptInfoVersion.get(path)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:177932:                    var info = _this.getScriptInfoForPath(path); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:178112:                var info = this.getOrCreateScriptInfoOpenedByClientForNormalizedPath(fileName, projectRootPath ? this.getNormalizedAbsolutePath(projectRootPath) : this.currentDirectory, fileContent, scriptKind, hasMixedContent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:178787:                for (var _i = 0, _a = this.hostConfiguration.extraFileExtensions; _i < _a.length; _i++) { // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:179244:            var scriptInfo = project.getScriptInfoForNormalizedPath(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:179280:            var start = (diag.file && convertToLocation(ts.getLineAndCharacterOfPosition(diag.file, diag.start))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:179281:            var end = (diag.file && convertToLocation(ts.getLineAndCharacterOfPosition(diag.file, diag.start + diag.length))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:179540:            // TODO: We might end up with a more logical allocation of refs to defs if we pre-sorted the defs by descending ref-count.
./utilities/ts/node_modules/typescript/lib/tsserver.js:179808:                        // TODO: GH#20447 report errors
./utilities/ts/node_modules/typescript/lib/tsserver.js:179813:                        // TODO: GH#20447 report errors
./utilities/ts/node_modules/typescript/lib/tsserver.js:179818:                        // TODO: GH#20447 report errors
./utilities/ts/node_modules/typescript/lib/tsserver.js:179864:                        // TODO: report errors
./utilities/ts/node_modules/typescript/lib/tsserver.js:179914:                        _this.openClientFile(server.toNormalizedPath(request.arguments.file), request.arguments.fileContent, server.convertScriptKindName(request.arguments.scriptKindName), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:180390:                this.doOutput(info, cmdName, reqSeq, /*success*/ !errorMsg, errorMsg); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:180638:                        textSpan: undefined // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:180849:                var start = ls.toLineColumnOffset(fileName, textSpan.start); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:180910:                    return this.getConfigFileDiagnostics(configFile, project, !!args.includeLinePosition); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181010:                return symLinkedProjects ? { projects: projects, symLinkedProjects: symLinkedProjects } : projects; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181224:                // TODO: avoid duplicate code (with formatonkey)
./utilities/ts/node_modules/typescript/lib/tsserver.js:181234:                return languageService.getFormattingEditsForRange(file, args.position, args.endPosition, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181244:                return languageService.getFormattingEditsAfterKeystroke(file, args.position, args.key, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181269:                                hasIndent += formatOptions.tabSize; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181439:                        newText: args.insertString // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181556:                    // TODO (https://github.com/microsoft/TypeScript/issues/47839)
./utilities/ts/node_modules/typescript/lib/tsserver.js:181567:                    // TODO (https://github.com/microsoft/TypeScript/issues/47839)
./utilities/ts/node_modules/typescript/lib/tsserver.js:181693:                // TODO (https://github.com/microsoft/TypeScript/issues/47839)
./utilities/ts/node_modules/typescript/lib/tsserver.js:181828:                var fileNamesInProject = fileNames.filter(function (value) { return !ts.stringContains(value, "lib.d.ts"); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:181845:                        var info = this.projectService.getScriptInfo(fileNameInProject); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:182019:                this.currentRequestId = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:182475:                            var snap = this.versions[this.versionToIndex(i)]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:182616:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:182645:                            deleteLength += lineText.length; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:185690:                        fs.writeSync(this.fd, buf, 0, buf.length, /*position*/ null); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:185827:                return new Logger(substitutedLogFileName, envLogOptions.traceToConsole, logVerbosity); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserver.js:186227:            var typingSafeListLocation = server.findArgument(server.Arguments.TypingSafeListLocation); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:868:        return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:7048:    // TODO: GH#18217 this is used as if it's certainly defined in many places.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:10407:            // TODO: Somehow track edits between file as it was during the creation of sourcemap we have and the current file and
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:12807:            // TODO: Add codePage support for readFile?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:14351:    // TODO: determine what this does before making it public.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:14367:    // TODO: GH#19856 Would like to return `node is Node & { jsDoc: JSDoc[] }` but it causes long compile times
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:15786:                        // TODO (drosen): TaggedTemplateExpressions may eventually support type arguments.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:16275:            // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:16326:            && nodeCanBeDecorated(node, parent, grandparent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:16330:        return nodeIsDecorated(node, parent, grandparent) || childIsDecorated(node, parent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:16336:                return ts.some(node.members, function (m) { return nodeOrChildIsDecorated(m, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:16340:                return ts.some(node.parameters, function (p) { return nodeIsDecorated(p, node, parent); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:17986:        // UpdateExpression:            // TODO: Do we need to investigate the precedence here?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:18019:        // TODO: JSXElement?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:18075:            // TODO: Should prefix `++` and `--` be moved to the `Update` precedence?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:18777:        // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:20407:        // TODO: Should this callback be cached?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22034:                        : expression; // TODO(rbuckton): Verify this assertion holds
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22053:                // TODO(rbuckton): Verify whether this assertion holds.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22056:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22060:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22064:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22075:            // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22084:                    // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22091:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:22098:                // TODO(rbuckton): Verifiy whether `setTextRange` is needed.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:27281:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:29234:    // TODO(rbuckton): Rename to 'isParameterDeclaration'
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:29822:    // TODO(rbuckton): isUnparsedPrologue
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:29827:    // TODO(rbuckton): isUnparsedText
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:29828:    // TODO(rbuckton): isUnparsedInternalText
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:29829:    // TODO(rbuckton): isUnparsedSyntheticReference
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:29843:    // TODO(rbuckton): isInputFiles
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30130:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30135:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30145:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30149:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30164:                /*type*/ undefined, getAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30170:                /*type*/ undefined, setAccessor.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:30188:        /*type*/ undefined, method.body // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:31924:            // TODO: should we separate these branches out?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:33988:                // TODO(rbuckton): Do we need to call `parseExpectedToken` or can we just call `createMissingNode` directly?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:34133:            // TODO(rbuckton): JSDoc parameters don't have names (except `this`/`new`), should we manufacture an empty identifier?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:34142:                // TODO(rbuckton): We never set the type for a JSDocNamepathType. What should we put here?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:36583:                // TODO(rbuckton): Consider manufacturing this when we need to report an error as it is otherwise not useful.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:36875:        // TODO: Review for error recovery
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:37247:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:39148:                    // TODO: Determine whether we should enforce this in the checker.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:39149:                    // TODO: Consider moving the `constraint` to the first type parameter as we could then remove `getEffectiveConstraintOfTypeParameter`.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:39150:                    // TODO: Consider only parsing a single type parameter if there is a constraint.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:39766:            // TODO: The below should be strongly type-guarded and not need casts/explicit annotations, since entryOrList is related to
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:39803:                                // TODO: It's probably fine to issue this diagnostic on all instances of the pragma
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:42207:                            result.set(name, value.map(function (element) { return getNameOfCompilerOptionValue(element, customTypeMap_1); })); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:42654:                // TODO extend type typeAcquisition
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:43271:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:45087:                // TODO: Assert that `resolvedTarget` is actually within the package directory? That's what the spec says.... but I'm not sure we need
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:46068:                //      TODO: Make this a more specific error and decouple it from the exclusion logic.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:46980:                // TODO: bindLogicalExpression is recursive - if we want to handle deeply nested `&&` expressions
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:47450:            var symbol = createSymbol(131072 /* SymbolFlags.Signature */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:48689:                    bindAnonymousDeclaration(node, 262144 /* SymbolFlags.TypeParameter */, getDeclarationName(node)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:51039:                            !checkAndReportErrorForMissingPrefix(errorLocation, name, nameArg) && // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:51216:                        var instanceType = getDeclaredTypeOfSymbol(classSymbol).thisType; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:51708:            var moduleSymbol = resolveExternalModuleName(node, moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:53038:                        // TODO: the below is shared with similar code in `resolveName` - in fact, rephrasing all this symbol
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:53044:                        // TODO: Should this filtered table be cached in some way?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:53447:                var entity = builder(symbol, meaning, enclosingDeclaration, nodeFlags); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:53469:                printer.writeNode(4 /* EmitHint.Unspecified */, sig, /*sourceFile*/ sourceFile, ts.getTrailingSemicolonDeferringWriter(writer)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:53644:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:53834:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:54174:                        return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:54651:                context.tracker.trackSymbol(symbol, context.enclosingDeclaration, meaning); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:55366:                // TODO: Use `setOriginalNode` on original declaration names where possible so these declarations see some kind of
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:55584:                        // TODO: Issue error via symbol tracker?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:55833:                    // TODO: `suppressNewPrivateContext` is questionable -we need to simply be emitting privates in whatever scope they were declared in, rather
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:55865:                        // TODO: Handle computed names
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:55910:                        // prop in the outermost scope (TODO: a namespace within a namespace would need to be appropriately handled by this)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:55936:                        // TODO: implement handling for the localVsRemoteMap.get("remote") - should be difficult to trigger (see comment above), as only interesting cross-file js merges should make this possible
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:56143:                            // TODO: Not part of a file's local or export symbol tables
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:56309:                        !ts.length(getSignaturesOfType(typeToSerialize, 1 /* SignatureKind.Construct */)) && // TODO: could probably serialize as function + ns + class, now that that's OK
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:56356:                            // TODO: https://github.com/microsoft/TypeScript/pull/32372#discussion_r328386357
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:56545:                var predicate = ts.factory.createTypePredicateNode(typePredicate.kind === 2 /* TypePredicateKind.AssertsThis */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createToken(129 /* SyntaxKind.AssertsKeyword */) : undefined, typePredicate.kind === 1 /* TypePredicateKind.Identifier */ || typePredicate.kind === 3 /* TypePredicateKind.AssertsIdentifier */ ? ts.factory.createIdentifier(typePredicate.parameterName) : ts.factory.createThisTypeNode(), typePredicate.type && nodeBuilder.typeToTypeNode(typePredicate.type, enclosingDeclaration, toNodeBuilderFlags(flags) | 70221824 /* NodeBuilderFlags.IgnoreErrors */ | 512 /* NodeBuilderFlags.WriteTypeParametersInQualifiedName */) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:57417:                    var sourceTypes = ts.some(constructorTypes, function (t) { return !!(t.flags & ~98304 /* TypeFlags.Nullable */); }) ? constructorTypes : types; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:57705:                // TODO: If back compat with pre-3.0/4.0 libs isn't required, remove the following SymbolConstructor special case transforming `symbol` into `unique symbol`
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:58156:        // TODO: GH#18217 If `checkBase` is undefined, we should not call this because this will always return false.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:58183:                node = node.parent; // TODO: GH#18217 Use SourceFile kind check instead
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:58501:            // TODO: Given that we allow type parmeters here now, is this `!isGenericMappedType(type)` check really needed?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:59886:            var constraintDeclaration = getConstraintDeclarationForMappedType(type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:61192:                return getTypeFromTypeNode(declaration.parameters[0].type); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:61584:                        // TODO: Adopt same permissive behavior in TS as in JS to reduce follow-on editing experience failures (requires editing fillMissingTypeArguments)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:64009:                result.aliasTypeArguments = aliasSymbol ? aliasTypeArguments : instantiateTypes(root.aliasTypeArguments, mapper); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:64121:                // TODO: Future work: support unions/generics/whatever via a deferred import-type
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:64529:                    // TODO(rbuckton): `NullKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:64539:                    // TODO(rbuckton): `ThisKeyword` is no longer a `TypeNode`, but we defensively allow it here because of incorrect casts in the Language Service and because of `isPartOfTypeNode`.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:64597:                // TODO(rbuckton): These aren't valid TypeNodes, but we treat them as such because of `isPartOfTypeNode`, which returns `true` for things that aren't `TypeNode`s.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:65193:            // TODO(anhans): A block should be context-sensitive if it has a context-sensitive return value.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:65735:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:67023:                            // TODO: Stack errors so we get a pyramid for the "normal" comparison above, _and_ a second for this
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:67339:                        // TODO: Find a nice way to include potential conditional type breakdowns in error output, if they seem good (they usually don't)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:68730:            // TODO (drosen): De-duplicate code between related functions.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:69681:                        // TODO: remove this when we support static private identifier fields and find other solutions to get privateNamesAndStaticFields test to pass
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:70134:                            // TODO: The `allowComplexConstraintInference` flag is a hack! This forbids inference from complex constraints within constraints!
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:73602:                    // TODO: Maybe issue a better error than 'object is possibly undefined'
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:75648:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:75650:            return s; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:76057:                containingType = containingType.isThisType ? getConstraintOfTypeParameter(containingType) : getBaseConstraintOfType(containingType); // TODO: GH#18217 Use a different variable that's allowed to be undefined
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:76444:                error(errorNode, ts.Diagnostics.Property_0_is_used_before_being_assigned, symbolToString(prop)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:78927:            var resolvedRequire = resolveName(node.expression, node.expression.escapedText, 111551 /* SymbolFlags.Value */, /*nameNotFoundMessage*/ undefined, /*nameArg*/ undefined, /*isUse*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:81858:            // TODO (yuisu): Remove this check in else-if when SyntaxKind.Construct is moved and ambient context is handled
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:81883:            // TODO(rbuckton): Should we start checking JSDoc types?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:82688:                            // TODO: GH#17345: These are methods, so handle computed name case. (`Always allowing computed property names is *not* the correct behavior!)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:82978:            var thenFunction = getTypeOfPropertyOfType(type, "then"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:83696:                // TODO: GH#22580
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:83822:                        //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:83829:                    //TODO: following line is possible reason for bug #41974, unusedTypeParameters_TemplateTag
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:84745:                reportTypeNotIterableError(errorNode, inputType, allowAsyncIterables); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:85469:            // TODO: Check that target label is valid
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:88885:                var target = getSymbolLinks(symbol).aliasTarget; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:89268:                    accessor = ts.getParseTreeNode(accessor, ts.isGetOrSetAccessorDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:89423:            var moduleSymbol = resolveExternalModuleNameWorker(specifier, specifier, /*moduleNotFoundError*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:89925:                    return grammarErrorOnNode(lastOverride, ts.Diagnostics._0_modifier_cannot_appear_on_a_constructor_declaration, "override"); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:91008:            // TODO: The spec needs to be amended to reflect this grammar.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:91293:        JsxNames.ElementAttributesPropertyNameContainer = "ElementAttributesProperty"; // TODO: Deprecate and remove support
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:91377:            // TODO(rbuckton): Remove dependency on `ts.factory` in favor of a provided factory.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:92710:        return !getImportNeedsImportStarHelper(node) && (ts.isDefaultImport(node) || (!!node.importClause && ts.isNamedImports(node.importClause.namedBindings) && containsDefaultReference(node.importClause.namedBindings))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:93221:        var target = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:93339:        var bindingTarget = ts.getTargetOfBindingOrAssignmentElement(element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:93367:            flattenContext.emitBindingOrAssignment(bindingTarget, value, location, /*original*/ element); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:94627:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:94630:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:95175:            //      // TODO, blah
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:95187:            //             // TODO, blah
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:97037:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:98417:                        var classAlias = classAliases[declaration.id]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:98586:            recordDeclarationName(node.variableDeclaration, catchClauseNames); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:98626:            var initializer = node.initializer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:100520:                ? ts.createJsxFactoryExpression(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:100541:            var element = ts.createExpressionForJsxFragment(factory, context.getEmitResolver().getJsxFactoryEntity(currentSourceFile), context.getEmitResolver().getJsxFragmentFactoryEntity(currentSourceFile), compilerOptions.reactNamespace, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:102046:                // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:102081:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:102299:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:104558:            default: return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:105249:            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:105906:            // TODO(rbuckton): `expression` should be required on `throw`.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:105944:                    beginCatchBlock(node.catchClause.variableDeclaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:105990:                            // TODO(rbuckton): Does this need to be parented?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:107243:            var name = ts.getLocalNameForExternalImport(factory, node, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:108649:            var exportStarFunction = addExportStarIfNeeded(statements); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:108772:                    var importVariableName = ts.getLocalNameForExternalImport(factory, entry, currentSourceFile); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:108872:                hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:108896:            hoistVariableDeclaration(ts.getLocalNameForExternalImport(factory, node, currentSourceFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:110366:                // TODO(jfreeman): Deal with computed properties in error reporting.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:110775:                // TODO: Do all these accessibility checks inside/after the first pass in the checker when declarations are enabled, if possible
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:110884:                        return undefined; // Omit declaration files from bundle results, too // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111081:            return canHaveLiteralInitializer(node) && resolver.isLiteralConstDeclaration(ts.getParseTreeNode(node)); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111085:                return resolver.createLiteralConstValue(ts.getParseTreeNode(node), symbolTracker); // TODO: Make safe
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111183:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111187:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111243:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111658:                                return undefined; // TODO GH#33569: Handle element access expressions that created late bound names (rather than silently omitting them)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111743:                        var id = ts.getOriginalNodeId(inner); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:111822:                        return [statement, cleanup(factory.updateClassDeclaration(input, modifiers, input.name, typeParameters, heritageClauses, members))]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:112323:                // TODO: Remove check and unconditionally use onEmitNode when API is breakingly changed
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:113611:            writer = _writer; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:117332:            var expr = ts.getExternalModuleName(node); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118226:        // TODO(rbuckton): Should be a `Set` but that requires changing the below code that uses `mutateMap`
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118716:            var _a = ts.getLineAndCharacterOfPosition(diagnostic.file, diagnostic.start), line = _a.line, character = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118802:        var _a = ts.getLineAndCharacterOfPosition(file, start), firstLine = _a.line, firstLineChar = _a.character; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118819:                output += formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118827:                output += formatCodeSpan(diagnostic.file, diagnostic.start, diagnostic.length, "", getCategoryFormat(diagnostic.category), host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118835:                        output += halfIndent + formatLocation(file, start, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:118836:                        output += formatCodeSpan(file, start, length_9, indent, ForegroundColorEscapeSequences.Cyan, host); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:119324:        var createProgramOptions = ts.isArray(rootNamesOrOptions) ? createCreateProgramOptions(rootNamesOrOptions, _options, _host, _oldProgram, _configFileParsingDiagnostics) : rootNamesOrOptions; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:119386:            var loader_1 = function (moduleName, resolverMode, containingFileName, redirectedReference) { return ts.resolveModuleName(moduleName, containingFileName, options, host, moduleResolutionCache, redirectedReference, resolverMode).resolvedModule; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:119395:            var loader_2 = function (typesRef, containingFile, redirectedReference, resolutionMode) { return ts.resolveTypeReferenceDirective(typesRef, containingFile, options, host, redirectedReference, typeReferenceDirectiveResolutionCache, resolutionMode).resolvedTypeReferenceDirective; }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:119968:                    : host.getSourceFile(oldSourceFile.fileName, sourceFileOptions, /*onError*/ undefined, shouldCreateNewSourceFile || sourceFileOptions.impliedNodeFormat !== oldSourceFile.impliedNodeFormat); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:120417:            var line = ts.computeLineAndCharacterOfPosition(lineStarts, start).line - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:120880:            getSourceFileFromReferenceWorker(fileName, function (fileName) { return findSourceFile(fileName, isDefaultLib, ignoreNoDefaultLib, reason, packageId); }, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:121225:                    processSourceFile(resolvedTypeReferenceDirective.resolvedFileName, /*isDefaultLib*/ false, /*ignoreNoDefaultLib*/ false, resolvedTypeReferenceDirective.packageId, reason); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:122402:                    var fileName = resolvedTypeReferenceDirective.resolvedFileName; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:122959:                var affectedFilesIndex = state.affectedFilesIndex; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:123530:            newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:123545:        newProgram = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:124060:        var getCurrentDirectory = ts.memoize(function () { return resolutionHost.getCurrentDirectory(); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:124085:        var rootPath = (rootDir && resolutionHost.toPath(rootDir)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:124519:                setDirectoryWatcher(rootDir, rootPath, /*nonRecursive*/ true); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:125048:                // TODO: maybe useful to keep around as an alternative option for certain contexts where the mode is overridable
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:125772:            diagnostics[0] = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:125840:        host.onUnRecoverableConfigFileDiagnostic = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:126897:            setConfigFileParsingResult(ts.getParsedCommandLineOfConfigFile(configFileName, optionsToExtendForConfigFile, parseConfigFileHost, extendedConfigCache || (extendedConfigCache = new ts.Map()), watchOptionsToExtend, extraFileExtensions)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:127438:        // TODO(rbuckton): Should be a `Set`, but that requires changing the code below that uses `mutateMapSkippingNewValues`
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:129185:                    inferredTypings.set(typingName, undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:130214:                // case SyntaxKind.ThisType: TODO: GH#9267
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:133687:                return undefined; // TODO: GH#18217 Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:133949:            default: return undefined; // TODO: GH#18217 throw Debug.assertNever(type);
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:134028:                        // TODO: Maybe we should classify these.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:134041:                    // TODO: This should be predicated on `token["kind"]` being compatible with `HasJSDoc["kind"]`
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:134340:                // TODO: we should get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:134344:                // TODO (drosen): we should *also* get another classification type for these literals.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:135015:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:136066:            // TODO(drosen): Right now we just permit *all* semantic meanings when calling
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:136092:            // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:136685:                    return createCompletionDetailsForSymbol(symbol, typeChecker, sourceFile, location, cancellationToken, codeActions, sourceDisplay); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:136789:                            return checker.getContextualType(parent.initializer); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:136829:            var currentToken = ts.getTokenAtPosition(sourceFile, position); // TODO: GH#15853
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:136830:            // We will check for jsdoc comments with insideComment and getJsDocTagAtPosition. (TODO: that seems rather inefficient to check the same thing so many times.)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:137650:                // TODO: support JS files.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:137931:                var moduleSpecifierSymbol = typeChecker.getSymbolAtLocation(moduleSpecifier); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:138332:                        // TODO: Account for computed property name
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:138491:                var contextToken = ts.findPrecedingToken(previousToken.getFullStart(), sourceFile, /*startNode*/ undefined); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:138531:                    // TODO: GH#18169
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:138799:                    return (isValidKeyword(contextToken.kind) || contextToken.kind === 41 /* SyntaxKind.AsteriskToken */ || ts.isIdentifier(contextToken) && isValidKeyword(ts.stringToToken(contextToken.text))) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:138841:        // TODO: GH#19856 Would like to return `node is Node & { parent: (ClassElement | TypeElement) & { parent: ObjectTypeDeclaration } }` but then compilation takes > 10 minutes
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:139294:                        // TODO: GH#20090
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:139688:                    entry.sourceFile = ts.updateLanguageServiceSourceFile(entry.sourceFile, scriptSnapshot, version, scriptSnapshot.getChangeRange(entry.sourceFile.scriptSnapshot)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:139867:                                break; // TODO: GH#23879
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:139944:                indirectUserDeclarations.push(sourceFileLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:141568:                return exposedByParent ? scope.getSourceFile() : scope; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:141652:                /// TODO: Cache symbol existence for files to save text search
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:143163:                    // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:143232:        for (var _i = 0, _a = sourceFile.referencedFiles || ts.emptyArray; _i < _a.length; _i++) { // TODO: GH#26162
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:143285:                return label ? [createDefinitionInfoFromName(typeChecker, label, "label" /* ScriptElementKind.label */, node.text, /*containerName*/ undefined)] : undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:143452:                var file = reference && program.getSourceFile(reference.resolvedFileName); // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:143651:            return __assign(__assign({ fileName: sourceFile.fileName, textSpan: textSpan, kind: symbolKind, name: symbolName, containerKind: undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:144015:                if (jsdoc.tags.some(function (t) { return t !== tag && ts.isJSDocParameterTag(t) && ts.isIdentifier(t.name) && t.name.escapedText === name; }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:144092:            // * TODO: other tags.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:144264:                    var importer = checker.getSymbolAtLocation(declaration.name); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:144306:            // TODO(cyrusn): get the gamut of comparisons that VS already uses here.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:144322:                // TODO(jfreeman): What should be the containerName when the container has a computed name?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:144939:            return ts.compareStringsCaseSensitiveUI(tryGetName(child1.node), tryGetName(child2.node)) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:145444:                    coalescedImports.push(updateImportDeclarationAndClause(defaultImport, defaultImport.importClause.name, namespaceImports[0].importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:145449:                }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:145453:                    coalescedImports.push(updateImportDeclarationAndClause(namespaceImport, /*name*/ undefined, namespaceImport.importClause.namedBindings)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:145466:                        newImportSpecifiers.push(ts.factory.createImportSpecifier(/*isTypeOnly*/ false, ts.factory.createIdentifier("default"), defaultImport.importClause.name)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:145480:                        : ts.factory.updateNamedImports(namedImports[0].importClause.namedBindings, sortedImportSpecifiers); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:145593:            return ts.factory.updateImportDeclaration(importDeclaration, importDeclaration.modifiers, ts.factory.updateImportClause(importDeclaration.importClause, importDeclaration.importClause.isTypeOnly, name, namedBindings), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:146288:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:146301:        // TODO: find a way to determine this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:146329:        // TODO: find a way to compute this for any unicode characters in a
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:146334:        // TODO(cyrusn): Find a way to support this for unicode digits.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:147438:                    var resolvedSignature = checker.getResolvedSignatureForSignatureHelp(invocation.node, candidates, argumentCount); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:148347:            var file = getSourceFileLike(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:148639:        // TODO(drosen): use contextual SemanticMeaning.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:148769:        // TODO(drosen): Currently completion entry details passes the SemanticMeaning.All instead of using semanticMeaning of location
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:148833:                    signature = typeChecker.getResolvedSignature(callExpressionLike); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:148908:                            signature = typeChecker.getSignatureFromDeclaration(functionDeclaration_1); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:149005:                            var signature = typeChecker.getSignatureFromDeclaration(declaration); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:150363:                // TODO
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:150885:                .filter(function (d) { return ts.rangeOverlapsWithStartEnd(originalRange, d.start, d.start + d.length); }) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:151346:                                listDynamicIndentation = getDynamicIndentation(parent, parentStartLine, indentationOnListStartToken, options.indentSize); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:151959:                    return getActualIndentationForListStartLine(containerList, sourceFile, options) + indentSize; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:152006:                        return getIndentationForNodeWorker(current, currentStart, /*ignoreActualIndentationRange*/ undefined, indentationDelta, sourceFile, /*isNextChild*/ true, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:152322:                    return getActualIndentationForListStartLine(containingList, sourceFile, options) + (listIndentsChild ? options.indentSize : 0); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:152430:                        if (!settings.indentMultiLineObjectLiteralBeginningOnBlankLine && sourceFile && childKind === 207 /* SyntaxKind.ObjectLiteralExpression */) { // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:153419:                // TODO: this emits the file, parses it back, then formats it that -- may be a less roundabout way to do this
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:153758:                || ts.isStatementButNotDeclaration(a) && ts.isStatementButNotDeclaration(b); // TODO: only if b would start with a `(` or `[`
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:153880:                    // TODO: There's currently no unused diagnostic for this, could be a suggestion
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:153906:        // Exported for tests only! (TODO: improve tests to not need this)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:154863:            // TODO: This does not properly handle `function(new:C, string)` per https://github.com/google/closure-compiler/wiki/Types-in-the-Closure-Type-System#the-javascript-type-language
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:154869:            var isRest = node.type.kind === 321 /* SyntaxKind.JSDocVariadicType */ && index === node.parent.parameters.length - 1; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:156125:                    // TODO: Maybe we should handle this? See fourslash test `refactorConvertToEs6Module_export_object_shorthand.ts`.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:156192:        // TODO: GH#22492 this will cause an error if a change has been made inside the body of the node.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:156215:                return makeConst(modifiers, ts.factory.createIdentifier(name), replaceImportUseSites(exported, useSitesToUnqualify)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:156599:        var fixId = "fixClassIncorrectlyImplementsInterface"; // TODO: share a group with fixClassDoesntImplementInheritedAbstractMember?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:159757:            // TODO (https://github.com/Microsoft/TypeScript/issues/21246): use shared helper
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:160441:            changes.replaceNode(sourceFile, oldTypeNode, checker.typeToTypeNode(newType, /*enclosingDeclaration*/ oldTypeNode, /*flags*/ undefined)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:160726:                    return ts.isSetAccessorDeclaration(ts.getContainingFunction(token)) ? ts.Diagnostics.Infer_type_of_0_from_usage : ts.Diagnostics.Infer_parameter_types_from_usage; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:161316:                            // TODO: use getFalsyflagsOfType
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:162227:                // TODO Handle auto quote preference.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:162382:            var leftHead = isStatic ? container.name : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:162440:            /*parameters*/ undefined, // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:162600:            var relatedImport = type.symbol.originatingImport; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:162713:            return getDefaultValueFromType(checker, checker.getTypeFromTypeNode(propertyDeclaration.type)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:164398:                var targetRange = rangeToExtract.targetRange; // TODO:GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:164536:                return { targetRange: { range: getStatementOrExpressionRange(node), facts: rangeFacts, thisNode: thisNode } }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:164645:                                // TODO: GH#18217 Silly to use `errors ||` since it's definitely not defined (see top of `visit`)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:164647:                                // Also TODO: GH#19956
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:164860:                context.cancellationToken.throwIfCancellationRequested(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165026:                    returnType = checker.typeToTypeNode(contextualType, scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165091:                        /*modifiers*/ undefined, ts.factory.createVariableDeclarationList([ts.factory.createVariableDeclaration(ts.getSynthesizedDeepClone(variableDeclaration.name), /*exclamationToken*/ undefined, /*type*/ ts.getSynthesizedDeepClone(variableDeclaration.type), /*initializer*/ call)], // TODO (acasey): test binding patterns
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165222:                    : checker.typeToTypeNode(checker.getContextualType(node), scope, 1 /* NodeBuilderFlags.NoTruncation */); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165238:                        ? ts.factory.createIdentifier(scope.name.getText()) // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165396:                    var lhs = range.facts & RangeFacts.InStaticRegion ? ts.factory.createIdentifier(scope.name.text) : ts.factory.createThis(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165468:                    var body = scope.body; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165549:                // TODO: GH#18217 `variableAssignments` not possibly undefined!
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165619:                        // TODO (https://github.com/Microsoft/TypeScript/issues/18924): allow this
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:165633:                    var contextualType = checker.getContextualType(targetRange.range); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:166423:                                : ts.skipAlias(checker.getSymbolAtLocation(name), checker); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:166525:                    defaultImport = ts.factory.createIdentifier(ts.symbolNameNoDefault(symbol)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:166983:                    return [decl.name.text]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:167135:                    return ts.emptyArray; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:167156:                return { edits: [] }; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:167469:                return ts.isVariableDeclaration(node) && ts.isVarConst(node) && ts.isIdentifier(node.name) && !node.type; // TODO: GH#30113
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:168728:                // TODO: GH#16312 Return a ReadonlyArray, avoid copying inheritedDocs
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:169249:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:169452:        // TODO: GH#18217 frequently asserted as defined
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:169521:            program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:169530:                program = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:169574:            return ts.Completions.getCompletionEntryDetails(program, log, getValidSourceFile(fileName), position, { name: name, source: source, data: data }, host, (formattingOptions && ts.formatting.getFormatContext(formattingOptions, host)), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170227:                    //  i.e. 'undefined' in position 3 above means TODO(jason) didn't match.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170246:                    // We don't want to match something like 'TODOBY', so we make sure a non
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170262:                // TODO comments can appear in one of the following forms:
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170264:                //  1)      // TODO     or  /////////// TODO
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170266:                //  2)      /* TODO     or  /********** TODO
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170269:                //           *   TODO
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170272:                // The following three regexps are used to match the start of the text up to the TODO
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170277:                // Match any of the above three TODO comment start regexps.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170279:                // so that we can determine the starting position of the TODO comment match.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170282:                // For example, if the descriptors are "TODO(jason)" and "HACK", then this will be:
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170284:                //      (?:(TODO\(jason\))|(HACK))
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170294:                // This is the portion of the match we'll return as part of the TODO comment result. We
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170299:                // /((?:\/\/+\s*)|(?:\/\*+\s*)|(?:^(?:\s|\*)*))((?:(TODO\(jason\))|(HACK))(?:.*?))(?:$|\*\/)/gim
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170304:                //  'i' is for case insensitivity (We do this to match C# TODO comment code).
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:170493:        return sourceFile.nameTable; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171236:        compilerOptions = ts.fixupCompilerOptions(compilerOptions, diagnostics); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171287:                return null; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171290:            var decoded = JSON.parse(encoded); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171297:                this.scriptSnapshotShim.dispose(); // TODO: GH#18217 Can we just use `if (this.scriptSnapshotShim.dispose)`?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171312:                    var resolutionsInFile = JSON.parse(_this.shimHost.getModuleResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171324:                    var typeDirectivesForFile = JSON.parse(_this.shimHost.getTypeReferenceDirectiveResolutionsForFile(containingFile)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171345:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171379:                return this.shimHost.getScriptKind(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171417:            var pattern = ts.getFileMatcherPatterns(path, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171438:                this.directoryExists = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171441:                this.realpath = function (path) { return _this.shimHost.realpath(path); }; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171444:                this.realpath = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:171448:            var pattern = ts.getFileMatcherPatterns(rootDir, exclude, include, this.shimHost.useCaseSensitiveFileNames(), this.shimHost.getCurrentDirectory()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172101:    /// TODO: this is used by VS, clean this up on both sides of the interface
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172109:    // TODO: it should be moved into a namespace though.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172128:        // TODO: Use a const enum (https://github.com/Microsoft/TypeScript/issues/16804)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172215:            return []; // TODO: GH#19873
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172285:                var before = log && self.host.getMemoryUsage(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172286:                self.host.gc(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172288:                    var after = self.host.getMemoryUsage(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172762:                // TODO: assert this offset is actually on the line
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:172912:                                project.projectService.realpathToScriptInfos.add(this.realpath, this); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173186:            globalTypingsCacheLocation: undefined // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173223:            // TODO: add more relevant properties
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173486:                var result = host.require(resolvedPath, moduleName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173599:                return (info && info.scriptKind); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173604:                return (info && info.getLatestVersion()); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173653:                return this.directoryStructureHost.directoryExists(path); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173656:                return this.directoryStructureHost.getDirectories(path); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:173660:                return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:174216:                this.program = this.languageService.getProgram(); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:174910:                // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:175673:                return result; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:175991:                    var fileContent = this.host.readFile(this.typesMapLocation); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:176616:                    this.realpathToScriptInfos.remove(realpath, info); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:177360:                    // TODO(rbuckton): Should we add the file as a root to these as well?
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:177400:                var compilerOptions = projectRootPath && this.compilerOptionsForInferredProjectsPerProjectRoot.get(projectRootPath) || this.compilerOptionsForInferredProjects; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:177638:                    info = new server.ScriptInfo(this.host, fileName, scriptKind, !!hasMixedContent, path, this.filenameToScriptInfoVersion.get(path)); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:177931:                    var info = _this.getScriptInfoForPath(path); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:178111:                var info = this.getOrCreateScriptInfoOpenedByClientForNormalizedPath(fileName, projectRootPath ? this.getNormalizedAbsolutePath(projectRootPath) : this.currentDirectory, fileContent, scriptKind, hasMixedContent); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:178786:                for (var _i = 0, _a = this.hostConfiguration.extraFileExtensions; _i < _a.length; _i++) { // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179243:            var scriptInfo = project.getScriptInfoForNormalizedPath(fileName); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179279:            var start = (diag.file && convertToLocation(ts.getLineAndCharacterOfPosition(diag.file, diag.start))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179280:            var end = (diag.file && convertToLocation(ts.getLineAndCharacterOfPosition(diag.file, diag.start + diag.length))); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179539:            // TODO: We might end up with a more logical allocation of refs to defs if we pre-sorted the defs by descending ref-count.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179807:                        // TODO: GH#20447 report errors
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179812:                        // TODO: GH#20447 report errors
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179817:                        // TODO: GH#20447 report errors
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179863:                        // TODO: report errors
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:179913:                        _this.openClientFile(server.toNormalizedPath(request.arguments.file), request.arguments.fileContent, server.convertScriptKindName(request.arguments.scriptKindName), // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:180389:                this.doOutput(info, cmdName, reqSeq, /*success*/ !errorMsg, errorMsg); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:180637:                        textSpan: undefined // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:180848:                var start = ls.toLineColumnOffset(fileName, textSpan.start); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:180909:                    return this.getConfigFileDiagnostics(configFile, project, !!args.includeLinePosition); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181009:                return symLinkedProjects ? { projects: projects, symLinkedProjects: symLinkedProjects } : projects; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181223:                // TODO: avoid duplicate code (with formatonkey)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181233:                return languageService.getFormattingEditsForRange(file, args.position, args.endPosition, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181243:                return languageService.getFormattingEditsAfterKeystroke(file, args.position, args.key, options); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181268:                                hasIndent += formatOptions.tabSize; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181438:                        newText: args.insertString // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181555:                    // TODO (https://github.com/microsoft/TypeScript/issues/47839)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181566:                    // TODO (https://github.com/microsoft/TypeScript/issues/47839)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181692:                // TODO (https://github.com/microsoft/TypeScript/issues/47839)
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181827:                var fileNamesInProject = fileNames.filter(function (value) { return !ts.stringContains(value, "lib.d.ts"); }); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:181844:                        var info = this.projectService.getScriptInfo(fileNameInProject); // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:182018:                this.currentRequestId = undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:182474:                            var snap = this.versions[this.versionToIndex(i)]; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:182615:                    return undefined; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:182644:                            deleteLength += lineText.length; // TODO: GH#18217
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.d.ts:7331:     * A request to get TODO comments from the file
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.d.ts:7342:         * Array of target TodoCommentDescriptors that describes TODO comments to be found
./utilities/ts/node_modules/fast-xml-parser/src/v5/valueParsers/booleanParser.js:15:            //TODO: performance: don't convert
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsArrBuilder.js:37:    //TODO: shift this check to the parser
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsArrBuilder.js:54:      //TODO TagPathMatcher 
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsArrBuilder.js:79:    //TODO: set pi flag
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/BaseOutputBuilder.js:8:      //TODO: better to pass tag path
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsObjBuilder.js:84:      //TODO TagPathMatcher 
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsObjBuilder.js:129:    //TODO: use bytes join
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/ParserOptionsBuilder.js:43://TODO
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsMinArrBuilder.js:38:    //TODO: shift this check to the parser
./utilities/ts/node_modules/fast-xml-parser/src/v5/OutputBuilders/JsMinArrBuilder.js:63:      //TODO TagPathMatcher 
./utilities/ts/node_modules/fast-xml-parser/src/v5/XmlPartReader.js:138:    //TODO: use regex to verify attributes if not set to ignore
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:45:      //TODO: Separate TagValueParser as separate class. So no scope issue in node builder class 
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:120:        //TODO: this will lead 2 extra stack operation
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:127:        // TODO: let's user set a stop node boundary detector for complex contents like script tag
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:128:        //TODO: pass tag name only to avoid string operations
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:168:            //TODO: shift parsing to output builder
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:193:      //TODO: return TagPath Object. User can call match method with path
./utilities/ts/node_modules/fast-xml-parser/src/v5/Xml2JsParser.js:221:      //TODO: if option is set then replace entities
./utilities/ts/node_modules/fast-xml-parser/src/v5/XmlSpecialTagsReader.js:18:  if (tagExp.tagName === "?xml") {//TODO: test if tagName is just xml
./utilities/ts/node_modules/fast-xml-parser/src/v5/XmlSpecialTagsReader.js:49:    //TODO: use readChAt like used in partReader
./utilities/ts/node_modules/fast-xml-parser/src/v5/inputSource/StringSource.js:98:      //   //TODO: handle the scenario when there are multiple lines
./utilities/ts/node_modules/fast-xml-parser/src/v5/inputSource/StringSource.js:99:      //   //TODO: col should be set to number of chars after last '\n'
./utilities/ts/node_modules/fast-xml-parser/src/v5/inputSource/StringSource.js:110:  //TODO: rename to updateBufferReadIndex
./utilities/ts/node_modules/fast-xml-parser/src/v5/inputSource/BufferSource.js:64:            else if(this.buffer[i] === '>'){ //TODO: if it should be equivalent ASCII
./utilities/ts/node_modules/fast-xml-parser/src/xmlparser/OrderedObjParser.js:123://TODO: change regex to capture NS
./utilities/ts/node_modules/fast-xml-parser/src/xmlparser/OrderedObjParser.js:182:  xmlData = xmlData.replace(/\r\n?/g, "\n"); //TODO: remove this line
./utilities/ts/node_modules/fast-xml-parser/src/xmlparser/OrderedObjParser.js:443://TODO: use jPath to simplify the logic
./utilities/ts/node_modules/fast-xml-parser/src/xmlparser/node2json.js:55:        //TODO: if a node is not an array, then check if it should be an array
./utilities/ts/node_modules/fast-xml-parser/src/xmlparser/DocTypeReader.js:3://TODO: handle comments
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/ts3.4/HeaderFormatter.d.ts:4: * TODO: duplicated from @smithy/eventstream-codec to break large dependency.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/ts3.4/HeaderFormatter.d.ts:5: * TODO: This should be moved to its own deduped submodule in @smithy/core when submodules are implemented.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/ts3.4/HeaderFormatter.d.ts:12: * TODO: duplicated from @smithy/eventstream-codec to break large dependency.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/ts3.4/HeaderFormatter.d.ts:13: * TODO: This should be moved to its own deduped submodule in @smithy/core when submodules are implemented.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/HeaderFormatter.d.ts:4: * TODO: duplicated from @smithy/eventstream-codec to break large dependency.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/HeaderFormatter.d.ts:5: * TODO: This should be moved to its own deduped submodule in @smithy/core when submodules are implemented.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/HeaderFormatter.d.ts:12: * TODO: duplicated from @smithy/eventstream-codec to break large dependency.
./utilities/ts/node_modules/@smithy/signature-v4/dist-types/HeaderFormatter.d.ts:13: * TODO: This should be moved to its own deduped submodule in @smithy/core when submodules are implemented.
./utilities/ts/node_modules/@aws-sdk/nested-clients/dist-cjs/submodules/sts/index.js:849:      // TODO(credentialScope): access normally when shape is updated.
./utilities/ts/node_modules/@aws-sdk/nested-clients/dist-cjs/submodules/sts/index.js:890:      // TODO(credentialScope): access normally when shape is updated.
./utilities/ts/node_modules/@aws-sdk/credential-provider-ini/dist-types/resolveAssumeRoleCredentials.d.ts:7: * TODO update the above to link to V3 docs
./utilities/ts/node_modules/@aws-sdk/middleware-sdk-s3/dist-types/s3-express/constants.d.ts:7: * TODO(s3-express): non-beta value, backend == S3Express.
./utilities/ts/node_modules/yn/index.js:32:// TODO: Remove this for the next major release
./utilities/ts/node_modules/yn/index.d.ts:58:	// TODO: Remove this for the next major release, refactor the whole definition to:
./utilities/ts/node_modules/pg/lib/query.js:210:    // TODO refactor this poor encapsulation
./utilities/ts/node_modules/pg/lib/native/client.js:37:  // for the time being. TODO: deprecate all this jazz
./utilities/ts/node_modules/pg/lib/connection.js:12:// TODO(bmc) support binary mode at some point
./utilities/ts/node_modules/pg/lib/client.js:206:  // TODO(bmc): deprecate pgpass "built in" integration since this.password can be a function
./utilities/ts/node_modules/pg/lib/client.js:330:      // TODO(bmc): this is swallowing errors - we shouldn't do this
./utilities/ts/node_modules/ts-node/dist-raw/node-internal-modules-cjs-helpers.js:20:// TODO: Use this set when resolving pkg#exports conditions in loader.js.
./utilities/ts/node_modules/ts-node/dist-raw/node-internal-modules-esm-resolve.js:92:// TODO receive cached fs implementations here
./utilities/ts/node_modules/ts-node/dist-raw/node-options.js:50:    // TODO: handle errors somehow
./utilities/ts/node_modules/ts-node/dist-raw/node-internal-modules-cjs-loader.js:179:      // TODO(BridgeAR): Add the requireStack as well.
./utilities/ts/node_modules/ts-node/dist-raw/node-internal-modules-cjs-loader.js:547:  // TODO(BridgeAR): Add the requireStack as well.
./utilities/ts/node_modules/ts-node/dist/util.js:135:    // TODO technically breaks if projectOption is path to a file, not a directory,
./utilities/ts/node_modules/ts-node/dist/transpilers/swc.js:107:    // TODO cache the results of this; slightly faster
./utilities/ts/node_modules/ts-node/dist/configuration.js:303:    const exclude = _exclude !== null && _exclude !== void 0 ? _exclude : [outDir]; // TODO technically, outDir is absolute path, but exclude should be relative glob pattern?
./utilities/ts/node_modules/ts-node/dist/configuration.js:304:    // TODO compute baseUrl
./utilities/ts/node_modules/ts-node/dist/esm.js:103:                // TODO file://./foo sets `hostname` to `'.'`.  Perhaps we should special-case this.
./utilities/ts/node_modules/ts-node/dist/bin.js:454:    // TODO this comes from BootstrapState
./utilities/ts/node_modules/ts-node/dist/index.js:227:        // TODO switch to getCanonicalFileName we already create later in scope
./utilities/ts/node_modules/ts-node/dist/index.js:390:                    // TODO ordering of this with getScriptVersion?  Should they sync up?
./utilities/ts/node_modules/ts-node/dist/repl.js:126:        // TODO: Figure out how to handle completion here.
./utilities/ts/node_modules/ts-node/dist/repl.js:156:        // TODO should evalCode API get the same error-handling benefits?
./utilities/ts/node_modules/ts-node/dist/repl.js:203:        // TODO assert that `service` is set; remove all `service!` non-null assertions
./utilities/ts/node_modules/ts-node/dist/resolver-functions.js:101:        // TODO consider using `ts.loadWithTypeDirectiveCache`
./utilities/ts/node_modules/@types/node/fs/promises.d.ts:94:    // TODO: Add `EventEmitter` close
./utilities/ts/node_modules/@types/node/util.d.ts:107:    export type CustomInspectFunction = (depth: number, options: InspectOptionsStylized) => any; // TODO: , inspect: inspect
./utilities/ts/node_modules/@types/node/perf_hooks.d.ts:97:        readonly detail?: NodeGCPerformanceDetail | unknown | undefined; // TODO: Narrow this based on entry type.
./utilities/ts/node_modules/@types/node/test.d.ts:74:         * Shorthand for marking a suite as `TODO`, same as `describe([name], { todo: true }[, fn])`.
./utilities/ts/node_modules/@types/node/test.d.ts:111:         * Shorthand for marking a test as `TODO`, same as `it([name], { todo: true }[, fn])`.
./utilities/ts/node_modules/@types/node/test.d.ts:135:     * Shorthand for marking a test as `TODO`, same as `test([name], { todo: true }[, fn])`.
./utilities/ts/node_modules/@types/node/test.d.ts:391:         * This function adds a `TODO` directive to the test's output. If `message` is provided, it is
./utilities/ts/node_modules/@types/node/test.d.ts:394:         * @param message Optional `TODO` message.
./utilities/ts/node_modules/@types/node/test.d.ts:476:         * If truthy, the test marked as `TODO`. If a string is provided, that string is displayed in
./utilities/ts/node_modules/@types/node/test.d.ts:477:         * the test results as the reason why the test is `TODO`.
./utilities/ts/node_modules/@types/node/events.d.ts:425:        // TODO: These should be described using static getter/setter pairs:
./utilities/ts/node_modules/@types/node/wasi.d.ts:138:        start(instance: object): number; // TODO: avoid DOM dependency until WASM moved to own lib.
./utilities/ts/node_modules/@types/node/wasi.d.ts:148:        initialize(instance: object): void; // TODO: avoid DOM dependency until WASM moved to own lib.
./utilities/ts/node_modules/@types/node/wasi.d.ts:155:        readonly wasiImport: NodeJS.Dict<any>; // TODO: Narrow to DOM types
./utilities/ts/node_modules/pg-protocol/src/parser.ts:309:    // TODO(bmc): maybe better types here
./utilities/ts/node_modules/pg-protocol/src/buffer-reader.ts:6:  // TODO(bmc): support non-utf8 encoding?
./utilities/ts/node_modules/pg-protocol/dist/parser.js:230:        // TODO(bmc): maybe better types here
./utilities/ts/node_modules/pg-protocol/dist/buffer-reader.js:9:        // TODO(bmc): support non-utf8 encoding?
./utilities/ts/node_modules/pg-pool/index.js:60:    // TODO - document that once the pool emits an error
./utilities/ts/node_modules/pg-pool/index.js:349:    // TODO(bmc): expose a proper, public interface _queryable and _ending
./.venv/lib/python3.12/site-packages/anyio/_core/_fileio.py:416:        def info(self) -> Any:  # TODO: add return type annotation when Typeshed gets it
./.venv/lib/python3.12/site-packages/uvicorn/protocols/websockets/wsproto_impl.py:120:            # TODO: Remove `type: ignore` when wsproto fixes the type annotation.
./.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:274:            # TODO: we don't go through the rebuild logic here directly because we don't want
./.venv/lib/python3.12/site-packages/pydantic/fields.py:55:    # TODO PEP 747: use TypeForm:
./.venv/lib/python3.12/site-packages/pydantic/fields.py:333:        # TODO check for classvar and error?
./.venv/lib/python3.12/site-packages/pydantic/fields.py:411:        # TODO check for classvar and error?
./.venv/lib/python3.12/site-packages/pydantic/fields.py:413:        # TODO infer from the default, this can be done in v3 once we treat final fields with
./.venv/lib/python3.12/site-packages/pydantic/fields.py:720:            # TODO: properly make use of the protocol (https://rich.readthedocs.io/en/stable/pretty.html#rich-repr-protocol)
./.venv/lib/python3.12/site-packages/pydantic/fields.py:797:    default: ellipsis,  # noqa: F821  # TODO: use `_typing_extra.EllipsisType` when we drop Py3.9
./.venv/lib/python3.12/site-packages/pydantic/deprecated/json.py:112:# TODO: Add a suggested migration path once there is a way to use custom encoders
./.venv/lib/python3.12/site-packages/pydantic/alias_generators.py:7:# TODO: in V3, change the argument names to be more descriptive
./.venv/lib/python3.12/site-packages/pydantic/functional_validators.py:213:            # TODO if `schema['serialization']` is one of `'include-exclude-dict/sequence',
./.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:124:# TODO: ultimately, make this public, see https://github.com/pydantic/pydantic/pull/9459#discussion_r1628197626
./.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:592:            # TODO: is there a better way? should we just not do this?
./.venv/lib/python3.12/site-packages/pydantic/dataclasses.py:277:        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:303:        # TODO: in theory we should check that the schema accepts a serialization key
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:407:            # TODO this is an ugly hack, how do we trigger an Any schema for serialization?
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:613:        # TODO: note, this is a fairly common pattern, re lax / strict for attempted type coercion,
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1724:        # TODO: do we really need to resolve type vars here?
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1743:                # TODO: something like https://github.com/pydantic/pydantic/issues/5952
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2005:        TODO support functional validators once we support them in Config
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2511:# TODO V3: this function is only used for deprecated decorators. It should
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:235:    # TODO: This could be unified with `get_standard_typevars_map` if we stored the generic metadata
./.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:276:        # TODO remove parentheses when we drop support for Python 3.10:
./.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:91:    # TODO When we drop 3.9, use a match statement to get better type checking and remove
./.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:170:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:176:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./.venv/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py:83:    # TODO: this is a bit redundant, we could probably avoid some of these
./.venv/lib/python3.12/site-packages/pydantic/_internal/_validators.py:44:    # TODO: refactor sequence validation to validate with either a list or a tuple
./.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:139:# TODO implement `is_finalvar_annotation` as Final can be wrapped with other special forms:
./.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:186:# TODO In 2.12, delete this export. It is currently defined only to not break
./.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:195:# TODO: Ideally, we should avoid relying on the private `typing` constructs:
./.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:445:        # TODO ideally recursion errors should be checked in `eval_type` above, but `eval_type_backport`
./.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:230:                # TODO we can also stop there if `__pydantic_fields_complete__` is False.
./.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:29:    TODO: Perhaps we should move this structure to pydantic-core. At the moment, though,
./.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:32:    TODO: It's unfortunate how functionally oriented JSON schema generation is, especially that which occurs during
./.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:236:            # TODO: should we merge the parent namespace here?
./.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:263:        # TODO `typ.__type_params__` when we drop support for Python 3.11:
./.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:394:                    # TODO: We should probably do something with this so that validate_assignment behaves properly
./.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:406:                        # TODO: same note as above re validate_assignment
./.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:433:            # was already evaluated. TODO: is this method relevant?
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:436:        TODO: the nested function definitions here seem like bad practice, I'd like to unpack these
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:505:        # TODO: I dislike that we have to wrap these basic dict updates in callables, is there any way around this?
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:713:            # TODO: should we add regex flags to the pattern?
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1117:        # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1240:        # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1281:                        # TODO: fixme - this is a workaround for the fact that we can't always resolve refs
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1320:        # TODO: Need to read the default value off of model config or whatever
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1321:        use_strict = schema.get('strict', False)  # TODO: replace this default False
./.venv/lib/python3.12/site-packages/pydantic/v1/utils.py:270:            # TODO: replace annotation with actual expected types once #1055 solved
./.venv/lib/python3.12/site-packages/pydantic/v1/networks.py:535:    # TODO: Needed to generic "Parts" for "Replica Set", "Sharded Cluster", and other mongodb deployment modes
./.venv/lib/python3.12/site-packages/pydantic/mypy.py:513:                    # TODO: Only do this if the first argument of the decorated function is `cls`
./.venv/lib/python3.12/site-packages/pydantic/mypy.py:622:                # TODO: We shouldn't be performing type operations during the main
./.venv/lib/python3.12/site-packages/pydantic/mypy.py:785:            # TODO this path should be removed (see https://github.com/pydantic/pydantic/issues/11119)
./.venv/lib/python3.12/site-packages/pydantic/main.py:4:# TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.
./.venv/lib/python3.12/site-packages/pydantic/main.py:1043:                    # TODO - matching error
./.venv/lib/python3.12/site-packages/pydantic/main.py:1689:    # TODO PEP 747: replace `Any` by the TypeForm:
./.venv/lib/python3.12/site-packages/pygments/formatters/terminal256.py:17:# TODO:
./.venv/lib/python3.12/site-packages/pygments/formatters/latex.py:334:        # TODO: add support for background colors
./.venv/lib/python3.12/site-packages/pygments/formatters/img.py:548:            # TODO: make sure tab expansion happens earlier in the chain.  It
./.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:445:            # TODO: these don't match the comments in docs, remove.
./.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:130:                # TODO unsure if ellipses are allowed elsewhere, see
./.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./.venv/lib/python3.12/site-packages/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./.venv/lib/python3.12/site-packages/pygments/lexers/textfmts.py:240:    # TODO: Make date regex more ISO 8601 compliant
./.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:755:            # TODO support other Python syntax like $foo['bar']
./.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:123:            # TODO: we should probably escape also here ''${ \${
./.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:135:        # TODO: let/in
./.venv/lib/python3.12/site-packages/pygments/lexers/ada.py:116:            # TODO: use Name.Namespace if appropriate.  This needs
./.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:150:            # TODO: better logging
./.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:347:                # TODO: better handle multiline comments at the end with
./.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:588:            # TODO: Backslash escapes?
./.venv/lib/python3.12/site-packages/pygments/lexers/mips.py:28:    # TODO: add '*.s' and '*.asm', which will require designing an analyse_text
./.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:886:    # TODO / should divide keywords/symbols into namespace/rest
./.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:1341:            (r'\S+\s+', Text)   # TODO: make tests pass without \s+
./.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:390:            # TODO: Treat context-depedendent names specially
./.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:396:            # TODO: templates start and end tokens.
./.venv/lib/python3.12/site-packages/pygments/lexers/urbi.py:34:    # TODO
./.venv/lib/python3.12/site-packages/pygments/lexers/dns.py:53:            # TODO, $GENERATE https://bind9.readthedocs.io/en/v9.18.14/chapter3.html#soa-rr
./.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:27:    # TODO String interpolation @VARNAME@ inner matches
./.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:28:    # TODO keyword_arg: value inner matches
./.venv/lib/python3.12/site-packages/pygments/lexers/perl.py:35:    # TODO: give this to a perl guy who knows how to parse perl...
./.venv/lib/python3.12/site-packages/pygments/lexers/_asy_builtins.py:9:    TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
./.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:140:            # TODO: regexes can have other delims
./.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:191:        # TODO: builtins are only subsequent tokens on lines
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:648:            (r'^(\* )(TODO)( .*)',
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:650:            (r'^(\*\*+ )(TODO)( .*)',
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:656:            # Unordered lists items, including TODO items and description items
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:672:            # TODO: language-dependent syntax highlighting (see Markdown lexer)
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:701:            (_inline(r'=', r'='), String), # TODO token
./.venv/lib/python3.12/site-packages/pygments/lexers/javascript.py:133:            # TODO: should this include single-line comments and allow nesting strings?
./.venv/lib/python3.12/site-packages/pygments/lexers/testing.py:200:            (r'(?i)\bTODO\b', Comment.Preproc),
./.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:49:            # TODO: highlight references in fandocs
./.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:85:        'insideUri': [  # TODO: remove copy/paste str/uri
./.venv/lib/python3.12/site-packages/pygments/lexers/c_like.py:212:            # TODO: "correctly" parse complex code attributes
./.venv/lib/python3.12/site-packages/pygments/lexers/modula2.py:474:        'TODO', 'FFI', 'ADDR', 'VARGLIST', 'VARGC',
./.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:24:    TODO:
./.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:85:# TODO:
./.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:123:                "varname",  # TODO varname the right fit?
./.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:273:                        "async for",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:274:                        "async with",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:702:        # TODO supported?
./.venv/lib/python3.12/site-packages/pygments/lexers/parsers.py:396:            # TODO finish implementing other possibilities for scope
./.venv/lib/python3.12/site-packages/pygments/lexers/css.py:555:            # TODO: broken, and prone to infinite loops.
./.venv/lib/python3.12/site-packages/pygments/lexers/rnc.py:36:            # TODO single quoted strings and escape sequences outside of
./.venv/lib/python3.12/site-packages/pygments/lexers/scripting.py:1502:            # TODO: JES3 statement
./.venv/lib/python3.12/site-packages/pygments/lexers/oberon.py:50:            # TODO: nested comments (* (* ... *) ... (* ... *) *) not supported!
./.venv/lib/python3.12/site-packages/pygments/lexers/dotnet.py:558:# TODO support multiple languages within the same source file
./.venv/lib/python3.12/site-packages/pygments/lexer.py:861:    TODO: clean up the code here.
./.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./.venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9:# TODO: remove this check when dropping Python 3.7 support
./.venv/lib/python3.12/site-packages/click/_termui_impl.py:525:    # TODO: This never terminates if the passed generator never terminates.
./.venv/lib/python3.12/site-packages/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./.venv/lib/python3.12/site-packages/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./.venv/lib/python3.12/site-packages/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./.venv/lib/python3.12/site-packages/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./.venv/lib/python3.12/site-packages/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./.venv/lib/python3.12/site-packages/ecdsa/keys.py:1079:                # TODO parse attributes or validate publickey
./.venv/lib/python3.12/site-packages/ecdsa/keys.py:1204:        # TODO: "BEGIN ECPARAMETERS"
./.venv/lib/python3.12/site-packages/prometheus_client/metrics_core.py:330:            # TODO: Handle None gsum_value correctly. Currently a None will fail exposition but is allowed here.
./.venv/lib/python3.12/site-packages/prometheus_client/values.py:113:            # TODO: Implement exemplars for multiprocess mode.
./.venv/lib/python3.12/site-packages/prometheus_client/values.py:122:            # TODO: Implement exemplars for multiprocess mode.
./.venv/lib/python3.12/site-packages/prometheus_client/openmetrics/parser.py:503:        # TODO: check labelvalues are valid utf8
./.venv/lib/python3.12/site-packages/pluggy/_hooks.py:411:        # TODO: Document, or make private.
./.venv/lib/python3.12/site-packages/pluggy/_hooks.py:417:    # TODO: Document, or make private.
./.venv/lib/python3.12/site-packages/pluggy/_hooks.py:421:    # TODO: Document, or make private.
./.venv/lib/python3.12/site-packages/yaml/scanner.py:187:        # TODO: support for BOM within a stream.
./.venv/lib/python3.12/site-packages/yaml/scanner.py:761:        # TODO: We need to make tab handling rules more sane. A good rule is
./.venv/lib/python3.12/site-packages/pydantic_core/core_schema.py:1135:            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
./.venv/lib/python3.12/site-packages/httpx/_auth.py:267:        # TODO: implement auth-int
./.venv/lib/python3.12/site-packages/pyasn1/type/univ.py:1724:        # TODO: remove when Py2.5 support is gone
./.venv/lib/python3.12/site-packages/pyasn1/type/univ.py:1952:                # TODO: we should wrap componentType with UnnamedType to carry
./.venv/lib/python3.12/site-packages/pyasn1/type/constraint.py:85:        # TODO: fix possible comparison of set vs scalars here
./.venv/lib/python3.12/site-packages/pyasn1/type/constraint.py:747:# TODO:
./.venv/lib/python3.12/site-packages/pyasn1/codec/cer/decoder.py:51:# TODO: prohibit non-canonical encoding
./.venv/lib/python3.12/site-packages/pyasn1/codec/ber/encoder.py:189:            # TODO: try to avoid ASN.1 schema instantiation
./.venv/lib/python3.12/site-packages/pyasn1/codec/ber/encoder.py:557:    # TODO: handling three flavors of input is too much -- split over codecs
./.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:48:        raise error.PyAsn1Error('SingleItemDecoder not implemented for %s' % (tagSet,))  # TODO: Seems more like an NotImplementedError?
./.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:58:        raise error.PyAsn1Error('Indefinite length mode decoder not implemented for %s' % (tagSet,)) # TODO: Seems more like an NotImplementedError?
./.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:1350:            # TODO: Seems not to be tested
./.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:1399:            yield chunk  # TODO: Weird
./.venv/lib/python3.12/site-packages/pyasn1/codec/der/encoder.py:34:                # TODO: move out of sorting key function
./.venv/lib/python3.12/site-packages/pyasn1/codec/der/encoder.py:41:                # TODO: support nested CHOICE ordering
./.venv/lib/python3.12/site-packages/pyasn1/codec/der/decoder.py:23:# TODO: prohibit non-canonical encoding
./.venv/lib/python3.12/site-packages/passlib/utils/compat/__init__.py:100:    # TODO: once we drop python 3.2 support, can use u'' again!
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:56:    # TODO: a bunch of other things are commonly assumed in this namespace
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:426:            # TODO: straighten out class naming, repr, and .name attr
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:446:        TODO: This should be done explicitly, but for now this mixin sets
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:938:    # TODO: document _norm_hash()
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1287:    # TODO: document _truncate_salt()
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1312:    # TODO: could support using(min/max_desired_salt_size) via using() and needs_update()
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1717:                # TODO: deprecate / disallow vary_rounds=1.0
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1768:            assert 0 <= vary_rounds <= 1 # TODO: deprecate vary_rounds==1
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2527:            # TODO: look into way to fix the issues.
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2626:        # TODO: needs UTs
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2627:        # TODO: any other cases where wrapped is "owned"?
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2691:        # TODO: under 2.0, throw TypeError if config is None, rather than passing it through
./.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:364:    # TODO: use izip instead (but first verify it's faster than zip for this case)
./.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:385:    # TODO: could check for cryptography package's version,
./.venv/lib/python3.12/site-packages/passlib/utils/binary.py:361:        # TODO: support padding character
./.venv/lib/python3.12/site-packages/passlib/utils/binary.py:492:        ##    # TODO: add padding size check?
./.venv/lib/python3.12/site-packages/passlib/exc.py:353:    # TODO: if handler.use_defaults is set, this came from app-provided value,
./.venv/lib/python3.12/site-packages/passlib/totp.py:265:        # TODO: allow a lot more things to be customized from here,
./.venv/lib/python3.12/site-packages/passlib/totp.py:1306:    # TODO: resync(self, tokens, time=None, min_tokens=10, window=100)
./.venv/lib/python3.12/site-packages/passlib/context.py:1692:    ##    # TODO: this should work w/ 'auto', but needs closer inspection
./.venv/lib/python3.12/site-packages/passlib/context.py:2109:            # TODO: offer replacement alternative.
./.venv/lib/python3.12/site-packages/passlib/context.py:2248:            # TODO: offer replacement alternative.
./.venv/lib/python3.12/site-packages/passlib/context.py:2332:            # TODO: offer replacement alternative.
./.venv/lib/python3.12/site-packages/passlib/apps.py:226:# TODO: support the drupal phpass variants (see phpass homepage)
./.venv/lib/python3.12/site-packages/passlib/handlers/pbkdf2.py:395:        # TODO: find out what crowd's policy is re: unicode
./.venv/lib/python3.12/site-packages/passlib/handlers/pbkdf2.py:469:        # TODO: find out what grub's policy is re: unicode
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:147:    # TODO: could support the optional 'data' parameter,
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:178:    # TODO: once rounds limit logic is factored out,
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:398:        # TODO: switch to working w/ str or unicode
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:459:        # TODO: factor out variable checksum size support into a mixin.
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:738:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:761:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:784:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:879:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./.venv/lib/python3.12/site-packages/passlib/handlers/scram.py:330:            # TODO: verify digest size (if digest is known)
./.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:3:TODO:
./.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:211:        # TODO: try to detect incorrect 8bit/wraparound hashes using kwds.get("secret")
./.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:454:        # TODO: check for 2x support
./.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:518:        # TODO: figure out way to skip these tests when not needed...
./.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:628:    # # TODO: would like to implementing verify() directly,
./.venv/lib/python3.12/site-packages/passlib/handlers/sun_md5_crypt.py:345:    # TODO: if we're on solaris, check for native crypt() support.
./.venv/lib/python3.12/site-packages/passlib/handlers/misc.py:111:    # TODO: rename attr to 'marker'...
./.venv/lib/python3.12/site-packages/passlib/handlers/scrypt.py:133:    # TODO: would like to dynamically pick this based on system
./.venv/lib/python3.12/site-packages/passlib/handlers/scrypt.py:139:    # TODO: make default block size configurable via using(), and deprecatable via .needs_update()
./.venv/lib/python3.12/site-packages/passlib/handlers/sha2_crypt.py:300:        # TODO: this *could* use uh.parse_mc3(), except that the rounds
./.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:83:    # TODO: add sha3 to this table.
./.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:245:    # TODO: add pysha3 support.
./.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:498:            # TODO: load in preset digest size info for known hashes.
./.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:874:# TODO: consider some alternatives, such as C-accelerated xor_bytes helper if available
./.venv/lib/python3.12/site-packages/passlib/crypto/des.py:40:# TODO: could use an accelerated C version of this module to speed up lmhash,
./.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:30:#: TODO: standardize this across backends, and expose support via scrypt hash config;
./.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:40:# TODO: unittests for this function
./.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:95:# TODO: configuration picker (may need psutil for full effect)
./.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:209:        # TODO: would like to enforce a single "maxmem" policy across all backends;
./.venv/lib/python3.12/site-packages/passlib/tests/test_utils.py:326:        # TODO: add some tests to ensure we take THETA(strlen) time.
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_cisco.py:209:        # TODO: these need confirming w/ an actual PIX system.
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:158:        # TODO: push this to passlib.apps django contexts
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:459:    # TODO: add get_hasher() checks where appropriate in tests below.
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:530:        # TODO: is_password_usable()
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:605:        # TODO: is_password_usable()
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:645:        # TODO: is_password_usable()
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:690:        # TODO: is_password_usable()
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:818:        # TODO: get_hasher()
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:901:        # TODO: test unpatch behavior honors flag.
./.venv/lib/python3.12/site-packages/passlib/tests/test_pwd.py:123:    # TODO: test rng option
./.venv/lib/python3.12/site-packages/passlib/tests/test_apache.py:72:        # TODO: under py3, could trap the more specific FileNotFoundError
./.venv/lib/python3.12/site-packages/passlib/tests/test_apache.py:610:    # TODO: test set_password autosave
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:120:    # TODO: find an authoritative source of test vectors
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:242:    # TODO: find an authortative source of test vectors
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:641:    # TODO: integrate EncodingHandlerMixin
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1212:    # TODO: get more test vectors (especially ones which properly test unicode)
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1250:    # TODO: find more test vectors (especially ones which properly test unicode)
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1316:    # TODO: integrate EncodingHandlerMixin
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1621:    # TODO: this scheme needs some real test vectors, especially due to
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1737:#    accepts_all_hashes = True # TODO: turn this off.
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_bcrypt.py:488:        # TODO: convert to v2 format
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:370:            # TODO: may want to filter out a few of this, but not blanket filter...
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:374:            # TODO: should be cleaned in 2.0, when support will be dropped.
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:489:        # TODO: make this display better diff of *which* warnings did not match
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:954:    # TODO: rename to do_hash() to match new API
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1639:        # TODO: check relaxed mode clips min-1
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1658:            # TODO: check relaxed mode clips max+1
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2053:    # TODO: check various supported idents
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2618:        # TODO: would like to enhance what this test covers
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2627:        # TODO: figure out what invariants we can reliably parse,
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:3287:    # TODO: turn into decorator, and use mock library.
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:3493:    # TODO: user size? kinda dicey, depends on algorithm.
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_pbkdf2.py:182:    # TODO: need a bunch more reference vectors from some real
./.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django_source.py:229:        # TODO: support wrapping django's harden-runtime feature?
./.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:307:    # TODO: test HasRawSalt mixin
./.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:611:        # TODO: handle fshp correctly, and other glitches noted in code.
./.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:766:        self.assertEqual(h.ident_values, None) # TODO: should output (u("?P$"), u("?H$")))
./.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:838:# TODO: provide data samples for algorithms
./.venv/lib/python3.12/site-packages/passlib/tests/backports.py:18:    # TODO: deprecate these exports in favor of "unittest.XXX"
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_argon2.py:398:            # TODO: make this fatal, and add refs for other version.
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_argon2.py:433:        # TODO: fuzz parallelism, digest_size
./.venv/lib/python3.12/site-packages/passlib/tests/test_context_deprecated.py:40:    # TODO: need to test user categories w/in all this
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:203:    # TODO: test secrets_path
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:232:    # TODO: test 'cost' param
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:375:        # TODO: rework timing test here to inject mock pbkdf2_hmac() function instead;
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:392:# TODO: this class is separate from TotpTest due to historical issue,
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:693:    # TODO: test using() w/ 'digits', 'alg', 'issue', 'wallet', **wallet_kwds
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1048:        # TODO: test window values that aren't multiples of period
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1083:        # TODO: test skew + larger window
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1581:    # TODO: to_dict()
./.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1595:    # TODO: from_json() / to_json().
./.venv/lib/python3.12/site-packages/passlib/tests/test_registry.py:127:        # TODO: check lazy load which calls register_crypt_handler (warning should be issued)
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_django.py:42:    #: TODO: for a bunch of the tests below, this is just max version where
./.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:52:    # TODO: these unittests could really use a good cleanup
./.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1025:        # TODO: should migrate these tests elsewhere, or remove them.
./.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1352:    # TODO: now that rounds generation has moved out of _CryptRecord to HasRounds,
./.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1446:        # TODO: test default falls back to mx / mn if handler has no default.
./.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1607:        # TODO: test dummy_verify() invoked by .verify() when hash is None,
./.venv/lib/python3.12/site-packages/passlib/tests/test_crypto_digest.py:194:    # TODO: write full test of compile_hmac() -- currently relying on pbkdf2_hmac() tests
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:75:    # TODO: add preset which includes HASHERS + PREFERRED_HASHERS,
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:365:            # TODO: should make iteration via registry easier
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:602:            # TODO: Solve redundancy that verify() call
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:809:        # TODO: would like to add support for inheriting config from a preset
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:813:        # TODO: wrap and import any custom hashers as passlib handlers,
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1010:        # TODO: would like access CryptContext, would need caller to pass it to get_passlib_hasher().
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1015:            # TODO: always call subcls/handler.needs_update() in case there's other things to check
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1028:# TODO: this code probably halfway works, mainly just needs
./.venv/lib/python3.12/site-packages/passlib/ifc.py:32:# TODO: make this actually use abstractproperty(),
./.venv/lib/python3.12/site-packages/passlib/ifc.py:67:    #: .. TODO: passlib 1.8: deprecate/rename this attr to "max_secret_size"?
./.venv/lib/python3.12/site-packages/passlib/ifc.py:80:    #: .. TODO: passlib 1.8: deprecate/rename this attr to "truncate_hash_error"?
./.venv/lib/python3.12/site-packages/passlib/ifc.py:277:    #: TODO: document this, or at least the use of testing for
./.venv/lib/python3.12/site-packages/passlib/registry.py:384:    # TODO: make _handlers a separate list, so we don't have module namespace mixed in.
./.venv/lib/python3.12/site-packages/passlib/registry.py:431:# TODO: needs UTs
./.venv/lib/python3.12/site-packages/passlib/registry.py:449:# TODO: needs UTs
./.venv/lib/python3.12/site-packages/passlib/registry.py:507:# TODO: move unix_crypt_schemes list to here.
./.venv/lib/python3.12/site-packages/passlib/registry.py:511:# TODO: needs UTs
./.venv/lib/python3.12/site-packages/passlib/registry.py:531:# TODO: needs UTs
./.venv/lib/python3.12/site-packages/typing_extensions.py:3267:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./.venv/lib/python3.12/site-packages/asyncio_mqtt/client.py:111:# TODO: Simplify the logic that surrounds `self._outgoing_calls_sem` with
./.venv/lib/python3.12/site-packages/asyncio_mqtt/client.py:355:    def id(  # noqa: A003 # TODO: When doing BREAKING CHANGES rename to avoid shadowing builtin id
./.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578:        # TODO: Add optional support for socket.gethostbyname checking.
./.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095:        # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
./.venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38:    # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
./.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144:        # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
./.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234:                # TODO: Arbitrary read value.
./.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282:            # TODO this is often present from upstream.
./.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325:    # TODO: This is a woefully incomplete response object, but works for non-streaming.
./.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332:        decode_content: bool = False,  # TODO: support decoding
./.venv/lib/python3.12/site-packages/urllib3/exceptions.py:306:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./.venv/lib/python3.12/site-packages/urllib3/util/url.py:454:    # TODO: Remove this when we break backwards compatibility.
./.venv/lib/python3.12/site-packages/urllib3/util/request.py:229:    # File-like object, TODO: use seek() and tell() for length?
./.venv/lib/python3.12/site-packages/urllib3/connection.py:330:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./.venv/lib/python3.12/site-packages/urllib3/connection.py:436:        # object later. TODO: Remove this in favor of a real
./.venv/lib/python3.12/site-packages/urllib3/connection.py:561:        # TODO should we implement it everywhere?
./.venv/lib/python3.12/site-packages/urllib3/response.py:1005:                # TODO make sure to initially read enough data to get past the headers
./.venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20:    # TODO: Remove this in favor of a better
./.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499:        # TODO should we eliminate the recursion?
./.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503:                    # TODO check whether we need to call `list_hook`
./.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511:            # TODO is the interaction between `list_hook` and `use_list` ok?
./.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516:                    # TODO check whether we need to call hooks
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863:    TODO: clean up the code here.
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./.venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558:            # TODO: Not sure if we need the SecTrustResultType for anything?
./.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./.venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:839:            # TODO version verification
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:922:                # TODO SHA256 digest
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401:        # TODO check k, v for valid values
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:560:    # TODO could add iter* variants
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:984:        # TODO: any other fields wanted
./.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:1020:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:3568:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522:        # TODO: Add optional support for socket.gethostbyname checking.
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659:        # TODO: should I do clean shutdown here? Do I have to?
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819:        # TODO: Well, crap.
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829:        # TODO: Update in line with above.
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./.venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./.venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1:# TODO: Add Generic type annotations to initialized collections.
./.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122:_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
./.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598:        # TODO: Add a deadline?
./.venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227:        # TODO: There is an assumption that the result will be a
./.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./.venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./.venv/lib/python3.12/site-packages/pip/_internal/cache.py:278:                # TODO: use DirectUrl.equivalent when
./.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:227:        # TODO performance: this means we iterate the dependencies at least twice,
./.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:362:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:201:        # TODO: Check already installed candidate, and use it if the link and
./.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:622:        # TODO: Are there more cases this needs to return True? Editable?
./.venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:344:        # TODO: In the future, it would be nice if pip supported PEP 691
./.venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:204:        # TODO: Try to get these passing down from the command?
./.venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./.venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6:# TODO: This needs Python 3.10's improved slots support for dataclasses
./.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:107:    # TODO: replace this with slots=True when dropping Python 3.9 support.
./.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:526:    # TODO: handle space after '\'.
./.venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:285:        # TODO: The is_installable_dir test here might not be necessary
./.venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:75:        TODO remove this property together with the legacy resolver, since the new
./.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:167:        # TODO: this property is relatively costly to compute, memoize it ?
./.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:177:                # TODO: get project location from second line of egg_link file
./.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:557:        # TODO: separate this part out from RequirementPreparer when the v1
./.venv/lib/python3.12/site-packages/_pytest/compat.py:115:    # TODO(RonnyPfannschmidt): This function should be refactored when we
./.venv/lib/python3.12/site-packages/_pytest/python.py:296:        # TODO: Improve the type of `parent` such that assert/ignore aren't needed.
./.venv/lib/python3.12/site-packages/_pytest/python.py:1532:    # TODO: If escaping is turned off and the user passes bytes,
./.venv/lib/python3.12/site-packages/_pytest/python.py:1705:    # TODO: Type ignored -- breaks Liskov Substitution.
./.venv/lib/python3.12/site-packages/_pytest/junitxml.py:512:            # TODO: breaks for --dist=each
./.venv/lib/python3.12/site-packages/_pytest/assertion/rewrite.py:881:            # TODO: This assert should not be needed.
./.venv/lib/python3.12/site-packages/_pytest/legacypath.py:389:        # TODO: This assert is probably not valid in all cases.
./.venv/lib/python3.12/site-packages/_pytest/cacheprovider.py:242:                # TODO: pass ignore_cleanup_errors=True when we no longer support python < 3.10.
./.venv/lib/python3.12/site-packages/_pytest/cacheprovider.py:575:        # TODO: evaluate generating upward relative paths
./.venv/lib/python3.12/site-packages/_pytest/mark/structures.py:158:            # TODO: Refactor to fix this type-ignore. Currently the following
./.venv/lib/python3.12/site-packages/_pytest/doctest.py:316:    # TODO: Type ignored -- breaks Liskov Substitution.
./.venv/lib/python3.12/site-packages/_pytest/doctest.py:346:            # TODO: ReprFileLocation doesn't expect a None lineno.
./.venv/lib/python3.12/site-packages/_pytest/raises.py:495:    # TODO: harmonize with ExceptionInfo.match
./.venv/lib/python3.12/site-packages/_pytest/raises.py:513:            # TODO: it instructs to use `-v` to print leading text, but that doesn't work
./.venv/lib/python3.12/site-packages/_pytest/raises.py:698:    # TODO: move common code into superclass
./.venv/lib/python3.12/site-packages/_pytest/terminal.py:1539:        # TODO: Revisit after marks scope would be fixed.
./.venv/lib/python3.12/site-packages/_pytest/reports.py:466:    # TODO: Check if this is actually reachable.
./.venv/lib/python3.12/site-packages/_pytest/reports.py:518:        # TODO: Investigate whether the duck typing is really necessary here.
./.venv/lib/python3.12/site-packages/_pytest/nodes.py:514:    # TODO: This omits the style= parameter which breaks Liskov Substitution.
./.venv/lib/python3.12/site-packages/_pytest/fixtures.py:159:# TODO: Try to use FixtureFunctionDefinition instead of the marker
./.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1249:# TODO: paramspec/return type annotation tracking and storing
./.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1535:        # TODO: The order of the FixtureDefs list of each arg is significant,
./.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1937:        # TODO: Fix this type ignore.
./.venv/lib/python3.12/site-packages/_pytest/capture.py:708:        # TODO: This type error is real, need to fix.
./.venv/lib/python3.12/site-packages/_pytest/main.py:945:                        # TODO: Remove parametrized workaround once collection structure contains
./.venv/lib/python3.12/site-packages/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./.venv/lib/python3.12/site-packages/requests/hooks.py:19:# TODO: response is the only one
./.venv/lib/python3.12/site-packages/iniconfig/__init__.py:80:    # TODO: investigate possible mypy bug wrt matching the passed over data
./.venv/lib/python3.12/site-packages/uvloop/_testbase.py:291:        # TODO This warning has to be fixed in asyncio.
./.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:221:# TODO at some point, we could switch to an enum flag, so that multiple sources
./.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:224:    # TODO if/when https://peps.python.org/pep-0767/ is accepted, add 'read_only'
./.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:319:        # TODO use a match statement when Python 3.9 support is dropped.
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:473:            # TODO: what happens if we don't have a filename?
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1464:        # TODO: verify that we're in the state MultipartState.END, otherwise throw an
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1655:                # TODO: check for error here.
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1685:                # TODO: handle mixed case
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1692:                # TODO: check for errors
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1703:                # TODO: check that we properly handle 8bit / 7bit encoding.
./.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1764:        # TODO: check the parser's return value for errors?
./.venv/lib/python3.12/site-packages/cryptography/hazmat/primitives/asymmetric/rsa.py:221:    # TODO: Replace with lcm(p - 1, q - 1) once the minimum
./.venv/lib/python3.12/site-packages/cryptography/x509/name.py:357:        # TODO: this is relatively expensive, if this looks like a bottleneck
./.venv/lib/python3.12/site-packages/mdurl/_parse.py:168:            # v0.12 TODO(isaacs): This is not quite how Chrome does things.
./.venv/lib/python3.12/site-packages/paho/mqtt/client.py:3216:                        # TODO: Something is odd here. I don't see why packet["info"] can't be None.
./.venv/lib/python3.12/site-packages/paho/mqtt/client.py:4674:            # TODO: this type error is a true error:
./.venv/lib/python3.12/site-packages/paho/mqtt/matcher.py:47:            # TODO
./.venv/lib/python3.12/site-packages/aioredis/lock.py:235:        # TODO: this can be simplified when the context manager is finished
./.venv/lib/python3.12/site-packages/aioredis/connection.py:227:    TODO: We're currently passing through two buffers,
./.venv/lib/python3.12/site-packages/pyinstrument/frame.py:126:        # TODO remove me
./.venv/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py:26:# TODO:
./.venv/lib/python3.12/site-packages/markdown_it/parser_inline.py:96:            # TODO: remove this workaround when CM standard will allow nested links
./.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:26:        self.debug = debug  # TODO: We ought to handle 404 cases if debug is set.
./.venv/lib/python3.12/site-packages/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./.venv/lib/python3.12/site-packages/fastapi/openapi/utils.py:344:                # TODO: probably make status_code a default class attribute for all
./.venv/lib/python3.12/site-packages/fastapi/openapi/models.py:147:    # TODO: uncomment and remove below when deprecating Pydantic v1
./.venv/lib/python3.12/site-packages/fastapi/params.py:36:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:150:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:236:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:320:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:406:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:490:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:606:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/params.py:690:        # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:55:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:380:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:684:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1000:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1327:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1642:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1956:    # TODO: update when deprecating Pydantic v1, import these types
./.venv/lib/python3.12/site-packages/fastapi/routing.py:368:            # TODO: remove this scope later, after a few releases
./.venv/lib/python3.12/site-packages/fastapi/routing.py:524:            # TODO: remove when deprecating Pydantic v1
./.venv/lib/python3.12/site-packages/fastapi/encoders.py:36:# TODO: pv2 should this return strings instead?
./.venv/lib/python3.12/site-packages/fastapi/encoders.py:217:        # TODO: remove when deprecating Pydantic v1
./.venv/lib/python3.12/site-packages/fastapi/encoders.py:239:            # TODO: remove when deprecating Pydantic v1
./.venv/lib/python3.12/site-packages/fastapi/applications.py:877:        # TODO: remove when discarding the openapi_prefix parameter
./.venv/lib/python3.12/site-packages/fastapi/security/oauth2.py:12:# TODO: import from typing when deprecating Python 3.9
./.venv/lib/python3.12/site-packages/fastapi/_compat.py:203:            # TODO remove when deprecating Pydantic v1
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1024:/* TODO: remove */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1029:/* TODO: move these enums out to the appropriate submodule */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1073:/* TODO: remove */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1024:/* TODO: remove */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1029:/* TODO: move these enums out to the appropriate submodule */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1073:/* TODO: remove */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:81:/* TODO */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:88:/* TODO: Detect UWP, a.k.a. Windows Store app, and set this to 0. */
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cuda_runtime.h:1391: * TODO detail
./api/pipeline/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cooperative_groups.h:1173:// TODO: Use a static dispatch to determine appropriate return type
./api/pipeline/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:594:        # TODO: Add logic that removes the TransferState if the transfer is
./api/pipeline/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:644:        # TODO: Not all exceptions are pickleable so if we are running
./api/pipeline/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:899:    # TODO: It may make sense to expose these class variables as configuration
./api/pipeline/.venv/lib/python3.12/site-packages/s3transfer/__init__.py:857:                # TODO: we need a way to reset the callback if the
./api/pipeline/.venv/lib/python3.12/site-packages/psycopg2/tz.py:158:# TODO: pre-generate some interesting time zones?
./api/pipeline/.venv/lib/python3.12/site-packages/psycopg2/_range.py:526:# TODO: probably won't work with infs, nans and other tricky cases.
./api/pipeline/.venv/lib/python3.12/site-packages/cv2/__init__.py:19:# TODO
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PdfParser.py:616:            # TODO: support reuse of deleted objects
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:2280:                    raise RuntimeError(msg)  # XXX TODO
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/IcoImagePlugin.py:75:            # TODO: invent a more convenient method for proportional scalings
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:134:    #TODO: Add support for sets provided by the user
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1323:        # TODO : Remove when lambdify accepts 'pymc' as module
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1340:                # TODO: Replace the try-except block with only given_fn(*args)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1366:                    # TODO: Replace the try-except block with only given_fn(*args)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1383:            # TODO: Replace the try-except block with only fn(*args)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1610:            # TODO: do this for drv.py and frv.py if necessary.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1611:            # TODO: add more distributions here if there are more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:114:    ### TODO: Add tests after adding matrix distributions in numpy_rv_map
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/frv.py:460:            #TODO: Implement the mechanism for handling queries for symbolic sized distributions.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/drv.py:152:        # TODO: support discrete sets with non integer stepsizes
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:415:            #TODO: Modify to support integration
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1694:    .. TODO - What is the difference between these degrees of freedom?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2986:    .. TODO - what does the parameter mean?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:77:        with ignore_warnings(UserWarning):  # TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:109:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:408:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:677:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1348:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1358:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_compound_rv.py:90:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_finite_rv.py:68:    # TODO: Make iid method!
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_mix.py:80:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/random_matrix_models.py:249:        # TODO : Add support for Lie groups(as extensions of sympy.diffgeom)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:10:# TODO: The code below could be made more granular with something like:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:74:    # TODO: How can we test that the output of a SyntaxError is the original
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:732:                    # TODO: Implement this case
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:868:                # TODO: support for singular initial condition
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:103:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/trigonometry.py:5:# TODO sin(a*x)*cos(b*x) -> sin((a+b)x) + sin((a-b)x) ?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:38:# TODO: Add messages to NonElementaryIntegralException errors
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:205:    # TODO: finish writing this and write tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:286:    # TODO: finish writing this and write tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:510:# TODO: better name for this function
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:653:            # TODO: Write a dummy function that does this idiom
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:713:        # TODO: Is this check necessary, and if so, what should it do if it fails?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:772:        # check for regularity conditions (TODO), see issue 4215
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:201:        # TODO handle derivatives etc
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:745:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:119:    # TODO this needs more polar_lift (c/f entry for exp)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:164:    # TODO can do sin^n, sinh^n by expansion ... where?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:170:    # TODO can do t + a. but can also do by expansion... (XXX not really)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:187:    # TODO these only hold for positive p, and can be made more general
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:189:    # TODO also it would be nice to derive them recursively ...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:202:    # TODO log(x)/(x+a) and log(x)/(x-1) can also be done. should they
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:204:    # TODO further formulae in this section seem obscure
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:207:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:230:    # TODO exp(-x)*erf(I*x) does not work
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:256:    # TODO all of the following should be derivable
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:282:    # TODO many more formulas. should all be derivable
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:286:    # TODO many more formulas. should all be derivable
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:524:    # TODO should this be a method of meijerg?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:852:    # TODO altered cases 4-7
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:876:    # TODO This leaves only one case from the three listed by Prudnikov.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:900:    # XXX TODO we should reduce order first
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:972:    # TODO should we try both?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:988:    # XXX TODO this is a testing *nightmare*
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1445:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:2040:            # TODO: This is for future development, as currently
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:333:        # TODO: This probably doesn't need to be completely recomputed at
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:366:                    # TODO: Would there ever be any benefit from just
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:395:            # TODO: Just put it in self.Tfuncs
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:497:                    # TODO: Add something to backsubs to put exp(const*p)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:530:                        # TODO: give algebraic dependence in error string
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:779:    # TODO: Rewrite algorithms below to use this (?)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:781:    # TODO: Pass through information about why the integral was nonelementary,
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:798:    # TODO: This should go in densetools.py.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:855:    # TODO: Use this on the final result.  That way, we can avoid answers like
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1006:    # TODO: This algorithm appears to be faster in every case
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1007:    # TODO: Verify this and splitfactor() for multiple extensions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1250:        # TODO also consider the complex roots which should
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1280:    # TODO: Use log_to_atan() from rationaltools.py
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1350:    # TODO: check what Lambda does with RootOf
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1365:    # TODO: verify that this is correct for multiple extensions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1458:        # TODO: This does not do the right thing when b is False
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1621:    # TODO: Integral from k?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1622:    # TODO: split out nonelementary integral
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1691:    # TODO: This is useful in and of itself, because isinstance(result,
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:114:    # TODO: Merge this with the very similar special_denom() in rde.py
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:158:                        # TODO: Add test
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:822:        # TODO: implement this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:878:    # TODO: finish writing this and write tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:921:        # TODO: We treat this as 'no solution', until the structure
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:952:    # TODO: Write the full algorithm using the structure theorems.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:957:        # TODO: This could be implemented more efficiently.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1035:        # TODO: What should really be done in this case?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1160:        # TODO: What should really be done in this case?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1185:            # TODO: But maybe we can tell if they're not rational, like
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1266:    # TODO: finish writing this and write tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1301:        # TODO: we can use more efficient residue reduction from ratint()
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:400:        # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:466:        # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:875:        # TODO not implemented yet, but also not important
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:977:        #  TODO : This part is quite hacky. Should be made more robust with
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:978:        #  TODO : respect to symbol names and scalable w.r.t higher dimensions.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:235:    # TODO: Skip or make faster
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:250:    # TODO: Add tests for integrate_hyperexponential() from the book
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:374:    # TODO: Add a test where two different parts of the extension use a
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:110:    # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:698:    # TODO sinh/cosh shifted come out a mess. also delayed trig is a mess
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:699:    # TODO should this simplify further?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:714:    # TODO can we make erf(t) work?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:756:    # TODO LT of Si, Shi, Chi is a mess ...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_trigonometry.py:32:    # TODO: remove conds='none' below. For this to work we would have to rule
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:328:    # TODO: Remove conds='none' below, let the assumption take care of it.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1140:    # TODO: Remove conds='none' below, let the assumption take care of it.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1329:    # TODO: How to test risch=False?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:149:    # TODO what simplifications should be done automatically?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:165:    # TODO it would be nice to test the condition
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:245:    # TODO more orthogonality integrals
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:257:    # TODO can do higher powers, but come out as high order ... should they be
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:262:    # TODO more besseli when tables are extended or recursive mellin works
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:273:    # TODO how does besselj(0, a*x)*besselj(0, b*x) work?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:274:    # TODO how does besselj(0, x)**2*besselj(1, x)**2 work?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:275:    # TODO sin(x)*besselj(0, x) etc come out a mess
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:276:    # TODO can x*log(x)*besselj(0, x) be done?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:277:    # TODO how does besselj(1, x)*besselj(0, x+a) work?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:278:    # TODO more indefinite integrals when struve functions etc are implemented
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:374:    # TODO gammasimp cannot prove that the factor is unity
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:517:    # TODO conditions are a mess
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:523:    # TODO gamma, rayleigh
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:579:    # TODO are there other distributions supported on (-oo, oo) that we can do?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:658:    # TODO maybe simplify the inequalities? when the simplification
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:668:    # TODO FT(besselj(0,x)) - conditions are messy (but for acceptable reasons)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:105:    # TODO: when bound_degree() can handle this, test degree bound from that too
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:147:    # TODO: Add test for deg(b) <= 0 with b small
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:262:    # TODO: Add more tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:280:    # TODO: Add more tests, including ones with exponentials
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:80:    # TODO does not work with bneg, argument wrong. Needs changes to matching.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:164:    # TODO we cannot currently do these (needs summation of 3F2(-1))
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:244:    # TODO we can't do any of these (delicate cancellation)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:253:    # TODO bessely(a, x)*besselk(a, x) is a mess
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:264:    # TODO products of besselk are a mess
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:271:    # TODO exp(x/2)*besselk(a, x/2) [etc] cannot currently be done
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:272:    # TODO various strange products of special orders
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:386:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:420:    # TODO this comes out as an amazing mess, but simplifies nicely
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:436:    # TODO this can be further simplified!
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:444:    # TODO more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:466:    # TODO for this to work with real a, need to expand abs(a*x) to abs(a)*abs(x)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:479:    # TODO IFT is a *mess*
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:481:    # TODO IFT
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:492:    # TODO IFT without factoring comes out as meijer g
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:502:    # TODO IFT (comes out as meijer G)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:504:    # TODO besselj(n, x), n an integer > 0 actually can be done...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:506:    # TODO are there other common transforms (no distributions!)?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:221:    # TODO: it looks like this used to work just by coincindence and
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:254:    # TODO: heurisch() is off by a constant: -3/4. Possibly different permutation
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:343:# TODO: convert the rest of PMINT tests:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:71:    # TODO: add more tests here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:114:    # TODO: Add test for when the degree bound becomes larger after limited_integrate
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:115:    # TODO: Add test for db == da - 1 case
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:118:    # TODO: Add tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:119:    # TODO: Add test for when the degree becomes larger after parametric_log_deriv()
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:179:    # TODO: Add more exp tests, including tests that require is_deriv_in_field()
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:193:    # TODO: Add more primitive tests, including tests that require is_deriv_in_field()
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:197:    # TODO: Add more tests for rischDE, including ones from the text
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:495:    # TODO: caching is significant factor for why permutations work at all. Change this.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:700:        # TODO: Currently it's better to use symbolic expressions here instead
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:726:                # TODO: Non-polynomial expression. This should have been
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/exprtools.py:1551:            # XXX TODO there should be a way to inspect what order the terms
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:139:       TODO: write about
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:310:        """process a -> b rule"""   # TODO write more?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:398:       # TODO b | c
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:180:# TODO: we should use the warnings module
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:278:# TODO caching with decorator, but not to degrade performance
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1456:                #TODO: this can probably be optimized more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1885:    # TODO make it decorator + bytecodehacks?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/expr.py:3692:        # TODO: Smarter heuristics
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/add.py:292:                seq.extend(o_args)  # TODO zerocopy?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:212:        # TODO: Look at nargs
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:1416:            #TODO: check if assumption of discontinuous derivatives exist
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:1673:        # TODO: deprecate?  YES, make this 'enumerated_variables' and
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/function.py:1675:        # TODO: support for `d^n`?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/symbol.py:637:    # TODO add check against another Wild
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1447:    # TODO: Disable string inputs (https://github.com/sympy/sympy/issues/11003)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_assumptions.py:410:    # TODO Change to x.is_nonzero is None
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_diff.py:138:    # TODO: assert diff(x**2, (x, n)) == x**(2-n)*ff(2, n)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3958:@SKIP("TODO: sympy.physics.quantum.shor: Cmod Not Implemented")
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:208:    # TODO UndefinedFunction does not subclass Expr
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_facts.py:70:# TODO move me to appropriate place
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:917:    # TODO UndefinedFunction does not subclass Expr
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:435:            # TODO: Make non-commutative exponents not combine automatically
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1049:        # TODO: Should these be self.func?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1190:        # TODO: Should this be self.func?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:2758:    # TODO: make this a class like bell()
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:423:        # TODO: extend this to complex numbers?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:283:        if arg.is_Add: # TODO, implement more if deep stuff here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:480:        if arg.is_Add: # TODO, implement more if deep stuff here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/_trigonometric_special.py:3:TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:985:        # TODO new and probably slow
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:578:                # TODO simplify hi <= upto
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:498:        if arg.is_Add:  # TODO, implement more if deep stuff here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:499:            # TODO: Do this more efficiently for more than two terms
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:867:        if arg.is_Add:  # TODO: Do this more efficiently for more than two terms
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1579:    # TODO refactor into TrigonometricFunction common parts of
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1223:    # TODO raise error if function is discontinuous at limit of
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_complexes.py:938:    # TODO XXX why does abs(x)._eval_evalf() not fall back to global evalf?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/gamma_functions.py:687:                # TODO n == 1 also can do some rational z
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:25:# TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:47:# TODO should __new__ accept **options?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:48:# TODO should constructors should check if parameters are sensible?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:210:        # TODO should we check convergence conditions?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:543:        # TODO should we check convergence conditions?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:980:    # TODO this can be nicer
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:656:            # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:24:# TODO series expansions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:25:# TODO see the "Note:" in Ei
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:1220:        # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:2738:            # TODO: is the series really correct?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:150:        # TODO Add more simplififcation here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:179:        # TODO: Make sure n \in N
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:180:        # TODO: Assert |m| <= n ortherwise we should return 0
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:189:        # TODO: Make sure n \in N
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:190:        # TODO: Assert |m| <= n ortherwise we should return 0
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:197:        # TODO: Make sure theta \in R and phi \in R
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:202:        # TODO: Handle deep and hints
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:150:            # TODO should something be polarified here?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:179:        # TODO use minpoly instead of ad-hoc methods when issue 5888 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:181:            # TODO reference?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/setexpr.py:84:        # TODO: this could be implemented straight into `imageset`:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2486:                    know its dimensions. TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2555:    # TODO: check subsets (`func` in `setv`)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2558:    # TODO: support more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:46:        # TODO: handle unevaluated condition.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:49:        # TODO: `s2 > s1` could be unevaluated.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:85:    # TODO: add logic for open intervals?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:34:    # TODO: some intervals containing 0 and oo will fail as 0*oo returns nan.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:41:    # TODO: handle symbolic intervals
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:38:    # TODO: handle functions with infinitely many solutions (eg, sin, tan)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:39:    # TODO: handle multivariate functions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:371:            # TODO: Design a technique to handle multiple-inverse
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:29:    # TODO: add support for more functions in the future:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:206:    # TODO: some expressions cannot be calculated due to bugs (currently
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:124:                # TODO: is this break necessary?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:297:        # TODO: this assumes that all arguments are matrices, it may not be the case:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:448:    # TODO: check if subremoved should be permuted as well...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:542:        # TODO: move this to ElementwiseApplyFunction
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py:189:    # TODO: this is returning a wrong result:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:50:    # TODO: not yet supported:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:54:    # TODO: not yet supported:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:445:    # TODO: reverse operation starting with `PermuteDims` and getting down to `bb`...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:113:        # TODO: check that Kronecker delta is only contracted to one other element:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:605:        # TODO: swap args positions in order to simplify the expression:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:606:        # TODO: this should be in a function
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:641:        # TODO: function in order to permute the args:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:842:        # TODO: add API for total rank and cumulative rank:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1263:        # TODO: add API for total rank and cumulative rank:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1390:        # TODO: check that `expr` has `.subranks`:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/array_derivatives.py:91:        # TODO: this could be done with multiple-dispatching:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:567:        # TODO: add checks for dimensions for `value`?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2208:        # TODO: add possibility of metric after (spinors)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2590:            # TODO: what is the part which is not a coeff?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3064:        # TODO: this could be optimized by only swapping the indices
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3203:    # TODO: put this into TensExpr?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3209:    # TODO: put this into TensExpr?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3225:        # TODO: inefficient, this should be done at root level only:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3268:        # TODO: check data compatibility with properties of tensor.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3344:        # TODO: replace .args[0] with .name:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3359:            # TODO: if there is no metric present, the derivative should be zero?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3661:    # TODO: this method should be private
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3662:    # TODO: should this method be renamed _from_components_free_dum ?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4540:        # TODO: inherit dummies from expr
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4563:        # TODO: can be improved:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5136:    # TODO: add a dum_to_components_map ?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:89:#   TODO:  (some ideas for improvement)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:375:         broadcasting.  (TODO)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:497:    # TODO: add check for *get_symmetric_group_sgs(0)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/_compilation/__init__.py:9:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:920:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:956:    # TODO: Replace solve with solveset when it gives Lambert solution
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:966:    # TODO: x = [-1, 2*(+/-asinh(1)*I + n*pi}, 3*(pi/6 + n*pi/3)]
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:967:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1014:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1032:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1038:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1047:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1052:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1059:    # TODO: Replace solve with solveset which gives both [+/- current answer]
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1077:    # TODO: Replace solve with solveset, as of now
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1084:    # TODO: Replace solve with solveset, as of now
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1092:    # TODO: Replace solve with solveset, as of now
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1099:    # TODO: Replace solve with solveset, as of now
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1118:    # TODO: Replace solve with solveset, as of now
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1194:    # TODO: Replace solve with solveset, as of now
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2252:    # TODO: Replace solve with solveset, current test fails for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3082:    # TODO: Replace solve with solveset, when it works for solveset
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:382:    # TODO: fix pickling of Options class (see GroebnerBasis._options)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:409:        check(c, exclude=[0, 1], check_attr=False) # TODO: Py3k
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:420:    # TODO: AssertionError: assert id(obj) not in self.memo
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:424:    # TODO: AssertionError: assert id(obj) not in self.memo
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:438:    # TODO: fix pickling of ModularInteger
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:444:    # TODO: fix pickling of RealElement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:448:    # TODO: fix pickling of ComplexElement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:457:    # TODO: fix pickling of ModularInteger
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:472:        # TODO: fix pickling of ModularInteger
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:489:    # TODO: fix pickling of RealElement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:493:    # TODO: fix pickling of ComplexElement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:500:    # TODO: AssertionError
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:504:    # TODO: AttributeError: 'PolyElement' object has no attribute 'ring'
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:526:    # TODO: Argh, Python is so naive. No lambdas nor inner function support in
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:559:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:563:    # TODO: TypeError: can't pickle instancemethod objects
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:612:    # TODO: PicklingError: Can't pickle <function <lambda> at 0x38578c0>: it's not found as __main__.<lambda>
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:622:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:635:    # TODO: fix pickling of `symbols' flag
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:639:# TODO: def test_pickling_polys_rootisolation():
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2494:                # prop is a Symbol.  TODO: Find out why.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:34:    # TODO it would be good to pick the smallest divisible power
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:798:    # TODO: Use solveset here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1072:            # TODO: Hint first order series should match only if d/e is analytic.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1783:    # TODO: if two solutions are solved for f(x), we still want to be
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:204:    # TODO: Add methods that can be used by many ODE solvers:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:359:    # TODO: improve solution testing
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2902:# TODO: option for calculating J numerically
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:2566:    # TODO: pre-simplification: Not necessary but may simplify
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:3893:        # TODO: Fall back to diop_DN when k = 2
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:175:        # TODO : 'best' hint should be implemented when adequate
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:284:    # TODO : For now pde.py uses support offered by the ode_order function
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:521:    # TODO : For now homogeneous first order linear PDE's having
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:611:    # TODO : For now homogeneous first order linear PDE's having
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:323:    # TODO: Is the above solution set definitely complete?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1862:    # TODO: add more simple testcases when solveset returns
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1727:    # TODO: Investigate why currently solution [0] is preferred over [1].
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:185:    # TODO: does this really have to be so complicated?!
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:694:        # TODO : We should not blindly recurse through all args of arbitrary expressions like this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1662:        # TODO Case: A-> function of symbol, can be extended here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:353:        # TODO: use |G:H| = |G|/|H| (currently H can't be made into a group)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:870:    # TODO:: Sims points out in [Sim94] that performance can be improved by
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:903:            # TODO: this should support input of a list of general words
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/coset_table.py:985:    # TODO: complete the docstring
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/combinatorics/tensor_can.py:1015:    TODO: use baseswap in the case in which if it fails in finding a
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:666:        # TODO: Replace solve with nonlinsolve, when nonlinsolve will be able to solve in real domain
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:919:        # TODO: Replace solve with solveset, when this line is tested
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:927:                # TODO: Replace solve with solveset, when these lines are tested
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1290:            # TODO: Replace solve with solveset, when this line is tested
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/geometry/plane.py:412:                # TODO: Replace solve with solveset, when this line is tested
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/concrete/summations.py:607:        # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1043:    # TODO Implement matrix geometric series summation.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:78:#TODO debugging output
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:403:    #TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:240:        # TODO The 3D stuff
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:304:        #TODO after fixing https://github.com/ipython/ipython/issues/1255
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/utils.py:159:    # TODO: prange check goes here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:128:        # TODO: _process_piecewise check goes here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:204:# TODO: Add color arrays for plots.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:205:# TODO: Add more plotting options for 3d plots.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:206:# TODO: Adaptive sampling for 3D plots.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:381:                # TODO: set cse=True once this issue is solved:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1146:        # TODO: for now, I assume that numpy functions are going to succeed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1156:                # TODO: what if points[k][idx]==e or points[k][idx+1]==e?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1774:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1790:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1871:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1972:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:2094:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:32:# TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1281:        # TODO this can be done more efficiently
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:102:    # TODO more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/polyroots.py:761:    # TODO: This is fragile. Figure out how to make this independent of construct_domain().
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1977:    # TODO Use _parallel_dict_from_expr instead of sring as sring is
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:515:        # TODO better data structure!!!
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:675:        # TODO apply the product criterion?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:683:        # TODO mergesort?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:726:    # (TODO again, better data structures)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:450:        # TODO: implement this in from_ methods
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:459:        else: # TODO: remove this branch
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:9:# TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:142:        # TODO optionally disable reduction?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/polynomialring.py:40:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/domains/fractionfield.py:34:        # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:796:    # TODO: to improve performance, choose the main variable here
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:2129:# TODO: add support for algebraic function fields
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:163:    # TODO: rewrite this so that it doesn't use expand() (see poly()).
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:467:        # TODO: should AlgebraicField be a Composite domain?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:1251:        elif len(self) <= 5: # TODO: use an actual density measure
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:2275:        else: # TODO: don't use dense representation (port PRS algorithms)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:3044:    # TODO: following methods should point to polynomial
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:173:    # TODO: Use a nontrivial pivoting strategy to control intermediate
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:321:    # TODO: Use a non-trivial pivoting strategy. Even just row swapping makes a
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/normalforms.py:11:# TODO (future work):
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:23:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:660:        # TODO: Implement similar algorithms for DDM and SDM.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/matrices/rref.py:256:            # TODO: Add partial pivot support to the sparse implementations.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_distributedmodules.py:50:# TODO test to_dict?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_heuristicgcd.py:53:    # TODO: assert heugcd(f, f.diff(x))[0] == g
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/heuristicgcd.py:124:    # TODO: don't expose poly repr implementation details
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:378:        # TODO: Integrate this into expand() itself
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:216:        # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1839:        # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/primes.py:678:    # TODO (future work):
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:327:    # TODO: handle piecewise defined functions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:328:    # TODO: handle transcendental functions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:329:    # TODO: handle multivariate functions
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/calculus/accumulationbounds.py:688:        # TODO : Devise a better method for Union of AccumBounds
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:702:            # TODO: trigsimp is needed here so that the matrix becomes
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/operators.py:214:        # TODO: is case of many coord systems, this gets a random one:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:158:        # TODO: This gets a random coordinate system in case of multiple ones:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:503:        # TODO : The following line introduces a performance issue
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:330:    # TODO: We should be able to support more than 2 elements
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:410:def test_optims_numpy_TODO():
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:442:    NUMBER_OF_DIGITS = 25   # TODO: this should ideally be automatically handled.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:526:    #TODO A class Complex may be implemented. The BeamParameter may
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:885:    #TODO add the other possible arguments
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:906:#TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:911:#TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/vector/vector.py:735:        # TODO : Circular dependency if imported at top. Should move
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:47:    # TODO : The unit vectors should print with subscripts but they just
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:50:    # TODO : The pretty print division does not print correctly here:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:35:    TODO: Handle condition such as symbols have subscripts/superscripts
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:94:    # TODO: Need to handle printing
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:172:        #TODO: Current version ignores the indices set for partial trace.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:189:        # TODO : improve this implementation
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:192:    #TODO: Review if the permute method is needed
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:3:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:428:            # TODO: make sure the hilbert spaces of the bra and ket are
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:491:        # TODO if operands are tensorproducts this may be will be handled
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:36:    TODO: implement a decompose property that returns how to do this in terms
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:3:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:417:            #TODO: Add support for sets of operators
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:451:    TODO (?): Support for Muls and other types of expressions?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cartesian.py:3:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:141:# TODO: Move this into sympy.matrices.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:242:            # TODO: This can be optimized to reduce the number of Qubit
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:104:    # TODO: don't expand the scalars in front of each Mul.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:251:    # TODO: I may need to expand before returning the final result.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:78:        # TODO: explore different sparse formats. But sparse.kron will use
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tensorproduct.py:151:        # TODO: disallow nested TensorProducts.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:145:        # TODO: add methods for uncoupling operators
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:157:    # TODO: move this to qapply_Mul
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:165:        #TODO: use options to use different j values
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:616:        # TODO: move evaluation up to represent function/implement elsewhere
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1017:            # TODO: better way to get angles of rotation
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1487:            # TODO: Need hilbert space fix, see issue 5732
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:1:#TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:486:    #TODO: Improve simplification method
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:675:    # TODO: Check for symmetries
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_trace.py:82:    #TODO: needed while testing reduced density operations, etc.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_density.py:269:    #TODO: test for invalid arguments
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:3:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:678:    # TODO: Fix non-unicode pretty printing
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_cartesian.py:113:    # TODO: Add tests for representations
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:13:TODO List:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/quantum/density.py:21:    TODO: Density operator support for Qubits
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:351:                # TODO: should this raise a warning?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:522:        #TODO: the inversion will fail if the system is inconsistent, for
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:206:    # TODO: decide whether to allow such expression in the future
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:227:    # TODO: Pow only support structural equality:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:244:    # TODO: need better simplification routine:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:249:    # TODO: need a better way to simplify expressions containing units:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:253:    # TODO: fix this, it should give `m` without `Abs`
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/kane.py:630:    # TODO : Remove `new_method` after 1.1 has been released.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_particle.py:55:    # TODO make the result not be system-dependent
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/series/gruntz.py:633:    # TODO this should not be necessary
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/series/series_class.py:70:        TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:441:    f = x*exp(x)*sin(2*x)  # TODO: rsolve needs improvement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:162:    # TODO : A better output for Order(log(x) + 1/log(x))
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:148:    # TODO zeta function series
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:152:    # TODO 8.35 - 8.37 (bessel, max-min)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:655:        TODO: Implement algorithm for sparse matrices (SFF),
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/hadamard.py:165:# TODO Implement algorithm for rewriting Hadamard product as diagonal matrix
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:52:    # TODO: this is commented because it slows down the tests.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:105:    # TODO: find a way to represent a four-dimensional zero-array:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:225:    # TODO: TensorProduct is not supported
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:292:    # TODO: no support for TensorProduct.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:407:    # TODO: restore this result (currently returning the transpose):
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:416:    # TODO: restore (currently returning the transpose):
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:435:    # TODO: not implemented
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:444:    # TODO: wrong
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:448:    # TODO: wrong
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:731:    TODO: Implement algorithm for sparse matrices (SFF),
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:1167:    # TODO: currently not working as ``_MinimalMatrix`` cannot be sympified:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3614:        TODO: Implement algorithm for sparse matrices (SFF),
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/matrices.py:70:    # TODO: Add handlers to make these keys work with
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/common.py:17:    # TODO: Add examples
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:238:    # TODO: Add examples
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:337:    # TODO: Add examples
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:394:    # TODO: Add examples
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/calculus.py:57:    # TODO: Add examples
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/refine.py:53:        # TODO: this will probably not work with Integral or Polynomial
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:47:    # TODO: implement sathandlers system for the matrices.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:77:    # TODO: implement sathandlers system for the matrices.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:94:    # TODO: implement sathandlers system for the matrices.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:218:    # TODO: This should be deducible from the nonzero handler
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:103:        # TODO: Run additional checks to see which combination of the
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:660:            # TODO: ANTLR refers to ISO 80000-2:2019. should we keep base 10 or base 2?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:520:            #TODO: No string type in AST
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:102:            # TODO: Arithmetic Assignment
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:151:            # TODO: Integer Binary Operations
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:239:            # TODO:Numbers when the LFortran ASR is updated
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:257:            # TODO: Return statement, variable declaration
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:796:            # TODO: Currently only works with symbols. Make it work for dynamicsymbols.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1269:            # TODO** Parse block matrices
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1936:        # TODO parse integers as well ?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2023:        # TODO: Should these be protected?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:26:# TODO you are a bit excessive in the use of Dummies
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:27:# TODO dummy point, literal field
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:28:# TODO too often one needs to call doit or simplify on the output, check the
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1101:        # TODO: you need a real dummy function for the next line
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1309:                    if c:  # TODO this is ugly - the Commutator can be Zero and
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1438:    # TODO the calculation of signatures is slow
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1439:    # TODO you do not need all these permutations (neither the prefactor)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1594:        # TODO: you need a real dummy function for the next line
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1892:    # TODO Is this a good idea?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1919:    # TODO move some of this to class methods.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1920:    # TODO rewrite using the .as_blah_blah methods
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1965:    # TODO move some of this to class methods.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1966:    # TODO rewrite using the .as_blah_blah methods
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_hyperbolic_space.py:86:    #TODO - it would be nice to have index contraction built-in
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:103:    #TODO assert m == R2_r.transform(R2_p, R2_p.transform(R2_r, [a, b])).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:117:    #TODO assert m == R3_r.transform(R3_c, R3_c.transform(R3_r, m)).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:120:    #TODO assert m == R3_r.transform(R3_s, R3_s.transform(R3_r, m)).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:123:    #TODO assert m == R3_c.transform(R3_s, R3_s.transform(R3_c, m)).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:128:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_c, R3_c.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:131:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:134:        #TODO assert m == R3_c.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_c, m)).applyfunc(simplify)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:19:    #TODO assert point.subs(x, 2) == Point(cs, [2, y])
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:20:    #TODO assert point.free_symbols == set([x, y])
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/str.py:962:        #TODO : Handle indices
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:107:    # TODO: a better class structure would avoid this mess:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:202:        # TODO: is this necessary?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:95:    # TODO - assumes all called functions take one double precision argument.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:200:# TODO: Make brackets adjust to height of contents
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:333:    # TODO robustify when no unicodedat available
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1574:        # TODO should exp_polar be printed differently?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1910:            #TODO: Move this code to prettyForm
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2239:        # TODO: the stuff to the left of the | and the stuff to the right of
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2602:        # TODO: copy-pasted from _print_Function: can we do better?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2671:                # TODO incorporate order
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2808:        #TODO: Handle indices
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:10:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4575:    # TODO: The "x in N" parts below should be centered independently of the
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7256:    # TODO: add support for ASCII pretty.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7620:    # TODO: TBD polylog(s - 1, z)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:238:    # TODO: merge this with the above, which requires a lot of test changes
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:1176:        # TODO should exp_polar be printed differently?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2585:                # TODO incorporate order
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2777:        # TODO: This expression is potentially confusing,
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2785:        # TODO nicer fractions for few generators...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2802:        # TODO nicer fractions for few generators...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2850:        # TODO: Handle indices
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:182:@SKIP  # TODO - this is currently not checked but should be implemented
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:236:    # TODO - matrix broadcasting?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:611:    # assert theq(aesara_code_(sy.Ne(x, y)), aet.neq(xt, yt))  # TODO - implement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:2079:    #TODO: Handle indices
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:172:@SKIP  # TODO - this is currently not checked but should be implemented
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:226:    # TODO - matrix broadcasting?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:599:    # assert theq(theano_code_(sy.Ne(x, y)), tt.neq(xt, yt))  # TODO - implement
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:93:    # TODO more tests
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:646:    # TODO: Apply different strategies, considering expression pattern:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1087:        # TODO: see if x*log(a)+x*log(a)*log(b) -> x*log(a)*(1+log(b))?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1247:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:50:#   TODO work this out in detail.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:86:    # TODO see if this can work as Mod(x, 1); this will require
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:253:    # TODO branching
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:736:        # TODO with symbolic parameters, it could be advantageous
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1947:    # TODO tons of more formulae
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1991:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2116:    # TODO for now, we use the following simple heuristic: inverse-shift
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2245:    # TODO the following would be possible:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2250:    # TODO Also, we tend to create combinations of gamma functions that can be
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2443:    # TODO it would be helpful to give conditions under which the integral
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:121:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:116:    # TODO [a+1, aRational(-1, 2)], [2*a]
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:130:    # TODO hyperexpand(hyper([a], [2*a + 1], z))
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:131:    # TODO [S.Half, a], [Rational(3, 2), a+1]
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:135:    # TODO [a], [a - S.Half, 2*a]
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:949:    # TODO polys
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1011:    # TODO LOTS more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1039:    # TODO LOTS more
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:393:                    # TODO is there a better heuristic?
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/gui.py:26:    # TODO: @classmethod: write() on GUI?
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/utils.py:9:# TODO consider using wcswidth third-party package for 0-width characters
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/cli.py:117:# TODO: add custom support for some of the following?
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/cli.py:125:        TODO: find out why this is needed.
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/rich.py:74:    # TODO: @classmethod: write()?
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/std.py:1442:        # TODO: private method
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/__init__.py:3:from .cli import main  # TODO: remove in v5.0.0
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/__init__.py:4:from .gui import tqdm as tqdm_gui  # TODO: remove in v5.0.0
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/__init__.py:5:from .gui import trange as tgrange  # TODO: remove in v5.0.0
./api/pipeline/.venv/lib/python3.12/site-packages/tqdm/tk.py:31:    # TODO: @classmethod: write()?
./api/pipeline/.venv/lib/python3.12/site-packages/anyio/_core/_fileio.py:416:        def info(self) -> Any:  # TODO: add return type annotation when Typeshed gets it
./api/pipeline/.venv/lib/python3.12/site-packages/uvicorn/protocols/websockets/wsproto_impl.py:120:            # TODO: Remove `type: ignore` when wsproto fixes the type annotation.
./api/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/backend.py:367:# TODO: Fill in the PR number
./api/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py:378:        # TODO: Ensure this primary_metric works as expected, also with bolding the right thing in the model card
./api/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:253:        # TODO: This is rather inefficient, as we load all data into memory. We might benefit from a more efficient solution
./api/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:323:            # load_best_model_at_end=save_best_model, # <- TODO: Look into a good solution for save_best_model
./api/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1405:# TODO: Fill in the PR number
./api/pipeline/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:118:                # TODO: Consider following these steps automatically so we can load PEFT models with other backends
./api/pipeline/.venv/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1600:        # TODO: use search_filter once with have an HasVector like condition
./api/pipeline/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:238:                # TODO is this the right name for the data attribute ?
./api/pipeline/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:305:        # TODO I think there is an edge case here where an annotation's span might not close
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/_utils.py:14:            # TODO: use `add_suggestion` from torchvision.prototype.utils._internal to improve the error message as
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/utils.py:315:    # TODO: There might be a way to vectorize this
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/_utils.py:11:    # TODO add back the assert
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/poolers.py:36:# TODO: (eellison) T54974082 https://github.com/pytorch/pytorch/issues/26744/pytorch/issues/26744
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:45:    # TODO: It's possible the masking here is unnecessary if y and
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:80:# TODO: this doesn't actually cache
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:81:# TODO: main library should make this easier to do
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:155:        # TODO: we should change all of this from ground up to simply take
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:190:        # TODO check if stream needs to always be the video stream here or not
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:193:        # TODO add some warnings in this case
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:206:        # TODO add a warning
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:321:            # TODO raise a warning?
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:160:            # TODO: load metadata
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:166:            # TODO: add extradata exception
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/kinetics.py:115:        # TODO: support test
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/video_utils.py:388:            # TODO: Revert it once the bug is fixed.
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:267:# TODO: specify the return type
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/datasets/celeba.py:173:                # TODO: refactor with utils.verify_str_arg
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:39:# TODO: Once torchscript supports Enums with staticmethod
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:1564:    # TODO: if image shape is [N1, N2, ..., C, H, W] and
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:70:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:94:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:392:        # TODO: Jit is failing on loading this op when scripted and saved
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:862:    # TODO: we should expect bincount to always be faster than histc, but this
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_color.py:36:    # TODO: Maybe move the validation that num_output_channels is 1 or 3 to this function instead of callers.
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/__init__.py:93:    hflip,  # TODO: Consider moving all pure alias definitions at the bottom of the file
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:186:    # TODO: Add _xywh_to_cxcywh and _cxcywh_to_xywh to improve performance
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:242:    # TODO: Investigate if it makes sense from a performance perspective to have an implementation for every
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:250:            # TODO: when https://github.com/pytorch/pytorch/issues/68430 is fixed (possibly by https://github.com/pytorch/pytorch/pull/100373),
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1239:        # TODO: See https://github.com/pytorch/pytorch/issues/40763
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1259:# TODO: This should be removed once torch_pad supports non-scalar padding values
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1326:        # TODO: add support of other padding modes
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1591:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1846:    # TODO: add in docstring about approximation we are doing for grid inversion
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1854:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:107:    # TODO: consider deprecating integers from sigma on the future
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:221:        # TODO: remove this branch as soon as `dtype.is_floating_point` is supported by JIT
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:360:    # TODO: Do we really need to check for out of bounds here? All
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_utils.py:91:# TODO: let's use torchvision._utils.StrEnum to have the best of both worlds (strings and enums)
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:15:# TODO: do we want/need to expose this?
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:377:                        # TODO: we don't need to enforce tensors, just that entries are indexable as t[bool_mask]
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/_presets.py:113:        # TODO: we could re-train the video models with antialias=True?
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/__init__.py:74:        # TODO: better messages
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/__init__.py:78:        # TODO: better messages
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/mobilenetv3.py:84:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/utils.py:38:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/shufflenetv2.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:51:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:42:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:64:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:86:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:120:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:202:    # TODO: simplify when indexing without rank will be supported by ONNX
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:451:    # TODO : replace below with a dynamic padding when support is added in ONNX
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:744:                # TODO: https://github.com/pytorch/pytorch/issues/26731
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/generalized_rcnn.py:86:        # TODO: Move this to a function
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:43:            # TODO change this
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:54:    # TODO: https://github.com/pytorch/pytorch/issues/26792
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:609:        # TODO: Move this to a function
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:629:        # TODO: Do we want a list or a dict?
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/_api.py:177:        # TODO: Replace ann.__args__ with typing.get_args(ann) after python >= 3.8
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/__init__.py:21:# TODO: we could / should document them publicly, but it's not clear where, as
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:154:                # TODO: If we have documentation on how to do that, put a link in the error message.
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:200:    # TODO: maybe we should use __getstate__ and __setstate__ instead of __reduce__, as recommended in the docs.
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/__init__.py:11:# TODO: Fix this. We skip this method as it leads to
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/_dwt.py:183:        # TODO: Check whether this makes a copy
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/_dwt.py:237:    # TODO: Lots of possible allocations to eliminate (zeros_like, asarray(rec))
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/_wavelet_packets.py:324:        node.parent = None  # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/_wavelet_packets.py:457:            data_a = node_a.reconstruct()  # TODO: (update) ???
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/_wavelet_packets.py:459:            data_d = node_d.reconstruct()  # TODO: (update) ???
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/tests/test_matlab_compatibility.py:23:         # TODO: Now have implemented asymmetric modes too.
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/tests/test_cwt_wavelets.py:287:    # TODO: investigate why atol = 1e-5 is necessary
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/tests/test_wp2d.py:158:    # TODO: decompose=True
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/tests/test_wpnd.py:124:    # TODO: decompose=True
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/tests/test_perfect_reconstruction.py:39:    # TODO: smoke testing - more failures for different seeds
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:274:            # TODO: we don't go through the rebuild logic here directly because we don't want
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:55:    # TODO PEP 747: use TypeForm:
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:333:        # TODO check for classvar and error?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:411:        # TODO check for classvar and error?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:413:        # TODO infer from the default, this can be done in v3 once we treat final fields with
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:720:            # TODO: properly make use of the protocol (https://rich.readthedocs.io/en/stable/pretty.html#rich-repr-protocol)
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/fields.py:797:    default: ellipsis,  # noqa: F821  # TODO: use `_typing_extra.EllipsisType` when we drop Py3.9
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/deprecated/json.py:112:# TODO: Add a suggested migration path once there is a way to use custom encoders
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/alias_generators.py:7:# TODO: in V3, change the argument names to be more descriptive
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/functional_validators.py:213:            # TODO if `schema['serialization']` is one of `'include-exclude-dict/sequence',
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:124:# TODO: ultimately, make this public, see https://github.com/pydantic/pydantic/pull/9459#discussion_r1628197626
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:592:            # TODO: is there a better way? should we just not do this?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/dataclasses.py:277:        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:303:        # TODO: in theory we should check that the schema accepts a serialization key
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:407:            # TODO this is an ugly hack, how do we trigger an Any schema for serialization?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:613:        # TODO: note, this is a fairly common pattern, re lax / strict for attempted type coercion,
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1724:        # TODO: do we really need to resolve type vars here?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1743:                # TODO: something like https://github.com/pydantic/pydantic/issues/5952
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2005:        TODO support functional validators once we support them in Config
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2511:# TODO V3: this function is only used for deprecated decorators. It should
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:235:    # TODO: This could be unified with `get_standard_typevars_map` if we stored the generic metadata
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:276:        # TODO remove parentheses when we drop support for Python 3.10:
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:91:    # TODO When we drop 3.9, use a match statement to get better type checking and remove
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:170:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:176:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py:83:    # TODO: this is a bit redundant, we could probably avoid some of these
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_validators.py:44:    # TODO: refactor sequence validation to validate with either a list or a tuple
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:139:# TODO implement `is_finalvar_annotation` as Final can be wrapped with other special forms:
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:186:# TODO In 2.12, delete this export. It is currently defined only to not break
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:195:# TODO: Ideally, we should avoid relying on the private `typing` constructs:
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:445:        # TODO ideally recursion errors should be checked in `eval_type` above, but `eval_type_backport`
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:230:                # TODO we can also stop there if `__pydantic_fields_complete__` is False.
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:29:    TODO: Perhaps we should move this structure to pydantic-core. At the moment, though,
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:32:    TODO: It's unfortunate how functionally oriented JSON schema generation is, especially that which occurs during
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:236:            # TODO: should we merge the parent namespace here?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:263:        # TODO `typ.__type_params__` when we drop support for Python 3.11:
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:394:                    # TODO: We should probably do something with this so that validate_assignment behaves properly
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:406:                        # TODO: same note as above re validate_assignment
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:433:            # was already evaluated. TODO: is this method relevant?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:436:        TODO: the nested function definitions here seem like bad practice, I'd like to unpack these
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:505:        # TODO: I dislike that we have to wrap these basic dict updates in callables, is there any way around this?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:713:            # TODO: should we add regex flags to the pattern?
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1117:        # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1240:        # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1281:                        # TODO: fixme - this is a workaround for the fact that we can't always resolve refs
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1320:        # TODO: Need to read the default value off of model config or whatever
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1321:        use_strict = schema.get('strict', False)  # TODO: replace this default False
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/v1/utils.py:270:            # TODO: replace annotation with actual expected types once #1055 solved
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/v1/networks.py:535:    # TODO: Needed to generic "Parts" for "Replica Set", "Sharded Cluster", and other mongodb deployment modes
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/mypy.py:513:                    # TODO: Only do this if the first argument of the decorated function is `cls`
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/mypy.py:622:                # TODO: We shouldn't be performing type operations during the main
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/mypy.py:785:            # TODO this path should be removed (see https://github.com/pydantic/pydantic/issues/11119)
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/main.py:4:# TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/main.py:1043:                    # TODO - matching error
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/main.py:1689:    # TODO PEP 747: replace `Any` by the TypeForm:
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/formatters/terminal256.py:17:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/formatters/latex.py:334:        # TODO: add support for background colors
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/formatters/img.py:548:            # TODO: make sure tab expansion happens earlier in the chain.  It
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:445:            # TODO: these don't match the comments in docs, remove.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:130:                # TODO unsure if ellipses are allowed elsewhere, see
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/textfmts.py:240:    # TODO: Make date regex more ISO 8601 compliant
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:755:            # TODO support other Python syntax like $foo['bar']
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:123:            # TODO: we should probably escape also here ''${ \${
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:135:        # TODO: let/in
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/ada.py:116:            # TODO: use Name.Namespace if appropriate.  This needs
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:150:            # TODO: better logging
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:347:                # TODO: better handle multiline comments at the end with
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:588:            # TODO: Backslash escapes?
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mips.py:28:    # TODO: add '*.s' and '*.asm', which will require designing an analyse_text
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:886:    # TODO / should divide keywords/symbols into namespace/rest
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:1341:            (r'\S+\s+', Text)   # TODO: make tests pass without \s+
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:390:            # TODO: Treat context-depedendent names specially
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:396:            # TODO: templates start and end tokens.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/urbi.py:34:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/dns.py:53:            # TODO, $GENERATE https://bind9.readthedocs.io/en/v9.18.14/chapter3.html#soa-rr
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:27:    # TODO String interpolation @VARNAME@ inner matches
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:28:    # TODO keyword_arg: value inner matches
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/perl.py:35:    # TODO: give this to a perl guy who knows how to parse perl...
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/_asy_builtins.py:9:    TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:140:            # TODO: regexes can have other delims
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:191:        # TODO: builtins are only subsequent tokens on lines
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:648:            (r'^(\* )(TODO)( .*)',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:650:            (r'^(\*\*+ )(TODO)( .*)',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:656:            # Unordered lists items, including TODO items and description items
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:672:            # TODO: language-dependent syntax highlighting (see Markdown lexer)
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:701:            (_inline(r'=', r'='), String), # TODO token
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/javascript.py:133:            # TODO: should this include single-line comments and allow nesting strings?
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/testing.py:200:            (r'(?i)\bTODO\b', Comment.Preproc),
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:49:            # TODO: highlight references in fandocs
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:85:        'insideUri': [  # TODO: remove copy/paste str/uri
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/c_like.py:212:            # TODO: "correctly" parse complex code attributes
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/modula2.py:474:        'TODO', 'FFI', 'ADDR', 'VARGLIST', 'VARGC',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:24:    TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:85:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:123:                "varname",  # TODO varname the right fit?
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:273:                        "async for",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:274:                        "async with",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:702:        # TODO supported?
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/parsers.py:396:            # TODO finish implementing other possibilities for scope
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/css.py:555:            # TODO: broken, and prone to infinite loops.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/rnc.py:36:            # TODO single quoted strings and escape sequences outside of
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/scripting.py:1502:            # TODO: JES3 statement
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/oberon.py:50:            # TODO: nested comments (* (* ... *) ... (* ... *) *) not supported!
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/dotnet.py:558:# TODO support multiple languages within the same source file
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexer.py:861:    TODO: clean up the code here.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/auto_augment.py:905:        # TODO the results appear in the right ballpark but they differ by more than rounding.
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_dataset.py:5:TODO: 2. NaFlexIterableDatasetWrapper - Iterable dataset that yields batches with variable sequence lengths
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:373:        # TODO: use foreach_pow if/when foreach_pow is added
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:342:        # TODO: use foreach_pow if/when foreach_pow is added
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/norm_act.py:114:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:104:        ValueError: if the string def not properly specified (TODO)
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/tiny_vit.py:626:            # TODO: whether move this func into model for dynamic input resolution? (high risk)
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/regnet.py:128:    # TODO dWr scaling?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:993:        block_fn = cfg.block_fn or Block  # TODO: Support configurable block_fn via string lookup
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:994:        mlp_layer = cfg.mlp_layer or Mlp   # TODO: Support configurable mlp_layer via string lookup
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/davit.py:813:# TODO contact authors to get larger pretrained models
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/resnest.py:49:        assert aa_layer is None  # TODO not yet supported
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/resnest.py:50:        assert drop_path is None  # TODO not yet supported
./api/pipeline/.venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9:# TODO: remove this check when dropping Python 3.7 support
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:167:    TODO: handle base64 as input
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:173:            yield get_session().get(content).content  # TODO: retrieve as stream and pipe to post request ?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:25:# Some TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:259:        # TODO: this should be handled in provider helpers directly
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:257:        # TODO: this should be handled in provider helpers directly
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/mcp_client.py:192:            # ^ TODO: should be handle `get_session_id_callback`? (function to retrieve the current session ID)
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:51:TODO: add support for `huggingface-cli delete-cache aaaaaa bbbbbb cccccc (...)` ?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:52:TODO: add "--keep-last" arg to delete revisions that are not on `main` ref
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:53:TODO: add "--filter" arg to filter repositories by name ?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:54:TODO: add "--limit" arg to limit to X repos ?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:55:TODO: add "-y" arg for immediate deletion ?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:85:    # TODO: refactor this + imports in a unified pattern across codebase
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:25:    # TODO: deprecate when adapted in transformers/datasets/gradio
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:43:    # TODO: deprecate when adapted in transformers/datasets/gradio
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:58:    # TODO: deprecate when adapted in transformers/datasets/gradio
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:60:    TODO: could be useful to be able to set a custom error message.
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:91:    # TODO: add an argument to opt-out validation for specific argument?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4726:            # TODO: remove this in v1.0
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4999:            # TODO: remove this in v1.0
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:796:                    # TODO: (optimization) download regular files to copy concurrently
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:323:    TODO: factorize logic with `read_download_metadata`.
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:380:            # TODO: can we do better?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:466:        # TODO - maybe handle this similarly to EvalResult?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:752:    # TODO - Check if there cases where this list is longer than one?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:476:                TODO - Some args above aren't used since we are calling
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:494:        # TODO: change this in a future PR. We are not returning a KerasModelHubMixin instance here...
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/_oauth.py:158:    # TODO: handle generic case (handling OAuth in a non-Space environment with custom dev values) (low priority)
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/constants.py:138:hf_cache_home = HF_HOME  # for backward compatibility. TODO: remove this in 1.0.0
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:121:    >>> from huggingface_hub import load_torch_model  # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:327:        # TODO: use `commit_description` to list all the deleted paths?
./api/pipeline/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:701:                    "tree_id": None,  # TODO: tree_id of the root directory?
./api/pipeline/.venv/lib/python3.12/site-packages/jinja2/ext.py:251:    # TODO: the i18n extension is currently reevaluating values in a few
./api/pipeline/.venv/lib/python3.12/site-packages/torch/quantization/fuse_modules.py:10:# TODO: These functions are not used outside the `fuse_modules.py`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/quantization/__init__.py:42:    # 'fuse_fx', 'quantize_fx',  # TODO: add quantize_dynamic_fx
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/uniform.py:28:    # TODO allow (loc,scale) parameterization to allow independent constraints.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/laplace.py:73:        # TODO: If we ever implement tensor.nextafter, below is what we want ideally.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:249:# TODO define a bijection for LowerCholeskyTransform
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:551:# TODO: Add Beta-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:590:# TODO: Add ContinuousBernoulli-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:649:# TODO: Add Exponential-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:694:# TODO: Add Gamma-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:726:# TODO: Add Gumbel-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:823:# TODO: Add Pareto-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:920:# TODO: Uniform-Laplace KL Divergence
./api/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:105:    # TODO Move this to C++ once the jit has better support for torch.Size.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:1477:    # TODO: type dim as BroadcastingList when
./api/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:1643:            _dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))
./api/pipeline/.venv/lib/python3.12/site-packages/torch/functional.py:1646:    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:408:    # TODO(albanD) This needs to be updated when more than one level is supported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:434:    # TODO: add an API to map real -> complex dtypes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:590:            # TODO: This implies that ellipses is valid syntax for allocating
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:7:# TODO: Should use `torch._C._get_privateuse1_backend_name()` to get
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:12:# TODO: Limitations and things about enable_torch_dispatch_mode we should fix before exposing it:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:629:                # TODO(https://github.com/pytorch/pytorch/issues/76750)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:650:        # TODO: add limited pickling support for sharing an iterator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/graph.py:22:# TODO(VitalyFedyunin): Make sure it works without dill module installed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:6:# TODO: Caveats
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/decoder.py:320:                # TODO: xinyu, figure out why Nvidia do this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:36:            # TODO(VitalyFedyunin): Replacing with TorchArrow only API, as we are dropping pandas as followup
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:120:        except Exception:  # TODO(VitalyFedyunin): Replace with better iterable exception
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:8:# TODO(VitalyFedyunin): Add error when two different traces get combined
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:53:#  TODO(VitalyFedyunin): Extract this list from the DFIterDataPipe registred functions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:61:    # TODO: All operations are shared across entire InitialCapture, need to figure out what if we join two captures
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:78:        # TODO(VitalyFedyunin): Currently can't pickle (why?)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:131:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:142:    # TODO(VitalyFedyunin): Add tests
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:143:    # TODO(VitalyFedyunin): Need to join context if one of them are empty because we used capture
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:146:        # TODO: Check if args or kwargs have more than one different context
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:148:            # TODO: Allow CaptureA to take context from mock
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:190:        # TODO(VitalyFedyunin): Do not use provate function here, copy own implementation instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:220:        # TODO: VitalyFedyunin execute kwargs and maybe nested structures
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:242:    # TODO(VitalyFedyunin): This should be atomic and thread safe
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:261:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:421:    # TODO(VitalyFedyunin): Must implement all special functions of datapipes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:146:            # TODO: Add try-except to in-place reduce traceback from the Exception
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:197:                # TODO: Simplify the traceback message to skip over `response = gen.send(None)`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/gen_pyi.py:227:    TODO: The current implementation of this script only generates interfaces for built-in methods. To generate
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:67:    # TODO: Lambda for picking
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:167:    # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/fileopener.py:54:        # TODO: enforce typing for each instance based on mode, otherwise
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:136:    # TODO(VitalyFedyunin): Verify that item is any sort of batch
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:138:        # TODO(VitalyFedyunin): Compact all batch dataframes into one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:155:            # TODO(VitalyFedyunin): Add default collation into df_wrapper
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:166:    # TODO(VitalyFedyunin): We can dynamically extract types from the tuple_values here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:167:    # TODO(VitalyFedyunin): Instead of ignoring mypy error, make sure tuple_names is not empty
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:227:        # TODO(VitalyFedyunin): Replace `Callable[..., Any]` with `Callable[[IColumn], Any]`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:228:        # TODO(VitalyFedyunin): Replace with `Dict[Union[str, IColumn], Union[Callable, Enum]]`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:235:                # TODO(VitalyFedyunin): Validate passed dictionary
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:104:        # TODO: Performance optimization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:15:# TODO: Use TypeAlias when Python 3.6 is deprecated
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:206:# TODO: When PyTorch drops the support for Python 3.6, it can be converted
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:262:        # TODO: the statements below are not reachable by design as there is a bug and typing is low priority for now.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:280:    # TODO: Fix isinstance bug
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:327:    # TODO: Fix isinstance bug
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:336:    # TODO: Fix isinstance bug
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:380:    # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/__init__.py:1:# TODO(VitalyFedyunin): Rearranging this imports leads to crash,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:156:# TODO: Implement `SeedSequence` like object for `torch.random`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:496:    TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py:8517:        # TODO: Undo this special-case; see the header for motivation behind this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:13:            # TODO: Remove this once ScriptModule supports registering None buffer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:54:            # TODO: Remove this once ScriptModule supports registering None buffer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:238:    # TODO(XuehaiPan): remove this condition when we make Python pytree out-of-box support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:110:        # TODO: when the bounds have free variables, this may be
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:180:    # TODO: this doesn't work with bools but arguably it should
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:606:        # TODO: We should tighten value ranges
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:622:        # TODO: We should tighten value ranges
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:768:        # TODO A better way of doing this would be to assign them a range upon creation, as
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:163:# sharing (TODO: considering splitting out a BaseReferenceAnalysis).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:31:# TODO: Dedupe this with SYMPY_INTERP
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:36:    # TODO add CeilDiv (it doesn't appear in the index_expr)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:38:    # TODO default to some decompositions if the interpreter doesn't have them
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:144:                        # TODO if https://github.com/openai/triton/issues/619 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:299:# TODO: As an indicator, this != 0 implies == 1 (and vice versa).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:312:        # TODO: it is possible to make progress evaluating this guard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/weak.py:319:        # TODO, add _fix_weakref type binding
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:103:        # TODO: make storage support buffer protocol so this isn't
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:112:    # TODO: factor this into a random utility
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:153:    # TODO: offer some sort of non-blocking API to speed things up
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:158:        # TODO: consider not using torch.save for this; we don't actually
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:184:        # TODO: Support more advanced snapshotting of requires_grad/grad/etc
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:33:    # TODO(#105471): Rename the count field
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:841:            # TODO: we can probably make this check stricter by checking that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1155:    # TODO: unify _is_compiling across all compile stacks
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:205:    # TODO: expose other parameters in the future.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:45:        # TODO; Specify a __slots__ for this class or potentially
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:114:        # TODO: See if we can remove this in the future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:216:        # TODO: compute correct memory usage and CPU time once
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:344:    # TODO: See if we can extract GPU vs CPU information from the PyTorch model
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:72:        # TODO: See if we can remove this in the future if we are
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:395:        # TODO: Should we do this even for non-contiguous tensors?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:405:        # TODO: Provide more useful diagnostics.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/dlpack.py:47:# TODO: add a typing.Protocol to be able to tell Mypy that only objects with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:83:                # TODO: This creates a temporary file for every frame, but we
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:174:            # TODO: Maybe indicate that the traceback was elided?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:299:            # TODO: change this warning to an error after OSS/internal stabilize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1407:# TODO(angelayi): remove this function after OSS/internal stabilize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1413:# TODO(angelayi): remove this function after OSS/internal stabilize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:74:      // TODO: Maybe check that compressed_size === file_size.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:81:  // TODO: Better formatting.  Right-align this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:121:      // TODO: Maybe show simple lists and tuples on one line.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:125:      // TODO: Maybe show simple lists and tuples on one line.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:129:      // TODO: Maybe show simple (empty?) dicts on one line.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:217:    // TODO: Check stride and indicate if the tensor is channels-last or non-contiguous
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:218:    // TODO: Check size, stride, offset, and numel and indicate if
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:220:    // TODO: Maybe show key?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:268:        // TODO: Less copy/paste between this and normal dicts.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:308:  // TODO: Add human-readable sizes?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:309:  // TODO: Add sorting options?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:310:  // TODO: Add hierarchical collapsible tree?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:481:// TODO: Maybe track by dtype as well.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:482:// TODO: Maybe distinguish between visible size and storage size.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:48:    - Fix various TODO comments in this file and the JS.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:179:            # TODO: Undo at least that second hack.  We should support string states.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:293:                # TODO: Handle this case better.  TorchScript ranges are in bytes,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:326:                # TODO: handle errors here and just ignore the file?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:278:        # TODO: Make this work with autograd
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:507:    # TODO: Figure out how to handle this better
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1055:    # TODO: Handle inference mode properly.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:170:            # TODO: Don't guard on this!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:236:# TODO: Remove ViewBufferFromNested, ViewNestedFromBuffer, and buffer_from_jagged once the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:327:        # TODO: An alternative way to construct offsets is to use F.pad. This avoids creating
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:64:        # TODO: Figure out whether masks are actually supported for this layout or not
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:315:        # TODO: Explore performance impact of copying
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:320:        # TODO: Explore performance impact of copying
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:326:        # TODO: Explore performance impact when compiling
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:370:# TODO: Next iteration should add test cases and check it works
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:550:    # [TODO] K and V have to have the same Nnz, should probably torch_check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:603:# TODO: coalesce with torch/nn/utils/attention.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:605:    # TODO: Investigate why math.sqrt() isn't properly handled by Dynamo?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nested/__init__.py:235:        # TODO: switch to as_nested_tensor(tensor) when it is available
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:78:    # TODO: test the specs match; empirically  sometimes we have a tuple
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:126:                # TODO: suppress guards
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:136:        # TODO: This probably does the wrong thing if you're running other
./api/pipeline/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:198:            # TODO: support get_autocast_gpu/cpu_dtype
./api/pipeline/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:271:                    # TODO: is there a way to split by device and dtype without appending in the inner loop?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:643:    # TODO: This feature could be added in the future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:670:                # TODO: Once we decide to break serialization FC, this case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:708:            # TODO: There's an issue here with FC. It might be impossible to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:786:    # TODO: This feature could be added in the future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:798:                # TODO: Once we decide to break serialization FC, this case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1138:                    # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1150:                    # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1206:                # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1226:                    # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:1387:        # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:3881:    # TODO: handle out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5007:# TODO: Deduplicate this with canonicalize_dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5771:    # TODO: Query cudnnGetRNNTrainingReserveSize (expose to python)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1376:    # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2400:            # TODO: Remove this once script supports type() calls
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2466:    # TODO: make use of reduce like below when JIT is ready with the missing features:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4524:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5412:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5421:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:1284:    # TODO: consider removing this check and allowing users to specify
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:65:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:136:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:20:    # TODO Make return type more specific
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:238:    # TODO allow kwargs such as unsafe and others for parametrization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:653:                        # TODO: Fix this for tensor subclasses that are parameters:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:171:        # TODO: Re-enable this check (.type isn't supported in TorchScript)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:295:# TODO: ContrastiveNorm2d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:296:# TODO: DivisiveNorm2d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:297:# TODO: SubtractiveNorm2d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:286:        padding_mode: str = 'zeros',  # TODO: refine this type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:438:        padding_mode: str = 'zeros',  # TODO: refine this type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1109:# TODO: Deprecate and remove the following alias `_ConvTransposeMixin`.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1132:# TODO: Conv2dLocal
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1133:# TODO: Conv2dMap
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1134:# TODO: ConvTranspose2dMap
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1300:        padding_mode: str = 'zeros',  # TODO: refine this type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:# TODO: fail fast on quantization API usage error, then remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:264:# TODO: PartialLinear - maybe in sparse?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/padding.py:10:# TODO: grad_output size asserts in THNN
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1843:    # TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1889:        # TODO: Remove `args` and the parsing logic when BC allows.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:626:# TODO: remove the overriding implementations for LSTM and GRU when TorchScript
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1287:            ret = input  # TODO: remove when jit supports exception flow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:57:        # TODO: check in THNN (if inplace == True, then assert value <= threshold)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:153:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1788:# TODO: L1HingeEmbeddingCriterion
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1789:# TODO: MSECriterion weight
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1790:# TODO: ClassSimplexCriterion
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/_reduction.py:18:        ret = -1  # TODO: remove once JIT exceptions support control flow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/comm.py:122:    # TODO: When `len(inputs) == 1` and all inputs are on `destination`, just
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:89:    # TODO (rohan-varma): keep_low_precision_grads: bool = False
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:90:    # TODO (rohan-varma): APIs to allow users to run batchnorm and layernorm
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:147:        # TODO: Expand to remote RRefs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:290:        # TODO: make DDP uneven inputs context manager support buffer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:840:            # params. TODO (rohan-varma): Make this compose with general
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1039:                        # TODO: when zero_grad(set_to_none=False) or in grad
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1511:            # TODO (rohan-varma) test this codepath.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1548:        # TODO: DDPSink is currently enabled for unused parameter detection and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:126:    # TODO: update notes/cuda.rst when this class handles 8+ GPUs well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/attention/bias.py:230:                    is_causal=True,  # TODO: Flash accepts causal = True and for this particular op it means lower right
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/attention/__init__.py:21:# TODO: Consider using this for sdpa regardless of subclasses
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:969:    # TODO: __name__ not set for submodules in recursive script
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:1368:# TODO support future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/library.py:146:            # TODO: in future, add more info about where the existing function is registered (this info is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/library.py:455:    # TODO(rzou): We're gonna need to stage this change with torchvision,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_script.py:837:                # TODO: we don't have _concrete_type set after load(), and in general we lose constant information.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_script.py:845:                # TODO: it's possible that the following is confusing:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_script.py:996:    # TODO MAKE SURE THAT DISABLING WORKS
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:64:    TODO: To remove this check once Union support lands.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:130:                    # TODO: To remove this check once Union suppport in TorchScript lands.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:443:        # TODO: this is hack to recognize NumberType
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:449:        # TODO: Determine if the other cases need to be fixed as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:539:    # TODO: Consider not exporting these during wildcard import (reserve
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:253:    # TODO: proper overriding analysis when implementing class inheritance
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:382:# TODO: more robust handling of recognizing ignore context manager
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:516:        # TODO: add input, output validator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:755:            # TODO: try to recover the location of else:? Python doesn't give us useful
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:32:# TODO: there should be a more principled way of doing this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:300:            # TODO: We should really error in this case, but its bc-breaking so
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:319:            # TODO: We should really error in this case, but its bc-breaking so
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:400:            # TODO: could add more detail here. For example, what the user should do
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:680:            # TODO: Why skip this? Because @torch.jit._overload_method will
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:686:        # TODO: we don't currently do this functions that are recursively
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:843:    (TODO add a link when the rules are published).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:86:# TODO: replace torch.sigmoid -> aten.sigmoid
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_builtins.py:120:    # TODO: add support for more ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_serialization.py:164:    # TODO: Pretty sure this approach loses ConstSequential status and such
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:159:            # TODO: figure out one liner to .clone() and set requires_grad
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:228:    # TODO: In principle, we track device information in our trace, so it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:232:    # TODO: Consider adding a utility function to torch.jit to test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:272:        # TODO: I'm not sure if the clone here is necessary but it is safer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_check.py:147:        # TODO @ansley: add `Union` once landed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:39:            # TODO: only assertion error is bound in C++ compilation right now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:94:            # TODO: only assertion error is bound in C++ compilation right now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:405:    # TODO: return self
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:611:        # TODO: handling of slice
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:617:        # TODO: handling of slice
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:678:    # TODO: look into rewriting with early return and getting loop unrolling to fire
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:698:    # TODO: assertions could be expanded with the error messages
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1029:        # TODO: return self
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1037:    # TODO: use slicing when slice optimization has landed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1439:# TODO: migrate over all of symbolic_shape_registry_util.cpp
./api/pipeline/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1454:# quantized_conv_prepack TODO
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:687:                # TODO: handle the other Ju
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:928:            # TODO: To cover more problematic cases, replace stride = 0 check with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1720:    # TODO: properly handle case when u is tuple instead of only taking first element
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1902:    # TODO: replicate https://github.com/pytorch/pytorch/pull/77743 for fast gradcheck as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:2194:    # TODO: do we want to test this too?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/_functions/tensor.py:30:# TODO: deprecate this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:598:        # TODO: TorchScript ignores standard type annotation here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:618:        # TODO: Too slow with __torch_function__ handling enabled
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:655:        # TODO: Too slow with __torch_function__ handling enabled
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:921:        )  # TODO: find in sqlite database
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:71:            # TODO: We can remove this conditional once we uniformly use
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:538:        # TODO: Raise exception instead of converting value.  This is only for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:563:        # TODO: Raise exception instead of converting value.  This is only for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:626:        # TODO: Raise exception instead of converting value.  This is only for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:674:    # TODO: Enable data-dependent checks with debug mode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:675:    # TODO: This check does not work with FakeTensor inputs; See Issue #85834
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:754:    # TODO: raise exception instead of converting value
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:810:# TODO: This ref supports int reduction and out kwarg to be compatible with ATen:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:812:# TODO: Could be rewritten to support complex:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:896:        # TODO: Raise exception instead of converting value.  This is only for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1042:        # TODO: Raise exception instead of converting value.  This is only for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/special/__init__.py:231:# TODO: add docstring
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:114:    "round",  # TODO: model kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:204:    "copy_to",  # TODO: add OpInfo (or implement .to)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:386:    # TODO: make common validations available as utils
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:450:# TODO: add type promotion support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:740:# TODO: if this is special maybe it should be defined there and imported here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:965:# TODO: register this as a real ref/decomposition once TorchInductor supports complex!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1614:# TODO: skip unnecessary conversion of long to float
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1695:# TODO: consider refactoring this with add impl
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1898:# TODO: implement alternate where
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2095:    # TODO: is_pinned is not currently supported in refs or fake_tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2119:    # TODO: non_blocking should be handled by `copy_to`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2151:            # TODO - this is true for eager mode currently, but it's wrong behavior for complex norms
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2782:        # TODO: fix this to work with meta tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2993:    # TODO: we could look at directing collapse_view to skip its meta function here (unsafe_collapse_view)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3058:# TODO: This must return a sparse tensor if the input is sparse, but refs have
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3222:# TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4416:    # TODO: Add sparse support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4544:# TODO: Turn this into a decomposition (currently fails on reshape meta tests)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5343:    requires_grad: bool = False,  # TODO: unused
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5370:    # TODO: Use requires_grad.  All refs taking the requires_grad kwarg must
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5970:    # TODO: fix inductor rand_like for integer, bool dtypes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6004:# TODO: add support for functionalization aten.normal_functional
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6264:    # TODO: this is inaccurate, we actually test PySequence_Check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6305:    # TODO: this is inaccurate, we actually test PySequence_Check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6315:            # TODO: test this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6373:    # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6377:    # TODO: test for numpy input with PyArray_Check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6405:    # TODO (or not): support names kwarg
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6415:        {"device": "cpu"},  # TODO: use torch.get_default_tensor_type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:126:        # TODO: This solution is no ideal since we may miss some factory methods. In future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:183:    # TODO: this part is TS backend specific for now and will be generalized to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:9:    TODO: This API is currently ts backend specific. We are working on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:23:    TODO: This API is currently ts backend specific. We are working on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_lazy/__init__.py:16:    # TODO(whc) expand this to include backend hooks and align with XLA backend needs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:222:    # TODO: Uhh.... it shouldn't matter, but changing this to true_fn results in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:225:    # TODO Sometimes the operands are not completely FakeTensor, something seems went wrong in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:16:# TODO to figure out a more generic approach
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:48:        # TODO(ydwu4): Subclassing HigherOrderOperator causes __module__ to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:21:# TODO: this is not really sufficient. While passes (hopefully) check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:77:# TODO: currently we just run the C++ implementation with fake tensors.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:290:                # TODO(oulgen): add support for tt.reduce
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:325:    # TODO(oulgen):
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:723:    # TODO(oulgen): Preexisting bug, if two kernel inputs are views of each
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:758:    # TODO(oulgen): For performance reasons, we want to ensure that these
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:774:    # TODO(oulgen): For performance reasons, we want to ensure that these
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:177:            # TODO: We want to use the same `checkpoint(Interpreter(gmod).run, *args, **kwargs)` here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/map.py:28:# TODO: We add this to prevent dymamo from tracing into map_wrapper,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:176:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:263:                # TODO: Validation currently involves an expensive traversal
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:363:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_utils.py:855:    TODO(khabinov): we should deprecate this function and use torch.compiler.is_compiling().
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_utils.py:97:            # TODO: there are many flatten/unflatten in IterGraph that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:50:        # TODO: if we do ``deepcopy(_codegen)`` and the input argument contains
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:352:        # TODO: This is a temporary solution. We are going to remove DCE usage
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:598:        # TODO: remove this API after DCE is removed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:614:        # TODO: remove this API after DCE is not used with IterGraph
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:739:        # TODO: remove this API once it is not used.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:59:# TODO(@fegin): Support multiple runs of graph optimization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:60:# TODO(@fegin): With this design, circular imports will happen when a pass
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:215:    # TODO: populate all the tensor metadata and remove the default.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:218:        # TODO: support symbolic shapes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:242:    # TODO: fix the memory_format
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:264:        # TODO: fix these value
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:324:                # TODO(@fegin): support symbolic shapes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:485:        # TODO: determine the dtype
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:601:# TODO(fegin): Have a template class for all Block class.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:611:    # TODO(fegin): populate/generate the max_exp_avg_sqs if exists
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:927:# TODO(fegin): The API only support fused adam now. Should extend it to support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:165:            # TODO: figure out why turning on cudagraphs cause exceptions.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:193:    # TODO(yifu): apparently having a meta kernel is not a necessary
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/comm_tensor.py:141:                # TODO(ezyang): I don't really understand what's going on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:483:    # TODO(@mrshenli): @yifuwang has a suggestion of conducting expansion and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:496:# TODO: ensure the key is unique.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:553:                    # TODO: SPMD should provid a default and configurable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/log_utils.py:47:        # TODO(anj): Add loggers for MPMD
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:39:        TODO(@wanchaol): some of these arguments are not necessary for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:53:        # TODO: add more necessary arguments to this interface.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:93:        # TODO: what if user passes in a incorrect `input_batch_dim`, how should we
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:100:            # TODO: add a few default passes here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:113:        # TODO: figure out a way to avoid explicit "cuda" mesh.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:132:        # TODO: add more necessary arguments to this interface.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:150:            # TODO: add a few default passes here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:215:        # TODO: move the trasnformation passed to this function
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:227:    # TODO: provide schema_suggestions when placements do not match
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:393:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:141:    # TODO: this is broken because it won't redistributed potential tensors on the kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:480:    # TODO(anj): This depends on the call function node -> actual DTensor output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:522:        # TODO(anj): We require mapping of the final DTensor output to the wait
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:540:                # TODO(anj): We are depending on the concrete DTensor output of the dummy add.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:730:            # TODO(anj): Pipe the output schema for the BW pass
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:158:    # TODO: Only NCCL supports AVG so using backend like Gloo would
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:358:                # TODO: Currently this specializes to fused optimizer ops, but we need
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:397:                    # TODO: optimizer parts should follow the dtensor prop logic
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:536:                    # TODO: add support for default mode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:226:            # TODO(yeounoh) implement DeviceMesh backend and register XLA backend.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:246:            # TODO: if user want to pass pg_options, offer a way to do it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:273:            # TODO(yifu): remove tag and ranks once we fully migrate to native
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:304:                        # TODO: Add two tests to cover internal tests scenarios and re-enable reuse subgroup if exists.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/nn/jit/templates/remote_module_template.py:60:# TODO: Merge these two templates together in the future once TorchScript syntax is improved.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:261:            # TODO: We need to change this to rpc.remote, and make it async (see the else branch below).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:204:# TODO assert if ranks has duplicated entries
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:232:    # TODO add dim support?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:280:    # TODO add dim support?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:80:    # TODO: should we use pytree?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:149:                # TODO: support DTensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:89:        # TODO: figure out dynamo support for instance method and switch this to instance method
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:394:                    # TODO: re-enable the check once we fix the compile path
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:471:                    # TODO: re-enable the check once we fix the compile path
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:80:        # TODO: we should allow user to pass in the default seed from a config
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:23:    # TODO: Will follow up with dynamo POC to make warnings.warn working with dynamo.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:40:    # TODO: To add perf optimizations to this iterations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:94:    # TODO: To add test cases and ensure that it works for nested modules
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/fsdp.py:350:            # TODO: this is a short term fix and we should make the get_unflat_views
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:20:        # TODO(@fegin): this variable is originally create for testing, we
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:131:    # TODO(fegin): using kwargs is not a good idea if we would like to make
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_init.py:129:    # TODO: De-duplicate with `_apply` after `swap_tensors` path lands:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:146:        # TODO: Replace the sharded DTensor parameter construction logic with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:148:        # TODO: Simplify the following sharded parameter padding logic after
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:178:            # TODO: Hard code FSDP + TP; need to support HSDP + TP
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:353:        # TODO: Prefer this DTensor to be read-only and generalize the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/fully_shard.py:218:        # TODO: Remove this padding logic once DTensor pads the local tensor:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:18:# TODO: we can add additional info to RegistryItem to share across APIs. E.g.,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:165:            # TODO: a stricter verification should also reject changing module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:168:            # TODO: verify that installed distributed paradigms are compatible with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:176:                {},  # TODO(@yhcharles): this is a temporary fix, need a better way
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:57:        # TODO: Once step_param interface is robust, refactor step to call
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py:71:            # TODO: Remove these attributes once we have a better way of accessing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:58:    TODO: Add tutorial for _NamedOptimizer.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:59:    TODO: Add documentation in the docstring for the public attributes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:313:        # TODO(chienchin): This API should be FSDP agnostic and should support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:322:        # TODO(chienchin): This API should be FSDP agnostic and should support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:29:# TODO (wanchaol): remove this once we added TorchScript
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:60:# TODO (wanchaol): remove/merge this with ScriptLocalOptimizer once
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:112:    # TODO: improve error propagation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1535:        # TODO: Manually add `self.param_groups` if using a functional
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:57:        # TODO: no union or any types in TorchScript, make step a scalar tensor instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/pipeline/sync/skip/skippable.py:241:# TODO(sublee): Move to above of Skippable class for better read flow.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_loader.py:33:        # TODO: test returning `load` here instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:9:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:19:# TODO: Update Docstring for nested_dict.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:34:# TODO: update docstring for traverse.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:145:        # TODO: add local offset for _local_tensor in print_nested.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_sharded_tensor_utils.py:15:# TODO: We need to refactor this code.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:384:# TODO: integrate with distributed logging flag
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:60:# TODO: Update docstrings for default_planner.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:46:# TODO: Update docstrings for optimizer.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:189:            # TODO: The ReadItems will have a displaced MetadataIndex, fix it.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:190:            # TODO: we should change _create_sharded_read_items to have more ergonomic API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:77:        # TODO: add logging for the gc details/time
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:373:        # TODO: make this faster.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:573:            # TODO: check if value is the same if exists.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:962:# TODO: correct the state_dict function signature.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:963:# TODO: this API is not yet fully tested. Make it private
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1017:# TODO: correct the load_state_dict function signature.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1018:# TODO: this API is not yet fully tested. Make it private
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:39:    # TODO: test returning `save` here instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_dedup_tensors.py:30:# TODO add docstring for dedup_tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:220:        # TODO replace with headq
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:269:            # TODO: Using the OverlappingCpuLoader with multiple threads creates significant
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:572:                # TODO sort by offset and cache the reading
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/format_utils.py:118:        # TODO: read on each host, instead of only the coordinator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:317:            # But maybe we need to? TODO(voz): Look into this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:579:        # TODO: Do not use the side stream for tensor copies for now; investigate
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:784:    # TODO: Post-backward prefetching does not support the multiple handles
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:961:    # TODO: Investigate why `NO_SHARD` breaks correctness when using
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:963:    # TODO (rohan-varma): When CPU offload and optimizer overlap,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:994:                # TODO (rohan-varma): For CPU offload, this unfortunately
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1084:        # TODO (rohan-varma): this also waits for the overlapped optimizer step to finish
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1127:            # TODO: This already-resharded check is brittle:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:155:    # TODO: need to check if this is always correct for composable FSDP.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:449:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:506:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626:            continue  # TODO: Improve unittesting for state_dict finetuning
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_wrap_utils.py:43:    # TODO: We may relax this no-nested-wrapping constraint to support manual
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:115:        # TODO: Move all the attributes to this class to enable typing for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:195:    # TODO: This is a temporary hack for differentiate between code paths.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:238:    # TODO: Explicitly replacing the checkpoint wrapper prefix is not ideal as
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:337:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:422:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:430:                            # TODO(voz): Don't graph break on this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:511:            # TODO: We need to run this mixed precision ignored module in fp32,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:559:        # TODO(voz): Extend a dynamo util to answer the above, unify the codepaths here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:81:        # TODO: figure out the case for the composable APIs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:96:        # TODO: figure out the case for the composable APIs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:142:        # TODO: Rank 0 can broadcast the `FlatParameter` to allow all ranks to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:253:            # TODO (awgu): The traversal function does not traverse through
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1448:        # TODO: This solution is not general and only apply to PTD TP solution.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1748:                # TODO: it is unclear if we need to do the same check with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:80:        # TODO (awgu): We can broadcast the metadata of rank 0's `all_handles`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:214:            # TODO (awgu): Since every module has at most one handle in the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:218:                # TODO(voz): Don't graph break on this - dynamo hates the n1 != n2
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:244:                # TODO(voz): Don't graph break on this - dynamo hates the i1 != i2
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:39:    # TODO: Add any other composable APIs that are mutually exclusive.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:46:# TODO (awgu): We may be able to remove this function if we retired the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:115:# TODO: Define this for now to avoid circular imports. See if we can remove.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1566:                # TODO (awgu): Gradient accumulation outside `no_sync()`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1607:            # TODO (rohan-varma): test for full precision with keep_low_precision_grads
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1616:        # TODO (awgu): We should replace these conditional checks to encode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1785:                # TODO: Change `_unpadded_unsharded_size` if we change the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2293:        # TODO: If we want to handle shared parameters, we need to re-generate
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:77:# TODO (awgu): Refactor this later
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:321:    # TODO: FSDP's contract for buffers is not well-defined. They are
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:517:    # TODO: we need to add additional check once we support FSDP + PiPPy.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:657:            # TODO: We may relax this by taking the FSDP instance's wrapped
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:832:    # TODO: We need to establish a contract for FSDP and buffers. For now, we
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1052:# TODO: See how to deprecate!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/distributed.py:77:            # TODO properly map the exceptions in pybind (c10d/init.cpp)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:430:        # TODO log_line_prefixes can be exanded too
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:144:        # TODO: look into using weakref here instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:190:# TODO: we should probably handle a few additional errors,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:248:        # TODO: look into using weakref here instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:919:        # TODO: implement timeout
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:84:    # TODO @kiuk - make entrypoint a required field
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:701:        # TODO after stopping workers, wait at least monitor_interval*2 for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py:100:# TODO: create an internal helper function and extract the duplicate code in FP16_compress and BF16_compress.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:72:            # not average. TODO: (rohan-varma) the div factor may be different
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:77:            # TODO (rohan-varma): upcast as needed for DDP mixed precision,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:593:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:814:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:285:    # TODO: Importing inside function to avoid circular import issue between FSDP and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:76:    # TODO: register_fsdp once FSDP supports communication hook.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:241:    # TODO this should be done inside AsyncCollectiveTensor to delay the wait() call
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:698:        # TODO: it should run collective in the whole mesh instead of dim 0
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:967:    group,  # TODO add a type,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:981:    op: str = "sum",  # TODO type is actually c10d ReduceOp. is this ok?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:982:    group=None,  # TODO add a type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/sharding_prop.py:173:        # scalar. TODO: figure out a better way to handle this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:138:            # TODO: by default check tensor metas across rank
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:139:            # TODO: See if we need to make this run_check logic
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:181:            # TODO: return the redistributed local tensor directly without
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:185:        # TODO: backward is also differentiable now, add a test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:248:        # TODO: consider all_gather the local tensors for better debugging
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:561:    # TODO: the value assignment to global variable is not the ideal solution
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_utils.py:16:# TODO: audit existing code base to see if we can safely remove this API.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:154:        # TODO: alltoall/permute reshuffling to change device_mesh if they are not the same
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:212:                # TODO: enable this with all_to_all
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:718:        # TODO: we can avoid forcing the redistribution once we figure out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:735:            # TODO: we can avoid forcing the redistribution once we figure out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:752:            # TODO: we can avoid forcing the redistribution once we figure out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:820:        # TODO: change the strategy to the following rule.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:827:            # TODO: now grad_out spec follows input spec. we may need
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:871:            # TODO: now d_weight spec follows input spec w/ a reduction.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:663:            # TODO: optimize this. we shouldn't simply blindly replicate
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/utils.py:140:        # TODO: maybe we should determine is_shardable based on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/random_ops.py:26:            # TODO: figure out how inplace random op should behave when it's partial
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/matrix_ops.py:151:    # TODO: sdpa might be a good candidate for us to explore decomposed sharding propagation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:98:                # TODO: further merge the sharding properly (i.e. reshard one input to replicate)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:164:            # TODO: consider a more advanced heuristic to pick the best sharding
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:115:            # TODO: see if this is valid for the submesh case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:171:    # TODO: filter out invalid strategies, at this point we generate
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/pointwise_ops.py:527:# TODO: add all for_each ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:178:        aten.new_empty_strided.default,  # TODO: re-think new_empty_strided
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:183:    # TODO: maybe we should generate all possible shardings intead of just stay
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:294:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:500:    TODO: exception: when the dtype of second input is "bool", then a torch.nonzero needs to be triggered first.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:775:    # TODO: tensor to split cannot have _Partial
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:785:    # TODO: just like slice op, split replicates before
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:44:        # TODO: evaluate if we need to release the mask buffer or the buffer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:177:    # TODO: implement rowwise sharding
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:253:    # TODO: implement rowwise sharding backward
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/dispatch.py:238:        # TODO: the op schema should probably just remain flattened so that we can avoid this tree flatten
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/tp_conv.py:13:    # TODO: whether there requires data exchange is currently determined by padding
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/placement_types.py:358:        # TODO: if the reduce_op is min/max, etc. the _partition_value should be a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/op_schema.py:214:    TODO: make this a frozen dataclass
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:26:# TODO: we need to migrate these APIs to be functional collectives
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:53:    # TODO: Ideally we should use the meta tensor way
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:109:    # TODO: Ideally we should use the meta tensor way
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:125:# TODO: test uneven split on GLOO and NCCL
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:142:        # TODO: pull the handle of uneven case in #492
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:207:                # TODO: see if we need to tweak this or offer a way for user
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:268:        # TODO: see if we want to support this once there's cross mesh communication
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/api.py:165:        # TODO: figure out a generic and efficient way to scatter the shards for EnumerableShardingSpec
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:150:        # TODO: Can we improve this error message to point out the gaps?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding.py:287:    # TODO: Make the result a PartialTensor.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding_bag.py:407:    # TODO: Make the result a PartialTensor and move the logic below there.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py:66:        # TODO: support named dimension
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:79:        # TODO: implement state_dict
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:90:        # TODO: implement load_state_dict
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:96:        # TODO: implement add_param_group
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:427:            # TODO make it as a view of out tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:492:        # TODO: make this a __torch_function__ op once ShardedTensor becomes a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:835:        # TODO: figure out what the API should behave when some rank have no shard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/tensor_ops.py:30:# TODO: set grad with a ShardedTensor that consists of all local grads
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:283:            # TODO: make async?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:342:        # TODO: add try-except and destroy _agent in all processes if any fails.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:245:        # TODO: remove this exception once UCC plugin is fully deprecated.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:482:        TODO don't expose the map, expose fine grained ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:492:        TODO don't expose the map, expose fine grained ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:502:        TODO don't expose the map, expose fine grained ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:512:        TODO don't expose the map, expose fine grained ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:522:        TODO don't expose group_count, use something else instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:611:            # TODO moco benchmark on CPU initializes pgnccl backend today, triggered this assert in CI before it was
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:816:# TODO: remove this once the ecosystem moves away from it.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:852:    # TODO(yifu): remove this function once ranks + tag is not a supported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1506:            # TODO: remove this check after lazy initialization is supported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1537:            # TODO: once UCC plugin is fully deprecated, remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1575:        # TODO: This defaults to the old behavior for PythonProcessGroups which overwrites the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3753:        # TODO(whc) aparently some existing test case for monitored_barrier passes in a timeout in float format?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4225:    # TODO copy settings and timeout from default PG
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_torch_docs.py:5271:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:43:# TODO: implement ref.cast with an option to enforce safe casting
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:172:# TODO: handle tuples of tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:362:            # TODO: There is a subtle bug here: prims like copy_to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:379:# TODO: when tracing this will add torch tensors and not TensorMeta objects
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:381:# TODO: this wrapper is currently untested
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:43:# TODO: Type[torch.SymInt], Type[torch.SymFloat]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:45:# TODO: This needs a lot more type annotations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:107:            # TODO: We should check that the symbols are consistent
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:134:# TODO: look at using torch.testing.assert_close instead with an option
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:164:        # TODO: we should review why this happens and see about fixing it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:440:    # TODO: are these necessary?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:449:    # TODO: do channels last too
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1034:        # TODO: type error here is real, replace with sym_complex
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1053:    # TODO: sym_complex_float?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1195:# TODO: maybe unify with can_cast_to?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1349:# TODO: when NumberType contains the sym types, can simplify this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1367:# TODO: document type promotion kinds
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1630:    # TODO: maybe inform the user of channels_last_3d if rank of the tensor is 5?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1923:    # TODO: a better way to handle this would be with a new op, "_unsafe_as_strided"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:123:    # TODO: no real reason to restrict multiple outputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:167:        # TODO: file issue
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:195:    # TODO: I think this does the wrong thing if r is inp
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:247:    # TODO: remove me
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:276:        # TODO: consider a memo
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:309:        # TODO: Add a config knob to turn off this unsound behavior
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:559:            # TODO: We can make this a little more faithful with best effort
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:941:            # TODO: Minor optimization: track if the shapes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:980:            # TODO: we don't need the compute type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:1002:        # TODO: is_non-overlapping_and_dense (not bound from Python
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/schema_check_mode.py:50:                # TODO: This is only OK if can't have NaN quantized; idk if
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_utils.py:109:                # TODO: enable_python_dispatcher() here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:69:    # TODO (tmanlaibaatar) make it a tag
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:103:            # TODO: right now, _make_wrapper_subclass's dynamic shape interaction is not great.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:288:            # TODO (tmanlaibaatar)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:468:    # TODO: pull these from aot autograd
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:82:        # TODO: test if is resizable (no direct query for this atm)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:83:        # TODO: audit AutogradMeta to see if it matches
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:84:        # TODO: test forward AD
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:216:            # TODO: make a dedicated UnknownSource for this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:415:                # TODO: Change this logic to use view replay for consistency?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:593:                    # TODO: Handle this better in Dynamo?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:872:                    # TODO: Use a valid grad-specific symbolic context instead of recycling
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:898:        # TODO: zero tensors?  We appear to have eliminated them by
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:913:                # TODO: sparse should support meta
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:50:# TODO: Hack to unblock https://github.com/pytorch/pytorch/pull/108186
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:416:    # TODO: Generalize this as needed, e.g., into a trie of memos
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1099:        # TODO: support caching sparse outputs?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1386:                    # TODO: Remove these exclusions, so that we can remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1405:        # TODO - we should be use the prim aten impl
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1406:        # TODO - fix prims complex ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1714:    # TODO: also check metadata change on inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:13:# TODO: Add type annotations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:14:# TODO: Check tensor types for ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:150:# TODO: Expose these directly to Python to avoid maintaining this list.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:206:    # TODO: Make this an enum.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:239:    # TODO: Support non-equal-rank broadcast where semantics match.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:264:    # TODO: Handle dilation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:492:                # TODO: Improve this error message, possibly after converting
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1169:            # TODO: Possibly check scale and zero point.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1171:            # TODO: Possibly support variable-sized inputs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1466:                # TODO: Support this by adding trailing 1 dims.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1496:        # TODO: Validate ceil_mode semantics.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1753:        # TODO: Transform at load time to share weights with CPU model.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1793:        # TODO: Support automatic reshape
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1832:        # TODO: Transform at load time to share weights with CPU model.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:2055:        # TODO: Transform at load time to share weights with CPU model.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:72:            # TODO: See if it's possible to use those directly.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:84:            # TODO: See if it's possible to use those directly.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:139:    # TODO: Maybe make these names match the original.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_custom_op/autograd.py:46:# TODO(#101191): Use the actual C++ autograd not implemented fallback,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:24:# TODO: Maybe we should allow for some sub-hierarchy so you can control which
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:113:    # flattens all the qnames together (TODO: consider memoizing?)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:1055:            # TODO: Actually, the rank probably should just be emitted once at
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset13.py:549:    # TODO: So far we don"t have a module using this method. We"ll keep
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1510:        # TODO: remove this as onnx opset 11 spec allows negative axes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1561:    # TODO(justinchuby): Looks like this op is deprecated in torch
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2446:    # TODO: remove this as onnx opset 11 spec allows negative axes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3451:# TODO(justinchuby): Support multiple quantized args in output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3477:# TODO(justinchuby): Support multiple quantized args in output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4261:# TODO(justinchuby): Support multiple quantized args in output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4291:# TODO(justinchuby): Support multiple quantized args in output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5376:    # TODO: remove this as onnx opset 11 spec allows negative axes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5856:            # TODO: If indexing is supported natively in ONNX in future opsets,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6311:        # TODO: Might need a fix in torch group_norm module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6820:# TODO: It would be better to export this as a chunk directly, as this is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6822:# TODO: Once we have proper scoping, stop reimplementing chunk, delete this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6884:        # TODO(justinchuby): Use a public method in the helper module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:112:# TODO(justinchuby): Add type checking by narrowing down the return type when input is None
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:252:            # TODO: Remove `check_shape` option once every shape inconsistent issue is addressed.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:435:        # TODO: remove this and treat mutating model separately. See #77679
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:619:    # TODO: refactor utils.py to remove duplicated code of context setup. See #78834
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:691:    # TODO: Below is doing aten graph to onnx. It should be abstracted as a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:873:        # TODO(#77679): remove this and treat mutating model separately.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:921:    # TODO: Only copy the argument if mutation is detected in Graph.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1278:            # TODO: A more compact graph printer.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1853:    # TODO: Copied from utils.py `export` until `_optimize_graph`.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_experimental.py:14:    TODO: Adopt this in `torch.onnx.export` api to replace keyword arguments.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:39:        # TODO(thiagocrepaldi): handle overload_name?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:45:        # TODO(thiagocrepaldi): handle overload_name?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:16:                        TODO: test coverage for mixed types inputs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:19:                        TODO: bfloat16 support.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:22:                        TODO: optional start/end attribute.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:156:    # TODO(justinchuby): Replace insinstance with _is_value once we figure out mypy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:432:            # TODO(justinchuby): Only single output is supported for now. We may want to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1346:        # TODO(justinchuby): Check if dtype is indeed a int.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1718:# TODO: remove these once we support Type's in the JIT IR and we can once again
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:75:# TODO(justinchuby): Remove dependency to this global variable from constant_fold.cpp
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1127:    # TODO: can we simplify this to always return a tuple of Tensor or None?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1379:            # TODO(justinchuby): Create a way to check if an op is fully supported.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1625:            # TODO: Don't allocate a in-memory string for the protobuf
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1851:        # TODO(justinchuby): Update the module name of GraphContext when it is public
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1952:                # TODO Wrap almost identical attrs assignment or comment the difference.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:134:        # TODO: get opset version from torchlib
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:362:        from torch.onnx._internal.fx import (  # TODO: Prevent circular dep
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1017:            # TODO: Should this be part of the serializer?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1080:        # TODO: Should we populate ONNXProgram with more info, such _model_torch for easier debug?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1119:    # TODO: Design the passes API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1154:        # TODO: https://github.com/pytorch/pytorch/issues/107714
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1164:        # TODO: Defer `import onnxscript` out of `import torch` path
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1174:            # TODO: Defer `import onnxscript` out of `import torch` path
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1451:    # TODO: Import here to prevent circular dependency
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/registration.py:149:    # TODO(justinchuby): Add @functools.lru_cache(maxsize=None) if lookup time becomes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:119:    # TODO: select a good default based on the capabilities of the host
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:683:    # TODO(wschin): Make it to inference session level flag.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:774:        # TODO(wschin): this is a naive implementation of cache without proper guard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:951:            # TODO(wschin): enable external allocators.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1079:                # TODO(wschin): use a better way to identify fused submodule
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:4:# TODO(justinchuby): Move more of the symbolic helper functions here and expose
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:359:# TODO: Expose this to user when migrating symbolic helper functions to here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:7:# TODO: Remove after https://github.com/huggingface/safetensors/pull/318
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:41:    TODO: Should this really be a global patcher? Can we make it a local patcher?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:98:# TODO: generalize to allow more checkpoints formats (torch or gguf)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:39:        # TODO: Figure out how to retrieve commit hash.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:188:    TODO(bowbao): Add more overridable methods in call hierarchy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:189:    TODO(bowbao): Create an example once more overridable methods are added.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:315:            # TODO(titaiwang): aten::sym_size has overload, but fx graph is using
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/op_validation.py:92:            # TODO(titaiwang): How to bound indices/dim: INT64
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:38:# TODO(bowbao): move to type utils.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1267:        # TODO(bowbao): diagnostic.emit and diagnostic.set_message api.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:54:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:109:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/diagnostics.py:129:    # TODO: Compact display of `param_schema`.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:56:    TODO(bowbao): Create fx utils module and move this function there.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:321:    # TODO: aten::sym_size has overload, but fx graph is using
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:400:    TODO: Convert methods to @staticmethod when the diagnostic system supports it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:409:        # TODO: Diagnostics API should be revised to get rid of this attribute.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:567:        # TODO: Fix FakeTensorMode limitation asap
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:761:        # TODO(wechi): Support call_method.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:818:        # TODO: We may want to consider other naming styles. The goal is to be stable and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/torch_export_graph_extractor.py:106:        # TODO: Import here to prevent circular dependency
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:125:# TODO: Migrate to `DynamoExporter` after fake model tracing is supported.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:159:        # TODO: plumb ``concrete_args`` to symbolic_trace call at ``generate_fx``
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:24:# TODO(bowbao): Add diagnostics for IO adapters.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:152:# TODO: make_fx lose stack info https://github.com/pytorch/pytorch/issues/90276
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:182:    # TODO(bowbao): Turn this check into diagnostic. Consider warning instead of error.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:493:                    "markdown": 'This error occurs when the ONNX converter is unable to find a corresponding symbolic function\nto convert a "call_function" node in the input graph to its equivalence in ONNX. The "call_function"\nnode represents a normalized function call in PyTorch, such as "torch.aten.ops.add".\n\nTo resolve this error, you can try one of the following:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/tutorials/beginner/onnx/onnx_registry_tutorial.html#overview) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n',
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:518:                    "markdown": "This error indicates that an FX graph contains one or more unsupported nodes. The error message\nis typically accompanied by a list of the unsupported nodes found during analysis.\n\nTo resolve this error, you can try resolving each individual unsupported node error by following\nthe suggestions by its diagnostic. Typically, options include:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n",
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:104:            # TODO(bowbao): by default diagnostic doesn't have stack.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:158:# TODO(bowbao): decorator to report only when failed.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:280:    # TODO(bowbao): Implement this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:406:            # TODO(bowbao): Create builtin-rules and create diagnostic using that.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/_infra.py:264:    # TODO: Implement this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:30:# TODO(After 1.13 release): Remove the deprecated SymbolicContext
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:146:# TODO(justinchuby): Deprecate these logging functions in favor of the new diagnostic module.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset10.py:763:    # TODO(justinchuby): Extract all the cast ops into a helper function.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/utils.py:75:                # TODO(avik): Assert the following property in the IR verifier:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:30:    # TODO(angelayi): remove this in favor of _check_val
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:42:        elif isinstance(val, (FakeTensor, torch.Tensor)):  # TODO(zhxchen17) Remove Tensor.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:161:            # TODO Remove this allowlist.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:170:                # TODO (tmanlaibaatar)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:199:                # TODO(T140410192): should have fake tensor for all dialects
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:247:                # TODO(zhxchen17)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/upgrade.py:109:        # TODO(larryliu0820): Add support for custom ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:234:        storage_offset=serialize_sym_int(0),  # TODO needs to be fixed.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:271:        # TODO: this should be fixed by deserialization instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:402:            # TODO(zhxchen17) Maybe provide a function name helper in FX.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:406:        else:  # TODO(zhxchen17) Don't catch all here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:439:                # TODO: create a new tensor_values here, meta might have faketensor info
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:476:                # TODO: This is not ideal, we should fix this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:858:            raise AssertionError("TODO")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1119:        # TODO: Directly serialize exported_program.constants once
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1179:        if serialized_target.startswith("_operator"):  # TODO(zhxchen17) Follow up on this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1185:        else:  # TODO(zhxchen17) Don't catch all here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1886:            # TODO(larryliu0820): Add support for upgrader & downgrader
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:102:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:107:                        # TODO we should allocate static shapes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:116:                        # TODO: This is just a workaround to get over the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:135:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:143:                        # TODO: This is just a workaround to get over the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:275:        # TODO(angelayi): Update this with what we decide to do for metadata in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py:16:# TODO (tmanlaibaatar) remove this after https://github.com/pytorch/pytorch/pull/100749
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:104:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:181:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:213:        # TODO(avik): Maybe record the constraint violation error instead and replay later?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_export/exported_program.py:8:# TODO(ycao): This is added to avoid breaking existing code temporarily.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/context.py:53:        # TODO: Should these methods be mapped some other way?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:233:        # TODO: This looks wrong, a number that is wrapped into a tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:338:# TODO: implement dtype validation here, too, or on the corresponding refs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:420:    # TODO: fix number type promotion (bool, complex->float)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:950:# TODO: complex needs a special meta to account for its float -> complex behavior
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1456:        # TODO: this is only here to support the unsqueeze ref
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1644:# TODO: make stride SymInt
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1695:# TODO: consider renaming split_dim_view
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1903:# TODO: review stride logic
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2054:        # TODO: update meta objects so this can be acquired directly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2118:# TODO: create a new return type for scalars?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2150:# TODO: create a new return type for scalars?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2182:# TODO: create a new return type for scalars?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2203:    # TODO: move this as an option on the reference
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2225:# TODO: Remove safe casting and implement on reference instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2288:# TODO: review support arbitrary resizes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2438:# TODO: layout, pin_memory, memory_format
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2439:# TODO: model requires_grad on TensorMeta
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2486:# TODO: layout, pin_memory, memory_format
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2487:# TODO: model requires_grad on TensorMeta
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2529:# TODO: add layout, pin_memory
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2584:# TODO: add layout, pin_memory
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2624:# TODO: add layout
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2707:# TODO: add layout and pin_memory support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2748:    # TODO The MAGMA backend returns V, so this is wrong if used with the MAGMA backend
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2875:# TODO: we should more seriously review randomness modeling and prims
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/executor.py:53:        # TODO: caching
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/maskedtensor/reductions.py:127:        # TODO: autograd.Function doesn't support kwarg
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:524:    assert mask.dense_dim() == input.dense_dim()  # TODO: eliminate this restriction
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:816:    # TODO: implement sparse CSR specific where operator for efficiency
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1381:            # TODO: compute count analytically
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1605:            # TODO: compute count analytically
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1621:        # TODO: replace torch.subtract/divide/square/maximum with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1785:    # TODO: eliminate mask_input as unnecessary when using masked divide.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1789:        # TODO: replace torch.maximum with masked maximum when available.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1791:        # TODO: replace torch.divide with masked divide when available.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:112:        # TODO(avik): use sympy value range analysis instead?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:126:        # TODO(avik): use sympy value range analysis instead?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:188:    # TODO: We don't need t_id; we can get it off of w_tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:287:        # TODO: A better way is needed. Currently we use 't_id' to map the constraint,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:364:        # TODO(avik): clean this up
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:277:            # TODO(suo): untangle this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:281:                # TODO(suo): The FlatArgsAdapter returns a list of flat args,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_unlift.py:246:    # TODO(suo) this should not be optional, but is since we still ahve
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:129:                # TODO(suo): this is horrible.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:270:        # TODO Make this tuple.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:281:        # TODO Make this tuple.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:302:        # TODO Make this tuple.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:312:        # TODO Make this tuple.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:133:    # TODO properly use the cached fake tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:186:                    # TODO Figure out why sometimes we have root sometimes we don't.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:208:                    except Exception:  # TODO(zhxchen17) Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:413:    transform=lambda x: x,  # TODO(zhxchen17) Revisit if this is needed later.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:446:    # TODO unfortunately preserving graph-level metadata is not
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/_trace.py:496:            # TODO: this branch is likely wrong, all permissible ConstantArgument type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:138:        verifier: Optional[Type[Any]] = None,  # TODO Change typing hint to Verifier.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:141:        ] = None,  # TODO: deprecate this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:478:        # TODO(zhxhchen17) Return the new graph_signature directly.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:543:        # TODO unfortunately preserving graph-level metadata is not
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:584:        # TODO(zhxchen17) Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:675:    # TODO(zhxchen17) Formalize this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/_unary_ufuncs_impl.py:71:# TODO set __name__ and __qualname__
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/random.py:162:    # TODO: check a.dtype is integer -- cf np.random.choice(3.4) which raises
./api/pipeline/.venv/lib/python3.12/site-packages/torch/optim/radam.py:466:            # TODO(mlazos): we should try and get a foreach_where op https://github.com/pytorch/pytorch/issues/117884
./api/pipeline/.venv/lib/python3.12/site-packages/torch/optim/_functional.py:19:# TODO: use foreach API in optim._functional to do all the computation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/optim/adam.py:51:            # TODO(crcrpar): [low prec params & their higher prec copy]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:59:            # TODO(crcrpar): [low prec params & their higher prec copy]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/package/importer.py:81:            # TODO: I guess we should do copyreg too?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/package/package_exporter.py:918:                # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:246:                # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:283:        # TODO from zdevito:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:27:# TODO: The mechanism we are using to register decompositions doesn't
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:97:# TODO: do these also belong here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:27:# TODO - We have to register many more distributions here, and also higher level
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:168:        # TODO: Investigate if there is be a better way to wrap the tuple in a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:59:        # TODO: pretty sure this is not quite right
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:387:# TODO: None of these loss castings are quite correct, see
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1413:# TODO: this doesn't appear to have enough precision in bfloat16
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1591:# TODO: Take a closer look at the type promotion semantics
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1798:# TODO: this decomposition is NOT here to stay. We would much prefer replacing native_batch_norm
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1965:    assert not layout or layout == torch.strided, "TODO"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1966:    assert not pin_memory, "TODO"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2257:            # TODO make minimum accept scalars
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4055:        # TODO: handling of slice
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:23:# TODO: relax key type here; torch registrations should be possible to; but
./api/pipeline/.venv/lib/python3.12/site-packages/torch/cpu/amp/autocast_mode.py:34:    # TODO: discuss a unified TorchScript-friendly API for autocast
./api/pipeline/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:293:    # TODO: Handle distinguishing between subclass and non-subclass versions of NT better
./api/pipeline/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:592:    # TODO: Maybe this should be in tensor_classes? :)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_lobpcg.py:993:        # TODO use torch.linalg.cholesky_solve once it is implemented
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_deploy.py:24:                # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_deploy.py:68:            # TODO: Once we decide to break serialization FC, we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_guards.py:60:    # TODO: consider also tracking the recompilation count
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_guards.py:779:# TODO(voz): Consider a toplevel torch/_source.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:32:# TODO(torch_deploy) figure out how to freeze version.py in fbcode build
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:566:                # TODO: fix their module from C++ side
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:651:            # TODO: Call like get_device_index() method corresponding to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:1507:        # TODO: Once the undocumented FC window is passed, remove the line bellow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:1937:# TODO: remove the function for PyTorch v 1.15.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:390:            # TODO: binary search
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:634:            # TODO: type annotations for *args and **kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:132:        # TODO node_name_to_scope will be depreciated in favor of
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:479:                # TODO: Define how to symbolically trace HigherOrderOperators
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:73:        # TODO: Figure out if this is safe. It seems like when generating the type signatures for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/meta_tracer.py:194:            # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:141:    TODO: we have to check if this is the case for all HF models
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:370:    # TODO: add the extra check mentioned here:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:393:        # TODO: review this rule; should input = dyn; output = dyn be included here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:519:            # TODO: we should figure out why there is a key-error here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:780:# TODO normalize index
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:884:        # TODO generate add constraints for scalar addition
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/schema_type_annotation.py:48:                # TODO: can we emit the union of these? What are the implications on TorchScript
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:354:                # TODO: add different size support for sparse_nn_partition
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:472:    TODO: Make Dynamo handle this appropriately if this is seen in Dynamo-ed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:477:    TODO: I didn't support min/max because I didn't have a use case where this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:540:    that doesn't have a lot of safety guarantees (TODO: provide higher level
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:580:    # TODO: Shouldn't we install a guard if the symbol is backed?  Or is the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:599:    # TODO: this does not install a deferred runtime assert yet
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:601:    # TODO: Maybe dedupe this with _maybe_guard_rel?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:610:        # TODO: Actually, we can support this as long as one of them is a symbol.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:657:        # TODO: check perf implications of this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:782:        # TODO: better printing for -oo and oo
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:939:    # TODO: add storage offset and stride symbolic_context
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:967:# TODO(voz): Shape env validation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:991:    # TODO(voz): consider a weakref to the shape_env here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1038:# TODO: Deduplicate this with torch/_prims_common/__init__.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1354:        # TODO(avik): https://github.com/pytorch/pytorch/issues/101093
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1756:                    # TODO(avik) Maybe we should generate an assertion here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1764:                    # TODO(avik) Maybe warn that `arg` in not in `signature`?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2383:        # TODO: make this configurable from outside symbolic_context; we made a symbolic_context
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2388:        # TODO: This should be DYNAMIC, using DUCK for BC
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2904:        # TODO: Make this more efficient by binding all the size/stride/offsets
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3566:        # TODO: when unbacked_only, can sometimes early return even when there
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3603:        # TODO it would seem that this pass is not necessary given the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3667:        # TODO: in a Dynamo context, having user code, and having the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3695:            # TODO: Help text about how to use our runtime tests to fix this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3748:            # TODO: Should we propagate size-like-ness?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4053:        # TODO: split conjunctions and evaluate them separately
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4126:                # TODO: dedupe this with _maybe_evaluate_static
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4175:                # TODO: If we successfully eliminate a symbol via equality, it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4187:                # TODO: deal with duplicate guards somehow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4247:        # TODO: split conjunctions and evaluate them separately
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4285:            # TODO: Do this in a way that is less janky than int(s.name[1:])
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/merge_matmul.py:116:        # TODO: Properly handle aliasing caused by get_attr. For now,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/_sym_dispatch_mode.py:50:        # TODO: properly compute types
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:184:    # TODO. We leave it like this till we add a type to represent tensor sizes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/_config.py:30:# TODO: Perhaps consider allowing unions for the configs below (so you can hit
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:154:            # TODO: This doesn't properly track storages.  A more robust
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:261:    # TODO: figure out if this API generally makes sense and bake it into the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:306:    # TODO: we could use types to test this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:332:        # TODO: maybe constant SymInts should also be allowed?  Not sure if
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:603:            # TODO(tmanlaibaatar): we should systematically couple it with expoert verifier,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:737:# TODO: I'm not sure what the point of this class is; you can just
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:756:        # TODO handle case where the first character of target is '*'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1042:            # TODO: it would be nice to line these up with the names
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1068:            # TODO: Would be nice to fix this at the source...
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1083:        # TODO: kind of a bad way to do it, should maybe figure out a better way
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:62:# TODO: An incomplete list
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:350:        # TODO: use the file/line for some useful diagnostic on why a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:360:        # TODO: use the file/line for some useful diagnostic on why a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:372:        # TODO: use the file/line for some useful diagnostic on why a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:389:        # TODO: file/line here is very important, because the assert has been
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:420:        # TODO: use the file/line for some useful diagnostic on why a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:444:# TODO: this probably needs the sizes-strides eval functions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:817:# NB: There is a TODO in C++ to allow omitting the batch dim.  If that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:882:    # TODO: These could also be done with indicators, maybe it is better
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:914:    # TODO: let C++ also take advantage of this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:957:        # TODO: consider constant prop here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1002:        # TODO: consider constant prop here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1103:            # TODO: Remove the args construction below if a different sentinel is used by FX.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1163:    # TODO: This is technically hotpath, but in the ideal end state
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1184:            # TODO: this is an awful implementation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:121:# TODO: Determine whether this can be removed after type inference.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:90:        # TODO: assert pattern is a connected graph
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:110:        # TODO(tmanlaibaatar) should probably make this actual API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:212:        # TODO: use a more efficient way to check if gn is matched before: two-way dict
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:133:            # TODO: do we really need copy the get_attr node into the graph?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/fake_tensor_prop.py:49:                # TODO: How is it possible that we get a non fake tensor?  We
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:11:    # TODO: why is submodules passed here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:51:    # TODO: single node partition may be wrong due to the pessimization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:295:        # TODO currently placeholders/parameters aren't put into random partitions,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:210:        # TODO(alexbeloi): add constraint management/validation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:129:# TODO: this should be beefed up to be able to properly re-inplace with:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:132:# TODO: we should also figure this info out using torchgen.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:538:                # TODO: later, add the optimization for handling `copy_()` calls in the graph.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/node.py:42:# TODO: Either refactor this into 2 functions 1 dce for functional graphs and 1 dce for all graphs,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:127:    # TODO: we shold handle __reduce_deploy__ the same way as __reduce_package__,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/hub.py:290:    # TODO: Remove `None` option in 2.0 and change the default to "check"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:280:        # TODO: Instead of always upcasting to int64, it would be sufficient to cast to the next higher dtype to avoid
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:787:        # TODO: Remove this conversion as soon as all operations are supported natively by the MPS backend
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1522:        # TODO: compose all metas into one AssertionError
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:324:        ),  # TODO: Move out to testing in param_group?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:345:# TODO: consider tensor LR! See multi_tensor_optimizer_configs in test_optim.py --> tensor LR should work
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:831:        ),  # TODO: Move out to testing in param_group?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:87:# TODO: due to case sensitivity problems, for now list these files by hand
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:701:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:707:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:733:        # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:29:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1547:            # TODO: now that nccl send/recv is supported, there does not seem to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2546:            # TODO: move this test to use torch.profiler once kineto issues are
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3593:            # TODO: Instead we should probably go through _rank_not_in_group
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6436:            # TODO: NCCL backend does not work correctly for bitwise reduction ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8408:            # TODO: enable this for general training use cases:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8637:            # TODO(#54879): Provide ability to wait and report all failed ranks
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:374:        # TODO: dist tensor need to support quantized and sparse
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:411:        # TODO: add multi mesh choices
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:928:        # TODO, need more investigation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:1152:            # TODO: Can't get a reliable time for this profiling event since
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1566:        # TODO, need more investigation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:548:    # TODO: use torch.futures.collect_all
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:1421:        # TODO: with TCP init, rank 0 raises Address already in use because
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3462:        # TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:5106:        # TODO: Cuda RPC is failing due to:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1037:        raise unittest.SkipTest('TODO: Memory availability checks for XLA?')
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1522:# TODO: the "all" in the name isn't true anymore for quite some time as we have also have for example XLA and MPS now.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:144:    # TODO: reference function
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:151:        # TODO(#50743): Figure out the error. "RuntimeError: Unrecognized tensor type ID: Batched"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2519:        # TODO(#50743): figure out the error
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2802:            # TODO: This code can path can be removed if #61309 is resolved
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3174:# TODO : Fix these discrepancies
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3317:            # TODO: compare structure (ensure analytic jacobian has correct shape)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3436:                # TODO: do this with in-memory files as soon as torch.save will support it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3732:                # TODO: torch.complex32 when properly supported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3814:    # TODO: check that criterions don't ignore grad_output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:45:# TODO: TensorBase should work
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:61:            # TODO: clone storage aliasing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:105:# TODO: Expand this class to handle abritrary settings in addition to boolean flags?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1261:# TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2349:# TODO: Revisit the relaxed pairs and check how much work it is to fix the tests that would fail without the relaxation.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2715:        # TODO: sure looks like we unconditionally initialize the context here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2788:        # TODO: Remove this; this is grandfathered in because we suppressed errors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3486:    # TODO: add args/kwargs for passing to assertEqual (e.g. rtol, atol)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3547:            # TODO: default this to True
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3621:            # TODO: compose all metas into one AssertionError
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3705:    # TODO: Support context manager interface
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4094:# TODO: consider more complicated noncontiguity schemes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4115:# TODO: remove this (prefer make_symmetric_matrices below)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4165:# TODO: remove this (prefer make_symmetric_pd_matrices below)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:341:    # TODO(future PR): consider combining with skipIfNoQNNPACK,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:975:            # TODO: make img_data a single example instead of a list
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1488:        # TODO: remove this check and define two fuse_modules function on this module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1710:# TODO: self.fc should be self.conv
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1724:# TODO: self.fc should be self.conv
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1741:# TODO: self.fc should be self.conv
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1890:        # TODO: remove this check and define two fuse_modules function on this module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2427:        # TODO: remove this check and define two fuse_model function on this module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:62:    # TODO: FSDP non-recursive wrapping
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1350:        # TODO: Disable checking the parameters for pure FP16 due to floating
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/hypothesis_utils.py:131:    # TODO: Maybe embed the enforced zero_point in the `torch.iinfo`.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:166:# TODO: Update all quantization tests to use this decorator.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:532:        # TODO: check gradients for parameters, not just inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:688:# TODO(suo) remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:752:# TODO: Remove me once https://bugs.python.org/issue42666 is resolved
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:821:        # TODO: inplace tests currently fail, fix and add inplace variant
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:825:    # TODO: find better way to standardize on op registration itself..
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:492:    # flaky test - TODO fix
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:530:# TODO: delete this list once we make all nn_tests work
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_cuda.py:53:# TODO(eqy): gate this against a cuDNN version
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:53:        "aliases": None,  # TODO add a check for alias coverage
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:55:        "inplace_variant": None,  # TODO: add a check for inplace coverage
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:754:    # TODO: rename this to supports_bwgrad_bwgrad to be consistent with below
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:835:    # TODO: rename supports_sparse to supports_sparse_coo
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1414:    # TODO(@heitorschueroff) Once all reduction operators are using
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1418:    # TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:2363:# TODO: in the future generalize the reference generators to handle n-ary elementwise operations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1534:        # TODO: backward uses in-place operations that vmap doesn't like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2394:            # TODO: is this really needed?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:150:                # TODO: remove this if-block after gh-98495 is fixed.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:215:            # TODO: remove this if-block after gh-98495 is fixed.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:248:            # TODO: remove this if-block after gh-98495 is fixed.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:42:# TODO: Consolidate `i0e` with sample_inputs_unary when `make_tensor`,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:70:        # TODO: eliminate low after gh-106692 is fixed:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:771:            # TODO Move fftshift to decomps
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:780:            # TODO Move ifftshift to decomps
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/signal.py:302:            # TODO: same as this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:791:        # TODO: we should pipe the exception of the failed subprocess here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:925:        # TODO: get test name from kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1025:        # TODO: figure out a better way to do this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:364:    # TODO: Uncomment when negative weights is supported.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:1507:        # TODO: add pos_weight to the definition here and corresponding SampleInputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1313:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1320:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1408:# TODO: add reduction kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1870:        # TODO: no layout
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1878:    # TODO: no layout
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2128:        # TODO: fix bug in the documentation for svd_lowrank:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3231:            # TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4405:    # TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5034:    # TODO: can't switch `to.device` overload to use positional arguments
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:7564:# TODO: add reference inputs for where(condition) signature
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8904:        # TODO: remove once the issue is resolved
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10179:                       # TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10821:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10832:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12524:           # TODO: some signatures of median do support out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12532:           # TODO: some signatures of nanmedian do support out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12540:           # TODO: some signatures of var_mean do support out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12553:           # TODO: some signatures of var_mean do support out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12565:           # TODO: some signatures of std_mean do support out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12578:           # TODO: some signatures of var_mean do support out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13032:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13052:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13081:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13246:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13288:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13336:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13386:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13446:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13488:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13521:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13565:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13582:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13603:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13653:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13670:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13687:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13940:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13959:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13987:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14033:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14049:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14077:           # TODO: add shape checks
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14142:           # TODO: add shape checks
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14146:           # TODO: investigate nondeterminism
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14261:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14350:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14400:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14481:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14508:            # TODO: Do not work even on MI200 because of stride mismatching.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14522:            # TODO Need to understand what this is testing and why it doesn't work
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14525:            # TODO skip this for now since we can't skip on runtime arch support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14582:            # TODO: Do not work on MI200 because of stride mismatching.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14603:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14648:    # TODO: combine this with the nn.functional.silu OpInfo when
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14726:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14825:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14831:        # TODO(whc) should not need sample_inputs_func, but without it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14922:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14946:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14965:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15132:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15287:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15889:               # TODO: Investigate this more
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16191:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16266:           # TODO(@heitorschueroff) update SampleInput to handle such cases
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16379:    # TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17332:               # TODO: same as this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17424:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17510:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17570:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17591:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17607:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17632:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17643:           # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17887:    OpInfo('trapz',  # TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18131:               # TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18315:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18403:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18451:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18478:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18511:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18544:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18569:        # TODO Benchmark again with the new implementation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18680:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18693:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18830:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18867:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18881:            # TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18908:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18959:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18962:    # TODO: delete this OpInfo once we add meta support for grid_sampler_3d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18970:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19326:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19375:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19450:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19526:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19544:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19639:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19661:        # TODO: Avoid COW materialize
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19838:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19839:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19867:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19868:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19899:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19900:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19926:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19927:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19953:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19954:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19982:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19983:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20012:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20013:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20946:    PythonRefInfo(  # TODO: Port this to an UnaryOpInfo
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21663:        # TODO: Uses minimum and clamp
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21691:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21699:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21707:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21718:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21748:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21756:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21764:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21772:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21783:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21794:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21805:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21813:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21821:        # TODO: If self already has the correct dtype and device, then self is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22680:# TODO: review porting these to make_tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_subclass.py:7:# TODO: Move LoggingTensor here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:227:        # TODO(future PR): consider designing this better, as the difference
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:233:        # TODO(future PR): consider refactoring this to better reuse the parent
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:260:        # TODO(future PR): make the comparison function configurable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:396:    # TODO(future PR): expose these
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:423:    # TODO(future PR): do not observe nodes we do not care
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:509:    # TODO(future PR): expose these
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:536:        # TODO(future PR): better check when scripted
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:583:# TODO(future PR): align on naming
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:664:    # TODO(future PR): expose these
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:805:    High level TODOs for future PRs:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:840:    # TODO(future PR): deduplicate repeating entries
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:864:# TODO(future PR): we should rethink the names of all the PNP APIs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:940:# TODO(future PR): we should rethink the names of all the PNP APIs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:963:# TODO(future PR): consider aligning API signature with other similar quantization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:973:# TODO(future PR): consider aligning API signature with other similar quantization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:996:        # TODO(future PR): consider matching in a safer way than
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:487:# TODO(future PR): clean this up
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:530:        # TODO(future PR): implement shadowing for binary ops and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:10:    # TODO(future PR): make this work correctly for methods
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:33:# TODO(future PR): reuse existing mapping instead of creating a new one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:112:    # TODO(future PR): try reversed(list(matches.items()))
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:166:            # TODO(future PR): make this code less confusing,  see discussion
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:242:    # TODO(future PR): reconsider the design to make this more intuitive.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:307:            # TODO(future): some graphs could have placeholders which are unrelated
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:346:            # TODO(future PR): handle non-normalized kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:373:            # TODO(future PR): this is not handling complicated graphs correctly, need to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:375:            # TODO(future PR): this is ignoring kwargs, will need to support kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:459:    # TODO(future PR): move logger classes to utils to remove circular dependency
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:491:        # TODO(future PR): deduplicate equivalent qconfigs that come from
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:528:            # TODO(future PR): handle fusion patterns where non-first nodes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:547:                    # TODO(future PR): clarify why we are adding kwargs to args
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:588:    # TODO(future PR): implement this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:609:        # TODO(future PR): add a test case for this once we have an easy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:623:    # TODO(future): consider making this configurable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:702:    # TODO(future PR): move logger classes to utils to remove circular dependency
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:800:                # TODO(future PR): make this support all possible args/kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:815:                        # cur_node_orig.name,  # TODO(future PR): set name explicitly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:992:    # TODO(future PR): move this to config
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1006:        # TODO(future PR, if needed): support kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1007:        # TODO(future PR, if needed): support multiple shadow users
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1011:            # TODO(before land): fix string match
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1086:# TODO(future PR): redesign this to make it easier to consume outputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1172:# TODO(future PR): redesign this to make it easier to consume outputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1252:# TODO(future PR): redesign this to make it easier to consume outputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:23:# TODO(future PR): consider deleting this enum and using the torch types
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:30:    # TODO(future PR): while these functions can support multiple dtypes,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:35:    # TODO(future PRs): dynamic quant, fake quant, etc
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:45:    # TODO(future PR): clean this up
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:196:        # TODO(future PR): handle more functionals
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:197:        # TODO(future PR): handle functional ops which inherit qparams from input
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:314:        # TODO(future PR): use relationship map instead of hardcoding
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/ns_types.py:18:# TODO(future PR): see if we can use typing_extensions's TypedDict instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:240:        # TODO(future PR): determine the actual dtype of node_c,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:303:                # TODO(future PR): add handling for quantize_per_tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:320:# TODO(future PR): look into using copy_node API instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:449:    TODO(before land): real docblock
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:480:            # TODO(future PR): enable multiple inputs for nodes which are not at start of subgraph
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:842:                    # TODO: explain this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:72:    # TODO(future PR): make more generic, handle everything
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:149:    # TODO(future PR): why does packed_weight.unpack() not work?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:24:    # TODO(future PR): allow customizations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:25:    # TODO(future PR): reuse existing quantization mappings
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:26:    # TODO(future PR): add the rest of modules and ops here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:69:    # TODO(future PR): allow customizations from default patterns.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:74:        # TODO: this is a temporary hack to flatten the patterns from quantization so
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:90:        # TODO(future PR): if needed, implement matching for a node
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:183:    # TODO(next): make this code handle matching by what is before the base op
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:211:                # TODO(future PR): check for matches start_op_node and base_op_node
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:342:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:474:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:590:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:640:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:691:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:49:    # TODO: deprecated, remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:247:            # TODO: make this compatible with xnnpack constraints
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:368:            # TODO: make this compatible with xnnpack constraints
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:171:        # TODO: keeping self.quant_min/max for BC; remove after a couple releases
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:274:    # TODO: rename observer to observer_ctr
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:395:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:37:# TODO: replace all usages with these constants
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:44:# TODO: derive this map from the BackendConfig
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:112:    # TODO Currently it's required that separate ops in a fused op/module have the same qconfig.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:126:    # TODO: add assert for backend choices
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:294:    # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:321:    # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:20:# TODO(future PR): improve this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:27:# TODO: not sure if typing supports recursive data types
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:33:# TODO: maybe rename this to MatchInputNode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:115:# TODO: not used now, remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:117:    # TODO: reuse is_fixed_qparam_node after we move this function to _lower_to_native_backend.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:360:    # TODO(jerryzh): Figure out why custom quant_min/quant_max are still adjusted.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:533:# (last update over 1 year ago) and when torchscript is fully deprecated we can refactor. TODO(jakeszwe, jerryzh168)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:591:        # TODO: switch to scale.item() after adding JIT support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:594:        # TODO: switch to zero_point.item() after adding JIT support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:122:    # TODO: change the value to QuantizationSpec in a separate PR
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:147:        # TODO: qat + per channel?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:272:        # TODO: move this to BoltNNQuantizer?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:379:        # TODO: implement the support for None to be canceling out previous annotations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:396:        # TODO: implement the support for None to be canceling out previous annotations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:129:    # TODO: Add more supported operators here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:502:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:559:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:606:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:641:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:55:    # TODO: remove, since we can use observer_or_fake_quant_ctr to express this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:488:        # TODO: annotate the uses of input, weight, and bias separately instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:902:# TODO: remove Optional in return type, fix annotated_partitions logic
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:918:            # TODO: change this to AnnotationException
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:958:        # TODO: remove?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1002:# TODO: make the list of ops customizable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:32:# TODO remove this once BC is no longer required to avoid a SEV
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:204:        # TODO remove Dropout special after codebase stable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:226:            # TODO: These are the modules that cannot be observed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:304:    # TODO: remove allow_list
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:322:    # TODO: maybe we should change activation_post_process to _activation_post_process
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:342:# TODO: rename to something more general
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:169:# TODO: rename this to _is_conv_node
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:179:# TODO: rename this to _is_conv_transpose_node
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:284:    # TODO: move this information to fx node itself
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:513:# TODO: Handle this in export itself and don't wrap the model in another GraphModule
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:78:    # TODO: change to mul.Scalar
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:83:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:125:    # TODO: use out_dtype(mul, ...) here when the op is ready
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:245:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:288:    # TODO: change this to mul.Scalar?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:328:    # TODO: use out_dtype op
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:398:    # TODO: use out_dtype(mul, ...) here when the op is ready
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:427:    # TODO: use out_dtype op
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:429:    # TODO: debug the implementation later when torchdynamo time out issue is resolved
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:100:    # TODO(Leslie): This function still fails to support custom momentum and eps value.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:162:# TODO: expose these under this namespace?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:27:# TODO: make pt2e folder private?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:125:    # TODO: add assertions for types of root qspecs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:263:            # TODO: maybe edge_or_node_to_qspec should be edge_or_node_to_root_qspec, this will simplify
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:474:        # TODO: simplify logic for inserting observers
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:95:# TODO: merge this with the `no_conv_bias` case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:111:        # TODO: allow setting eps
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:142:        # TODO: allow setting eps
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:196:    # TODO: allow setting eps
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:240:    # TODO: allow setting eps
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:427:# TODO: this is error prone, use the replace_literals_with_placeholders hack instead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:555:    # TODO: use the public replace_pattern API once it also returns replacement nodes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:598:    #       TODO: do this for literal args for batchnorm as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:102:    # TODO: check qconfig_mapping to make sure conv and bn are both configured
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:104:    # TODO: (maybe) rewrite this with subgraph_rewriter
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:179:    # TODO: only fuse if conv and bn are both configured to be quantized
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:80:            # TODO: currently it only works for modules,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:82:            # TODO: currently it only works for object_type configurations,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:235:# TODO: correct the namespace for these modules
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:241:# TODO: merge with STATIC_LOWER_MODULE_MAP after we merge
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:268:    # TODO: LinearLeakyReLU is registered as global but it is only fused and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:354:# TODO: add tests for lowering these ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:733:        # TODO: maybe define a WeightedDynamicallyQuantizedModule
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:756:        # TODO: WeightedQuantizedModule is currently assuming static quant apis
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:759:        # TODO: maybe define a WeightedWeightOnlyQuantizedModule
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1021:        # TODO: add safety checks that users for the ref_node and dq_node needs to be one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1024:            # TODO: add a warning or error out here? (bc-breaking if error out)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1032:            # TODO: add a warning or error out here? (bc-breaking if error out)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1054:        # TODO: enable we have patterns that needs to swap the modules
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:47:# TODO: revisit this list. Many helper methods shouldn't be public
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:305:                        # TODO(future PR): remove this entire function  and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:322:                    # TODO(future PR): remove this entire function  and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:726:        TODO: traverse upwards from the output and handle the case when tuple is not a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:802:    # TODO: log warnings only when the user enabled a debug flag
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:810:        # TODO: for now, just use the existing eps value as scale_min. In the future, we should
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:845:            # TODO: handle fp16 qconfigs properly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:103:# TODO: remove other variants and keep this one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:173:        # TODO: investigate why
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:213:# TODO: remove other variants and keep this one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:465:        # TODO: investigate why
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:547:# TODO: move this to https://github.com/pytorch/pytorch/blob/main/torch/ao/quantization/fx/_decomposed.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:729:    # TODO: support fp16
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:739:# TODO: dtype is ignored for now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:760:    # TODO: check for dtype, currently we can't express torch.int4 so it's omitted
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:18:# TODO: replace all usages with these constants
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:168:    # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:330:    # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:397:    # TODO: remove this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:100:        # TODO: change the signature for fuser_method to take matched module patterns
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:118:            # TODO: is this logic right?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:270:    # TODO: instead of instantiating the instance, we can use inspect to get the default args
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:292:    # TODO: support check for standalone module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:300:        # TODO(future PR): remove the cast to bool below after figuring
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:308:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:318:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:333:    # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:335:    # TODO: we should check is_dynamic here as well, the code from _is_input_arg_dtype_supported_by_backend
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:341:    # TODO: this is a hack because we can only specify one activation_obs_or_fq for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:508:        # TODO: refactor the following code in terms of apply a qconfig to a pattern
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:555:    TODO(future PR, if needed): explicitly spell out the non-Tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:759:    # TODO: move this to a separate function
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:769:            # TODO: we are assuming "target_dtype_info" exists here, maybe
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:829:        # TODO: this is looking into how the value is used in the future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1071:            # TODO: this does not handle dynamic quantization yet
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1128:    # TODO: probably need to remove `is_general_tensor_value_op`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1261:    # TODO(future PR): delete the orphaned observer modules
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1367:    # TODO: we probably don't need this counter since each graph will only have
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1417:            # TODO(future PR): update the output_quantized_idxs API to match
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1422:            # TODO(future PR): support more dtypes in model outputs, if necessary
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1443:        # TODO: we might want to handle these more uniformly with the default path
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1473:    # TODO: reuse placeholder_node_to_input_index and output_node_to_output_index
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1480:    # TODO: change this to insert obs/fq by pattern instead of by node
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1512:            # TODO: take a closer look to see if we can remove this check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1581:                            # TODO: This currently diverges from how custom modules are handled today,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1802:    # TODO: support regex as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:26:# TODO(future PR): the 1st argument is typed as `List[Node]`, but a better type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:141:    # TODO: 1. merge with fuse matcher 2. document the code
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:40:    # TODO: We should make this private in the future
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:80:    # TODO: change this to inplace changes to graph, since we no longer construct
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:109:            # TODO: add validation that root_node is a module and has the same type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:133:    # TODO: dedup with quantization matching function in match_utils.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:141:        # TODO: probably should cleanup this condition check, it's hard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:186:                # TODO: we can add the information of whether a value needs to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:196:                    # TODO: maybe need more complex attr name here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:296:                # TODO: we can add the information of whether a value needs to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:377:        # TODO: probably should cleanup this condition check, it's hard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:402:                # TODO: we can add the information of whether a value needs to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:406:                    # TODO: maybe need more complex attr name here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:424:        # TODO: get reduce range from observer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:447:                # TODO: we can add the information of whether a value needs to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:461:# TODO: DeQuantStubs are currently inserted only after custom module LSTM, while observers are inserted
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:548:    TODO: this logic is hacky, we should think about how to remove it or make it more
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:582:        # TODO: it's not used, so actually we can skip quantization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:633:    # TODO: remove is_reference flag
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:666:    # TODO: allow convert_custom_config to override backend_config
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:723:    # TODO: rename weight_is_statically_quantized to weight_is_int8_quantized
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:738:    # TODO: move this to the reference quantized module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:854:        TODO: maybe we want to redesign this part to align with reference model design
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:880:            # TODO: This is the first step in enabling the full fx custom module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:991:    # TODO refactor this code once we update the prepare logic to have additional information on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1120:    # TODO: maybe move this to quantize_fx.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1124:    # TODO: this looks hacky, we want to check why we need this and see if we can
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:145:# TODO: remove this class, this is still exposed in torch.ao.quantization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:153:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:157:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:161:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:165:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:169:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:173:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:179:# TODO: remove this class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:183:# TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:187:# TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:191:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:195:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/pattern_utils.py:14:# TODO(future PR): fix the typing on QuantizeHandler (currently a circular dependency)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:19:# TODO: move all LSTM util functions from fx/utils.py to this file
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:92:    # TODO: maybe make this work for layer_bw as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:327:        # TODO(jakeszwe, jerryzh168)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:371:            # TODO: switch to scale.item() after adding JIT support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:374:            # TODO: switch to zero_point.item() after adding JIT support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:392:# TODO(after v1.13): delete this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:479:        # TODO: MinMaxObserver by itself doesn't support dynamic quantization, but
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1239:            # TODO: For some reason, this is required for it to pass torchscript test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1393:        quant_min: minimum value in quantized domain (TODO: align behavior with other observers)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1670:# TODO(future PR): remove these defaults and enforce activation functions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1676:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:1:# TODO: rename executorch to qnnpack_executorch since executorch is a general runtime
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:262:        # TODO: we can add fusion for torch.relu as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:306:        # TODO: this is not used right now since we have extra check in prepare
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/native.py:158:    # TODO: express this BackendConfig as a union of the FBGEMM and QNNPACK BackendConfigs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/utils.py:158:# TODO(future PR): move backend_config_dict to use dataclass and move this logic to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/qnnpack.py:80:# TODO: add additional restriction on qscheme to ensure it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/fbgemm.py:25:# TODO: For now, these DTypeConfigs are identical to the ones defined in native.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/tensorrt.py:26:    TODO: add a README when it's more stable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:23:    # TODO: need to fix the way we insert observers for this pattern
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:88:    # TODO: remove when functionalization is supported in PT2 mode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:130:        # TODO: this is not used right now since we have extra check in prepare
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:141:            # TODO: remove when functionalization is supported in pt2_mode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:28:# TODO: rename to be more explicit, e.g. qat_conv_relu
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:86:        # TODO: this is not used right now since we have extra check in prepare
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:323:        # TODO: we can add fusion for torch.relu as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:46:# TODO: maybe rename this to something that's not related to observer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:263:    # TODO: refer to NativeBackendConfig once that is implemented
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quant_type.py:22:# TODO: make this private
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:181:# TODO: merge with default static mapping
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:329:# TODO: merge with get_static_quant_module_class
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/rnn.py:86:        # TODO: make this tanh a member of the module so its qparams can be configured
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/activation.py:308:        # TODO: This method has some duplicate lines with the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:237:        # TODO: dedup with __init__ of RNNBase
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:924:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:939:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1005:            ret = input  # TODO: remove when jit supports exception flow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:118:    # TODO: maybe change to this when https://github.com/pytorch/pytorch/pull/32958 is landed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/activation.py:221:        # TODO: This is a potential source of accuracy drop.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:144:    # TODO: add an util function for converting qdtype to dtype
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:165:        # TODO: torch.quint4x2 is not supported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:191:    # TODO: get the quant_min and quant_max from activation_post_process
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:197:    # TODO: add an util function for converting qdtype to dtype
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:218:        # TODO: torch.quint4x2 is not supported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:44:        # TODO(jerryzh168): maybe make this arg a required arg
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:66:            # TODO: refactor the duplicated code to utils.py
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:126:    # TODO: refactor nn.RNNCell to have a _forward that takes weight_ih and weight_hh as input
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:153:            ret = input  # TODO: remove when jit supports exception flow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:292:        # TODO(jerryzh168): maybe make this arg a required arg
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:539:        # TODO: maybe we can try inheriting from that class and define get_flat_weights
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/dynamic/modules/linear_relu.py:36:            # TODO check if we should set reduce_rage = True by default here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:41:        # TODO: Add qat support for BNReLU2d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:77:        # TODO: Add qat support for BNReLU3d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:18:# TODO: factor out the common parts to ConvNd
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:220:        # TODO(jerryzh): extend
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:102:        # TODO: Need to add options to qconfig to avoid the calibration.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:103:        # TODO: Add calibration for the sparsity
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:117:        # TODO (zaf): Mask might not be part of the qconfig (T83295194)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:8:# TODO (zaf): Inherit from `quantized.LinearPackedParams` (T83294430)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:66:# TODO (zaf): Inherit from `quantized.Linear` (T83294430)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:155:        TODO(zaf): Need to add the sparse params to the qconfig
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:165:        # TODO: Need to add options to qconfig to avoid the calibration.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:166:        # TODO: Add calibration for the sparsity
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:28:# TODO update desc with new config args
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:95:        TODO: Need a clean way of loading the state of the "prepared" module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:165:        self.model = model  # TODO: Need to figure out how to load without this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:172:        # TODO: Remove the configuration by reference ('module')
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:297:                # TODO handle multiple tensor being quantized on a single module, where to store sparse_params?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:40:        # TODO Fix this typing, as Type[Module] has no attribute "from_dense"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/base_structured_sparsifier.py:108:        # TODO LSTM Structured pruning does not support returned state currently.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:320:        TODO: Might have to treat functions (reduce_fn, mask_fn etc) in a different manner while serializing.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/cuda/amp/autocast_mode.py:43:    # TODO: discuss a unified TorchScript-friendly API for autocast
./api/pipeline/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:225:        # TODO(torch_deploy): this accesses linecache, which attempts to read the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_library/utils.py:104:    TODO: torchgen/model.py's FunctionSchema.parse is the source of truth for this,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/pytree_hacks.py:9:# TODO: remove this file when the migration of the pytree utility is done
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:175:        # TODO: Resolve this so we always have matching real / symbolic tensors / metadata.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:251:    # TODO: we should kill this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:301:        # TODO: we should apply the below "detach inputs if their gradients are statically known to be None"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:777:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:856:                        # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:884:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:915:        # TODO: Check aliasing relationships
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:916:        # TODO: Check strides for metadata mutation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:193:# TODO: UNUSED. delete?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:225:    #   TODO: add a test case to assert we error when this happens, instead of getting silent correctness
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:117:    # TODO: should factor this into a separate function for export that always only returns just the graph.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:184:    # TODO: in AOTAutograd, we create metadata like _indices_of_inps_to_detach to detect
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:115:            # TODO: Please remove soon
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:515:    # TODO (tmanlaibaatar) revisit this if we ever need to turn on non-strict joint graph export
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:562:    # TODO: add subclass guards (later PR).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:652:        # TODO: handle Tensor returns
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:155:                    #     TODO: discuss on the PR and decide if we want to tr to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:261:                # TODO: handle the custom autograd function case here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:524:    # TODO: Can avoid the zip here too, probably
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:540:        # TODO(voz): This structure is 1:1, we could consider an alternate structure like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:608:        # TODO: work out how to setup this assert correctly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:15:# TODO: It would be nice to reset the numbering every time aot_id goes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:47:    # TODO: Don't shove the aot_id in here; set it in the context
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:74:    # TODO: refactor to kill this flag
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:174:            #     TODO: discuss this in the PR. Both supporting this, and detecting + erroring out,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:319:    # isn't actually true.  (TODO: Could this cause problems for Inductor?)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:96:        # TODO: Remove the following hack for namedtuples
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:162:            # TODO: There is some sort of problem where we record that an
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:181:        # TODO: update following link from master to stable once that's out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:274:            # TODO: Update link to stable once that's out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:286:        # TODO: Update link to stable once that's out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:346:        # TODO: What is to_size_hint suppose to be?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:808:            # TODO: Investigate why this hack helps.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:809:            # TODO: Investigate the interaction with compiler assisted
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:279:        # TODO: We don't need to copy the model to create a stateless copy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:330:        # TODO: We don't need to copy the model to create a stateless copy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:438:    # TODO: Chillee argues that dynamo itself should pass in fake tensors to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:513:                    # TODO: Ensure that this codepath is never exercised from
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:549:                    # TODO: refactor the subclass path of run_functionalized_fw_and_collect_metadata
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:612:        # TODO: Do this properly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:909:    # TODO: There is something deeply wrong here; compiled_fn running with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1167:    # TODO: we might have to temporarily patch config.functionalize_rng
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__config__.py:12:# TODO: In principle, we could provide more structured version/config
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:96:            # TODO: skipping storage copy is wrong for meta, as meta
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:149:                    # TODO: Once we decide to break serialization FC, no longer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:316:            # TODO: Once we decide to break serialization FC, no longer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:372:                # Ideally, we'd use a private API for this instead. TODO: Switch to this if
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:413:                # TODO: Once we decide to break serialization FC, no longer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_tensor.py:1130:            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:247:            # TODO(jansel): explore this further normalization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:116:# TODO(jansel): ezyang says we won't need this in the future, try removing it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:132:    # TODO(jansel): add quantized types?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:275:        # TODO maybe we need to use pytrees here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:837:        # TODO: It would be better to realize the input if any of its sizes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1144:        # TODO <leslie> Remove this fallback when we support vectorization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1206:    # TODO: We observed negative performance impact of pointwise_cat optimization on CPU so disabled it.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1315:        # TODO: We don't have to guard on sizes per se, but the number
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1400:    # TODO: don't guard on static shape here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2182:# TODO(jansel): we should implement decomps or lowerings for these
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2457:    # TODO(jansel): memory format
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3448:            # TODO: Need to support more reduction type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3672:            # TODO(Lezcano) Here we may not need to set-up a device_size
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4025:    # TODO(jansel): should we force these to be realized?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4059:        # TODO will need a better way of determining if inputs are channels-last
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4323:    # TODO: should we force these to be realized?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4685:            # TODO(jansel): optimize to do `int(x<h)` rather than `x<h?1:0`
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4694:    # TODO(jansel): should we force these to be realized?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:41:    TODO will it be necessary to tune multiple fields simultaneously.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:44:    TODO: what if both increasing and decreasing a field can improve perf.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:319:        TODO(ezyang): I think, in principle, every IRNode should have an
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:743:            # TODO the best heuristic currently has XBLOCK (corresponding to numel_hint) 128
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:842:            # TODO this will fail for something like ((1, N) * (N, 1)).sum()
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:867:            # TODO determine splits when all inputs are broadcast
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1257:        # TODO(jansel): realize the reduction so we can do dynamic indexing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1422:        # TODO: Unrolled reduction
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1592:        # TODO: Can combine_fn/reindex close over unbacked symbols? If so, we
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1655:            # TODO: CPU support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1720:        # TODO: custom splitting heuristic for scan
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2115:        # TODO: a new class for FixedTransferLayout that output layout is constrained by input layout
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3148:        TODO(jansel): A better algorithm here would look at downstream consumers of this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3802:        # TODO(jansel): replace this with dynamic shape formulas
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3829:        # TODO: Unconditionally do this, not just when example_output has
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3905:            # TODO(jansel): impose layout preference on realized buffer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3949:        # TODO - Storage to InputBuffer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4456:        assert isinstance(new_size, int), "TODO: dynamic shapes"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4661:    # TODO: handle bools carefully
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5399:        # TODO <Leslie> cleaned up the fake_tensor trace as Linear implementation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5693:        # TODO: op.call: input[0] should be at::Tensor&
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7318:        # TODO(whc) i'm not sure what's going on here, this probably means I missed something upstream
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7382:            # TODO: avoid more than one ref of the same pg (even though they are cached inside the api)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7429:        # TODO: A better fix is to figure out how to propagate the aliases properly,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7798:# TODO(yifu): replace the CollectiveKernel IR hierarchy with _CollectiveKernel.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7879:    # TODO(yifu): add a pre-grad pass to validate the correctness of collective
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:8056:        # TODO: might be necessary to do some pretty printing on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:545:                # TODO: migrate all disable reasons to stack trace, refactor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:601:    # TODO: Should we actually dump this?  It should be redundant with the aot
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:864:    # TODO(jansel): figure out why this version doesn't work:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:948:                    # TODO - could make one single op of multiple slices
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1303:    # TODO: can add logging before/after the call to create_aot_dispatcher_function
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1344:    # TODO(voz): It would be nice to enable this assert, but there are lots of tests that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1357:    # TODO(voz): Should we always have one anyway?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:39:# TODO: A superclass that does desugaring for operations like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:180:    # TODO: Better explain how the "collective" semantics of these ops;
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:202:    # TODO: in practice, this seems to actually return None, but not returning
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:218:        # TODO: Improve the description with some pseudocode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:465:    # TODO(ezyang): Is this really the best way to do this?  What if we have
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/index_propagation.py:80:            # TODO: Inductor doesn't handle floating point in sympy expressions well at the moment
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/utils.py:218:    # TODO: There is a bug in a call to this function, to repro:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:45:    # TODO (tmanlaibaatar) figure out why this is different
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:105:    # TODO - further restrict cse ? right now needed to dedup aliasing ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1078:    # TODO: Revisit the functionalize_rng_ops for lowmem dropout
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1357:    # TODO - look into using aot autograd, asserting no mutating ops here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/triton_helpers.py:340:    # TODO(isuruf): use inline_asm_elementwise here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:60:    # TODO when we drop support for Python < 3.10, we can use
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:143:# TODO(xmfan): reuse an existing mapping for this if it exists, or formalize this into ir.py:ExternKernel
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:385:                            # but TODO this might be a convenient place to signal to the Collective kernels to inplace
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:453:            # TODO(voz): Should the pragma be constant somewhere?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:474:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:625:                    # TODO(xmfan): find a better heuristic to model FLOPS/latency relationship
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:665:            # TODO make this a property of the IR
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1597:        # TODO: ideally, we should deduplicate .users and .node_users,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1724:            # TODO support benchmarking epilogue fusion
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:156:            # TODO: this should not be needed once #93059 lands
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:158:            # TODO: make a dedicated UnknownSource for this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:419:            # TODO - get different values per hardware
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:746:        # TODO(jansel): handle input aliasing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:948:                # TODO: this is sus, it probably should be handled in the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1049:                # TODO(jansel): introduce a store vs inline choice
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1124:            # TODO(Eikan): Only support mixing cpu and other device now.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1191:            # TODO: reuse self.scheduler from the first pass to speed up the second pass
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1262:        # TODO. Revisit this once the logging API is more mature
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:423:        # TODO: These tensors don't currently pickle, so we can't cache a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:654:    # TODO(masnesral): Investigate whether it's beneficial to store compiled graphs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:920:    # TODO: When making an API that can save compiled models e2e to disk
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:179:    - 8 gpus per node  # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:187:    # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:553:    # we could also generate all these patterns in 3d.. TODO
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:685:            # TODO: Enable CUDA after solving Bert accuracy issue of calling efficient attention
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:55:        # TODO: remove the need to run fake_tensor_prop on the whole model.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:59:        # TODO - decompose/type promote to avoid this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:85:        # TODO handle Tensor-Scalar adds, it's a different schema
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:182:        # TODO - we could also Tensors which get replaced with arange here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:127:        # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:22:# TODO: need a better strategy for decomposing mm
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:173:            # TODO: support scalar case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:191:        # TODO: support scalar case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:269:                # TODO: support linear?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/serialized_patterns/central_index.py:111:    # TODO - could add more validation that the same set of decomps used when
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:762:                # TODO: Haozhe investigate how add guard here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:890:            # TODO: Support dynamic shape case for MKLDNN conv transpose.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1186:        # TODO: aarch64: enable op fusion for acl once it supports fused operators. Disabling it for now.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:313:                # TODO: support kwargs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:475:                # TODO(yifu): this doesn't properly remove copy epilogues for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:249:    # TODO - finetune coefficient here. As a reference point, Triton mm model assumes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:402:        # TODO: Build a learned model which would be better than this heuristic
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:377:    # TODO(jansel): rewrite this as a bmm?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cuda.py:195:        # TODO: only works for constant now, need type info
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:470:                        # TODO: input shape checking for regular tensor interface as well?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1077:        # TODO: support other overload for cpp wrapper and remove the below assertions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1204:            # TODO: Add buf name directly into check_inf_and_nan.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1647:        # TODO: Only support tensor(s) returns for now, SymInt is not implemented yet
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1302:    # TODO: these look dead, but with all the getattr it's hard to tell...
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1429:        # TODO: hoist this to top level
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:587:        # TODO(jgong5): A more accurate way of deciding the dtype of the variables is to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1280:    # TODO: this seems to be dead
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1393:        # TODO(jgong5): support conversion for other types
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2427:            self._load_mask is None  # TODO: support transposition with mask
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2773:            # TODO(Eikan): To record, deduce and propagate the data type of every expression.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3059:                # TODO(Eikan): Regarding get_index and index_expr, we should conclude the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3380:            # TODO(jgong5): support alternative tiling factors and data types
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3546:        # TODO(jansel): allow fusion pointwise (vars1, ()) suffix?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3565:        # TODO: we can extend fusion support with compatible ranges for FusedSchedulerNode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3589:        # TODO: we can fix if it allows us to CSE at least one of the variables
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3682:        # TODO: support kernel profile on other platforms
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3713:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3912:            # TODO(jansel): look into chunk size and other schedules
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:210:                # TODO mlazos: support dynamic shapes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:243:            # TODO: refactor generate_kernel_call
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:284:            # TODO(jansel): we could try harder here by merging overlapping in space
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:677:                # TODO(jansel): we should support reusing buffers created via ExternKernelAlloc
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:51:    # TODO(ipiszy): remove this hack when CUTLASS solves Python scripts packaging structure issues.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:122:    # TODO: these three look dead?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_epilogue_gen.py:135:        # of a previous epilogue node, a constant or (TODO) an auxiliary input.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:219:        TODO: Will add needed args to pass it in if it is dynamic.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:243:        TODO: Will add needed args to pass it in if it is dynamic.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:263:        TODO: Will add needed args to pass it in if it is dynamic.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:319:        )  # @TODO: Hack for ensuring that Cutlass Kernel is preferred
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:400:        # TODO(ipiszy): Check whether it's necessary to swap X/W.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:482:        # TODO: update epilogue functor according to epilogues.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:682:            # TODO: Support split_k.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1628:        # TODO instead of trying to blindly find complicated exprs, we should hoist the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1701:            # TODO(jansel): it is sometimes possible to do higher dimensional block_ptrs with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1800:            # TODO(jansel): do we need a reshape here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2904:        # TODO(jansel): if there are constants, we shouldn't bother passing them as args
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3504:                    # TODO - use split ranges ?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3533:            # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3582:            # TODO: Maybe unify CUDATemplateKernel to also use PartialRender for flexible epilogue fusion.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3737:            # TODO(jansel): should we tile reductions?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:136:# TODO: Move to a well known place
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:705:        # TODO: Add check for python too.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:725:                # TODO: integrate memory planning & stack allocation?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:778:            # TODO: this seems legit, NullLine has no node
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1068:            # TODO(aakhundov): add None args to constants, too. currently, this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1187:        # This is handled in `generate_args_decl` which has a correct comment of: TODO: only works for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:13:        # TODO: Remove fp8 special handling when Triton supports PyTorch fp8 dtypes.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:90:            # TODO(voz): These are kinda redundant, if we can solve out statically_known_multiple_of with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:186:    # TODO - remove, prevents cleanup
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:207:    TODO: in the future, we would like to do the following once storage weak refs land
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:253:        # TODO - when issue #91395 is landed, we can set a weakref on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:924:        # TODO - one jit kernel across multiple inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1452:        # TODO: - should we make the storage resizable ?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1535:            lambda: "TODO: graph recording observed an input tensor deallocate during graph "
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1659:    # TODO: make generation increment configurable, warn on overwrite.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:2078:        # TODO: we could also allow the these weak refs to continue to be allocated,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:506:                # TODO(jansel): should we use sympy.diff here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1293:        # TODO: this may only be beneficial when each iteration of the reduction
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1348:    # TODO(jansel): we should be able to improve these heuristics
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:114:        # TODO - fix errors with this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:121:        # TODO - constant folding triton kernel returns the inputs -- fix this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:130:        # TODO - more complicated strategy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:509:                # TODO(nmacchioni): fix sympy division by zero
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:820:        # TODO(nmacchioni): remove once CI tests are fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:377:    # TODO: check if it's beneficial to convert Conv1d to Conv2d and then
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:382:        # TODO maybe we can convert weights to channels last just once before
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:454:                # TODO(jansel): try unroll for bigger kernels once fixed:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm.py:170:        # TODO: Re-enable eager mode implementation once cuBLAS is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm_plus_mm.py:208:        # TODO(jansel): support different K values when this is fixed:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:329:# TODO: fork is not safe in a multithreaded environment, we should evaluate changing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:406:# TODO: remove later
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:510:    # TODO - need to debug why this prevents cleanup
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:624:        # TODO: Support non-zero workspace_size.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:637:            None,  # set workspace ptr, TODO: update it to a real ptr if workspace_size > 0
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:97:# TODO: for now, inductor doesn't handle asserts
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:324:    assert not self.is_complex(), "TODO: implement this"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:386:    # TODO: _to_copy tensor to stride permutation
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:50:    # TODO - there are dominated uses whose dtype does not depend on whether
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:71:                    # TODO - not sure if we should be doing int/float casts while tracing,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:109:    # TODO - if dominated node of one to_dtype is not expressible in int32,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:39:   TODO: Define a parent class / protocol that defines all of the operations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:128:            # TODO: To be honest, I feel we probably should just error in this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:159:)  # TODO: improve type
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:43:    TODO: We might want to adjust this in the future to account for memory limitations.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:99:    TODO: Come up with a better approach
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:259:                # TODO: Smarter heuristics here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:331:        # TODO - Running exec generated frame seems propagates f_globals to the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:354:                assert recompile_reasons, "TODO(whc) any other recompile reasons?"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:832:# TODO mlazos: add support for same args, or record them
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:877:            # TODO: the first condition is not covered by any test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:214:            # TODO: replace `same` function with the one in testing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:269:        # TODO: maybe should just pass the entire f_code in here?  Not
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:306:            # TODO (tmanlaibaatar) Remove this once we always lift params and buffers
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:461:    # TODO(rzou): can delete after we refactor speculate_subgraph to use nested GraphTracer.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:538:        # TODO - Consider having a torch level API for torch_function_state. As
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:658:            # TODO: don't readd symint if we already have it in graph
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1158:            # TODO(voz): The way export uses gm, and fake tensors, is not supported with us resetting
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1162:            # TODO(voz): Ostensibily, this should be scoped and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1206:            # TODO: Why isn't this stored in meta :think:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1324:    # TODO: this is a generic pass that should live outside of Dynamo
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1334:        # TODO: Request simplification on runtime asserts before emitting them
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1496:                            # TODO: Remove relaxing assert on unbacked_symint https://github.com/pytorch/pytorch/issues/119689
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1507:                                # TODO: use ra.msg here, but it's pretty
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:237:                # TODO(whc)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:350:            # TODO - better way of doing this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:58:                    # TODO: not correct for args that contain tensors in a struct
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:64:        # TODO: error on unrecognized nodes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/tvm.py:86:            # TODO(shingjan): This could be replaced by tvm.contrib.torch.optimize_torch
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:733:    # TODO: this is questionable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1467:     * (TODO)confirming which functions got compiled/skipped
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1956:            from tabulate import tabulate  # TODO: Check that this is installed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2172:    # TODO - This is a temporary situation where we have two versions of
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:112:            # TODO: Maybe complain if this isn't a int/bool/float variable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:129:        # TODO: The default repr is pretty bad, do better
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:132:    # TODO: API for adding a custom guard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:217:        # TODO: improve printing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:228:        # TODO: improve by improving the VariableTracker printing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:259:        # TODO: improve print format, current guard format is extremely
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:11:    # TODO(jansel): double check exception handling
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/types.py:85:        # TODO(whc) how do I annotate a _RecordFunction here?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/source.py:538:# TODO: can probably write a generic "test this on everything in the chain"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:91:    # TODO(jansel): we should move guarded_backend_cache to C++
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:687:# TODO(voz): Consider making "explain" output alongside a run / part of a run
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:691:        # TODO(voz): Do we want a decorator for this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:727:        # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:748:        # TODO(voz): Do we want a decorator for this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:803:                    # TODO(zhxchen17) Also preserve all the user constraints here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:903:            # TODO: option to print ALL of the stack traces at once
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1309:            # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:52:# TODO(jansel): need to ensure this does not get DCEed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/test_minifier_common.py:129:            # TODO: return a more appropriate data structure here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:802:                # TODO(voz):
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:833:                # TODO(jansel): returning None here is wrong, it should be
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:912:        # TODO: Should we allow non SymTypes here?  Today it is allowed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1024:            unimplemented(f"TODO: add support for ndarray.{name}")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:179:    # TODO: storing a SymInt here but not a FakeTensor is a pretty strange
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:656:            # TODO: this doing it manually is bad
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:665:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:669:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:673:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:769:            # TODO(whc): Why do we limit this to methods on NNModules?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:797:                # TODO(jansel): combine this case with the one above
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:929:            # TODO(whc) We could add a guard on the opposite case, where a user compiled/ran
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1227:                # TODO: This should be dynamic, as we in general do not
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1236:                    # TODO: dynamic_dim = DimDynamic.STATIC should work but
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1460:        # TODO: not sure about this fake mode test
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1722:    # TODO: index export_constraints ahead of time so we don't have to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:218:    TODO: make it possible to use ProcessGroupVariable as input to simple functions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:223:    TODO: should we make this inherit VT instead of UDOV? Do we want any of the default behaviors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:251:        # TODO should this just raise unimplemented?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:417:            # TODO: support pytree output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:569:        # TODO(voz): Support fake tensor dispatch for recursive
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:636:            # TODO: Support kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:924:        # TODO: Support kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1020:        # TODO: Support `fn` with kwargs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1056:        # TODO: Support kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1300:        # TODO (tmanlaibaatar) support pytree here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1597:        # TODO: assert that bwd_graph didn't capture values that were
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1600:        # TODO(oulgen): Ideally, we would not do a linear search for output
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:287:                # TODO: If we expand this to handle tensor args, we need to manually
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1331:                    # TODO(voz): Make it work properly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:471:            # TODO(voz): This is rewritten as a call_method because
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:481:        # TODO: These special cases shouldn't be necessary; we should
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:606:            # TODO: this probably should be folded somewhere else but I'm not
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:608:            # TODO: some of the other symbolic_shapes special tools can also
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:641:            # TODO(voz): Replace w/ dynamic shape rewrite table.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:660:                    # TODO: there maybe other recursive structures you need to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:270:                # TODO: Use named_children when it supports remove_duplicate=False.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:323:                    # TODO: do we want to support __call__ for GM's?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:91:        # TODO(jansel): there is a small chance this could trigger user code, prevent that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:209:        # TODO: support an expression form as well
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:739:            # TODO Add all the functions that go from constants to constants to can_constant_fold_through
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:72:            # TODO Temorarily remove to figure out what keys are we breaking on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:98:            # TODO: Put this in utils and share it between variables/builtin.py and here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:579:            # TODO(jansel): implement unpacking logic in ModelOutput.__post_init__
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:779:    # TODO(voz): Upstream to transformers lib
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:299:            )  # TODO(voz): These can invoke user code!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:302:            )  # TODO(voz): These can invoke user code!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:305:            and len(kwargs) == 0  # TODO(ybliang): support kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:575:                # TODO(jansel): add a guard to check for monkey patching?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:880:        # TODO this should probably be merged with the dict handling
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:169:        # TODO: shouldn't this be f_locals/f_globals from frame?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:159:        # TODO - Assuming that all modules can be safely repr'd. Check if that assumption is correct.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:214:        # TODO - Keep this code for now. But, I don't think we will need this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:531:# TODO: Support bundling the entire repro into a zip file for ease of
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:558:                    # TODO: transfer it to the right device?  But failing this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:620:        # TODO: consider ensuring tensor and storage counters line up?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:654:        # TODO: being optional on device is kind of pointless as the default
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:699:    # TODO: this doesn't actually symint atm
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/cache_size.py:74:    TODO(janimesh) - Consider adding a map from tuple_of_match_ids to count -
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3120:    # TODO: Once we require py3.9 use removesuffix instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:856:# TODO use the actual object instead, can interface from eval_frame.c
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/resume_execution.py:467:            # TODO(jansel): add dead code elimination here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:266:        # TODO: something here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:367:            # TODO(janimesh) - This is currently restricted to nn.Module objects
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:474:        # the internal types match.  (TODO: what about nested lists?)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:494:        # TODO: It feels like it would be better to just implement our own
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:574:    # TODO(voz): Deduplicate w/ AOTAutograd dupe input guards
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:748:            # TODO(voz): Either populate a dispatch_key check into the guards, or error on users passing in an unsupported
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:752:            # TODO(voz): We are missing storage offset in all our tensor guards?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1041:                # TODO: we could make use of 'DefaultsSource' and offer a .guard.is_defaults() API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1053:        # TODO(janimesh) - Currently this information is stored as an attr on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1187:        # TODO: the "guard" here is actually just the top level SHAPE_ENV
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1232:        # TODO(whc) maybe '.code_parts' was only kept around for the guard callback? so we don't need both
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1481:        # TODO(voz): Combine local and global guard builders.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:21:    TODO(khabinov): we should deprecate this function and use one of these two:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:159:    TODO(voz): We now have allow_in_graph, disallow_in_graph, forbid_in_graph - some more robust
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:222:        # TODO: Make this configurable via a supported public API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:231:        # TODO(voz): Should we bounds check?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:249:        # TODO: Make this configurable via a supported public API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:255:        # TODO(voz): Should we bounds check?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:286:        # TODO: Make this configurable via a supported public API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:292:        # TODO(voz): Should we bounds check?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:321:# TODO: we should delete this whole _allow_in_graph_einops logic by approximately 2024 Q2
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:86:        # TODO(jansel): are all these modes needed?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:330:            # TODO maybe should respect DtoH sync intention of users later??
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:463:                # TODO link the torch.cond doc later
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:504:                # TODO: Also report the traceback from the parent frame
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2157:        # TODO(jansel): check the id of the cell rather than the contents
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2357:        # TODO: mlazos, add support for enabling multiple artifact logs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2555:        # TODO(jansel): figure out why this is needed, it isn't in the docs for YIELD_VALUE
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2578:                    # TODO(voz): Unclear if we need the push None in YIELD_VALUE?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:150:    # TODO: Figure out why torch.compile'd hash isn't work on this codepath
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:156:            # TODO: improve these names with FQN
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:236:    # TODO: factor this out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:263:    # TODO: It's inconsistent to pass SymInt inputs but REAL tensors.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:424:            # TODO: disable clone
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:76:        # TODO: why do we need to deepcopy the original graph?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:85:            # TODO: Failures here are troublesome because no real inputs,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:236:            # TODO: improve these names with FQN
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:315:    # TODO: factor this out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:480:    # TODO: speed this up
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:555:    # TODO: The logic for cloning inputs/models here is intentionally
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:644:    # TODO: check eager determinism
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:711:# TODO: lazily load the inputs or something, rather than cloning them
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:860:    # TODO: make this an option for --analyze too
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:102:# TODO(janimesh, voz): Remove both of these flags (or atleast guard_nn_modules)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:180:# TODO: Detect this situation automatically so the user doesn't need
./api/pipeline/.venv/lib/python3.12/site-packages/torch/contrib/_tensorboard_vis.py:137:        # TODO: handle attrs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:58:        # TODO: The cache is NOT currently used by HigherOrderOperator, but it should!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:103:                # TODO(voz): Should we replace setting torch._C.DispatchKey.Python entirely with setting mode keys?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:276:        # TODO (tmanlaibaatar) Make it generic fallback mechanism
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:660:                # TODO: We also need to handle tensor subclasses here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:661:                # TODO(voz): We should walk all the nodes here / turn it into a list, topmode is ok for now.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:667:                    # TODO: This path is slow, should generally encourage this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:670:                # TODO(voz): The idea behind this is that we do not yet support dispatch by key + mode, only key.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:705:                            # TODO: need to double check the semantics of the "types" argument to torch_dispatch.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:713:                        # TODO: check that I got these args correct (in C++, we pass in "0000"??)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:731:        # TODO: We could potentially have lots of debugging wrappers against
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:766:    # TODO: add more methods to expose information about input and output arguments
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:828:            # TODO: disallow access to overloads registered by JIT
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_ops.py:856:    # TODO: use this to make a __dir__
./api/pipeline/.venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:91:        # TODO: investigate if contiguity along other axes than the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:261:            # TODO in the future we can add in padding to support sparse dimensions that aren't perfect multiples
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/xpu/XPUEvent.h:112:    // TODO: provides the ability to time the execution of commands in a SYCL
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CUDAFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:29:// TODO: Add constructors for all of the descriptors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:99:  // TODO: Figure out why const-correctness doesn't work here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:369:        "TODO: support more cuDNN activation modes");
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradNestedTensorFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:62:// [TODOs]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:111:// TODO: move this from `at::` to `jit::torch::` after
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/Utils.h:93:    // TODO: is this necessary?  We used to treat nullptr-vs-not in IntList
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CPUFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/quantized/QTensorImpl.h:33:  // TODO: Expose in PyTorch Frontend
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:35:// TODO: try to remove this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/symbol.h:77:  // TODO: eliminate me
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/DispatchKeyExtractor.h:41:  // TODO: It's a bit irritating that we have to do logical ORs here, it would
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/Dispatcher.h:187:  // TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:256:  // TODO Use list_element_from?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:282:  // TODO Use list_element_from?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:69:  // TODO(jerryzh): add a Get(c10::DeviceType) function?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:78:    // TODO: after we add Get<Tensor>(c10::DeviceType)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:108:      // TODO Re-enable logging
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TransformationHelper.h:129:  // TODO: must be investigated and unified!!!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:13:// TODO: consider storing namespace separately too
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:20:  // TODO: These two functions below are slow!  Fix internal data structures so
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PythonOpRegistrationTrampoline.h:5:// TODO: this can probably live in c10
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/stack.h:9:// TODO move this to c10 namespace
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:132:    // TODO(min-jean-cho) change to Polar method, a more efficient version of Box-Muller method
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:133:    // TODO(voz) We use std:: below, and thus need a separate impl for CUDA.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:1764:// TODO this is deprecated but we don't throw a warning because a lot of ops in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:196:  // TODO: temporarily disabled
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:235:  // TODO: Deprecate me
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:1368:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:273:   * TODO: need to support customizing equality
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:345:    // TODO: Find way to expose alias info for opaque tensors.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:465:    // TODO (after Tensor merge) If we pass in a Blob holding a Tensor, extract
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1085:        // TODO: Find way to expose alias info for opaque tensors.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1120:  // TODO: There are several places that recurse over IValue. This is fragile.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dynamic_type.h:133:  // TODO Change Ptr to DynamicTypePtr when all migrations are done.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:506:  // TODO remove the mutation here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List.h:457:  // TODO Test use_count
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:576:// TODO: investigate making this SingletonOrSharedTypePtr<TensorType>
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2098:  // TODO: static_assert that a templated function exists, and throw a friendly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2105:  // TODO: static_assert that a templated function exists, and throw a friendly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/Generator.h:51: * TODO: Look into changing the threading semantics of Generators in ATen (e.g., making
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/BoxedKernel.h:130:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:15:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:209:  // TODO: it probably would be good to tighten this up quite a bit more with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:268:    // TODO static_assert(AllowDeprecatedTypes, "You tried to register a kernel with an unsupported output type: std::vector<T>. Please use List<T> instead.");
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:432:  // TODO Delete this once kernels don't do that anymore
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/test_helpers.h:29:  // TODO: We add this to simulate the ideal case where we only have Autograd backend keys
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/boxing.h:80:  // TODO Reuse stack vector instead of allocating?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:13:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:157:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:404:  // TODO: once modules support arbitrary ivalue attributes, we don't need this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:406:  // TODO: This is better represented as an OrderedDict, but alas it is not yet
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:551:  /// TODO: it's not in native_functions.yaml yet as it's not exposed to python
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:589:  // TODO(#97856) Make this return a const pointer. This currently
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:612:  // TODO(#97856) Make this return a const pointer. This is currently
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:9:// TODO: Clean up what remains here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:70:// TODO: AutoNonVariableTypeMode should be removed in release 1.10.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/adaption.h:49:  // TODO: Remove this once the following issue is addressed:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:249:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:278:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:293:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:308:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:349:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:390:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:528:       // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:559:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:576:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_allowlist.h:3:// TODO: unify to C10_MOBILE. In theory this header could be used in OSS.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/NestedIntSymNodeImpl.h:40:  // the higher-level API in python instead (TODO: actually introduce that).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/detail/CUDAHooksInterface.h:59:// TODO: Consider putting the stub definitions in another class, so that one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/FunctionalTensorWrapper.h:207:  // TODO: maybe it's possible to arrange for that to happen automatically
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:31:// TODO: Move the MPSGuardImpl to inherit from NoOpDeviceGuardImpl
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:64:    // TODO: Currently setting only device 0
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:81:      //TODO: extend it for multi-device case
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:19:// TODO: Unify the logic with CUDACachingAllocator and remove redundant code.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:119:    // TODO: check the caching performance of write-combined mode
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:316:  // TODO: make a common function to do size unit conversions in PyTorch.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:46:  // TODO: don't expose private implementation details like this; in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:52:  // TODO: don't expose private implementation details like this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:112:  // TODO: numel_custom and is_contiguous_custom can be profitably overridden
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:170:  // TODO: maybe we can remove this metadata since
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradNonFunctionalFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpp_custom_type_hack.h:93:  at::AutoDispatchBelowADInplaceOrView guard; // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_int.h:747:      // TODO<leslie> We can use _mm512_zextsi128_si512 in the furture,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_double.h:159:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_float.h:574:// TODO(jgong5): rewrite with ATEN vectorized (need to add unpack and shuffle)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_bfloat16.h:1053:// TODO(Leslie): Add the AVX2 Version of transpose_mxn for BFloat16 and Float16
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_float.h:654:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:118:    // TODO
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:273:  // this should be removed. TODO (kimishpatel)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_int.h:686:      // TODO<leslie> We can use _mm256_zextsi128_si256 in the furture,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:196:  // TODO: can we support caching this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:240:  // TODO: can we support caching this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/MetaFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/utils/Factory.h:13:// TODO: Remove this function when at::native::empty() is modified to accept a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:47:// TODO: Figure out if we need a non-moving wrap_buffer()
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:287:// TODO: Add static assert to verify lambda arguments match nested_node types
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:15:// TODO: make all operations that resize given outputs use this function
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/AffineQuantizerBase.h:11:// TODO combine this with quantize_val once the numerics for ARM are aligned
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/fbgemm_utils.h:312:// TODO: Remove functions below when ChannelsLast3d is ready.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:339:// TODO: Move it to third_party/ideep
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:394:  // TODO Support more OSs.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/OperationUtils.h:194:// TODO: Improve the overall design of MPSGraphCache.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/MPSGraphVenturaOps.h:4:// TODO: Remove me when moved to MacOS 13
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:19:// TODO: This file only supports AVX2. We could split the AVX kernels into
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:178:  // TODO: we may want to merge that into the fallback code (currently called
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:254:  // TODO: we may want to merge that into the fallback code (currently called
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:293:// future improvement that can be done: look for the TODOs in this file.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:1197:  // TODO: Do we also need block 4 ???
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:55:// TODO: put this into the public API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:67:// TODO: Expose this for real in ATen, some day?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:36:// TODO: CPU instruction set selection should be folded into whatever
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:212:    // TODO: make this point at hip_dispatch_ptr
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:296:// TODO: cut this over to HIP dispatch once we stop pretending that CUDA
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/MaxPooling.h:64:// TODO(Heitor) Template by dimension
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:350:  // TODO: instead of variable name 'sigma', use 'gamma' or 'scale'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:384:  // TODO: Fix resize_as_. See pytorch/pytorch#11665.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:27:  // TODO: remove this special case for HIP when issue is fixed:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:38:  // TODO: remove this special case for HIP when issue is fixed:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:17:// TODO: update and add a usage example after https://github.com/pytorch/pytorch/pull/58092 lands.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:25:            // TODO: figure out how to make compiler happy without dynamic casts
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:33:            // TODO: get std::forward<> to work
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:302:    // TODO: Our current linear mode impls use unbound indices
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:202:  // TODO: check that output->size() matches output_sizes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:203:  // TODO: check that weight matches output->sizes()
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:362:  // TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:209:  // TODO: implement negative step
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:314:  // TODO: check scalarType
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/DynamicLayer.h:39:// TODO: we can excise DynamicLayer in favor of Interpreter,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/LegacyVmapTransforms.h:102:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/PlumbingHelper.h:59:  // TODO: should really check this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/BatchedTensorImpl.h:156:// TODO: should probably contain more (or all?) backend keys
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/LegacyVmapTransforms.h:95:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/cuda/detail/CUDAHooks.h:8:// TODO: No need to have this whole header, we can just put it all in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:58:// TODO: Consider generalizing this into a call stack.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/caffe2/serialize/versions.h:92:// risk of breaking existing clients. TODO: A better way would be to allow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/GeneratorImpl.h:44: * TODO: Look into changing the threading semantics of Generators in ATen (e.g.,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:214:  /// TODO: This function encourages bad behavior (assuming CUDA is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:403:  // TODO: Deprecate this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:436:  // TODO remove after TensorOptions rationalization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:545:  // TODO: MemoryFormat is not implemented in this way
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Storage.h:92:  // TODO: remove later
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Scalar.h:138:  // TODO: Support ComplexHalf accessor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymBool.h:81:  // TODO: optimize to union
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymbolicShapeMeta.h:162:  // TODO: should the SymBool cases avoid the short circuit?  Need to reason
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/StorageImpl.h:107:  // TODO: remove later
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:251:  // TODO: Consider reading Tensor and TensorList constructors here, when
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/SizesAndStrides.h:25:  // TODO: different iterator types for sizes & strides to prevent
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:72:    // TODO: make a version that takes an impl argument.  Unfortunately,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:179:  // TODO: put this in BackendComponents
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:183:  // TODO: put this in BackendComponents
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:192:  Vulkan, // TODO: put this in BackendComponents
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:193:  Metal, // TODO: put this in BackendComponents
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:209:  // TODO: Make Mkldnn a functionality key, so we can give it Meta
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:236:  // TODO: delete this in favor of Python-implemented fake tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:262:  // TODO: delete this once torchdim lands in functorch
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:354:  // TODO: make Autocast a functionality key
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/CPUAllocator.h:12:// TODO: rename to c10
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:255:      // TODO dim == 3 case will be enabled once it is fully tested
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:271:      // TODO dim == 4 case will be enabled once it is fully tested
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarTypeToTypeMeta.h:8:// TODO move to typeid.h (or codemod away) when TypeMeta et al
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:98:// TODO: To add unsigned int types here, we must define accumulate type.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:167:    /* TODO: remove once the bug is fixed. */                                \
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:380:    // TODO: Replace the link to the documentation once it's available.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:534:  // TODO: When Variable is added, delete these constructors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:637:  // TODO: does C++14 have a stdlib template for this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:743:    // TODO: maybe this should be toggled by strides
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:911:      // TODO: provide stride_custom, symmetrically with size_custom.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:968:    // TODO: We could add support to Python dispatch here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:969:    // TODO: We could call into aten::size.int instead of
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:976:    // TODO: We could add support to Python dispatch here.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:977:    // TODO: We could call into aten::size.int instead of
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1218:  // TODO: remove this once we don't automatically enabled Autograd dispatch
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1285:      // TODO: implement layout() as native function/method so that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1748:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1767:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1794:    // TODO: this should probably consult policy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1891:    // TODO: at some point, we should kill this field completely.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:2140:    // TODO: A useful internal assert would be to show that device_opt_ is null
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:3050://    strong refcount           TODO: pack these into one word
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymFloat.h:107:  // TODO: optimize to union
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:57:      // TODO dim == 3 case will be enabled once it is fully tested
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:86:      // TODO dim == 4 case will be enabled once it is fully tested
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymInt.h:55:  // TODO: these implementations are not optimal because they allocate a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymIntArrayRef.h:16:// TODO: a SymIntArrayRef containing a heap allocated large negative integer
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/Backend.h:284:// TODO: This probably shouldn't actually be static inline
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/core/DeviceGuard.h:49:  /// TODO: The consistency check here is inconsistent with StreamGuard's
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/ApproximateClock.h:79:// TODO: We should use
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Deprecated.h:27:// TODO Is there some way to implement this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:345:// TODO: Brian Vaughan observed that we might be able to get this to work on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:563:// TODO: We're going to get a lot of similar looking string literals
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeList.h:158:  // TODO Direct implementation might be faster
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:14:// TODO Make it work for more compilers
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:67:  // TODO Disallow this and rather use std::unordered_map/set everywhere
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeCast.h:169:// Trigger tests for D25440771. TODO: Remove this line any time you want.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:622:  // TODO: Use std::bit_cast once C++20 becomes available.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/C++17.h:92:// TODO This is an incomplete implementation of std::apply, not working for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:43:// TODO(xiaofeng): Define GOOGLE_PROTOBUF_HAS_CONSTEXPR when constexpr is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:143:// TODO: perhaps it would be nice to have int128, a signed 128-bit type?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:46:  // TODO Making operator== noexcept if underlying type is noexcept equality
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:55:  // TODO Making operator!= noexcept if operator== is noexcept doesn't work with
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/Half.h:395:// TODO : move to complex.h
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/intrusive_ptr.h:572:   * TODO: https://github.com/pytorch/pytorch/issues/56482
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/MathConstants.h:13:// TODO: Replace me with inline constexpr variable when C++17 becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:110:    // TODO: split out
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:530:    // TODO At some point this should probably be done, including tricks
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex_utils.h:20:// TODO: Write in more idiomatic C++17
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:140:// TODO(@zasdfgbnm): c10::complex<c10::Half> is not currently supported,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:581:// TODO(@zasdfgbnm): implement them as c10::conj
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:589:// TODO(@zasdfgbnm): implement it by ourselves
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/ArrayRef.h:75:  // TODO Make this explicit
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/hash.h:58:// TODO: Compare vs OpenSSL and/or CryptoPP implementations
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:37:// TODO: This file is still in the caffe2 namespace, despite living
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:87:// TODO Disallow this and rather use std::unordered_map/set everywhere
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/cuda/CUDACachingAllocator.h:36:// TODO: Turn this into an honest to goodness class. I briefly attempted to do
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/macros/Macros.h:125:// TODO: It's possible this is still triggering
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class_detail.h:137:  // TODO We shouldn't use c10::impl stuff directly here. We should use the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class.h:401:      // TODO: we need to figure out how to profile calls to custom functions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:108:  // TODO: This is morally the same thing as KernelRegistrationConfig, but it's
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:167:        // TODO: Don't go through WrapRuntimeKernelFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:184:        // TODO: Don't go through WrapRuntimeKernelFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:201:        // TODO: Don't go through WrapRuntimeKernelFunctor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:681:    // TODO: need to raise an error when you impl a function that has a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:702:    // TODO: need to raise an error when you impl a function that has a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/throughput_benchmark-inl.h:57:  // TODO: add GUARDED_BY once it is available
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:388:// TODO: this can return MaybeOwned
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:1168: * TODO: we could use different names for the following 'handle_torch_function'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/model.h:249:    // TODO: Handle shared storage case.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/arrayref_tensor.h:40:  // TODO Make this explicit
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/interface.h:22:// TODO: Deprecate this API. This was kept for BC compatibility.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runner/model_container_runner.h:78:  // TODO: need an OSS proxy executor implementation. For now,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/tensor.h:40:    // TODO(alanwaketan): Remove this ctor. This is a
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:109:  // TODO: even though this API is currently used **only** in codegen to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:136:  // TODO(alanwaketan): Revisit if all of them need to be accessible to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:264:  // TODO(alanwaketan): Add a registry such that we don't need to make all
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_metadata.h:35:// TODO(whc) is this going to be used outside of in IR decompositions?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/trie.h:46:  // TODO: Because we don't expect user to explicitly call this function via
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:19:// TODO(alanwaketan): Consolidate it with c10::scope_exit.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:68:// TODO(alanwaketan): This is clever, but is there really no std or c10
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_builder.h:140:// TODO: this should return Value
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir.h:209:  // TODO: Some IR classes share the same opkind, such as Mean and MeanDim, so
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/helpers.h:16:// TODO: Consolidate this file with util.h
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_node.h:85:// TODO(whc) once Shape() API is moved to Node base, also make it virtual, and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/config.h:4:// TODO(whc) unclear if this is useful, has only been tested as true
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:21:  // TODO: Scalar node is not currently used by ts_backend. Enable reusing
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:55:  // TODO: verify if IR node reusing works for Dynamic shape ops
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:31:        "TODO(whc) implement TS computation shapes or change interface");
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:41:        "TODO(whc) implement TS computation shapes or change interface");
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:82:  // TODO(whc) need to keep this?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:131:  // TODO(whc)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/instruction.h:89:  // TODO: check for overflow
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:53: * TODO Instead of doing it this way, we should only have pure-jit ops in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:146:    // TODO: some sort of caching mechanism?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:178:                  // TODO What if it gets set later?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/register_ops_utils.h:360:    // TODO: remove when possible, since it just slows down
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/flatbuffer_loader.h:132:// no op, TODO(qihan) delete
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/observer.h:39:  // TODO: Kimish
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/code.h:27:  // TODO After we actually export CALL instructions we can remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:583:// TODO: supports only single comprehension for now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:597:  // TODO: no ifs for now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:607:// TODO: supports only single comprehension for now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:624:  // TODO: no ifs for now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/source_range.h:368:    // TODO: c10::optional<>::value returns an rvalue ref so can't use it here??
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:74:  // TODO @wconstab refactor to use ModuleValue::asTuple instead of new API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:425:  // TODO holding this thing is creepy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/graph_opt.h:104:// TODO: add error reporting for graphs that can't be converted.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/reduction.h:268:  // TODO possible to remove this arg by deferring the init value until we
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:393:  // TODO: add memory types.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:841:// TODO: move to this an internal IR.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:842:// TODO: make IR nodes extensible.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:141:  //     loop variable. TODO: Remove this constraint.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:144:  //     TODO: Remove this constraint.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:473:  // TODO: Add an IR verifier check to detect invalidly compressed buffers.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:584:// TODO: Revisit this once we decide on how dependencies analysis should look
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/external_functions_registry.h:20:// case we need to run aten ops (TODO: support different devices). The first
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/codegen.h:69:  // TODO: Figure out how to unify these call interfaces.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/mem_dependency_checker.h:245:  // TODO: this will return only the AccessInfo for A. It's included for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:171:  // TODO: unique_name
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:215:  // TODO: unique_name
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:263:// TODO: add TORCH_API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:287:// TODO: add TORCH_API
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/python_list.h:39:  // TODO: Do these make sense?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind.h:140:    // TODO: Is there a way to py::cast that doesn't raise an exception on
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:635:      // TODO: this message is not correct anymore, since this InferredType is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:971:// TODO: Remove once we clean up the GraphExecutor usage.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:1105:  // TODO: we could add __torch_function__ dispatch here but I don't know
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/quantization_patterns.h:553:  // TODO: add %dtype after when https://github.com/pytorch/pytorch/issues/34351
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:138:// TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:142:// TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:148:// TODO: refactor all current uses of this function to the Opt one
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:186:// TODO: add a macro to declare the filters
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/symbolic_shape_cache.h:10:  // TODO: Consider in the future if it is reasonable to
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/value_refinement_utils.h:18:// TODO: vector may be faster
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickle.h:39:///  // TODO: when tensors are stored in the pickle, delete this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickler.h:249:  // TODO: only use this if necessary (add a pass to find all shared ivalues,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/flatbuffer_serializer.h:90:// TODO(qihan): delete
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/export.h:258:// TODO remove these switches once interface call is rolled out.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:41: *  - Pattern graph nodes cannot alias. TODO: the check not implemented yet.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:43: * found matches, no nodes in the subgraph alias with each other). TODO: check
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:249:  // TODO: make this more const correct
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1746:  // TODO: return iterator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1822:  // TODO: return iterator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/function_impl.h:141:  // TODO: add more executors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/compilation_unit.h:173:    // TODO: class types cannot be redefined because we have no way right now
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:22:    // TODO: Nested Tensor does not have an implementation of detach. The
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:44:        // TODO: Actually detect views in the accumulateGrad function so that
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/VariableTypeUtils.h:134:// TODO: Blegh, bare references
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function.h:561:  /// TODO: it might be possible to handle cases where backward is
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/custom_function.h:271:  // TODO Add tracing here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/forward_grad.h:205:  // TODO(albanD): replace this with a SmallVector
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:167:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:185:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:204:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:220:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:853:/// TODO: Eliminate this function as much as possible, as it can be expressed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/dynamo/compiled_autograd.h:141:    // TODO(jansel): Here we unpack the SavedVariable exactly once.  This might
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:491:    // TODO: HACK for backend name to get sequence number for that backend.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:512:    // TODO: HACK for backend name to get sequence number for that backend.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:581:    // TODO: if nccl was specified then use it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:626:    // TODO: should we add these entries after the backend setting succeeds?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/logger.hpp:70:  // TODO to support single process multiple devices and multi device modules,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:124:  // TODO this function makes broadcast communication call and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:396:    // TODO(@pietern)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/Utils.hpp:537:    // TODO: see if we should add overflow protection for offset
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/tensorpipe_agent.h:314:  // TODO: To achieve better performance we can have a pipe pool per
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_proto.h:15:// TODO: Remove all these messages and use rpc + registered functions instead.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_context.h:201:  // TODO: make this a context guard
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:75:// TODO: current RRef implementation does not tolerate failures
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:88:// TODO: RRef internal messages are not yet idempotent
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:186:// TODO: make RRef an IValue, and edit createStackForSchema accordingly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:187:// TODO: make RRef system messages idempotent and retry on failures.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/tensor/python_tensor.h:27:// TODO: This is nuts!  There is no reason to let the default tensor type id
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/CudaIPCTypes.h:71:  // TODO: Can be changed to FIFO in order to avoid full traverse on every
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/parallel/data_parallel.h:89:      // TODO: use nccl reduce
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:10:// TODO: These don't really belong here but torchvision builds in CI need them
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/util.h:17:// TODO: replace with pytorch/rfcs#43 when it is ready.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/containers.h:180:  // TODO: cbegin and cend()
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/collection.h:476:    TensorListBegin, // TODO: generalize to other lists.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:188:    // TODO PYBIND11_DEPRECATED(
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:1365:// TODO: After the deprecated constructors are removed, this macro can be simplified by
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/common.h:357:/// Compatibility macros for Python 2 / Python 3 versions TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/type_caster_base.h:482:        // TODO: is this still true for pure Python 3.6?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/tensor.h:503:    // TODO: Move to std::optional once std::optional has more support
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/matrix.h:94:          // TODO: when Eigen bug #747 is fixed, remove the tests for non-negativity.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1295:    using module_def = PyModuleDef; // TODO: Can this be removed (it was needed only for Python 2)?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1322:        // TODO: Should be reinterpret_steal for Python 3, but Python also steals it again when
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2346:                    // TODO consolidate the erasure code in pybind11_meta_dealloc() in class.h
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2433:    // TODO: state captures only the types of Extra, not the values
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:141:            # TODO: find a better way to identify cudaLaunchKernel
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:145:            # TODO: find a better way to identify CUDA Kernel
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:367:# TODO(dberard) - deprecate / remove workaround for CUDA >= 12, when
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:167:        # TODO(robieta): Move away from load bearing names
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:305:        # TODO(robieta):
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:1061:        # TODO: Write a faster serialize (orjson not available in CI)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:181:        # TODO: We should also check tensor identities
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:216:        # TODO: Check if tensor is reused
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:418:        # TODO: fixme! Due to lifetime issues of the function name, this field might
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:437:        # TODO: We should also check if the loader is bottleneck.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:483:        # TODO: We should also check if the optimizer's numerical behavior will change.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/beta/_client_adaptations.py:85:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:43:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:413:                return None  # TODO(nathaniel): call the multimethod.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_auth.py:37:    # TODO(xuanwn): Give credentials an actual type.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_server.py:1182:        # TODO(https://github.com/grpc/grpc/issues/6597): eliminate these fields.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_server.py:1238:# TODO(https://github.com/grpc/grpc/issues/6597): delete this function.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_server.py:1463:        # TODO(xuanwn): We should validate method_handlers first.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_channel.py:257:# TODO(xuanwn): Create a base class for IntegratedCall and SegregatedCall.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_channel.py:1835:    # TODO(xuanwn): Refactor this: https://github.com/grpc/grpc/issues/31704
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_channel.py:2253:        # TODO(https://github.com/grpc/grpc/issues/12531): Several releases
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/_observability.py:271:    # TODO(xuanwn): use channel args to exclude those metrics.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_server.py:87:        # TODO(xuanwn): Implement this for AsyncIO.
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:409:                # TODO(lidiz) drop this hack after 3.8 deprecation
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:484:    # TODO(xuanwn): Implement this method after we have
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:489:    # TODO(xuanwn): Implement _registered_method after we have
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:509:    # TODO(xuanwn): Implement _registered_method after we have
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:529:    # TODO(xuanwn): Implement _registered_method after we have
./api/pipeline/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:549:    # TODO(xuanwn): Implement _registered_method after we have
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:56:    cext.SSWAP: _common.STATUS_RUNNING,  # TODO what status is this?
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:180:    # TODO - the filtering logic should be better checked so that
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:256:        # TODO: rewrite this in C (entstat forks, so use truss -f to follow.
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_psaix.py:531:        # TODO rewrite without using procfiles (stat /proc/pid/fd/* and then
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_pswindows.py:866:                # TODO: the C ext can probably be refactored in order
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:230:    # TODO - the filtering logic should be better checked so that
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:288:        # TODO: refactor and use _common.conn_to_ntuple.
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:639:        # TODO: rewrite this in C (...but the damn netstat source code
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1004:    # TODO: #595
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1041:    # TODO: #595
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:564:    # TODO: remove this once 1892 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:841:                        # TODO: skip AF_INET6 for now because I get:
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_osx.py:122:    # TODO: remove this once 1892 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:254:        # TODO: UNIX sockets are temporarily implemented by parsing
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:368:    # TODO: remove this once 1892 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:386:    # TODO: remove this skip when this gets fixed
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_unicode.py:116:        # TODO - this is quite random and I'm not sure why it happens,
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_aix.py:60:        # TODO maybe try to use "swap -l" to check "used" too, but its units
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_bsd.py:7:# TODO: (FreeBSD) add test for comparing connections with 'sockstat' cmd.
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:2028:    # TODO: re-enable this test.
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:284:        # TODO: check ntuple fields
./api/pipeline/.venv/lib/python3.12/site-packages/psutil/tests/test_contracts.py:235:    # TODO: remove this once 1892 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/click/_termui_impl.py:525:    # TODO: This never terminates if the passed generator never terminates.
./api/pipeline/.venv/lib/python3.12/site-packages/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./api/pipeline/.venv/lib/python3.12/site-packages/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./api/pipeline/.venv/lib/python3.12/site-packages/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./api/pipeline/.venv/lib/python3.12/site-packages/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./api/pipeline/.venv/lib/python3.12/site-packages/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./api/pipeline/.venv/lib/python3.12/site-packages/ecdsa/keys.py:1079:                # TODO parse attributes or validate publickey
./api/pipeline/.venv/lib/python3.12/site-packages/ecdsa/keys.py:1204:        # TODO: "BEGIN ECPARAMETERS"
./api/pipeline/.venv/lib/python3.12/site-packages/prometheus_client/metrics_core.py:330:            # TODO: Handle None gsum_value correctly. Currently a None will fail exposition but is allowed here.
./api/pipeline/.venv/lib/python3.12/site-packages/prometheus_client/values.py:113:            # TODO: Implement exemplars for multiprocess mode.
./api/pipeline/.venv/lib/python3.12/site-packages/prometheus_client/values.py:122:            # TODO: Implement exemplars for multiprocess mode.
./api/pipeline/.venv/lib/python3.12/site-packages/prometheus_client/openmetrics/parser.py:503:        # TODO: check labelvalues are valid utf8
./api/pipeline/.venv/lib/python3.12/site-packages/yaml/scanner.py:187:        # TODO: support for BOM within a stream.
./api/pipeline/.venv/lib/python3.12/site-packages/yaml/scanner.py:761:        # TODO: We need to make tab handling rules more sane. A good rule is
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic_core/core_schema.py:1135:            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/client.py:95:        # TODO: Migrate things away from scoped_config in favor of the
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/client.py:680:            # TODO: fallback partition_name should be configurable in the
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/client.py:758:        # TODO: This normalization logic is duplicated from the
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/utils.py:2314:                # TODO: Update message to reflect use_arn_region
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/docs/bcdoc/style.py:321:        # TODO: Need to control the bullets used for LI items
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/discovery.py:276:        # TODO: Improve eviction behavior to only evict the bad endpoint if
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/handlers.py:976:# TODO: Remove this class as it is no longer used
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/auth.py:245:            # TODO: We should set the host ourselves, instead of relying on our
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/auth.py:943:        TODO: Do we need this?
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/serialize.py:71:    # TODO: Unknown protocols.
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/retryhandler.py:157:        # TODO: send a signal.
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/response.py:102:            # TODO: the url will be None as urllib3 isn't setting it yet
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/response.py:119:            # TODO: the url will be None as urllib3 isn't setting it yet
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/response.py:203:    # TODO: Unfortunately, we have to have error logic here.
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/retries/special.py:17:# TODO: This is an ideal candidate for the retryable trait once that's
./api/pipeline/.venv/lib/python3.12/site-packages/botocore/endpoint.py:346:        # TODO: avoid naming conflicts with ResponseMetadata and Error
./api/pipeline/.venv/lib/python3.12/site-packages/h2/windows.py:116:        # TODO: Can the window be smaller than 1024 bytes? If not, we can
./api/pipeline/.venv/lib/python3.12/site-packages/h2/utilities.py:417:    # TODO: We should also guard against receiving duplicate Host headers,
./api/pipeline/.venv/lib/python3.12/site-packages/httpx/_auth.py:267:        # TODO: implement auth-int
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/type/univ.py:1724:        # TODO: remove when Py2.5 support is gone
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/type/univ.py:1952:                # TODO: we should wrap componentType with UnnamedType to carry
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/type/constraint.py:85:        # TODO: fix possible comparison of set vs scalars here
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/type/constraint.py:747:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/cer/decoder.py:51:# TODO: prohibit non-canonical encoding
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/encoder.py:189:            # TODO: try to avoid ASN.1 schema instantiation
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/encoder.py:557:    # TODO: handling three flavors of input is too much -- split over codecs
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:48:        raise error.PyAsn1Error('SingleItemDecoder not implemented for %s' % (tagSet,))  # TODO: Seems more like an NotImplementedError?
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:58:        raise error.PyAsn1Error('Indefinite length mode decoder not implemented for %s' % (tagSet,)) # TODO: Seems more like an NotImplementedError?
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:1350:            # TODO: Seems not to be tested
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:1399:            yield chunk  # TODO: Weird
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/der/encoder.py:34:                # TODO: move out of sorting key function
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/der/encoder.py:41:                # TODO: support nested CHOICE ordering
./api/pipeline/.venv/lib/python3.12/site-packages/pyasn1/codec/der/decoder.py:23:# TODO: prohibit non-canonical encoding
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/compat/__init__.py:100:    # TODO: once we drop python 3.2 support, can use u'' again!
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:56:    # TODO: a bunch of other things are commonly assumed in this namespace
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:426:            # TODO: straighten out class naming, repr, and .name attr
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:446:        TODO: This should be done explicitly, but for now this mixin sets
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:938:    # TODO: document _norm_hash()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1287:    # TODO: document _truncate_salt()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1312:    # TODO: could support using(min/max_desired_salt_size) via using() and needs_update()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1717:                # TODO: deprecate / disallow vary_rounds=1.0
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1768:            assert 0 <= vary_rounds <= 1 # TODO: deprecate vary_rounds==1
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2527:            # TODO: look into way to fix the issues.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2626:        # TODO: needs UTs
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2627:        # TODO: any other cases where wrapped is "owned"?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2691:        # TODO: under 2.0, throw TypeError if config is None, rather than passing it through
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:364:    # TODO: use izip instead (but first verify it's faster than zip for this case)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:385:    # TODO: could check for cryptography package's version,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/binary.py:361:        # TODO: support padding character
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/binary.py:492:        ##    # TODO: add padding size check?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/exc.py:353:    # TODO: if handler.use_defaults is set, this came from app-provided value,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/totp.py:265:        # TODO: allow a lot more things to be customized from here,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/totp.py:1306:    # TODO: resync(self, tokens, time=None, min_tokens=10, window=100)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:1692:    ##    # TODO: this should work w/ 'auto', but needs closer inspection
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:2109:            # TODO: offer replacement alternative.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:2248:            # TODO: offer replacement alternative.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:2332:            # TODO: offer replacement alternative.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/apps.py:226:# TODO: support the drupal phpass variants (see phpass homepage)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/pbkdf2.py:395:        # TODO: find out what crowd's policy is re: unicode
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/pbkdf2.py:469:        # TODO: find out what grub's policy is re: unicode
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:147:    # TODO: could support the optional 'data' parameter,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:178:    # TODO: once rounds limit logic is factored out,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:398:        # TODO: switch to working w/ str or unicode
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:459:        # TODO: factor out variable checksum size support into a mixin.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:738:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:761:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:784:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:879:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/scram.py:330:            # TODO: verify digest size (if digest is known)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:3:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:211:        # TODO: try to detect incorrect 8bit/wraparound hashes using kwds.get("secret")
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:454:        # TODO: check for 2x support
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:518:        # TODO: figure out way to skip these tests when not needed...
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:628:    # # TODO: would like to implementing verify() directly,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/sun_md5_crypt.py:345:    # TODO: if we're on solaris, check for native crypt() support.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/misc.py:111:    # TODO: rename attr to 'marker'...
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/scrypt.py:133:    # TODO: would like to dynamically pick this based on system
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/scrypt.py:139:    # TODO: make default block size configurable via using(), and deprecatable via .needs_update()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/sha2_crypt.py:300:        # TODO: this *could* use uh.parse_mc3(), except that the rounds
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:83:    # TODO: add sha3 to this table.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:245:    # TODO: add pysha3 support.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:498:            # TODO: load in preset digest size info for known hashes.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:874:# TODO: consider some alternatives, such as C-accelerated xor_bytes helper if available
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/des.py:40:# TODO: could use an accelerated C version of this module to speed up lmhash,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:30:#: TODO: standardize this across backends, and expose support via scrypt hash config;
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:40:# TODO: unittests for this function
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:95:# TODO: configuration picker (may need psutil for full effect)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:209:        # TODO: would like to enforce a single "maxmem" policy across all backends;
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_utils.py:326:        # TODO: add some tests to ensure we take THETA(strlen) time.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_cisco.py:209:        # TODO: these need confirming w/ an actual PIX system.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:158:        # TODO: push this to passlib.apps django contexts
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:459:    # TODO: add get_hasher() checks where appropriate in tests below.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:530:        # TODO: is_password_usable()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:605:        # TODO: is_password_usable()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:645:        # TODO: is_password_usable()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:690:        # TODO: is_password_usable()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:818:        # TODO: get_hasher()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:901:        # TODO: test unpatch behavior honors flag.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_pwd.py:123:    # TODO: test rng option
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_apache.py:72:        # TODO: under py3, could trap the more specific FileNotFoundError
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_apache.py:610:    # TODO: test set_password autosave
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:120:    # TODO: find an authoritative source of test vectors
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:242:    # TODO: find an authortative source of test vectors
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:641:    # TODO: integrate EncodingHandlerMixin
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1212:    # TODO: get more test vectors (especially ones which properly test unicode)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1250:    # TODO: find more test vectors (especially ones which properly test unicode)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1316:    # TODO: integrate EncodingHandlerMixin
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1621:    # TODO: this scheme needs some real test vectors, especially due to
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1737:#    accepts_all_hashes = True # TODO: turn this off.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_bcrypt.py:488:        # TODO: convert to v2 format
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:370:            # TODO: may want to filter out a few of this, but not blanket filter...
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:374:            # TODO: should be cleaned in 2.0, when support will be dropped.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:489:        # TODO: make this display better diff of *which* warnings did not match
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:954:    # TODO: rename to do_hash() to match new API
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1639:        # TODO: check relaxed mode clips min-1
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1658:            # TODO: check relaxed mode clips max+1
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2053:    # TODO: check various supported idents
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2618:        # TODO: would like to enhance what this test covers
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2627:        # TODO: figure out what invariants we can reliably parse,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:3287:    # TODO: turn into decorator, and use mock library.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:3493:    # TODO: user size? kinda dicey, depends on algorithm.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_pbkdf2.py:182:    # TODO: need a bunch more reference vectors from some real
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django_source.py:229:        # TODO: support wrapping django's harden-runtime feature?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:307:    # TODO: test HasRawSalt mixin
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:611:        # TODO: handle fshp correctly, and other glitches noted in code.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:766:        self.assertEqual(h.ident_values, None) # TODO: should output (u("?P$"), u("?H$")))
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:838:# TODO: provide data samples for algorithms
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/backports.py:18:    # TODO: deprecate these exports in favor of "unittest.XXX"
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_argon2.py:398:            # TODO: make this fatal, and add refs for other version.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_argon2.py:433:        # TODO: fuzz parallelism, digest_size
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context_deprecated.py:40:    # TODO: need to test user categories w/in all this
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:203:    # TODO: test secrets_path
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:232:    # TODO: test 'cost' param
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:375:        # TODO: rework timing test here to inject mock pbkdf2_hmac() function instead;
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:392:# TODO: this class is separate from TotpTest due to historical issue,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:693:    # TODO: test using() w/ 'digits', 'alg', 'issue', 'wallet', **wallet_kwds
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1048:        # TODO: test window values that aren't multiples of period
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1083:        # TODO: test skew + larger window
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1581:    # TODO: to_dict()
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1595:    # TODO: from_json() / to_json().
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_registry.py:127:        # TODO: check lazy load which calls register_crypt_handler (warning should be issued)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_django.py:42:    #: TODO: for a bunch of the tests below, this is just max version where
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:52:    # TODO: these unittests could really use a good cleanup
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1025:        # TODO: should migrate these tests elsewhere, or remove them.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1352:    # TODO: now that rounds generation has moved out of _CryptRecord to HasRounds,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1446:        # TODO: test default falls back to mx / mn if handler has no default.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1607:        # TODO: test dummy_verify() invoked by .verify() when hash is None,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_crypto_digest.py:194:    # TODO: write full test of compile_hmac() -- currently relying on pbkdf2_hmac() tests
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:75:    # TODO: add preset which includes HASHERS + PREFERRED_HASHERS,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:365:            # TODO: should make iteration via registry easier
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:602:            # TODO: Solve redundancy that verify() call
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:809:        # TODO: would like to add support for inheriting config from a preset
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:813:        # TODO: wrap and import any custom hashers as passlib handlers,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1010:        # TODO: would like access CryptContext, would need caller to pass it to get_passlib_hasher().
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1015:            # TODO: always call subcls/handler.needs_update() in case there's other things to check
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1028:# TODO: this code probably halfway works, mainly just needs
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ifc.py:32:# TODO: make this actually use abstractproperty(),
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ifc.py:67:    #: .. TODO: passlib 1.8: deprecate/rename this attr to "max_secret_size"?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ifc.py:80:    #: .. TODO: passlib 1.8: deprecate/rename this attr to "truncate_hash_error"?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ifc.py:277:    #: TODO: document this, or at least the use of testing for
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/registry.py:384:    # TODO: make _handlers a separate list, so we don't have module namespace mixed in.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/registry.py:431:# TODO: needs UTs
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/registry.py:449:# TODO: needs UTs
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/registry.py:507:# TODO: move unix_crypt_schemes list to here.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/registry.py:511:# TODO: needs UTs
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/registry.py:531:# TODO: needs UTs
./api/pipeline/.venv/lib/python3.12/site-packages/typing_extensions.py:3267:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/pipeline/.venv/lib/python3.12/site-packages/asyncio_mqtt/client.py:111:# TODO: Simplify the logic that surrounds `self._outgoing_calls_sem` with
./api/pipeline/.venv/lib/python3.12/site-packages/asyncio_mqtt/client.py:355:    def id(  # noqa: A003 # TODO: When doing BREAKING CHANGES rename to avoid shadowing builtin id
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:26:  # TODO: Remove this import after fix api_implementation
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:271:    # TODO: Add function to calculate full_name instead of having it in
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:474:# TODO: We should have aggressive checking here,
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:480:# TODO: for this and other *Descriptor classes, we
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:539:  # TODO: Find a way to eliminate this repetition.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:563:  # TODO: Find a way to eliminate this repetition.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:600:  # TODO: Find a way to eliminate this repetition.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:139:    # TODO: implement this API.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:143:    # TODO: implement this API.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_pool.py:1360:  # TODO: This pool could be constructed from Python code, when we
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/pyext/cpp_message.py:21:# TODO: Remove this import after fix api_implementation
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:100:        # TODO: Remove this check here. Duplicate extension
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:140:      # TODO: Remove this check here. Duplicate extension
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:88:    # TODO: fail back to python
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:135:# TODO: Remove the API, it returns a constant. b/228102101
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:10:# TODO: Helpers for verbose, common checks like seeing if a
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:215:  # TODO: Escape Python keywords (e.g., yield), and test this support.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:230:  # TODO:  Remove this method entirely if/when everyone agrees with my
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:464:    # TODO: This may be broken since there may not be
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:717:    # TODO: This may be broken since there may not be
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:767:  # TODO: Remove duplication with similar method
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:824:  # TODO: Migrate all users of these attributes to functions like
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:827:    # TODO: Use cls.MESSAGE_FACTORY.pool when available.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:977:  # TODO: Don't use the factory of generated messages.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:989:  # TODO: For now we just strip the hostname.  Better logic will be
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:1035:    # TODO: Fix UnknownFieldSet to consider MessageSet extensions,
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/builder.py:96:  # TODO: Remove this on-op
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:37:# TODO: Unify error handling of "unknown extension" crap.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:38:# TODO: Support iteritems()-style iteration over all
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:98:# TODO: Remove this. BaseContainer does *not* conform to
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:214:# TODO: Constrain T to be a subtype of Message.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/symbol_database.py:136:    # TODO: Fix the differences with MessageFactory.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:22:# TODO Import thread contention leads to test failures.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:477:          # TODO: refactor and optimize if this becomes an issue.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1081:        # TODO: Change to _allow_singular_overwrites.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1637:# TODO: Migrate violators to textformat_tokenizer.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:8:# TODO: We should just make these methods all "pure-virtual" and move
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:43:  # TODO: Link to an HTML document here.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:45:  # TODO: Document that instances of this class will also
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:49:  # TODO: Document these fields and methods.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:66:    # TODO: Remove this once the UPB implementation is improved.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:182:  # TODO: MergeFromString() should probably return None and be
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:217:    # TODO: Document handling of unknown fields.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:218:    # TODO: When we switch to a helper, this will return None.
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:263:  # TODO: Decide whether we like these better
./api/pipeline/.venv/lib/python3.12/site-packages/google/protobuf/message.py:269:  # TODO: Be sure to document (and test) exactly
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578:        # TODO: Add optional support for socket.gethostbyname checking.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095:        # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38:    # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144:        # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234:                # TODO: Arbitrary read value.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282:            # TODO this is often present from upstream.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325:    # TODO: This is a woefully incomplete response object, but works for non-streaming.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332:        decode_content: bool = False,  # TODO: support decoding
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/exceptions.py:306:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/util/url.py:454:    # TODO: Remove this when we break backwards compatibility.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/util/request.py:229:    # File-like object, TODO: use seek() and tell() for length?
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/connection.py:330:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/connection.py:436:        # object later. TODO: Remove this in favor of a real
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/connection.py:561:        # TODO should we implement it everywhere?
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:1005:                # TODO make sure to initially read enough data to get past the headers
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20:    # TODO: Remove this in favor of a better
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499:        # TODO should we eliminate the recursion?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503:                    # TODO check whether we need to call `list_hook`
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511:            # TODO is the interaction between `list_hook` and `use_list` ok?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516:                    # TODO check whether we need to call hooks
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863:    TODO: clean up the code here.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558:            # TODO: Not sure if we need the SecTrustResultType for anything?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:839:            # TODO version verification
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:922:                # TODO SHA256 digest
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401:        # TODO check k, v for valid values
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:560:    # TODO could add iter* variants
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:984:        # TODO: any other fields wanted
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:1020:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:3568:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522:        # TODO: Add optional support for socket.gethostbyname checking.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659:        # TODO: should I do clean shutdown here? Do I have to?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819:        # TODO: Well, crap.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829:        # TODO: Update in line with above.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1:# TODO: Add Generic type annotations to initialized collections.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122:_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598:        # TODO: Add a deadline?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227:        # TODO: There is an assumption that the result will be a
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/cache.py:278:                # TODO: use DirectUrl.equivalent when
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:227:        # TODO performance: this means we iterate the dependencies at least twice,
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:362:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:201:        # TODO: Check already installed candidate, and use it if the link and
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:622:        # TODO: Are there more cases this needs to return True? Editable?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:344:        # TODO: In the future, it would be nice if pip supported PEP 691
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:204:        # TODO: Try to get these passing down from the command?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6:# TODO: This needs Python 3.10's improved slots support for dataclasses
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:107:    # TODO: replace this with slots=True when dropping Python 3.9 support.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:526:    # TODO: handle space after '\'.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:285:        # TODO: The is_installable_dir test here might not be necessary
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:75:        TODO remove this property together with the legacy resolver, since the new
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:167:        # TODO: this property is relatively costly to compute, memoize it ?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:177:                # TODO: get project location from second line of egg_link file
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:557:        # TODO: separate this part out from RequirementPreparer when the v1
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:36:    BaseTy.float: "double",  # TODO: how about other floating point types?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:97:            # TODO: BaseTy.Dimname, BaseTy.Generator, etc.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:98:            raise NotImplementedError(f"TODO: add support for arg type {repr(typ)}")
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:203:                f"TODO: add support for return type {repr(ret.type)}"
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:316:        # TODO: No need to generate C shim for Inductor lowered ops.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:48:    # TODO: Matching on CType seems wrong; should be matching on Type
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:60:                # TODO: I don't understand when you should put lazy_ in the name
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:72:                f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:447:                # TODO(alanwaketan): Maybe we want to apply GetLtcTensorOrCreateForWrappedNumber here, but hold it
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:455:                    f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:540:            # TODO: this is trolling
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:581:            # TODO(whc) remove this if XLA switches to using static method for creation
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:39:# TODO: use BackendIndex
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:75:        # TODO: don't hardcode; return type will be inferred based on tags on
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:501:        # TODO: don't hardcode ufunc:: namespace here, should be centralized smh
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:160:      // TODO: avoid the redispatch here
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:428:            # TODO: dedupe this with the structured codegen
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:453:                    # TODO: handle in place on tensor list
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:662:            # TODO: Make sure out argument is guaranteed to be self
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:708:            # TODO: Move to OptionalMPSGuard.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:720:            f"      return {output_value};\n",  # type: ignore[possibly-undefined]  # TODO: audit
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:722:            f"    std::array<{output_type}, {len(f.func.returns)}> outputs_;",  # type: ignore[possibly-undefined]  # TODO: audit
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:723:            f"{textwrap.indent(proxy_field, indent)}",  # type: ignore[possibly-undefined]  # TODO: audit
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:739:        # TODO: Now, there is something interesting going on here.  In the code below,
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:762:        # (e.g., at::cpu::add).  We don't generate methods (TODO: do this
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:815:                # TODO: dedup this branch
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:893:                        # TODO: Stop hardcoding that the output type is a Tensor.  Note
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:908:                # TODO: https://github.com/pytorch/pytorch/issues/53023
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:918:                # TODO: I think this means structured won't work with method
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:947:            # TODO: Do this in translate instead
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:965:            sig_body.append(f"return {ret_expr};")  # type: ignore[possibly-undefined]  # TODO: audit
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:342:        # TODO: for ops with structured_delegate it should check the dispatch table of
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:786:# TODO: This was historically used to help some JIT interop code
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:1041:# TODO: Get rid of dynamic_type, after getting tools/autograd
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:1310:        # TODO: What exactly is the semantics of the 'dispatch' field?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:1424:    # TODO: how come ValuesView isn't a Sequence lol
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:2227:                    # TODO: this condition is a bit questionable
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:2723:    # TODO: --op-registration-whitelist will be removed when all call-sites
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen.py:2790:    # TODO: stop generating CUDA kernels for non-CUDA builds
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_backend_stubs.py:139:            # TODO: allow structured external backends later.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:789:        # TODO: The below ops all have "problematic" schemas that prevent them from
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:60:# TODO: Use a real parser here; this will get bamboozled
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:98:        # TODO: this does the wrong thing with KeyError
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:108:# TODO: put this somewhere else, maybe
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/utils.py:159:            # TODO: Update the comment reference to the correct location
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:272:        # TODO: remove the skip after these two operators schemas are fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:327:            # TODO: remove the skip after these two operators schemas are fixed
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:23:# TODO: Duplicated Subset from codegen.tool.gen_oplist, remove declaration in codegen
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:64:        type_alias_map: Dict[str, List[str]],  # TODO: Support unwrapped str val
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:91:            # TODO: Support inlined arguments
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:130:                )  # TODO: fix this discrepancy
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:140:        # TODO: keeping these special cases for Tensor[] and Tensor?[] so that we can hookup with ATen kernels.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:215:        # TODO: Consider incorporating this into the data model
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/executorch/api/custom_ops.py:94:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_executorch.py:368:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:149:    # TODO(whc) add a check for shape inference functions that have meta kernels implement and should be retired.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:368:        TODO(alanwaketan): Remove this sorting hack once all ops are grouped properly.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:75:        # TODO: these ones got added recently and need manual inspection
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:252:        # TODO: stop doing type tests by converting to C++ and then testing
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:278:    # TODO: stop type testing by converting to C++
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:476:    # TODO: figure out what this does
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:684:            # TODO: verify that the tag is valid and has an entry in tags.yaml
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:763:                # TODO: maybe it's better to test the return
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:926:        # TODO: probably better to accumulate these errors and report them all
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1293:            # TODO: This discrepancy isn't required; we could also generated
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1359:    # TODO: Need to handle collisions with argument names at some point
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1733:        # TODO: implement a proper parser if this gets more ugly
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1856:    ConstQuantizerPtr = auto()  # TODO: rename
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:1996:        # TODO: deduplicate annotation matching with Return
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:2281:        # TODO: Use a real parser here; this will get bamboozled
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:2400:        # TODO: These invariants are weirdly asymmetric?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/model.py:2401:        # TODO: Fancier types?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:228:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:251:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:298:    # TODO: maybe don't need keep scattered out fields for python signature?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:322:                # TODO: shouldn't this be OptionalType[ListType[...]], since it defaults to None?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:337:    # TODO: create a dedicated SelfArgument type for 'self'?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:354:    # TODO: maybe create a PythonTensorOptionsArgument?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:723:        # TODO: directly translate a.default to python default
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:775:    # [old codegen] TODO: because these aren't guaranteed to be 100% faithful
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:946:            # TODO: this doesn't seem right...
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1095:# TODO: This is to keep same byte-for-byte result as the old codegen - maybe unnecessary?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1127:            # TODO: avoid this special handling?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1405:            # TODO: why this needs to be special case?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1426:            # TODO: make this part of something more general, or get rid of it.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1480:    # TODO: maybe move to the generator side as it's not related to binding.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/native.py:47:    # TODO: delete this!
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/native.py:114:        # TODO: Not sure why the arguments assigned here are for
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:149:        # TODO: My kingdom for a pattern matcher
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:152:        # TODO: This could get us in recomputation trouble if b.expr is nontrivial.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:253:        # TODO: These are referentially equal, shouldn't have to do this;
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:368:            # TODO: You might also want to solve this from longSymVec_ctype or
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:120:            raise AssertionError(f"TODO add support for type {repr(typ)}")
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:125:            # TODO(whc) is this actually correct? or should it use a Vector like above
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:131:            # TODO: return a value type.  The problem here is analogous to
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:146:# TODO: Determining this based off of CType is bad; this should be computed
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:166:        # TODO: report True for this
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:192:# TODO: dedupe with Type.is_generator_like
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:209:    # TODO: this is lies, it is false for symint list
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:229:            # TODO: lists of symints are not currently treated as value types
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:306:# TODO: This is not idiomatic with how other torchgen APIs transform on schema.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:314:    # TODO: Need to handle collisions with argument names at some point
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:164:                )  # TODO: fix this discrepancy
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:181:        # TODO: remove these special cases, ArrayRef fallthrough works fine
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:285:        # TODO: Consider incorporating this into the data model
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:422:                default = "at::kLong"  # TODO: this is wrong
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:114:    # TODO: maybe the logic to search for all variants is no longer necessary?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:233:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:241:#   TODO: some cpp naming logic (e.g. resolving name conflict) might be irrelevant?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:250:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:261:# TODO: Update comment below since it is out of date.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:348:# TODO(crcrpar): Avoid hard coding "Default" ideally.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:632:            # TODO(crcrpar): Avoid hard coding "Default" ideally.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:85:    # TODO: Kill this when we eventually remove it!
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:188:    # TODO: Kill this when we eventually remove it!
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:211:    # TODO: maybe don't represent default here
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:246:    # TODO: Kill this when we eventually remove it!
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/api/structured.py:76:        # TODO: delete these special cases; see torchgen.api.cpp--these
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/RegisterBackendSelect.cpp:31:  // TODO: fetch scalar type from Tensor? But it doesn't really matter...
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:196:  // TODO: temporarily disabled
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:235:  // TODO: Deprecate me
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:539:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:19:// TODO: rename this file to something more generic.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:50:// TODO: this doesn't handle restriding empty tensors correctly; see
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/DispatchKeyFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/FunctionalInverses.h:26:// TODO: Change codegen to generate these. See the following link:
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/Functions.cpp:10:   AutoDispatchBelowADInplaceOrView guard{}; // TODO: Remove.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:110:    # TODO: byte-for-byte compatible with old codegen behavior - should clean up
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:302:    # TODO: clean up old codegen behavior
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:256:    # TODO: Should handle optional here?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:261:    # TODO: Should handle optional here?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:338:    return f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:355:    # TODO: Clean this logic up if we get rid of reverse view funcs or reify them.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:174:# TODO: Why is this going through CppSignatureGroup, that doesn't make sense...
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:395:            # TODO we are trolling
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:592:        # TODO: do we need eagerly calculate and save it here? Can it be derived
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:653:    # TODO: maybe the logic to handle the legacy schema is no longer necessary?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:943:            # TODO: it would be nice to not have these special cases
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1079:        # TODO: `cpp_type` is only to keep it byte-for-byte compatible with the old codegen, should remove.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1100:                    # TODO(crcrpar): Make it simpler.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1221:            # TODO: process all derivative formulas!!!
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1345:            # TODO: should be `arg.type.is_tensor_like()`?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1605:            base_name = f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1729:        # TODO: flatten allocates a std::vector, which could be expensive
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1857:                # TODO update this when inplace namings are unified
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1967:                    # TODO(crcrpar): Should this (= the foreach specific logic) be refactored somehow?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py:441:# TODO: This is probably not exhaustive, but it's a start
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1250:        # TODO: should use some canonical form instead of 'str(arg.type)' - see comments
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1338:        # TODO: Checking `ps.method and ('requires_grad' in parser_outputs)` is a hacky
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_factories.py:22:# TODO: maybe update the cpp argument API to take optional namespace argument?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:73:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:91:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:110:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:126:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:156:    // TODO: consider factoring this out
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:371:  // TODO: change the condition to `self_.dim() != 0` once we expose scalars
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:416:  // TODO: Make this call the TensorOptions version, maybe?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:422:  // TODO: Make this call the TensorOptions version, maybe?
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./api/pipeline/.venv/lib/python3.12/site-packages/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./api/pipeline/.venv/lib/python3.12/site-packages/requests/hooks.py:19:# TODO: response is the only one
./api/pipeline/.venv/lib/python3.12/site-packages/einops/einops.py:52:    # TODO add support for added_axes
./api/pipeline/.venv/lib/python3.12/site-packages/einops/tests/test_einsum.py:352:    # TODO: Include check for giving normal einsum pattern rather than einops.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:167:# TODO: add support for `axis` tuples
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_correlation.py:10:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:44:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1262:    # TODO: properly avoid NaN when y is negative infinity
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1263:    # TODO: silence warning with taking log of complex nan
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1264:    # TODO: deal with x == y better
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3015:    # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3453:        # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:4442:    # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_morestats.py:2627:    # TODO: calculate exact distribution considering ties
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_qmc.py:456:        # TODO consider returning both the mean and the standard deviation
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_page_trend_test.py:322:    if ranks.ndim != 2:  # TODO: relax this to accept 3d arrays?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:193:    # TODO: add more where possible with test coverage,
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:321:    # TODO: add more where possible with test coverage,
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_fast_gen_inversion.py:144:# TODO: add more distributions
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous_basic.py:136:        # TODO: multiple checks in this function are not robust, tweaking the
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:26:    # Check that `var` keyword returns a value.  TODO: check whether returned
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:43:    # TODO: check that implementation is correct.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2367:    # TODO: add method "pearsonr" after fix overflow issue
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2387:    # TODO: add method "pearsonr" after fix overflow issue
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_basic.py:1260:# TODO: for all ttest functions, add tests with masked array inputs
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:5780:        # These are excluded by the filters below. TODO: Rewrite tests so that
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous.py:890:    # TODO: add `supported` method and check here
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_stats.py:79:    # TODO: write these tests to handle missing values properly
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs.py:221:    # TODO use a better error approximation
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:38:#TODO renovate or move this class when scipy operators are more mature
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:73:#TODO renovate or move this function when SciPy operators are more mature
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_lapack.py:1941:                # TODO: Add a test for ONB?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/pyprima/cobyla/geometry.py:24:    TODO: Check whether it improves the performance if JDROP = NUM_VARS is allowed when
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:181:        # TODO: Does this depend on device?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:243:        # TODO: Does this depend on device?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/torch/_aliases.py:833:    # TODO: is the return type a list or a tuple
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:42:    # TODO: import from typing (requires Python >=3.13)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:119:    # TODO: Should we reject ndarray subclasses?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:264:    # TODO: Account for other backends.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:293:        # TODO: drop support for numpy<2 which didn't have __array_namespace__
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:300:        # TODO: drop support for jax<0.4.32 which didn't have __array_namespace__
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:642:            # TODO: Support Python scalars?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:876:        # TODO: What if our array is on the GPU already?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:16:    # TODO: import from typing (requires Python >=3.13)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:309:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:381:    # TODO: np.clip has other ufunc kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:32:# TODO: use the QR wrapper once dask
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:59:    # TODO: can't avoid computing U or V for dask
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:65:    # TODO: respect device keyword?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:96:    # TODO: respect device keyword?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:163:    # TODO: respect device keyword?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:224:    # TODO: This won't handle dask unknown shapes
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_at.py:23:    # TODO import from typing (requires Python >=3.11)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:36:    # TODO import from typing (requires Python >=3.12 and >=3.13)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:307:    TODO this helper should be eventually removed once all the special cases
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/testing.py:23:    # TODO import override from typing (requires Python >=3.12)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/differentiate/_differentiate.py:372:    # TODO (followup):
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/cluster/hierarchy.py:1385:        # TODO ARRAY_API complex indexing not supported
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_direct_py.py:256:    # TODO: fix disp argument
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py:349:        # TODO: Use more advanced strategies from [2]_
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py:54:    # TODO: Use a symmetric indefinite factorization
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:61:    # TODO: revert this once the warning bug fix in sksparse is merged/released
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:101:    # TODO: Use a symmetric indefinite factorization
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_ip.py:92:                # TODO: revert this suppress_warning once the warning bug fix in
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2050:    # TODO: add hessp (callable or FD) to ScalarFunction?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_chandrupatla.py:7:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:72:    # TODO: test redundant row removal better
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:73:    # TODO: make solve more efficient with BGLU? This could take a while.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:376:        # TODO: cythonize?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:477:        pass  # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:716:                    # self.n #TODO: Should always be self.n, this is
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1176:        # TODO: Only do this if global mode
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1502:            # TODO: Uncertain if n_prc needs to add len(self.LMC.xl_maps)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_chandrupatla.py:970:        # # TODO: Test zero tolerance
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_optimize.py:3063:        # TODO this test should really be equivalent to factorized version
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__remove_redundancy.py:5:# TODO: add tests for:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:579:        # TODO: Make default n higher for faster tests
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:715:        # TODO: This test doesn't cover anything new, it is unknown what the
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1179:            sign_det_A_11 = -1  # TODO: Choose another det of j instead?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1180:            # TODO: Unlikely to work in many cases
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1187:            # TODO: Note that scipy might be faster to add as an optional
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1191:            # TODO: Note if sign_det_A_j0 == then the point is coplanar to the
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1217:        # TODO: Is checking the projection of one vertex against faces of other
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1220:        # TODO: Literature seems to suggest using proj.T, but why is this
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1222:        if np.linalg.det(proj) == 0.0:  # TODO: Replace with tolerance?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_remove_redundancy.py:423:        v = U[:, -1]  # TODO: return these so user can eliminate from problem?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:862:        if rr and A_eq.size > 0:  # TODO: Fast sparse rank check?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:876:        try:  # TODO: use results of first SVD in _remove_redundancy_svd
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/special/_support_alternative_backends.py:125:            # TODO use xpx.lazy_apply to add jax.jit support
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/special/_lambertw.py:146:    # TODO: special expert should inspect this
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/special/tests/test_sf_error.py:34:    # TODO: special expert should correct
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/special/tests/test_basic.py:2448:        # TODO: cannot use N itself yet; factorial uses `gamma(N+1)` resp. `(hi+lo)//2`
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/io/_harwell_boeing/hb.py:12:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:21:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:842:        # TODO: this is where we are spending time (~80%). I think things
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/io/_netcdf.py:20:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/interpolate/_fitpack_impl.py:19:TODO: Make interfaces to the following fitpack functions:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_legendre.py:56:        # TODO: current converting to/from numpy
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:78:        # TODO: Currently only support for degree 7 Genz-Malik cubature, should aim to
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:134:        # TODO: Currently only support for the degree 5 lower rule, in the future it
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_kronrod.py:83:        # TODO: nodes and weights are currently hard-coded for values 15 and 21, but in
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:82:    # TODO: Optimize for hermitian and real?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:194:    # TODO: Optimize for hermitian and real?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/tests/test_basic.py:865:# TODO: Is this test actually valuable? The behavior it's testing shouldn't be
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/fft/tests/test_real_transforms.py:110:    # TODO write an array-agnostic pad
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:885:    # TODO: Why are we using _as_euler_from_matrix here? As a sanity check? It is not
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:920:    # TODO: Same as before: Remove _as_euler_from_matrix?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:2083:    # TODO: Do we want to support this for all Array API frameworks?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:412:    # TODO: delete next 15 lines [combine with _eye()] once spmatrix removed
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:541:    # TODO: delete next 10 lines and replace _sparse with _array when spmatrix removed
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:627:    # TODO: delete next 8 lines and replace _sparse with _array when spmatrix removed
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:684:    # TODO remove this if-structure when sparse matrices removed
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:134:                # TODO infer shape here
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:346:        # TODO eliminate zeros
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/tests/test_svds.py:626:            # TODO: arpack crashes when v0=v0, which="SM"
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/minres.py:357:            break  # TODO check this
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:20:# TODO check that method preserve shape and type
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:21:# TODO test both preconditioner methods
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:366:    # TODO: minres / tfqmr. It didn't historically use absolute tolerances, so
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:369:        pytest.skip("TODO: Add atol to minres/tfqmr")
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:145:        #TODO this test seems to give estimates that match the table,
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:146:        #TODO even though no attempt has been made to deal with
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:147:        #TODO complex numbers in the one-norm estimation.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_dok.py:474:            # TODO implement resize across dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:227:        # TODO check for duplicates?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:700:        # TODO: don't fall back to fancy indexing here
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:967:            # TODO: only sort where necessary
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_base.py:656:            # TODO sparse broadcasting
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_csr.py:229:        # TODO: uncomment this once it's faster:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_data.py:18:# TODO implement all relevant operations
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:238:                # TODO: make sparse matrix indexing work for sparray
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:303:            # TODO: handle this for nD (adjacent arrays stay, separated move to start)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_construct.py:23:#TODO check whether format=XXX is respected
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:297:# TODO test prune
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:298:# TODO test has_sorted_indices
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:4733:        # TODO: properly handle this assertion on ppc64le
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:5469:        # TODO check that NC has duplicates (which are not explicit zeros)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_spfuncs.py:16:        #TODO expose through function
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:516:                and n_fft > 0):  # TODO: review threshold acc. to benchmark?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:1643:    # TODO in the near future:
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:4886:# TODO: Make this a real public function scipy.misc.ff
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_ltisys.py:1996:    # TODO: This could use some more work.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:604:        # TODO: add meaningful test where X0 is a list
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:676:        # TODO: add meaningful test where X0 is a list
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2565:        # TODO: Why so inaccurate?  Is reference flawed?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2570:        # TODO: Why so inaccurate?  Is reference flawed?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2580:        # TODO: Why so inaccurate?  Is reference flawed?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2585:        # TODO: Why so inaccurate?  Is reference flawed?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_windows.py:820:    @xfail_xp_backends(np_only=True, reason='TODO: make resample array API ready')
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:211:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:884:    @xfail_xp_backends(np_only=True, reason="TODO: swapaxes")
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:290:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:305:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:319:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/pipeline/.venv/lib/python3.12/site-packages/uvloop/_testbase.py:291:        # TODO This warning has to be fixed in asyncio.
./api/pipeline/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:221:# TODO at some point, we could switch to an enum flag, so that multiple sources
./api/pipeline/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:224:    # TODO if/when https://peps.python.org/pep-0767/ is accepted, add 'read_only'
./api/pipeline/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:319:        # TODO use a match statement when Python 3.9 support is dropped.
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:473:            # TODO: what happens if we don't have a filename?
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1464:        # TODO: verify that we're in the state MultipartState.END, otherwise throw an
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1655:                # TODO: check for error here.
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1685:                # TODO: handle mixed case
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1692:                # TODO: check for errors
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1703:                # TODO: check that we properly handle 8bit / 7bit encoding.
./api/pipeline/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1764:        # TODO: check the parser's return value for errors?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/_typing/_dtype_like.py:61:_DTypeLikeNested = Any  # TODO: wait for support for recursive types
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/_typing/_array_like.py:56:# TODO: Wait until mypy supports recursive objects in combination with typevars
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1795:    # TODO: are there no other tests for cholesky?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/getlimits.py:367:    TODO: MachAr should be retired completely ideally.  We currently only
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs.py:2312:        assignment examples; TODO).
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/arrayprint.py:1466:        # TODO: Custom repr for user DTypes, logic should likely move.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:170:        # TODO: this path can never be reached
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:179:    # TODO: this duplicates the C metastr_to_unicode functionality
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs_scalars.py:320:# TODO: work out how to put this on the base class, np.floating
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:80:        # TODO: Optimize case when `where` is broadcast along a non-reduction
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_scalarmath.py:97:        # TODO: It would be nice to resolve this issue.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:7434:# TODO: test for multidimensional
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:452:        # TODO: This discrepancy _should_ be resolved, either by relaxing the
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:892:    # TODO: This is arguably weird/wrong, but seems old:
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:12:# TODO: branch cuts (use Pauli code)
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:13:# TODO: conj 'symmetry'
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:14:# TODO: FPU exceptions
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:23:# TODO: replace with a check on whether platform-provided C99 funcs are used
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:26:# TODO This can be xfail when the generator functions are got rid of.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:122:    # TODO This can be xfail when the generator functions are got rid of.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:479:    # TODO This can be xfail when the generator functions are got rid of.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_casting_unittests.py:782:        # TODO: While this test is fairly thorough, right now, it does not
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_api.py:163:# TODO: remove when fastCopyAndTranspose deprecation expires
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:1544:        # TODO: Allowing unsafe casting by
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:2520:        # TODO: add absolute (gold standard) time span limit strings
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/numeric.py:480:    # TODO: this works around .astype(bool) not working properly (gh-9847)
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1873:    /* TODO: Make this definition public in the API, as soon as its settled */
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:221: * TODO: Due to the fact that `resolve_descriptors` is also used for `can_cast`
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:366:// TODO: These slots probably still need some thought, and/or a way to "grow"?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:398: * TODO: These two functions are currently only used for experimental DType
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:821:        // TODO: do something better than 128 bit math
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:855:        // TODO: do something better than 128 bit math
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/mixins.py:163:    # TODO: handle the optional third argument for __pow__?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:73:# TODO: .zip support, .tar support?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:335:        # TODO: Doesn't handle compressed files!
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:401:        # TODO:  This should be more robust.  Handles case where path includes
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:515:        # TODO: There is no support for opening a file for writing which
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:518:        # TODO: Add a ``subdir`` parameter for specifying the subdirectory
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:3543:        # TODO: Note that times have dubious rounding as of fixing NaTs!
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:4101:        # TODO: Median does not support Datetime, due to `mean`.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:311:                sup.filter(ResourceWarning)  # TODO: specify exact message
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/core.py:207:        # TODO: This is probably a mess, but should best preserve behavior?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/core.py:4673:        # TODO: We don't actually support K, so use A instead.  We could
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5430:    # TODO: Test masked_object, masked_equal, ...
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/_isocbind.py:55:# TODO: See gh-25229
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:134:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2066:    TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2505:                    # TODO: test .eq., .neq., etc replacements.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2551:                outmess(f'get_parameters[TODO]: '
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2594:        # TODO: use symbolic from PR #19805
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:723:        /* TODO: change the type of `len` so that we can remove this */
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:783:            // TODO: update when numpy will support 1-byte and
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:808:        /* TODO: This error (and most other) error handling needs cleaning. */
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:830:# TODO: These should be dynamically generated, too many mapped to int things,
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:248:    # TODO: support Fortran `len` function with optional kind parameter
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:504:        # TODO: Evaluate intent_flags here.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:23:# TODO: support logical constants (Op.BOOLEAN)
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:24:# TODO: support logical operators (.AND., ...)
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:25:# TODO: support defined operators (.MYOP., ...)
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:520:                # TODO: other kind not used
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:570:        # TODO: implement a method for deciding when __call__ should
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:811:            # TODO: determine correct kind
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:846:            # TODO: determine correct kind
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:896:            # TODO: denom kind not used
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:1108:            # TODO: find common divisor of coefficients
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/src/fortranobject.c:1358:  // TODO: detect the size of buf and make sure that size(buf) >= size(localbuf).
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:395:    # TODO: Clean up to prevent passing --overwrite-signature
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:494:    TODO: Test to ensure this has no effect without --latex-doc
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:638:    TODO: Document this in the help string
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:662:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:671:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:727:    # TODO: f2py2e should not call sys.exit() after printing the version
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:752:# TODO: These should be tested separately
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:759:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:767:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:775:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:783:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:791:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:799:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:807:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:815:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:823:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:831:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:839:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:847:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:855:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:863:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:871:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:879:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:887:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:895:    # TODO: populate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_docs.py:55:    # TODO: implement test methods for other example Fortran codes
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:448:    # TODO: Remove all this when scaninputline is replaced
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/_set_functions.py:15:# TODO in this implementation as this behavior may be reverted in np.unique().
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/__init__.py:98:Still TODO in this module are:
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/_creation_functions.py:69:        # to an object array. TODO: This won't handle large integers in lists.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_array_object.py:387:    TODO: Find and use appropriate __setitem__() case.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_data_type_functions.py:29:    # TODO: These will require https://github.com/numpy/numpy/issues/23883
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:436:        # TODO: we're stuck with disabling math formatting until we handle
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/random/tests/test_random.py:1062:    # TODO: Include test for randint once it can broadcast
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:688:    # TODO: Find some kind of fallback if there is no _CHECKPOINT_FOR_DOC in any of the modeling file.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:41:# TODO: This doesn't work for all packages (`bs4`, `faiss`, etc.) Talk to Sylvain to see how to do with it better.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:48:            # TODO: Once python 3.9 support is dropped, `importlib.metadata.packages_distributions()`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:71:                # TODO: remove once `importlib.metadata.packages_distributions()` is supported.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:401:    # TODO check if some bugs cause push backs on the exact version
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:578:        # TODO: more precise exception matching, if possible.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:602:        # TODO: more precise exception matching, if possible.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1048:        # TODO: Bump the requirement to 2.1.0 once released in https://github.com/ROCmSoftwarePlatform/flash-attention
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/attention_visualizer.py:188:            if "token_type_ids" in inputs:  # TODO inspect signature of update causal mask
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1803:                # TODO: Remove this check once configuration version is handled natively by Quark.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:93:# TODO: clean this for v5?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:530:# TODO cyril: Deprecated and should be removed in 4.51
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:197:    # TODO: add support for them as it should be quite easy to do so (small blocking issues).
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:389:    # TODO: infer shape without performing the computation, this might be quite hard.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:582:        # TODO: infer shape without performing the computation.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:1351:            # TODO: solves GraphModule creation.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:336:        # TODO: remove this hack when the legacy code that initializes generation_config from a model config is
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:1117:                    # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:371:        # TODO (Joao): this function might trigger XLA retracing as `cur_len` increases. Fix it if it becomes
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:428:        # TODO (joao): enable XLA on this logits processor. See discussion and attempts in
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:1942:        # TODO(Patrick): Make sure that official models have max_initial_timestamp_index set to 50
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:317:# TODO (joao): remove the equivalent classes and typing shortcuts below in v5
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:519:        # 8. Remove unexpected `generate` inputs (TODO @joao: fix trainer and examples)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:800:                # TODO (joao): remove output/input mismatch when these old models (xlnet, reformer) are deprecated
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1082:            # TODO (sanchit): move this exception to GenerationConfig.validate() when TF & FLAX are aligned with PT
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1088:        # TODO (joao): find a strategy to specify the order of the processors
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1353:        # TODO(joao): remove this function in v4.50, i.e. when we remove the inheritance of `GenerationMixin` from
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1428:            # TODO: A better way to handle this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1564:        # TODO (joao): per-model generation config classes.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1821:        # TODO(joao): support static caches in assisted generation. assisted generation needs to roll back caches,
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2135:            # TODO (joao): generalize this check with other types of inputs
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3331:                # TODO (joao): this OP throws "skipping cudagraphs due to ['incompatible ops']", find solution
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3386:        TODO: standardize cache formats and make all models compatible with `Cache`. It would remove the need
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3505:        # TODO (joao): This function should take an optional beam scorer function, to manipulate the scores after
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3669:        # TODO (joao): standardize special cases
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1627:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1911:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2254:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2789:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:537:        # TODO joao: find out a way of not depending on external fields (e.g. `assistant_model`), then make this a
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:54:# TODO: Move BatchFeature to be imported by both image_processing_utils and image_processing_utils
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:71:# TODO: (Amy) - factor out the common parts of this and the feature extractor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/image_utils.py:1325:        # TODO raise a warning here instead of simply logging?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1496:            # TODO Matt: This is a workaround for older versions of datasets that are missing the `cols_to_retain`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2025:        # TODO (joao): flagged for replacement (by `_v2_resized_token_embeddings`) due to embeddings refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2065:        # TODO (joao): flagged for delection due to embeddings refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2096:        # TODO (joao): flagged for replacement (by `_v2_resize_token_embeddings`) due to embeddings refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2133:            # TODO (joao): this one probably needs a v2 version with other models
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2156:        # TODO (joao): flagged for replacement (by `_v2_get_resized_lm_head_bias`) due to embeddings refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2283:        # TODO (joao): flagged for replacement (by `_v2_get_resized_embeddings`) due to embeddings refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2954:            # TODO Matt: This is a temporary workaround to allow weight renaming, but requires a method
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3335:    # TODO (joao): flagged for delection due to embeddings refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:197:        # TODO use valid to mask invalid areas due to padding in loss
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:210:        # TODO: randomness could apply a random seed, ex. rng = random.Random(random_seed)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/data/processors/squad.py:179:        encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:201:        # TODO: The default inputs only work for text models. We need to add support for vision/audio models.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:227:        # TODO: figure out dynamo support for instance method and switch this to instance method
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:261:        # TODO: figure out dynamo support for instance method and switch this to instance method
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:876:        # TODO clean this up at some point (probably by switching to fast tokenizers)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/audio_utils.py:381:# TODO This method does not support batching yet as we are mainly focused on inference.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:279:        # TODO: Remove the `query_length != 1` check once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/onnx/convert.py:141:            # TODO: Check when exporting QA we provide "is_pair=True"
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:516:        # TODO: should we set seq_length = 1 when self.use_past = True?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:702:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/tf_utils.py:70:    # TODO: When the issue linked above gets sorted, add a check on TF version here and use the original function if
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:271:    # TODO: @AjayP13, @younesbelkada replace this check with version check at the next `accelerate` release
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:1542:                # TODO Change dtypes back to M=FP32, Var = BF16, Kahan = False once they can be cast together in torchdistx.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:2865:            # TODO: in the future support only specific min PEFT versions
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:2959:                    # TODO: in the future support only specific min PEFT versions
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:3785:        # TODO: this needs to be fixed and made cleaner later.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/trainer.py:4561:                    # TODO: this needs to be fixed and made cleaner later.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:545:        # TODO this is fairly slow to improve!
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:1103:        # TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_string
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:213:    TODO(Patrick): Delete safety argument `_enable=True` at next major version. .
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1760:# TODO (joao): remove `GenerationMixin` inheritance in v4.50
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4065:            # TODO: we can relax this check when we support taking tp_plan from a json file, for example.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:160:        # TODO try and retrieve it in a nicer way from _sanitize_parameters.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:103:    # TODO: Update task_summary docs to include an example with document QA and then update the first sentence
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:379:            # TODO: check why slower `LayoutLMTokenizer` and `LayoutLMv2Tokenizer` don't have this key in outputs
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:467:        # TODO: A lot of this logic is specific to Donut and should probably be handled in the tokenizer
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1301:        # TODO hack by collating feature_extractor and image_processor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1344:        # TODO make the get_iterator work also for `tf` (and `flax`).
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1419:        # TODO hack by collating feature_extractor and image_processor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:103:    # TODO  Use a faster algorithm this can probably be done in O(n)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:969:    # TODO: we need to make `NO_IMAGE_PROCESSOR_TASKS` and `NO_FEATURE_EXTRACTOR_TASKS` more robust to avoid such issue.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:341:# TODO need to add the __repr__ that shows that it is a colwise parallel
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/sagemaker/training_args_sm.py:29:# TODO: should be moved to `utils` after refactoring of SageMakerTrainer
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:61:        # TODO: deprecate this function in favor of `cache_position`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:453:        # TODO: deprecate this function in favor of `cache_position`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:596:    # TODO (tmanlaibaatar) This won't be needed in torch 2.7.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1021:        # TODO: deprecate this function in favor of `cache_position`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1172:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1276:        # TODO: deprecate this function in favor of `cache_position`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1356:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1567:    # TODO(gante, sanchit-gandhi): move following functionality into `.generate`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1659:    # TODO (joao): dive deeper into gemma2 and paligemma -- there are reports of speed loss with compilation. Revert
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1663:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1806:        # TODO: deprecate this function in favor of `cache_position`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1865:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1866:    # TODO (joao): add layer_device_map arg and update code in `generate` accordingly
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2044:        # TODO(gante): Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2078:            # TODO(gante): Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2136:        # TODO(gante): Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2148:        # TODO(gante): Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2160:        # TODO(gante): Remove this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/training_args.py:223:# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/training_args.py:2162:        # those deprecated arguments are removed from TrainingArguments. (TODO: v5)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/image_transforms.py:791:# TODO (Amy): Accept 1/3/4 channel numpy array as input and return np.array as default
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:133:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:261:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:414:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:459:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1218:                # TODO: Remove once eetq releases a fix and this release is used in CI
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1506:    # TODO (if possible): Avoid exceptional cases
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/agents/agents.py:1094:                # TODO: observation naming could allow for different names of same type
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:269:            # TODO: When tracing with TorchDynamo with fullgraph=True, the model is recompiled depending on the input
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:297:                # TODO: maybe revisit this with https://github.com/pytorch/pytorch/pull/114823 in PyTorch 2.3.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:375:    # TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:66:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/helium/modeling_helium.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/shieldgemma2/processing_shieldgemma2.py:153:        # TODO(ryanmullins): Support images from PIL or URLs.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:274:    # TODO: maybe jit, otherwise move inside forward
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/pegasus/tokenization_pegasus.py:33:# TODO ArthurZ refactor this to only use the added_tokens_encoder
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/emu3/modeling_emu3.py:1234:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:279:        # TODO: remove the redundant computation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:394:        # TODO replace this with
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:467:        # TODO: This code is most likely not very efficient and should be improved
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2473:        # TODO (Joao): investigate why LED has numerical issues in XLA generate
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmo/modeling_olmo.py:311:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:188:            # TODO: figure this case out.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:287:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:317:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:251:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granite/modeling_granite.py:346:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:99:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:356:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:461:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:525:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:300:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:428:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:203:            # TODO: figure this case out.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:302:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/processing_grounding_dino.py:319:                    # TODO: @pavel, set labels to None since v4.51.0 or find a way to extract ids
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1582:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:26:# TODO Update this
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:364:# TODO: ^ interpret this
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:418:    # TODO: this file should be downloaded in a setup script
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:2007:# TODO Add information to the docstring about any methods that convert to PDB format, or otherwise prepare
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/tokenization_esm.py:65:        # TODO, all the tokens are added? But they are also part of the vocab... bit strange.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:330:        # `sqrt` in order to prevent NaNs during training in bfloat16. TODO a bit annoying
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:347:    # TODO refactor
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:709:        if use_cache and inputs_embeds.shape[1] != 1:  # TODO let's maybe only call in the `generate`?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:776:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->RECURRENTGEMMA,Llama->RecurrentGemma,llama->gemma
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:866:        # Soft-cap the logits TODO remove if always done.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:324:        # TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:971:        # TODO: deal with head_mask
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:1046:        # TODO: deal with head_mask
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:344:        # TODO check if the t5/llama PR also applies here
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:156:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:629:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:210:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:239:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:310:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:424:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:612:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:685:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:740:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:307:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:431:        # TODO: @yoni, change in v4.48 (use_fast set to True by default)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:496:        # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:262:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:270:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:608:        # TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1295:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py:504:                # TODO: Should we use the pre-trained projection as well ?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:669:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:487:        # TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:346:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:475:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:687:        # TODO Matt: What is going on here? Why is a non-trainable weight randomly initialized?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama_fast.py:244:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:117:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:268:# TODO: (Amy) Move to image_transforms
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:661:        # TODO: (Amy)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:618:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:747:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1577:        >>> # TODO: Add full pretraining example
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1594:        # TODO(PVP) - add pretraining logic and add to tests
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:338:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:562:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:573:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:622:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:679:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:700:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:203:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1709:        # TODO (joao):workaround until nested generation config is compatible with PreTrained Model
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bark/generation_configuration_bark.py:245:    # TODO (joao): nested from_dict
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:462:        # TODO: (amy) add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py:628:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:158:        # TODO ArthurZ fairseq_ids_to_tokens should be removed
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:423:        # TODO fix this
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:516:        # TODO find a better way of exposing other arguments
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1152:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:216:            # TODO: Support arbitrary patch sizes.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:931:                # TODO can we simplify this?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:1345:        # TODO (Qian): is it possible to revert the original cell if it is in the final answer?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:388:        self.t2u_variance_predictor_embed_dim = t2u_variance_predictor_embed_dim  # TODO: add to docstrings
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:389:        self.t2u_variance_predictor_hidden_dim = t2u_variance_predictor_hidden_dim  # TODO: add to docstrings
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:390:        self.t2u_variance_predictor_kernel_size = t2u_variance_predictor_kernel_size  # TODO: add to docstrings
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:391:        self.t2u_variance_pred_dropout = t2u_variance_pred_dropout  # TODO: add to docstrings
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:354:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:483:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/configuration_m2m_100.py:274:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:197:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:399:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:412:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:510:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:531:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:313:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere2/modeling_cohere2.py:78:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:504:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:461:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:664:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:793:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt2/configuration_gpt2.py:202:            # TODO: how to do that better?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:300:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:388:            # TODO add support for MLM
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:572:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:170:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:637:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:839:            # TODO(PVP): need to verify if below code is correct
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/byt5/tokenization_byt5.py:97:            additional_special_tokens=additional_special_tokens,  # TODO extra ids are not used :sweatywmile:
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:414:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:506:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1446:        # TODO: As is this currently fails with saved_model=True, because
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bridgetower/configuration_bridgetower.py:279:        # TODO: remove this once the Hub files are updated.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:287:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:504:    _supports_static_cache = False  # TODO: needs a HybridCache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:330:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:458:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:63:# TODO: Update before the merge
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1263:    _supports_static_cache = False  # TODO: @raushan more involved due to local/global attn
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:2227:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:696:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:390:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:595:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:817:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:936:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1830:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py:248:        # TODO: @raushan update config in the hub
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:216:            # TODO: Support arbitrary patch sizes.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:129:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:232:        # TODO support align_corners=True in image_transforms.resize
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:457:        # TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:307:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:414:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:651:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:176:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:230:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:337:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmo2/modeling_olmo2.py:312:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:73:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:96:# TODO(joao): add me back asap :)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:149:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: this may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:280:    # TODO(joao): add me back asap :)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:374:# TODO(joao): add me back asap :)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:385:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:437:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim].
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:511:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:593:# TODO(joao): add me back asap :)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:124:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:313:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:324:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:371:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:428:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:450:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:1010:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->NEMOTRON,Llama->Nemotron,llama->nemotron
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/ijepa/modeling_ijepa.py:585:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:140:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:266:        # TODO (raushan): remove in v4.46 (RoPE is computed in the model, not in the decoder layers)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:472:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:511:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1024:        # TODO: As of torch==2.2.0, the `attention_mask` passed to the model in `generate` is 2D and of dynamic length even when the static
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:306:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:258:        # TODO check if the t5/llama PR also applies here
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:342:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:434:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:51:# TODO @ArthurZucker bring copied from back
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:262:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:303:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:305:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:413:        # TODO find a better way of exposing other arguments
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:287:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:391:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:496:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:352:    # TODO add a deprecation cycle as this can have different behaviour from our API
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:188:            # TODO: figure this case out.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:287:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:297:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:426:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py:213:                # TODO: Check if this is needed, as it ensures that decode(encode(doc)) != doc by adding extra whitespace in the decoded document
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:131:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:630:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:749:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:941:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1707:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py:237:        # TODO: @raushan update config in the hub
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:594:        # TODO: We should check if the opset_version being used to export
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1967:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py:103:    # TODO: make it with torch instead of numpy
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gptj/configuration_gptj.py:148:            # TODO: how to do that better?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deit/modeling_deit.py:595:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:34:# TODO this class is useless. This is the most standard sentencpiece model. Let's find which one is closest and nuke this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:353:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:82:        # TODO maybe make it torch compatible later on. We can also just slice
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:112:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:863:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:874:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:168:        # TODO(enijkamp): factor out number of logical TPU-v4 cores or make forward pass agnostic
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/codegen/configuration_codegen.py:159:            # TODO: how to do that better?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:345:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1672:        # TODO: Implement `WhisperTimeStampLogitsProcessor`.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:366:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:423:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:491:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1005:                    # TODO Handle when language is different from the previous
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:93:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:762:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1436:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:251:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:208:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:243:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/vit/modeling_vit.py:604:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py:2349:            # TODO (joao, raushan): refactor `generate` to avoid these operations with VLMs
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:348:# TODO: Implement attention with SDPA for PLBart.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:375:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:638:            # TODO(PVP): need to verify if below code is correct
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:210:            # TODO: figure this case out.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:309:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:422:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:292:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:323:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:194:        # TODO decode outputs do not match between fast and slow
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1289:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:263:# TODO: (Amy) Move to image_transforms
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:660:        # TODO: (Amy)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:607:        # TODO: Check fp32 layer norm possiblity
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:454:        # TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:49:# TODO: Replace all occurrences of the checkpoint with the final one
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:242:        # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:545:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:754:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:1012:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:2202:        # TODO: we have no attention_mask so this won't work, check if we really won't need attention mask and find another way
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:265:            TODO: add aspect_ratio_ids and aspect_ratio_mask and cross_attention_mask
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:537:        # TODO Come up with footnote formatting inside a table
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:661:        # TODO: (Amy)
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:659:        # TODO: remove the redundant computation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:774:        # TODO replace this with
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1031:        # TODO: This code is most likely not very efficient and should be improved
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:394:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:593:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:604:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:648:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:705:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:726:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1415:        # TODO (Joao): investigate why Speech2Text has numerical issues in XLA generate
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:317:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:40:# TODO(PVP) - this should be removed in Transformers v5
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:38:# TODO(PVP) - this should be removed in Transformers v5
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1942:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:188:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:404:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:448:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:522:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:865:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaModel with Llama->Olmoe
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:58:# TODO: Could have better fused kernels depending on scaling, dropout and head mask.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:284:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:521:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:636:# TODO - (Amy) make compatible with other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:659:# TODO - (Amy) make compatible with other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1039:    # TODO (Amy) - update to use `rescale_factor` instead of `scale`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1500:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:475:        # TODO find a better way of exposing other arguments
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:495:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:624:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:601:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:730:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1560:        >>> # TODO: Add full pretraining example
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1597:        # TODO(PVP) - add negative sampling & loss computation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:400:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:411:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:450:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:508:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:530:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:783:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1261:                # TODO(ls): Add cross attention values to respective lists
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1434:                # TODO(ls): Add cross attention values to respective lists
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:2127:        # TODO: As is this currently fails with saved_model=True, because
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:451:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:543:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:107:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:1247:            # TODO(SS): do we need to ignore pad tokens in labels?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:188:            # TODO: figure this case out.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:288:            # TODO: test this.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bloom/configuration_bloom.py:156:            # TODO: how to do that better?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:64:    TODO @thomasw21 this doesn't work as nicely due to the masking strategy, and so masking varies slightly.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bloom/tokenization_bloom_fast.py:113:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/starcoder2/modeling_starcoder2.py:305:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/perceiver/tokenization_perceiver.py:182:    # TODO @ArthurZ refactor this as well....
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:193:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:523:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:534:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:573:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:631:# TODO cyril: modular
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:653:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:153:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:502:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/cohere/modeling_cohere.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:505:            # TODO(Patrick): if we train more RAG models, I want to put the input first to take advantage of effortless truncation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:506:            # TODO(piktus): better handling of truncation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:415:            # TODO: make sure we are using `FacebookAI/xlm-mlm-enro-1024`, since XLM-100 doesn't have this step
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:431:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:331:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:385:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:458:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:579:        # TODO refer to https://github.com/ArthurZucker/transformers/blob/0f0a3fe5ca5697ee58faeb5b53f049af720b5e98/src/transformers/models/vit_mae/modeling_vit_mae.py#L871
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:120:        # TODO Remove this logic in a subsequent release since subsequences are not supported.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:353:        self.max_position_embeddings = 16384  # TODO Can't derive this from model files: where to set it?
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:375:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:445:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:526:            qlen: TODO Lysandre didn't fill
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:527:            mlen: TODO Lysandre didn't fill
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:526:        # TODO find a better way of exposing other arguments
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1123:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1525:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1527:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:489:        # TODO find a better way of exposing other arguments
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:272:        # Tokenizer arguments TODO: eventually tokenizer and models should share the same config
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:396:            # TODO (joao): this should be an exception if the user has modified the loaded config. See #33886
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:62:                # TODO: Update message once eetq releases a fix
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:317:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_awq.py:125:            model._awq_is_fused = True  # TODO: consider storing this flag in model.config instead
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:274:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./api/pipeline/.venv/lib/python3.12/site-packages/cryptography/hazmat/primitives/asymmetric/rsa.py:221:    # TODO: Replace with lcm(p - 1, q - 1) once the minimum
./api/pipeline/.venv/lib/python3.12/site-packages/cryptography/x509/name.py:357:        # TODO: this is relatively expensive, if this looks like a bottleneck
./api/pipeline/.venv/lib/python3.12/site-packages/mdurl/_parse.py:168:            # v0.12 TODO(isaacs): This is not quite how Chrome does things.
./api/pipeline/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:3216:                        # TODO: Something is odd here. I don't see why packet["info"] can't be None.
./api/pipeline/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:4674:            # TODO: this type error is a true error:
./api/pipeline/.venv/lib/python3.12/site-packages/paho/mqtt/matcher.py:47:            # TODO
./api/pipeline/.venv/lib/python3.12/site-packages/aioredis/lock.py:235:        # TODO: this can be simplified when the context manager is finished
./api/pipeline/.venv/lib/python3.12/site-packages/aioredis/connection.py:227:    TODO: We're currently passing through two buffers,
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/video_manager.py:311:        # TODO(v0.7): Add DeprecationWarning that this class will be removed in v0.8: 'VideoManager
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/video_manager.py:574:        # TODO: Seeking only works for the first (or current) video in the VideoManager.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/video_manager.py:578:            # TODO: This should throw an exception instead of potentially failing silently
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:30:# TODO: Replace below imports with `ty.` prefix.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:84:# TODO(v1.0): Relax restriction on metric types only being float or int when loading from disk
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:124:    # TODO(v1.0): Change frame_number to a FrameTimecode now that it is just a hash and will
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:185:        # TODO(v0.7): Replace with DeprecationWarning that `base_timecode` will be removed in v0.8.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:228:    # TODO(v1.0): Create a replacement for a calculation cache that functions like load_from_csv
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:249:        # TODO: Make this an error, then make load_from_csv() a no-op, and finally, remove it.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/stats_manager.py:307:    # TODO: Get rid of these functions and simplify the implementation of this class.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:122:# TODO: This value can and should be tuned for performance improvements as much as possible,
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:200:    # TODO(v0.7): Use the warnings module to turn this into a warning.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:221:# TODO(#463): Move post-processing functionality into separate submodule.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:420:    # TODO: Combine this resize with the ones below.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:641:        # TODO: Validate that encoder_param is within the proper range.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:672:        # TODO(v1.0): Split up into multiple sub-expressions so auto-formatter works correctly.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:785:    # TODO(v0.7): Add DeprecationWarning that `video_manager` will be removed in v0.8.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:795:    # TODO: Validate that encoder_param is within the proper range.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:836:    # TODO(v1.0): Split up into multiple sub-expressions so auto-formatter works correctly.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:885:                # TODO: Add extension to template.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:886:                # TODO: Allow NUM to be a valid suffix in addition to NUMBER.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:899:                # TODO: Combine this resize with the ones below.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:969:        # TODO(v1.0): This class should own a StatsManager instead of taking an optional one.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:973:        # TODO(v1.0): This class should own a VideoStream as well, instead of passing one
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1140:        # TODO(v0.7): Replace with DeprecationWarning that `base_timecode` will be removed in v0.8.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1181:        # TODO(#283): This breaks with AdaptiveDetector as cuts differ from the frame number
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1254:        # TODO(v0.7): Add DeprecationWarning that `frame_source` will be removed in v0.8.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1257:        # TODO(v0.8): Remove default value for `video` after `frame_source` is removed.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1264:        # TODO: These checks should be handled by the FrameTimecode constructor.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1299:        # TODO: Figure out a better solution for communicating framerate to StatsManager.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1382:                # TODO(v1.0): This optimization should be removed as it is an uncommon use case and
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1493:        # TODO(v0.7): Use the warnings module to turn this into a warning.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_manager.py:1515:        # TODO(v0.7): Use the warnings module to turn this into a warning.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/context.py:183:        # TODO(v1.0): Make the stats value optional (e.g. allow -s only), and allow use of
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/context.py:364:        # TODO(v0.7): Remove these branches when removing -d/--min-delta-hsv.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/context.py:428:        # TODO(v1.0): add_last_scene cannot be disabled right now.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/__init__.py:370:    # TODO: Other commands still seem to run if this is specified.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:276:    # TODO: This should be part of the FrameTimecode object itself.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:320:    # TODO: Need to handle other video formats!
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:321:    VIDEO_FORMAT_TODO_HANDLE_OTHERS = "FFVideoFormat1080p24"
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:325:    ElementTree.SubElement(resources, "format", id="format1", name=VIDEO_FORMAT_TODO_HANDLE_OTHERS)
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:329:    # TODO: We should calculate duration from the scene list.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:331:    duration = str(duration.get_seconds()) + "s"  # TODO: Is float okay here?
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:341:        hasAudio="1",  # TODO: Handle case of no audio.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:350:    )  # TODO: Allow customizing project name.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:429:        # TODO: Are these supposed to be frame numbers or another format?
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:438:        # TODO: Can we just use path.as_uri() here?
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/commands.py:504:    # TODO(#497): Allow exporting without an audio track.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/config.py:328:# TODO(v0.7): Remove [detect-adaptive] min-delta-hsv
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/_cli/controller.py:123:    # TODO(#380): Ensure this does not erroneusly fire.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/pyav.py:32:    # TODO: Investigate adding an accurate_duration option to backends to calculate the duration
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/pyav.py:73:        # TODO(#258): See what self._container.discard_corrupt = True does with corrupt videos.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/pyav.py:125:            # TODO: Refactor FrameTimecode to support raw timing rather than framerate based calculations.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/moviepy.py:51:        # TODO: Investigate how MoviePy handles ffmpeg not being on PATH.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/moviepy.py:52:        # TODO: Add framerate override.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/moviepy.py:59:        # TODO: Need to map errors based on the strings, since several failure
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/moviepy.py:117:        # TODO: Use cached_property once Python 3.7 support is deprecated.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/moviepy.py:190:            # TODO(#380): Other backends do not currently throw an exception if attempting to seek
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/opencv.py:86:        # TODO(v0.7): Replace with DeprecationWarning that `path_or_device` will be removed in v0.8.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/opencv.py:159:            # TODO: This excludes any suffix after the sequence identifier.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/opencv.py:356:# TODO(#168): Support non-monotonic timing for `position`. VFR timecode support is a
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/__init__.py:79:# TODO(v1.0): Consider removing and making this a namespace package so that additional backends can
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/__init__.py:83:# TODO: Future VideoStream implementations under consideration:
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/backends/__init__.py:101:# TODO: Lazy-loading backends would improve startup performance. However, this requires removing
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:107:        # TODO(v1.0): Make these actual @properties.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:139:    # TODO(v1.0): Add a `frame` property to replace the existing one and deprecate this getter.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:154:    # TODO(v1.0): Add a `framerate` property to replace the existing one and deprecate this getter.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:175:    # TODO(v1.0): Add a `seconds` property to replace this and deprecate the existing one.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:187:    # TODO(v1.0): Add a `timecode` property to replace this and deprecate the existing one.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:223:    # TODO(v1.0): Add a `previous` property to replace the existing one and deprecate this getter.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/frame_timecode.py:464:    # TODO(v1.0): __int__ and __float__ should be removed. Mark as deprecated, and indicate
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_detector.py:35:# TODO(v0.7): Add a new base class called just "Detector" to eventually replace SceneDetector.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_detector.py:54:    # TODO(v0.7): Make this a proper abstract base class.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_detector.py:60:    # TODO(v1.0): Remove - this is a rarely used case for what is now a neglegible performance gain.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/scene_detector.py:135:# TODO(v0.7): Remove this early, no point in keeping it around.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/platform.py:78:# TODO: Move this into scene_manager.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/histogram_detector.py:87:            # TODO: We can have EMA of histograms to make it more robust
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/content_detector.py:40:    # TODO: This equation is based on manual estimation from a few videos.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/content_detector.py:55:    # TODO: Come up with some good weights for a new default if there is one that can pass
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/content_detector.py:151:        # TODO: Add option to enable motion estimation before calculating score components.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/content_detector.py:152:        # TODO: Investigate methods of performing cheaper alternatives, e.g. shifting or resizing
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/content_detector.py:225:        # TODO: Add config file entries for sigma, aperture/kernel size, etc.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/adaptive_detector.py:71:        # TODO(v0.7): Replace with DeprecationWarning that `video_manager` and `min_delta_hsv` will
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/adaptive_detector.py:89:        # TODO: Turn these options into properties.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/adaptive_detector.py:131:        # TODO(#283): Merge this with ContentDetector and turn it on by default.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/adaptive_detector.py:173:        # TODO(v0.7): Add DeprecationWarning that `get_content_val` will be removed in v0.7.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/detectors/threshold_detector.py:70:        # TODO(v0.7): Replace with DeprecationWarning that `block_size` will be removed in v0.8.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/video_splitter.py:233:        # TODO: Capture stdout/stderr and show that if the command fails.
./api/pipeline/.venv/lib/python3.12/site-packages/scenedetect/video_splitter.py:367:                # TODO: Capture stdout/stderr and display it on any failed calls.
./api/pipeline/.venv/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py:26:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/markdown_it/parser_inline.py:96:            # TODO: remove this workaround when CM standard will allow nested links
./api/pipeline/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:26:        self.debug = debug  # TODO: We ought to handle 404 cases if debug is set.
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/numpy_pickle_utils.py:237:    TODO python2_drop: is it still needed? The docstring mentions python 2.6
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/pool.py:49:    TODO python2_drop : can this be simplified ?
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/memory.py:44:# TODO: The following object should have a data store object as a sub
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/memory.py:53:# TODO: Same remark for the logger, and probably use the Python logging
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/memory.py:583:            # TODO (pierreglaser): do the same with get_func_name?
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/_store_backends.py:209:                        # TODO(1.5) turn into error
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/_memmapping_reducer.py:164:        # TODO: check scipy sparse datastructure if scipy is installed
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/parallel.py:2054:            # TODO: this iterator should be batch_size * n_jobs
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/test/common.py:18:# TODO straight removal since in joblib.test.common?
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/test/common.py:44:# TODO: Turn this back on after refactoring yield based tests in test_hashing
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:146:    # TODO: test that the cache related to the function cache persists across
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:170:            # TODO when Python 3.11 is the minimum supported version, use
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/compressor.py:235:    TODO python2_drop: is it still needed since we dropped Python 2 support A
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/externals/cloudpickle/cloudpickle.py:1342:        # TODO: decorrelate reducer_override (which is tied to CPython's
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/externals/loky/_base.py:20:# TODO investigate why using `concurrent.futures.Future` directly does not
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py:11:# TODO: investigate which Python version is required to be able to use
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/func_inspect.py:168:        # TODO: Maybe add a warning here?
./api/pipeline/.venv/lib/python3.12/site-packages/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./api/pipeline/.venv/lib/python3.12/site-packages/boto3/resources/factory.py:586:                    # TODO: Make this configurable in the future?
./api/pipeline/.venv/lib/python3.12/site-packages/boto3/resources/response.py:151:        # TODO: Remove the '$' check after JMESPath supports it
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/rrule.py:1182:                    # TODO: Check -numweeks for next year.
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:55:# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:265:                ("Tue", "Tuesday"),     # TODO: "Tues"
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:267:                ("Thu", "Thursday"),    # TODO: "Thurs"
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:272:              ("Feb", "February"),      # TODO: "Febr"
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:291:    # TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:777:                                # TODO: not hit in tests
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:815:                    # TODO: check that l[i + 1] is integer?
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:823:                        min_offset = int(l[i + 3])  # TODO: Check that l[i+3] is minute-like?
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:910:                # TODO: Check if res attributes already set.
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:934:                # TODO: checking that hour/minute/second are not
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:941:            value = self._to_decimal(tokens[idx + 2])  # TODO: try/except for this?
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1032:            # TODO: Are we sure this is the right condition here?
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1100:        # TODO: Every usage of this function sets res.second to the return
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1112:        # TODO: Is this going to admit a lot of false-positives for when we
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:25:    except IOError as e:  # TODO  switch to FileNotFoundError?
./api/pipeline/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:76:# TODO: Remove after deprecation period.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:839:            # TODO: What could we test if loss.approx_hessian?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:874:                # TODO: What could we test if loss.approx_hessian?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_plotting.py:167:        # TODO(1.9): Remove deprecated **kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:258:    # TODO: test with intercept
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:259:    # TODO: test with multiple responses
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:789:            TODO(1.8): remove return value
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:831:    # TODO(1.8): remove generate_only
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:1117:        # TODO There are a few errors in SearchCV with array-api-strict because
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3454:    # TODO: find out why PLS and CCA fail. RANSAC is random
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3795:        # TODO(devtools): this should be a separate check.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3827:                    # TODO(devtools): separately check that the constructor doesn't
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:499:# TODO(devtools): allow third-party developers to pass test specific params to checks
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:501:    # TODO(devtools): check that function names here exist in checks for the estimator
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:565:    # TODO(1.9) simplify when averaged_inverted_cdf is the default
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:604:            # TODO: dual=True is a stochastic solver: we cannot rely on
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:824:    # TODO(devtools): enable this behavior for third party estimators as well
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:853:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:862:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:871:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:880:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:893:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:902:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:941:        # TODO: investigate failure see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:950:        # TODO: investigate failure see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:983:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:992:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1001:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1015:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1027:        # TODO: replace by a statistical test when _dual=True, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1039:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1048:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1057:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1067:        # TODO: fix sample_weight handling of this estimator when probability=False
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1068:        # TODO: replace by a statistical test when probability=True
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1081:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1095:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1104:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1126:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1135:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1148:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1157:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1179:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1188:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1197:        # TODO: replace by a statistical test, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1229:        # TODO: fix sample_weight handling of this estimator when probability=False
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1230:        # TODO: replace by a statistical test when probability=True
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1240:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1258:# TODO: remove when scipy min version >= 1.11
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1285:        # TODO: remove when scipy min version >= 1.16
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:35:# TODO: We can consider removing the containers and importing
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:58:# TODO: Remove when SciPy 1.11 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:71:# TODO: Remove when Scipy 1.12 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:84:# TODO : remove this when required minimum version of scipy >= 1.9.0
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:116:# TODO: Fuse the modern implementations of _sparse_min_max and _sparse_nan_min_max
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:224:# TODO: Adapt when Pandas > 2.2 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:238:# TODO: remove when SciPy 1.12 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:285:# TODO: remove when SciPy 1.12 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:355:# TODO: Remove when Scipy 1.12 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:200:    # TODO(1.9) remove UserList when the force_int_remainder_cols param
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:315:        # TODO: we should probably use _is_pandas_df_or_series(X) instead but:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:372:            # TODO(1.3): check if the warning is still raised or remove the filter.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:22:# TODO: complete __all__
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:572:    # TODO: Update to use `__array_namespace__info__()` from array-api v2023.12
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:673:    # TODO: Remove this once https://github.com/scipy/scipy/issues/21736 is fixed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:682:    # TODO: refactor once nan-aware reductions are standardized:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:702:    # TODO: refactor once nan-aware reductions are standardized:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:722:    # TODO: refactor once nan-aware reductions are standardized:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:850:    # TODO: once sufficiently adopted, we might want to instead rely on the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:986:    # TODO: update if bincount is ever adopted in a future version of the standard:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_testing.py:1373:        # TODO: remove when pyamg > 5.0.1
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/optimize.py:95:        # TODO: It seems that the new check for the sum of absolute gradients above
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:654:    # TODO: Remove when the minimum version of SciPy supported is 1.12
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2408:        # TODO: remove the pandas-specific branch once the minimum supported
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_extmath.py:226:    # more accurate but slow (TODO find realistic settings here)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_plotting.py:217:# TODO(1.9) : Remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:24:# TODO: add this estimator into the _mocking module in a further refactoring
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:2338:# TODO(1.8): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:40:# TODO(1.8): Update when implementing __sklearn_tags__ is required
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:92:# TODO(1.8): Update this test to check for errors
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_array_api.py:297:# TODO: add cupy to the list of libraries once the following upstream issue
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:127:# TODO(1.8): remove force_all_finite and change the default value of ensure_all_finite
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:251:# TODO(1.8): Remove this function
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:327:        # TODO(1.8): turn the warning into an error
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/stats.py:116:# TODO: refactor to do the symmetrisation inside _weighted_percentile to avoid
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:292:        # TODO(1.9): remove and switch to quantile_method="averaged_inverted_cdf"
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:360:                    # TODO: make _weighted_percentile and
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2351:        # TODO: This should be refactored because binarize also calls
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:480:    ## TODO: change to averaged inverted cdf, but that means we only get bin
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:519:    # TODO this check is redundant with common checks and can be removed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:957:        # TODO: Remove this condition, once scipy 1.10 is the minimum version.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1120:            # TODO: Remove this conditional error when the minimum supported version of
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1144:            # TODO: Remove ones scipy 1.10 is the minimum version. See comments above.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:108:    # TODO: Use loss.fit_intercept_only where appropriate instead of
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:257:            # TODO: Multiply here by learning rate instead of everywhere else.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:449:        # TODO: Without oob, i.e. with self.subsample = 1.0, we could call
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:672:        y = column_or_1d(y, warn=True)  # TODO: Is this still required?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_base.py:23:    # TODO(SLEP6): remove if-condition for unrouted sample_weight when metadata
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:116:    # TODO: (slep6) remove if condition for unrouted sample_weight when metadata
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:155:        # TODO(SLEP6): remove if condition for unrouted sample_weight when metadata
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py:140:        # TODO: consider always using platform agnostic dtypes for fitted
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:15:# TODO(1.8) remove the filterwarnings decorator
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:107:        # TODO: We are not entirely satisfied with this lax comparison, but the root
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:125:# TODO(1.8) remove the filterwarnings decorator
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:202:# TODO(1.8) remove the filterwarnings decorator
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:90:    # TODO: Ideally this should be computed in parallel over the leaves using something
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:125:    TODO: in the future, we could explore the possibility to extend the scorer
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:572:            # TODO: remove when PDP supports sample weights
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:682:                # TODO: incorporate sample_weight in sampling here, as well as
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1086:        # TODO: incorporate sample_weights here in `resample`
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:2225:        # TODO: This could be done in parallel
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py:327:        # TODO: complexity is O(n_categorical_features * 255). Maybe this is
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:490:    # TODO(1.8): remove "algorithm" entry
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:745:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:1129:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_weight_boosting.py:635:# TODO(1.8): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/isotonic.py:164:        # TODO: remove this branch when Scipy 1.12 is the minimum supported version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:655:                # TODO: incorporate sample_weight in sampling here.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neural_network/_base.py:211:    # TODO: Decide what to do with the term `xlogy(y_true, y_true) - y_true`. For now,
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:330:            # TODO: systematize this mapping of metric for
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:338:                # TODO: Implement efficient multi-output solution
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:363:                    # TODO: adapt the heuristic for `strategy="auto"` for
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:36:# TODO: implement a brute force version for testing purposes
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:37:# TODO: create a density estimation base class?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:330:        # TODO: implement sampling for other valid kernel shapes
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:378:        # TODO: also test radius_neighbors, but requires different assertion
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1623:# TODO: remove when NearestNeighbors methods uses parameter validation mechanism
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1727:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2253:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2488:    # TODO: if score is refactored to evaluate models for other scoring
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_lof.py:252:    # TODO: compare results on dense and sparse data as proposed in:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/calibration.py:329:            # TODO(1.8): Remove this code branch and cv='prefit'
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/calibration.py:863:        # TODO: Remove casting to np.float64 when minimum supported SciPy is 1.11.2
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:658:    # TODO(1.9): Remove base_estimator
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:676:    # TODO(1.8): This is a temporary getter method to validate input wrt deprecation.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:791:            # TODO: remove this condition check when the minimum supported scipy version
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1037:    # TODO(1.9): Remove base_estimator from __init__
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:372:        # TODO: for Scipy <= 1.10, `isspmatrix(X)` returns `True` for sparse arrays.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:1060:# TODO this class should fit on either p-values or scores,
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:225:    # TODO(1.8) remove this property
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:791:    # TODO(1.8): remove `groups` from the signature after deprecation cycle.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:377:                # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:461:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_optics.py:621:    # TODO: handle working_memory somehow?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:772:                # TODO: Support np.nan in Cython implementation for precomputed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:834:                # TODO: Benchmark KD vs Ball Tree efficiency
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:938:                # TODO: Implement weighted argmin PWD backend
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_birch.py:245:# TODO(1.8): Remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:30:# TODO: AffinityPropagation must preserve dtype for its fitted attributes
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:114:    # TODO: we should handle missing values (i.e. `np.nan`) specifically and store them
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:716:            # TODO(1.9): raise a ValueError instead.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:682:    # TODO: extend to HistGradientBoosting once sample_weight is supported
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:705:    # TODO: remove/fix when PDP supports HGBT with sample weights
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:510:    # TODO(1.8): Remove this attribute
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:583:    # TODO(1.8): Remove this attribute
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:659:    # TODO(1.8): Remove this attribute
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1012:    # TODO(1.8): Remove this attribute
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1062:    # TODO(1.8): Remove this attribute
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1202:    # TODO(1.8): Remove this check
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1242:    # TODO(1.8): Remove this check
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1284:    # TODO(1.8): Remove this check
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/base.py:1309:    # TODO(1.8): Remove this check
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:551:    # TODO We can do this cheaper; sorted_indices copies the whole matrix.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:570:        # TODO: simplify interfaces and implementations in _svmlight_format_fast.pyx.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_arff_parser.py:67:    # TODO: improve for efficiency
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:341:        # TODO: feature request OpenML.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:640:        # TODO (1.8): remove this once the deprecation is removed. In the meantime,
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:654:            # TODO (1.8): remove this once the deprecation is removed to keep only
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:663:            # TODO (1.8): remove this once the deprecation is removed to keep only
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:684:                # TODO (1.8): remove this `if` branch once the following issue is
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:468:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:571:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:13:    # TODO: remove this check once the estimator is no longer experimental.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:19:# TODO: remove this check once the estimator is no longer experimental.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:413:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:429:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:459:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:495:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1550:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1761:        # TODO(1.8): Remove the condition and still call getattr(imputer, method)(X)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1259:        TODO: Remove when ``set_config(enable_metadata_routing=False)`` is no
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/compose/tests/test_column_transformer.py:975:# TODO(1.9): remove this test
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:50:    TODO(1.8): remove this context manager and replace with check_is_fitted.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:406:    # TODO(1.8): Remove this property
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:780:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:896:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:943:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:981:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1027:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1082:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1127:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1178:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1902:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1951:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:2024:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:446:                # TODO: tree shouldn't need this in this case
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:624:                # TODO: the tree shouldn't need this param
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:170:        # TODO(slep006): remove when metadata routing is the only way
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:239:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:251:        # TODO(slep006): remove when metadata routing is the only way
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:296:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:456:                # TODO (1.8): scoring="max_error" has been deprecated in 1.6,
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:498:        # TODO(slep006): remove when metadata routing is the only way
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:738:# TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2200:    # TODO(1.9): When `raise_warning` is removed, the following changes need to be made:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_supervised.py:1256:    # TODO(1.9): remove the sparse parameter
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/tests/test_supervised.py:515:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:398:    TODO: use a float64 accumulator in row_norms to avoid the latter.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1972:        # TODO: do it also for other norms.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:80:            # TODO: implement a stable simultaneous_sort.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:128:                # TODO: support CSR matrices without non-zeros elements
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:131:                # TODO: support CSR matrices with int64 indices and indptr
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:476:            # TODO: implement Euclidean specialization using GEMM.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:644:            # TODO: implement Euclidean specialization using GEMM.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1398:    # TODO: remove when enable_metadata_routing is deprecated
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1656:# TODO(1.8): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_classification.py:762:# TODO(1.9): remove test
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:366:# TODO: Handle multi_class metrics that has a labels argument as well as a
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:975:            # TODO those metrics doesn't support string label yet
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:179:        # TODO Fix manhattan_distances to preserve dtype.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:190:        # TODO Fix manhattan_distances to preserve dtype.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:1672:# TODO(1.8): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:709:    # TODO: support CSR matrices without non-zeros elements
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:716:    # TODO: support CSR matrices with int64 indices and indptr
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:913:    # TODO: introduce assertions on UserWarnings once the Euclidean specialisation
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:80:            # TODO: Inspect slight numerical discrepancy
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:164:            # TODO: Inspect slight numerical discrepancy
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/roc_curve.py:581:        # TODO(1.9): remove after the end of the deprecation period of `y_pred`
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:325:# TODO(1.9): Remove in 1.9
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:334:# TODO(1.9): Remove in 1.9
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:926:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:939:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_common_curve_display.py:167:# TODO: remove this test once classes moved to using `name` instead of
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:229:        # TODO: if alpha=0 check that X is not rank deficient
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:401:        # TODO: Adapt link to User Guide in the docstring, once
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:405:        # TODO: make D^2 a score function in module metrics (and thereby get
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:398:            # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:47:# TODO: bayesian_ridge_regression and bayesian_regression_ard
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:154:        Always an array of ones. TODO: refactor the code base to make it
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:205:# TODO: _rescale_data should be factored into _preprocess_data.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:832:            # TODO: instead of warning and recomputing, we could just center
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:16:    # TODO: This "sandwich product" is the main computational bottleneck for solvers
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1251:        # TODO(1.8) remove multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1362:        # TODO: Refactor this to avoid joblib parallelism entirely when doing binary
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1923:        # TODO(1.8) remove multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:813:        # TODO: better names for these variables: z
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:870:                # TODO: this could be updated
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:882:                # Cov_n = Cov_j + x_j * X + increment(betas) TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:888:                # TODO: this could be updated
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1685:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1714:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1732:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1750:# TODO(1.9): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_theil_sen.py:298:# TODO(1.8): Remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_common.py:66:        # TODO: FIx SAGA which fails badly with sample_weights.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:150:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:202:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:254:# TODO(1.8): remove whole test with deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:279:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:619:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:705:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1306:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1350:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1486:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1746:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1794:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1833:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1963:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2137:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2182:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2360:# TODO(1.8): remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2427:# TODO(1.8): check for an error instead
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_sag.py:490:    # TODO: uncomment when sparse Ridge with intercept will be fixed (#4710)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:29:# TODO: use another dataset that has multiple drops
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:120:# TODO: remove warning filter when numpy min version >= 2.0.0
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:132:# TODO: remove warning filter when numpy min version >= 2.0.0
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1500:        # TODO(1.9): remove "warn" and None options.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1607:        # TODO(1.9): remove n_alphas and alphas={"warn", None}; set alphas=100 by
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_omp.py:1065:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:164:        # TODO(1.8) remove None option
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:166:        # TODO(1.8) remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:195:        # TODO(1.8) remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:206:        # TODO(1.8): remove and only keep clone(self.estimator)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:217:        # TODO(1.8) remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:622:        # TODO(1.8): remove the condition check together with base_estimator
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/tests/test_self_training.py:349:# TODO(1.8): remove in 1.8
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:60:    # TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:86:# TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:364:                # TODO(SLEP6): also pass metadata to the predict method for
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1182:                # TODO(SLEP6): also pass metadata for the predict method.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1637:                # TODO(SLEP6): also pass metadata to the predict method for
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1982:                # TODO(SLEP6): also pass metadata to the predict method for
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:480:    # TODO(1.8) remove this property
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:862:        # TODO(slep006): remove when metadata routing is the only way
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:46:    # TODO: remove this check once the estimator is no longer experimental.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:90:# TODO: remove this check once the estimator is no longer experimental.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_validation.py:2471:# TODO(1.8): remove `learning_curve`, `validation_curve` and `permutation_test_score`.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:1117:    # Test the IID parameter  TODO: Clearly this test does something else???
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:192:# TODO(1.9): change default `n_init` to 1, see PR #31117
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:430:# TODO(1.9): change default `n_init` to 1, see PR #31117
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:341:    # TODO: compare results on dense and sparse data as proposed in:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:1068:        # TODO: re-enable this test if/when `manhattan_distances` is refactored to
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:122:# TODO(1.9): remove warning filter
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:136:# TODO(1.9): remove warning filter
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:175:# TODO(1.9): remove warning filter
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:202:# TODO(1.9): remove warning filter
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:225:# TODO(1.9): delete this test
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:48:    # TODO: rewrite this test to make less sensitive to the random seed,
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:121:    # TODO check that it actually does something useful
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_spectral_embedding.py:107:# TODO: investigate why this test is seed-sensitive on 32-bit Python
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:148:    # TODO check that it actually does something useful
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:234:    # TODO: compare results on dense and sparse data as proposed in:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:94:        # TODO(jjerphan): Once SciPy 1.11.3 is the minimum supported version, use
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/conftest.py:212:        # TODO: configure numpy to output scalar arrays as regular Python scalars
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:315:            # TODO: add keyword copy to copy on demand
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_helper.c:158:     * TODO: does this provoke memory leaks (we just malloc'ed them)?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:84: * TODO: precomputed kernel.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:386: * TODO: merge in the cython layer
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_svm.py:4:TODO: remove hard coded numerical results when possible
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_bounds.py:17:# TODO(1.8): remove filterwarnings after the deprecation of liblinear multiclass
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_metaestimators.py:279:# TODO: remove data validation for the following estimators
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstrings.py:191:    # TODO: this detection can be improved. Currently we assume that we have
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:867:# TODO(1.9):  remove when deprecated `base_estimator` is removed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:124:# TODO(1.8): remove test when generate_only is removed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:229:                # TODO: FIX MLP to not check validation set during MLP
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:272:# TODO: As more modules support get_feature_names_out they should be removed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:2063:# TODO(1.8): change warning to checking for NotFittedError
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:308:    # TODO(1.8): Remove cv="prefit" options here and the @ignore_warnings of the test
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:1119:    # TODO(1.8): remove me once the deprecation period is over.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_metadata_routing.py:912:    # TODO: these test classes can be moved to sklearn.utils._testing once we
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_base.py:271:# TODO(1.8): Remove this test when the deprecation is removed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:203:        # TODO(devtools): use _tested_estimators instead of all_estimators in the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:223:    # TODO(1.9) remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:227:    # TODO(1.9) remove
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:171:        # TODO: Does this depend on device?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:233:        # TODO: Does this depend on device?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:63:    # TODO: Should we reject ndarray subclasses?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:95:    # TODO: Should we reject ndarray subclasses?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:123:    # TODO: Should we reject ndarray subclasses?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:238:    # TODO: Account for other backends.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:580:            # TODO: Support Python scalars?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:793:        # TODO: What if our array is on the GPU already?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:277:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:334:    # TODO: np.clip has other ufunc kwargs
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:36:# TODO: use the QR wrapper once dask
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:60:    # TODO: can't avoid computing U or V for dask
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:67:    # TODO: respect device keyword?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:97:    # TODO: respect device keyword?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:168:    # TODO: respect device keyword?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:229:    # TODO: This won't handle dask unknown shapes
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_at.py:21:    # TODO import from typing (requires Python >=3.11)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_utils/_helpers.py:20:    # TODO import from typing (requires Python >=3.13)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/testing.py:20:    # TODO import override from typing (requires Python >=3.12)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:564:        # TODO: remove the following two lines when scikit-learn only depends
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:617:            # TODO: remove the following two lines when scikit-learn only
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:778:        # TODO: update this code to either:
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:142:        # TODO: Make verbosity argument for Lasso?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:158:            # TODO: move this handling (which is currently too broad)
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/_lda.py:462:        # TODO: make Parallel._effective_n_jobs public instead?
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:617:    # TODO: explain what this is testing
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:634:    # TODO: explain what this is testing
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_nmf.py:992:        # TODO: use the provided W when init="custom".
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:116:        # TODO: Explore the choice of using bincount + add.at as it seems sub optimal
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/asyn.py:347:        # TODO: implement on_error
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/asyn.py:511:        # TODO: on_error
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/asyn.py:998:    # TODO: readahead might still be useful here, but needs async version
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/generic.py:327:        # TODO: special case for one FS being local, which can use get/put
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/generic.py:328:        # TODO: special case for one being memFS, which can use cat/pipe
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/utils.py:302:    # TODO: allow length to be None and read to the end of the file?
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:78:            # TODO: tarfile already implements compression with modes like "'r:gz'",
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:92:        # TODO: load and set saved index, if exists
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:101:        # TODO: save index to self.index_store here, if set
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:322:            # TODO: action where partial file exists in read-only cache
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:394:        # TODO: use transaction support in SMB protocol
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/cache_metadata.py:158:                # TODO: consolidate blocks here
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http.py:104:        # TODO: Maybe rename `self.kwargs` to `self.request_options` to make
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:147:        # TODO: derive fs from `root`
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:473:        # TODO: only save needed columns
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:546:        # TODO: only clear those that we wrote to?
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:748:            # TODO: warning here, since this can be very expensive?
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:884:        # TODO: if references is lazy, pre-fetch all paths in batch before access
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:985:        # TODO: we make dircache by iterating over all entries, but for Spec >= 1,
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:352:    # TODO: if all incoming paths were posix-compliant then separator would
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:393:                # TODO: check if path is writable?
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:105:        # TODO: encoding from headers
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:883:    # TODO: not allowed in JS
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:896:    # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/spec.py:493:        # TODO: allow equivalent of -name parameter
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/compression.py:13:# TODO: files should also be available as contexts
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/caching.py:94:        # TODO: use rich for better formatting
./api/pipeline/.venv/lib/python3.12/site-packages/fsspec/caching.py:502:        # TODO: only set start/end after fetch, in case it fails?
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:214:    # TODO allow pos to be None and use a nice TikZ default
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:277:        # TODO -- handle bending of multiedges
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:2499:        # TODO should this be list or array (as in a numpy array)?
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:792:            Ai = A.getrowview(i).toarray()  # TODO: revisit w/ sparse 1D container
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:1152:    # TODO: Rm csr_array wrapper in favor of spdiags array constructor when available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:75:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:77:    # TODO: Rm csr_array wrapper when eye array creation becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:128:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:238:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:244:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:341:        # TODO: rm csr_array wrapper when spdiags creates arrays
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:344:        # TODO: rm csr_array wrapper when spdiags creates arrays
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:436:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:498:        # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:503:            # TODO: Rm csr_array wrapper when identity array creation becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:192:        # TODO: rm csr_array wrapper when spdiags array creation becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:279:                # TODO: rm csc_array wrapping when spdiags array becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:296:                # TODO: rm csr_array wrapping when spdiags array becomes available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:129:    # TODO: Remove between the lines when `link` deprecation expires
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:274:    # TODO: Remove between the lines when `link` deprecation expires
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/tests/test_node_link.py:27:    # TODO: To be removed when signature change complete
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:463:    # TODO: csr_array
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/tests/test_connectivity.py:138:        # TODO Is this really the intended behavior for providing a
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:94:    # TODO: csr_array
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:173:    # TODO: csr_array
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/dag.py:1175:    # TODO In Python 3, this would be better as `yield from ...`.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/efficiency_measures.py:118:    # TODO This can be made more efficient by computing all pairs shortest
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/distance_regular.py:184:# TODO There is a definition for directed strongly regular graphs.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/dominating_set.py:22:# TODO Why doesn't this algorithm work for directed graphs?
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:805:            # TODO: this branch does not restore original_edge_weights of G!
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/clique.py:300:# TODO Should this also be not implemented for directed graphs?
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/walks.py:72:    # TODO: Use matrix_power from scipy.sparse when available
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/coloring/equitable_coloring.py:163:        # TODO: Checking whether a color has been visited can be made faster by
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:686:    # TODO: support DiGraph
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:111:    # TODO This can be trivially parallelized.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:206:    # TODO This can be trivially parallelized.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:1135:    # TODO This can be trivially parallelized.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:181:    # TODO This can be trivially parallelized.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:475:    # TODO This can be trivially parallelized.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:276:            # TODO - The lines between --- were unused and were thus commented
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:282:            #     # TODO Why is extra inner loop necessary?
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:287:            # TODO Originally, this function returned a three-tuple:
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/redundancy.py:93:    # TODO This can be trivially parallelized.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/tests/test_matching.py:110:        # TODO Assert that the vertices are the correct ones.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:124:        # TODO This can be parallelized, both in the outer loop over
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:132:        # TODO This loop can be parallelized, to an extent (the union
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:11:# TODO: Implement method from Gabow, Galil, Spence and Tarjan:
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cycles.py:841:                if thisnode not in B[nextnode]:  # TODO: use set for speedup?
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:217:        # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:292:        # TODO: graph and subgraph setter methods that invalidate the caches.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:293:        # TODO: allow for precomputed partitions and colors
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_swap.py:40:    # TODO: Rewrite function to explicitly check for impossible swaps and raise error
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:97:            # TODO: investigate https://arxiv.org/abs/1412.6466 for k=2
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:314:    # @not_implemented_for('multigraph')  # TODO: fix decor for classmethods
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/traversal/beamsearch.py:77:        # TODO The Python documentation states that for small values, it
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:19:# TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:322:# TODO What is the generalization to two arguments, S and T? Does the
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:362:# TODO What is the generalization to two arguments, S and T? Does the
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/conftest.py:102:# TODO: The warnings below need to be dealt with, but for now we silence them.
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/geometric.py:190:    # TODO Is this function just a special case of the geographical
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/community.py:1034:    # TODO The original code incremented the number of iterations each
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/tests/test_expanders.py:37:    # TODO The second largest eigenvalue should be smaller than a constant,
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/generators/degree_seq.py:671:    # TODO Does this need to be sorted in reverse order?
./api/pipeline/.venv/lib/python3.12/site-packages/pynvml/nvml.py:1089:#     # TODO handle the error
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:265:            # TODO: reasonable sign of infinity
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/factorials.py:112:    # TODO: fixme, obviously
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/theta.py:926:    # TODO: write _jacobi_theta2a and _jacobi_theta3a using fixed-point
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:18:    # TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:313:        # TODO: something else is required here
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:373:    # TODO: correct evaluation at singularities
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:28:        # TODO: the integer special-casing shouldn't be necessary.
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:147:    # TODO: avoid cancellation for imaginary arguments
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:384:# TODO: do this more generically?
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:423:# TODO: could be expressed more elegantly using triple factorials
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:468:        # TODO: limits
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:521:                # TODO: asymptotic series for derivatives
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:562:        # TODO: limits
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:718:    # TODO: check that chop=True chops when and only when it should
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:757:    # TODO: check that chop=True chops when and only when it should
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:833:    TODO: this can be optimized, e.g. by reusing evaluation points.
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:878:                # TODO: use v <= j'_{v,1} < y_{v,1}?
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:238:# TODO: fix the interface wrt contexts
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:287:# TODO: for bernpoly and eulerpoly, ensure that all exact zeros are covered
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:385:# TODO: this should be implemented low-level
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:620:    # TODO: implement for derivatives
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:697:            # TODO: the following could perhaps be tidied a bit
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:11:        # Avoid division by zero in leading factors (TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:284:            # TODO: handle the all-real case more efficiently!
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:285:            # TODO: figure out how much precision is needed (exponential growth)
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:404:        # TODO: the following logic can be simplified
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:760:    # TODO: much of the following could be shared with 2F3 instead of
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:832:    # TODO: much of the following could be shared with 2F3 instead of
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1091:    # TODO: continuation
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1107:    # TODO: continuation
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:174:# TODO: tests; improve implementation
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:182:    # TODO: accurately eval the smaller of the real/imag parts
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:212:    # TODO: accurately eval the smaller of the real/imag part
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:257:            # TODO: this can be done *much* faster
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:604:    # TODO: the following could be generalized into a perfect
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/identification.py:273:        # slowly (e.g. a factor 1-10) with each step TODO: we could
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:306:    # TODO: add more of these, make consistent, write docstrings, ...
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:171:    (TODO: find a better solution to this problem.)
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1969:            # TODO: we are evaluating log(1+eps) -> eps, which is
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/differentiation.py:364:    TODO: most exponents are zero, so maybe a sparse representation
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/odes.py:219:    **TODO**
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:264:            # TODO: maybe refactoring with function for divided differences
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:289:# TODO: consider raising a ValueError when there's no sign change in a and b
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:418:                # TODO: better condition (when f is very flat)
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:457:# TODO: check whether it's possible to combine it with Illinois stuff
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:503:                # TODO: better condition (when f is very flat)
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:560:            # TODO: decide not to use convergence acceleration
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:573:# TODO: add Brent
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:601:# TODO: test with user-specified jacobian matrix
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:665:            # damping step size TODO: better strategy (hard task)
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:984:        if verify and norm(f(*xl))**2 > tol: # TODO: better condition?
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:99:# TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:136:                if current > biggest: # TODO: what if equal?
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:218:                    # TODO: necessary to check also b?
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:239:            raise RuntimeError("need n*n matrix") # TODO: really?
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:372:    # TODO: implement this
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:4:# TODO: interpret list as vectors (for multiplication)
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:208:        COMMENT: TODO: the above "doctest:+SKIP" may be removed as soon as we
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:3:# TODO: should use diagonalization-based algorithms
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:14:        TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/math2.py:207:        # TODO: sinpi
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/math2.py:221:        # TODO: sinpi
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/math2.py:359:# TODO: could implement complex erf and erfc here. Need
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:273:    # TODO: many more tests
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:404:    # TODO: need many more tests
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/torture.py:27:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_matrices.py:57:    # TODO remove exec() wrapper as soon as we drop support for Python <= 3.5
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_gammazeta.py:599:    # TODO: more tests for polyexp
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_linalg.py:1:# TODO: don't use round
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/runtests.py:57:# TODO: add a flag for this
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:54:TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:199:        # TODO: when there are several real parameters and just a few complex
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:332:# TODO: mpf_erf should call mpf_erfc when appropriate (currently
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:355:        # TODO: interval rounding
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:617:            # TODO: could return finite imaginary value at -inf
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:911:# TODO: for extremely large x, we could use an asymptotic
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:914:# TODO: recompute at higher precision if the fixed-point mantissa
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1046:    TODO:
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1081:    # TODO: for |x| << 1/2, one could use fall back to
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:4:TODO: rename, cleanup, perhaps move the gmpy wrapper code
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:129:# TODO: speed up for bases 2, 4, 8, 16, ...
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:458:    TODO: speed up using factorization
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:342:    # TODO: handle rnd direction of the logarithm carefully
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:711:        # TODO: if close enough to 1, we could use Taylor series
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:876:# TODO: cleanup the special cases
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1158:        # TODO: the best cutoff depends on both x and the precision.
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1249:    # TODO: optimize division precision
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:179:    # formula to the tail. TODO: choose more intelligently
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:626:TODO: the current estimation of N for m > 0 is *very suboptimal*.
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:628:TODO: implement the reflection formula for m > 0, Re(z) << 0.
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:633:TODO: maybe use exact algorithms to compute psi for integral
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1160:# TODO: optimize / cleanup interface / unify with list_primes
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1383:    TODO: this is currently only used for gamma, but could
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1942:    # a fixed-point value. TODO: determine a precise cutoff of validity
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:498:    # TODO: handle cancellation when c ~=  -1 and ch ~= 1
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:584:# TODO: avoid loss of accuracy
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:124:# TODO: optimize
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:367:    # TODO: combine evaluation code to avoid duplicate modulo
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:631:    # TODO: optimize for real/imag cases
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:643:    # TODO: optimize for real/imag cases
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:670:    # TODO: accuracy for small x
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:759:    # TODO: recognize/speed up real cases, integer y
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:848:        # TODO: reflection formula
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:885:            # TODO: reflection formula
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1175:    # TODO: account for precision when doing this
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1320:    TODO: the rounding does not work properly for large exponents.
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/openapi/utils.py:344:                # TODO: probably make status_code a default class attribute for all
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/openapi/models.py:147:    # TODO: uncomment and remove below when deprecating Pydantic v1
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:36:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:150:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:236:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:320:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:406:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:490:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:606:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/params.py:690:        # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:55:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:380:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:684:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1000:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1327:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1642:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1956:    # TODO: update when deprecating Pydantic v1, import these types
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/routing.py:368:            # TODO: remove this scope later, after a few releases
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/routing.py:524:            # TODO: remove when deprecating Pydantic v1
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/encoders.py:36:# TODO: pv2 should this return strings instead?
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/encoders.py:217:        # TODO: remove when deprecating Pydantic v1
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/encoders.py:239:            # TODO: remove when deprecating Pydantic v1
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/applications.py:877:        # TODO: remove when discarding the openapi_prefix parameter
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/security/oauth2.py:12:# TODO: import from typing when deprecating Python 3.9
./api/pipeline/.venv/lib/python3.12/site-packages/fastapi/_compat.py:203:            # TODO remove when deprecating Pydantic v1
./api/.venv/lib/python3.12/site-packages/anyio/_core/_fileio.py:416:        def info(self) -> Any:  # TODO: add return type annotation when Typeshed gets it
./api/.venv/lib/python3.12/site-packages/uvicorn/protocols/websockets/wsproto_impl.py:120:            # TODO: Remove `type: ignore` when wsproto fixes the type annotation.
./api/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:274:            # TODO: we don't go through the rebuild logic here directly because we don't want
./api/.venv/lib/python3.12/site-packages/pydantic/fields.py:55:    # TODO PEP 747: use TypeForm:
./api/.venv/lib/python3.12/site-packages/pydantic/fields.py:333:        # TODO check for classvar and error?
./api/.venv/lib/python3.12/site-packages/pydantic/fields.py:411:        # TODO check for classvar and error?
./api/.venv/lib/python3.12/site-packages/pydantic/fields.py:413:        # TODO infer from the default, this can be done in v3 once we treat final fields with
./api/.venv/lib/python3.12/site-packages/pydantic/fields.py:720:            # TODO: properly make use of the protocol (https://rich.readthedocs.io/en/stable/pretty.html#rich-repr-protocol)
./api/.venv/lib/python3.12/site-packages/pydantic/fields.py:797:    default: ellipsis,  # noqa: F821  # TODO: use `_typing_extra.EllipsisType` when we drop Py3.9
./api/.venv/lib/python3.12/site-packages/pydantic/deprecated/json.py:112:# TODO: Add a suggested migration path once there is a way to use custom encoders
./api/.venv/lib/python3.12/site-packages/pydantic/alias_generators.py:7:# TODO: in V3, change the argument names to be more descriptive
./api/.venv/lib/python3.12/site-packages/pydantic/functional_validators.py:213:            # TODO if `schema['serialization']` is one of `'include-exclude-dict/sequence',
./api/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:124:# TODO: ultimately, make this public, see https://github.com/pydantic/pydantic/pull/9459#discussion_r1628197626
./api/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:592:            # TODO: is there a better way? should we just not do this?
./api/.venv/lib/python3.12/site-packages/pydantic/dataclasses.py:277:        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:303:        # TODO: in theory we should check that the schema accepts a serialization key
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:407:            # TODO this is an ugly hack, how do we trigger an Any schema for serialization?
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:613:        # TODO: note, this is a fairly common pattern, re lax / strict for attempted type coercion,
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1724:        # TODO: do we really need to resolve type vars here?
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1743:                # TODO: something like https://github.com/pydantic/pydantic/issues/5952
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2005:        TODO support functional validators once we support them in Config
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2511:# TODO V3: this function is only used for deprecated decorators. It should
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:235:    # TODO: This could be unified with `get_standard_typevars_map` if we stored the generic metadata
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:276:        # TODO remove parentheses when we drop support for Python 3.10:
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:91:    # TODO When we drop 3.9, use a match statement to get better type checking and remove
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:170:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:176:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py:83:    # TODO: this is a bit redundant, we could probably avoid some of these
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_validators.py:44:    # TODO: refactor sequence validation to validate with either a list or a tuple
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:139:# TODO implement `is_finalvar_annotation` as Final can be wrapped with other special forms:
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:186:# TODO In 2.12, delete this export. It is currently defined only to not break
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:195:# TODO: Ideally, we should avoid relying on the private `typing` constructs:
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:445:        # TODO ideally recursion errors should be checked in `eval_type` above, but `eval_type_backport`
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:230:                # TODO we can also stop there if `__pydantic_fields_complete__` is False.
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:29:    TODO: Perhaps we should move this structure to pydantic-core. At the moment, though,
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:32:    TODO: It's unfortunate how functionally oriented JSON schema generation is, especially that which occurs during
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:236:            # TODO: should we merge the parent namespace here?
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:263:        # TODO `typ.__type_params__` when we drop support for Python 3.11:
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:394:                    # TODO: We should probably do something with this so that validate_assignment behaves properly
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:406:                        # TODO: same note as above re validate_assignment
./api/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:433:            # was already evaluated. TODO: is this method relevant?
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:436:        TODO: the nested function definitions here seem like bad practice, I'd like to unpack these
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:505:        # TODO: I dislike that we have to wrap these basic dict updates in callables, is there any way around this?
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:713:            # TODO: should we add regex flags to the pattern?
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1117:        # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1240:        # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1281:                        # TODO: fixme - this is a workaround for the fact that we can't always resolve refs
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1320:        # TODO: Need to read the default value off of model config or whatever
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1321:        use_strict = schema.get('strict', False)  # TODO: replace this default False
./api/.venv/lib/python3.12/site-packages/pydantic/v1/utils.py:270:            # TODO: replace annotation with actual expected types once #1055 solved
./api/.venv/lib/python3.12/site-packages/pydantic/v1/networks.py:535:    # TODO: Needed to generic "Parts" for "Replica Set", "Sharded Cluster", and other mongodb deployment modes
./api/.venv/lib/python3.12/site-packages/pydantic/mypy.py:513:                    # TODO: Only do this if the first argument of the decorated function is `cls`
./api/.venv/lib/python3.12/site-packages/pydantic/mypy.py:622:                # TODO: We shouldn't be performing type operations during the main
./api/.venv/lib/python3.12/site-packages/pydantic/mypy.py:785:            # TODO this path should be removed (see https://github.com/pydantic/pydantic/issues/11119)
./api/.venv/lib/python3.12/site-packages/pydantic/main.py:4:# TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.
./api/.venv/lib/python3.12/site-packages/pydantic/main.py:1043:                    # TODO - matching error
./api/.venv/lib/python3.12/site-packages/pydantic/main.py:1689:    # TODO PEP 747: replace `Any` by the TypeForm:
./api/.venv/lib/python3.12/site-packages/pygments/formatters/terminal256.py:17:# TODO:
./api/.venv/lib/python3.12/site-packages/pygments/formatters/latex.py:334:        # TODO: add support for background colors
./api/.venv/lib/python3.12/site-packages/pygments/formatters/img.py:548:            # TODO: make sure tab expansion happens earlier in the chain.  It
./api/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:445:            # TODO: these don't match the comments in docs, remove.
./api/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:130:                # TODO unsure if ellipses are allowed elsewhere, see
./api/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./api/.venv/lib/python3.12/site-packages/pygments/lexers/textfmts.py:240:    # TODO: Make date regex more ISO 8601 compliant
./api/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:755:            # TODO support other Python syntax like $foo['bar']
./api/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:123:            # TODO: we should probably escape also here ''${ \${
./api/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:135:        # TODO: let/in
./api/.venv/lib/python3.12/site-packages/pygments/lexers/ada.py:116:            # TODO: use Name.Namespace if appropriate.  This needs
./api/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:150:            # TODO: better logging
./api/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:347:                # TODO: better handle multiline comments at the end with
./api/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:588:            # TODO: Backslash escapes?
./api/.venv/lib/python3.12/site-packages/pygments/lexers/mips.py:28:    # TODO: add '*.s' and '*.asm', which will require designing an analyse_text
./api/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:886:    # TODO / should divide keywords/symbols into namespace/rest
./api/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:1341:            (r'\S+\s+', Text)   # TODO: make tests pass without \s+
./api/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:390:            # TODO: Treat context-depedendent names specially
./api/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:396:            # TODO: templates start and end tokens.
./api/.venv/lib/python3.12/site-packages/pygments/lexers/urbi.py:34:    # TODO
./api/.venv/lib/python3.12/site-packages/pygments/lexers/dns.py:53:            # TODO, $GENERATE https://bind9.readthedocs.io/en/v9.18.14/chapter3.html#soa-rr
./api/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:27:    # TODO String interpolation @VARNAME@ inner matches
./api/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:28:    # TODO keyword_arg: value inner matches
./api/.venv/lib/python3.12/site-packages/pygments/lexers/perl.py:35:    # TODO: give this to a perl guy who knows how to parse perl...
./api/.venv/lib/python3.12/site-packages/pygments/lexers/_asy_builtins.py:9:    TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
./api/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:140:            # TODO: regexes can have other delims
./api/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:191:        # TODO: builtins are only subsequent tokens on lines
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:648:            (r'^(\* )(TODO)( .*)',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:650:            (r'^(\*\*+ )(TODO)( .*)',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:656:            # Unordered lists items, including TODO items and description items
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:672:            # TODO: language-dependent syntax highlighting (see Markdown lexer)
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:701:            (_inline(r'=', r'='), String), # TODO token
./api/.venv/lib/python3.12/site-packages/pygments/lexers/javascript.py:133:            # TODO: should this include single-line comments and allow nesting strings?
./api/.venv/lib/python3.12/site-packages/pygments/lexers/testing.py:200:            (r'(?i)\bTODO\b', Comment.Preproc),
./api/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:49:            # TODO: highlight references in fandocs
./api/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:85:        'insideUri': [  # TODO: remove copy/paste str/uri
./api/.venv/lib/python3.12/site-packages/pygments/lexers/c_like.py:212:            # TODO: "correctly" parse complex code attributes
./api/.venv/lib/python3.12/site-packages/pygments/lexers/modula2.py:474:        'TODO', 'FFI', 'ADDR', 'VARGLIST', 'VARGC',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:24:    TODO:
./api/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:85:# TODO:
./api/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:123:                "varname",  # TODO varname the right fit?
./api/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:273:                        "async for",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./api/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:274:                        "async with",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./api/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:702:        # TODO supported?
./api/.venv/lib/python3.12/site-packages/pygments/lexers/parsers.py:396:            # TODO finish implementing other possibilities for scope
./api/.venv/lib/python3.12/site-packages/pygments/lexers/css.py:555:            # TODO: broken, and prone to infinite loops.
./api/.venv/lib/python3.12/site-packages/pygments/lexers/rnc.py:36:            # TODO single quoted strings and escape sequences outside of
./api/.venv/lib/python3.12/site-packages/pygments/lexers/scripting.py:1502:            # TODO: JES3 statement
./api/.venv/lib/python3.12/site-packages/pygments/lexers/oberon.py:50:            # TODO: nested comments (* (* ... *) ... (* ... *) *) not supported!
./api/.venv/lib/python3.12/site-packages/pygments/lexers/dotnet.py:558:# TODO support multiple languages within the same source file
./api/.venv/lib/python3.12/site-packages/pygments/lexer.py:861:    TODO: clean up the code here.
./api/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/.venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9:# TODO: remove this check when dropping Python 3.7 support
./api/.venv/lib/python3.12/site-packages/click/_termui_impl.py:525:    # TODO: This never terminates if the passed generator never terminates.
./api/.venv/lib/python3.12/site-packages/ecdsa/keys.py:1079:                # TODO parse attributes or validate publickey
./api/.venv/lib/python3.12/site-packages/ecdsa/keys.py:1204:        # TODO: "BEGIN ECPARAMETERS"
./api/.venv/lib/python3.12/site-packages/prometheus_client/metrics_core.py:330:            # TODO: Handle None gsum_value correctly. Currently a None will fail exposition but is allowed here.
./api/.venv/lib/python3.12/site-packages/prometheus_client/values.py:113:            # TODO: Implement exemplars for multiprocess mode.
./api/.venv/lib/python3.12/site-packages/prometheus_client/values.py:122:            # TODO: Implement exemplars for multiprocess mode.
./api/.venv/lib/python3.12/site-packages/prometheus_client/openmetrics/parser.py:503:        # TODO: check labelvalues are valid utf8
./api/.venv/lib/python3.12/site-packages/yaml/scanner.py:187:        # TODO: support for BOM within a stream.
./api/.venv/lib/python3.12/site-packages/yaml/scanner.py:761:        # TODO: We need to make tab handling rules more sane. A good rule is
./api/.venv/lib/python3.12/site-packages/pydantic_core/core_schema.py:1135:            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
./api/.venv/lib/python3.12/site-packages/httpx/_auth.py:267:        # TODO: implement auth-int
./api/.venv/lib/python3.12/site-packages/pyasn1/type/univ.py:1724:        # TODO: remove when Py2.5 support is gone
./api/.venv/lib/python3.12/site-packages/pyasn1/type/univ.py:1952:                # TODO: we should wrap componentType with UnnamedType to carry
./api/.venv/lib/python3.12/site-packages/pyasn1/type/constraint.py:85:        # TODO: fix possible comparison of set vs scalars here
./api/.venv/lib/python3.12/site-packages/pyasn1/type/constraint.py:747:# TODO:
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/cer/decoder.py:51:# TODO: prohibit non-canonical encoding
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/encoder.py:189:            # TODO: try to avoid ASN.1 schema instantiation
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/encoder.py:557:    # TODO: handling three flavors of input is too much -- split over codecs
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:48:        raise error.PyAsn1Error('SingleItemDecoder not implemented for %s' % (tagSet,))  # TODO: Seems more like an NotImplementedError?
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:58:        raise error.PyAsn1Error('Indefinite length mode decoder not implemented for %s' % (tagSet,)) # TODO: Seems more like an NotImplementedError?
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:1350:            # TODO: Seems not to be tested
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/ber/decoder.py:1399:            yield chunk  # TODO: Weird
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/der/encoder.py:34:                # TODO: move out of sorting key function
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/der/encoder.py:41:                # TODO: support nested CHOICE ordering
./api/.venv/lib/python3.12/site-packages/pyasn1/codec/der/decoder.py:23:# TODO: prohibit non-canonical encoding
./api/.venv/lib/python3.12/site-packages/passlib/utils/compat/__init__.py:100:    # TODO: once we drop python 3.2 support, can use u'' again!
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:56:    # TODO: a bunch of other things are commonly assumed in this namespace
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:426:            # TODO: straighten out class naming, repr, and .name attr
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:446:        TODO: This should be done explicitly, but for now this mixin sets
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:938:    # TODO: document _norm_hash()
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1287:    # TODO: document _truncate_salt()
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1312:    # TODO: could support using(min/max_desired_salt_size) via using() and needs_update()
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1717:                # TODO: deprecate / disallow vary_rounds=1.0
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1768:            assert 0 <= vary_rounds <= 1 # TODO: deprecate vary_rounds==1
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2527:            # TODO: look into way to fix the issues.
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2626:        # TODO: needs UTs
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2627:        # TODO: any other cases where wrapped is "owned"?
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:2691:        # TODO: under 2.0, throw TypeError if config is None, rather than passing it through
./api/.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:364:    # TODO: use izip instead (but first verify it's faster than zip for this case)
./api/.venv/lib/python3.12/site-packages/passlib/utils/__init__.py:385:    # TODO: could check for cryptography package's version,
./api/.venv/lib/python3.12/site-packages/passlib/utils/binary.py:361:        # TODO: support padding character
./api/.venv/lib/python3.12/site-packages/passlib/utils/binary.py:492:        ##    # TODO: add padding size check?
./api/.venv/lib/python3.12/site-packages/passlib/exc.py:353:    # TODO: if handler.use_defaults is set, this came from app-provided value,
./api/.venv/lib/python3.12/site-packages/passlib/totp.py:265:        # TODO: allow a lot more things to be customized from here,
./api/.venv/lib/python3.12/site-packages/passlib/totp.py:1306:    # TODO: resync(self, tokens, time=None, min_tokens=10, window=100)
./api/.venv/lib/python3.12/site-packages/passlib/context.py:1692:    ##    # TODO: this should work w/ 'auto', but needs closer inspection
./api/.venv/lib/python3.12/site-packages/passlib/context.py:2109:            # TODO: offer replacement alternative.
./api/.venv/lib/python3.12/site-packages/passlib/context.py:2248:            # TODO: offer replacement alternative.
./api/.venv/lib/python3.12/site-packages/passlib/context.py:2332:            # TODO: offer replacement alternative.
./api/.venv/lib/python3.12/site-packages/passlib/apps.py:226:# TODO: support the drupal phpass variants (see phpass homepage)
./api/.venv/lib/python3.12/site-packages/passlib/handlers/pbkdf2.py:395:        # TODO: find out what crowd's policy is re: unicode
./api/.venv/lib/python3.12/site-packages/passlib/handlers/pbkdf2.py:469:        # TODO: find out what grub's policy is re: unicode
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:147:    # TODO: could support the optional 'data' parameter,
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:178:    # TODO: once rounds limit logic is factored out,
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:398:        # TODO: switch to working w/ str or unicode
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:459:        # TODO: factor out variable checksum size support into a mixin.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:738:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:761:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:784:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/argon2.py:879:        # TODO: add in 'encoding' support once that's finalized in 1.8 / 1.9.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/scram.py:330:            # TODO: verify digest size (if digest is known)
./api/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:3:TODO:
./api/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:211:        # TODO: try to detect incorrect 8bit/wraparound hashes using kwds.get("secret")
./api/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:454:        # TODO: check for 2x support
./api/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:518:        # TODO: figure out way to skip these tests when not needed...
./api/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:628:    # # TODO: would like to implementing verify() directly,
./api/.venv/lib/python3.12/site-packages/passlib/handlers/sun_md5_crypt.py:345:    # TODO: if we're on solaris, check for native crypt() support.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/misc.py:111:    # TODO: rename attr to 'marker'...
./api/.venv/lib/python3.12/site-packages/passlib/handlers/scrypt.py:133:    # TODO: would like to dynamically pick this based on system
./api/.venv/lib/python3.12/site-packages/passlib/handlers/scrypt.py:139:    # TODO: make default block size configurable via using(), and deprecatable via .needs_update()
./api/.venv/lib/python3.12/site-packages/passlib/handlers/sha2_crypt.py:300:        # TODO: this *could* use uh.parse_mc3(), except that the rounds
./api/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:83:    # TODO: add sha3 to this table.
./api/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:245:    # TODO: add pysha3 support.
./api/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:498:            # TODO: load in preset digest size info for known hashes.
./api/.venv/lib/python3.12/site-packages/passlib/crypto/digest.py:874:# TODO: consider some alternatives, such as C-accelerated xor_bytes helper if available
./api/.venv/lib/python3.12/site-packages/passlib/crypto/des.py:40:# TODO: could use an accelerated C version of this module to speed up lmhash,
./api/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:30:#: TODO: standardize this across backends, and expose support via scrypt hash config;
./api/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:40:# TODO: unittests for this function
./api/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:95:# TODO: configuration picker (may need psutil for full effect)
./api/.venv/lib/python3.12/site-packages/passlib/crypto/scrypt/__init__.py:209:        # TODO: would like to enforce a single "maxmem" policy across all backends;
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_utils.py:326:        # TODO: add some tests to ensure we take THETA(strlen) time.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_cisco.py:209:        # TODO: these need confirming w/ an actual PIX system.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:158:        # TODO: push this to passlib.apps django contexts
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:459:    # TODO: add get_hasher() checks where appropriate in tests below.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:530:        # TODO: is_password_usable()
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:605:        # TODO: is_password_usable()
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:645:        # TODO: is_password_usable()
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:690:        # TODO: is_password_usable()
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:818:        # TODO: get_hasher()
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django.py:901:        # TODO: test unpatch behavior honors flag.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_pwd.py:123:    # TODO: test rng option
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_apache.py:72:        # TODO: under py3, could trap the more specific FileNotFoundError
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_apache.py:610:    # TODO: test set_password autosave
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:120:    # TODO: find an authoritative source of test vectors
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:242:    # TODO: find an authortative source of test vectors
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:641:    # TODO: integrate EncodingHandlerMixin
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1212:    # TODO: get more test vectors (especially ones which properly test unicode)
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1250:    # TODO: find more test vectors (especially ones which properly test unicode)
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1316:    # TODO: integrate EncodingHandlerMixin
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1621:    # TODO: this scheme needs some real test vectors, especially due to
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1737:#    accepts_all_hashes = True # TODO: turn this off.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_bcrypt.py:488:        # TODO: convert to v2 format
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:370:            # TODO: may want to filter out a few of this, but not blanket filter...
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:374:            # TODO: should be cleaned in 2.0, when support will be dropped.
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:489:        # TODO: make this display better diff of *which* warnings did not match
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:954:    # TODO: rename to do_hash() to match new API
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1639:        # TODO: check relaxed mode clips min-1
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1658:            # TODO: check relaxed mode clips max+1
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2053:    # TODO: check various supported idents
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2618:        # TODO: would like to enhance what this test covers
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:2627:        # TODO: figure out what invariants we can reliably parse,
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:3287:    # TODO: turn into decorator, and use mock library.
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:3493:    # TODO: user size? kinda dicey, depends on algorithm.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_pbkdf2.py:182:    # TODO: need a bunch more reference vectors from some real
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_ext_django_source.py:229:        # TODO: support wrapping django's harden-runtime feature?
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:307:    # TODO: test HasRawSalt mixin
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:611:        # TODO: handle fshp correctly, and other glitches noted in code.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:766:        self.assertEqual(h.ident_values, None) # TODO: should output (u("?P$"), u("?H$")))
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_utils_handlers.py:838:# TODO: provide data samples for algorithms
./api/.venv/lib/python3.12/site-packages/passlib/tests/backports.py:18:    # TODO: deprecate these exports in favor of "unittest.XXX"
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_argon2.py:398:            # TODO: make this fatal, and add refs for other version.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_argon2.py:433:        # TODO: fuzz parallelism, digest_size
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context_deprecated.py:40:    # TODO: need to test user categories w/in all this
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:203:    # TODO: test secrets_path
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:232:    # TODO: test 'cost' param
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:375:        # TODO: rework timing test here to inject mock pbkdf2_hmac() function instead;
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:392:# TODO: this class is separate from TotpTest due to historical issue,
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:693:    # TODO: test using() w/ 'digits', 'alg', 'issue', 'wallet', **wallet_kwds
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1048:        # TODO: test window values that aren't multiples of period
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1083:        # TODO: test skew + larger window
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1581:    # TODO: to_dict()
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_totp.py:1595:    # TODO: from_json() / to_json().
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_registry.py:127:        # TODO: check lazy load which calls register_crypt_handler (warning should be issued)
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers_django.py:42:    #: TODO: for a bunch of the tests below, this is just max version where
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:52:    # TODO: these unittests could really use a good cleanup
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1025:        # TODO: should migrate these tests elsewhere, or remove them.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1352:    # TODO: now that rounds generation has moved out of _CryptRecord to HasRounds,
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1446:        # TODO: test default falls back to mx / mn if handler has no default.
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:1607:        # TODO: test dummy_verify() invoked by .verify() when hash is None,
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_crypto_digest.py:194:    # TODO: write full test of compile_hmac() -- currently relying on pbkdf2_hmac() tests
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:75:    # TODO: add preset which includes HASHERS + PREFERRED_HASHERS,
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:365:            # TODO: should make iteration via registry easier
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:602:            # TODO: Solve redundancy that verify() call
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:809:        # TODO: would like to add support for inheriting config from a preset
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:813:        # TODO: wrap and import any custom hashers as passlib handlers,
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1010:        # TODO: would like access CryptContext, would need caller to pass it to get_passlib_hasher().
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1015:            # TODO: always call subcls/handler.needs_update() in case there's other things to check
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1028:# TODO: this code probably halfway works, mainly just needs
./api/.venv/lib/python3.12/site-packages/passlib/ifc.py:32:# TODO: make this actually use abstractproperty(),
./api/.venv/lib/python3.12/site-packages/passlib/ifc.py:67:    #: .. TODO: passlib 1.8: deprecate/rename this attr to "max_secret_size"?
./api/.venv/lib/python3.12/site-packages/passlib/ifc.py:80:    #: .. TODO: passlib 1.8: deprecate/rename this attr to "truncate_hash_error"?
./api/.venv/lib/python3.12/site-packages/passlib/ifc.py:277:    #: TODO: document this, or at least the use of testing for
./api/.venv/lib/python3.12/site-packages/passlib/registry.py:384:    # TODO: make _handlers a separate list, so we don't have module namespace mixed in.
./api/.venv/lib/python3.12/site-packages/passlib/registry.py:431:# TODO: needs UTs
./api/.venv/lib/python3.12/site-packages/passlib/registry.py:449:# TODO: needs UTs
./api/.venv/lib/python3.12/site-packages/passlib/registry.py:507:# TODO: move unix_crypt_schemes list to here.
./api/.venv/lib/python3.12/site-packages/passlib/registry.py:511:# TODO: needs UTs
./api/.venv/lib/python3.12/site-packages/passlib/registry.py:531:# TODO: needs UTs
./api/.venv/lib/python3.12/site-packages/typing_extensions.py:3267:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/.venv/lib/python3.12/site-packages/asyncio_mqtt/client.py:111:# TODO: Simplify the logic that surrounds `self._outgoing_calls_sem` with
./api/.venv/lib/python3.12/site-packages/asyncio_mqtt/client.py:355:    def id(  # noqa: A003 # TODO: When doing BREAKING CHANGES rename to avoid shadowing builtin id
./api/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578:        # TODO: Add optional support for socket.gethostbyname checking.
./api/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095:        # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
./api/.venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38:    # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
./api/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144:        # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
./api/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234:                # TODO: Arbitrary read value.
./api/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282:            # TODO this is often present from upstream.
./api/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325:    # TODO: This is a woefully incomplete response object, but works for non-streaming.
./api/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332:        decode_content: bool = False,  # TODO: support decoding
./api/.venv/lib/python3.12/site-packages/urllib3/exceptions.py:306:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./api/.venv/lib/python3.12/site-packages/urllib3/util/url.py:454:    # TODO: Remove this when we break backwards compatibility.
./api/.venv/lib/python3.12/site-packages/urllib3/util/request.py:229:    # File-like object, TODO: use seek() and tell() for length?
./api/.venv/lib/python3.12/site-packages/urllib3/connection.py:330:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./api/.venv/lib/python3.12/site-packages/urllib3/connection.py:436:        # object later. TODO: Remove this in favor of a real
./api/.venv/lib/python3.12/site-packages/urllib3/connection.py:561:        # TODO should we implement it everywhere?
./api/.venv/lib/python3.12/site-packages/urllib3/response.py:1005:                # TODO make sure to initially read enough data to get past the headers
./api/.venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20:    # TODO: Remove this in favor of a better
./api/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499:        # TODO should we eliminate the recursion?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503:                    # TODO check whether we need to call `list_hook`
./api/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511:            # TODO is the interaction between `list_hook` and `use_list` ok?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516:                    # TODO check whether we need to call hooks
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863:    TODO: clean up the code here.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/.venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558:            # TODO: Not sure if we need the SecTrustResultType for anything?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./api/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:839:            # TODO version verification
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:922:                # TODO SHA256 digest
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401:        # TODO check k, v for valid values
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:560:    # TODO could add iter* variants
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:984:        # TODO: any other fields wanted
./api/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:1020:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:3568:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522:        # TODO: Add optional support for socket.gethostbyname checking.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659:        # TODO: should I do clean shutdown here? Do I have to?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819:        # TODO: Well, crap.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829:        # TODO: Update in line with above.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./api/.venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1:# TODO: Add Generic type annotations to initialized collections.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122:_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598:        # TODO: Add a deadline?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./api/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227:        # TODO: There is an assumption that the result will be a
./api/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./api/.venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./api/.venv/lib/python3.12/site-packages/pip/_internal/cache.py:278:                # TODO: use DirectUrl.equivalent when
./api/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:227:        # TODO performance: this means we iterate the dependencies at least twice,
./api/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:362:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./api/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:201:        # TODO: Check already installed candidate, and use it if the link and
./api/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:622:        # TODO: Are there more cases this needs to return True? Editable?
./api/.venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:344:        # TODO: In the future, it would be nice if pip supported PEP 691
./api/.venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./api/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:204:        # TODO: Try to get these passing down from the command?
./api/.venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./api/.venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6:# TODO: This needs Python 3.10's improved slots support for dataclasses
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:107:    # TODO: replace this with slots=True when dropping Python 3.9 support.
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:526:    # TODO: handle space after '\'.
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:285:        # TODO: The is_installable_dir test here might not be necessary
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:75:        TODO remove this property together with the legacy resolver, since the new
./api/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./api/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:167:        # TODO: this property is relatively costly to compute, memoize it ?
./api/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:177:                # TODO: get project location from second line of egg_link file
./api/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:557:        # TODO: separate this part out from RequirementPreparer when the v1
./api/.venv/lib/python3.12/site-packages/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./api/.venv/lib/python3.12/site-packages/requests/hooks.py:19:# TODO: response is the only one
./api/.venv/lib/python3.12/site-packages/uvloop/_testbase.py:291:        # TODO This warning has to be fixed in asyncio.
./api/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:221:# TODO at some point, we could switch to an enum flag, so that multiple sources
./api/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:224:    # TODO if/when https://peps.python.org/pep-0767/ is accepted, add 'read_only'
./api/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:319:        # TODO use a match statement when Python 3.9 support is dropped.
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:473:            # TODO: what happens if we don't have a filename?
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1464:        # TODO: verify that we're in the state MultipartState.END, otherwise throw an
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1655:                # TODO: check for error here.
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1685:                # TODO: handle mixed case
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1692:                # TODO: check for errors
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1703:                # TODO: check that we properly handle 8bit / 7bit encoding.
./api/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1764:        # TODO: check the parser's return value for errors?
./api/.venv/lib/python3.12/site-packages/cryptography/hazmat/primitives/asymmetric/rsa.py:221:    # TODO: Replace with lcm(p - 1, q - 1) once the minimum
./api/.venv/lib/python3.12/site-packages/cryptography/x509/name.py:357:        # TODO: this is relatively expensive, if this looks like a bottleneck
./api/.venv/lib/python3.12/site-packages/mdurl/_parse.py:168:            # v0.12 TODO(isaacs): This is not quite how Chrome does things.
./api/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:3216:                        # TODO: Something is odd here. I don't see why packet["info"] can't be None.
./api/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:4674:            # TODO: this type error is a true error:
./api/.venv/lib/python3.12/site-packages/paho/mqtt/matcher.py:47:            # TODO
./api/.venv/lib/python3.12/site-packages/aioredis/lock.py:235:        # TODO: this can be simplified when the context manager is finished
./api/.venv/lib/python3.12/site-packages/aioredis/connection.py:227:    TODO: We're currently passing through two buffers,
./api/.venv/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py:26:# TODO:
./api/.venv/lib/python3.12/site-packages/markdown_it/parser_inline.py:96:            # TODO: remove this workaround when CM standard will allow nested links
./api/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:26:        self.debug = debug  # TODO: We ought to handle 404 cases if debug is set.
./api/.venv/lib/python3.12/site-packages/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./api/.venv/lib/python3.12/site-packages/fastapi/openapi/utils.py:344:                # TODO: probably make status_code a default class attribute for all
./api/.venv/lib/python3.12/site-packages/fastapi/openapi/models.py:147:    # TODO: uncomment and remove below when deprecating Pydantic v1
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:36:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:150:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:236:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:320:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:406:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:490:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:606:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/params.py:690:        # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:55:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:380:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:684:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1000:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1327:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1642:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1956:    # TODO: update when deprecating Pydantic v1, import these types
./api/.venv/lib/python3.12/site-packages/fastapi/routing.py:368:            # TODO: remove this scope later, after a few releases
./api/.venv/lib/python3.12/site-packages/fastapi/routing.py:524:            # TODO: remove when deprecating Pydantic v1
./api/.venv/lib/python3.12/site-packages/fastapi/encoders.py:36:# TODO: pv2 should this return strings instead?
./api/.venv/lib/python3.12/site-packages/fastapi/encoders.py:217:        # TODO: remove when deprecating Pydantic v1
./api/.venv/lib/python3.12/site-packages/fastapi/encoders.py:239:            # TODO: remove when deprecating Pydantic v1
./api/.venv/lib/python3.12/site-packages/fastapi/applications.py:877:        # TODO: remove when discarding the openapi_prefix parameter
./api/.venv/lib/python3.12/site-packages/fastapi/security/oauth2.py:12:# TODO: import from typing when deprecating Python 3.9
./api/.venv/lib/python3.12/site-packages/fastapi/_compat.py:203:            # TODO remove when deprecating Pydantic v1
./api/search/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1024:/* TODO: remove */
./api/search/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1029:/* TODO: move these enums out to the appropriate submodule */
./api/search/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer_v8.h:1073:/* TODO: remove */
./api/search/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1024:/* TODO: remove */
./api/search/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1029:/* TODO: move these enums out to the appropriate submodule */
./api/search/.venv/lib/python3.12/site-packages/nvidia/cudnn/include/cudnn_ops_infer.h:1073:/* TODO: remove */
./api/search/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:81:/* TODO */
./api/search/.venv/lib/python3.12/site-packages/nvidia/nvtx/include/nvtx3/nvtxDetail/nvtxInit.h:88:/* TODO: Detect UWP, a.k.a. Windows Store app, and set this to 0. */
./api/search/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cuda_runtime.h:1391: * TODO detail
./api/search/.venv/lib/python3.12/site-packages/nvidia/cuda_runtime/include/cooperative_groups.h:1173:// TODO: Use a static dispatch to determine appropriate return type
./api/search/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:594:        # TODO: Add logic that removes the TransferState if the transfer is
./api/search/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:644:        # TODO: Not all exceptions are pickleable so if we are running
./api/search/.venv/lib/python3.12/site-packages/s3transfer/processpool.py:899:    # TODO: It may make sense to expose these class variables as configuration
./api/search/.venv/lib/python3.12/site-packages/s3transfer/__init__.py:857:                # TODO: we need a way to reset the callback if the
./api/search/.venv/lib/python3.12/site-packages/psycopg2/tz.py:158:# TODO: pre-generate some interesting time zones?
./api/search/.venv/lib/python3.12/site-packages/psycopg2/_range.py:526:# TODO: probably won't work with infs, nans and other tricky cases.
./api/search/.venv/lib/python3.12/site-packages/cv2/__init__.py:19:# TODO
./api/search/.venv/lib/python3.12/site-packages/PIL/PdfParser.py:616:            # TODO: support reuse of deleted objects
./api/search/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:2279:                    raise RuntimeError(msg)  # XXX TODO
./api/search/.venv/lib/python3.12/site-packages/PIL/IcoImagePlugin.py:75:            # TODO: invent a more convenient method for proportional scalings
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv_types.py:134:    #TODO: Add support for sets provided by the user
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1323:        # TODO : Remove when lambdify accepts 'pymc' as module
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1340:                # TODO: Replace the try-except block with only given_fn(*args)
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1366:                    # TODO: Replace the try-except block with only given_fn(*args)
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1383:            # TODO: Replace the try-except block with only fn(*args)
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1610:            # TODO: do this for drv.py and frv.py if necessary.
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/rv.py:1611:            # TODO: add more distributions here if there are more
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/matrix_distributions.py:114:    ### TODO: Add tests after adding matrix distributions in numpy_rv_map
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/frv.py:460:            #TODO: Implement the mechanism for handling queries for symbolic sized distributions.
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/drv.py:152:        # TODO: support discrete sets with non integer stepsizes
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/joint_rv.py:415:            #TODO: Modify to support integration
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:1694:    .. TODO - What is the difference between these degrees of freedom?
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/crv_types.py:2986:    .. TODO - what does the parameter mean?
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:77:        with ignore_warnings(UserWarning):  # TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:109:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_stochastic_process.py:408:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:677:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1348:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1358:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_compound_rv.py:90:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_finite_rv.py:68:    # TODO: Make iid method!
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_mix.py:80:    with ignore_warnings(UserWarning): ### TODO: Restore tests once warnings are removed
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/random_matrix_models.py:249:        # TODO : Add support for Lie groups(as extensions of sympy.diffgeom)
./api/search/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:10:# TODO: The code below could be made more granular with something like:
./api/search/.venv/lib/python3.12/site-packages/sympy/interactive/tests/test_ipython.py:74:    # TODO: How can we test that the output of a SyntaxError is the original
./api/search/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:732:                    # TODO: Implement this case
./api/search/.venv/lib/python3.12/site-packages/sympy/holonomic/holonomic.py:868:                # TODO: support for singular initial condition
./api/search/.venv/lib/python3.12/site-packages/sympy/logic/algorithms/lra_theory.py:103:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/trigonometry.py:5:# TODO sin(a*x)*cos(b*x) -> sin((a+b)x) + sin((a-b)x) ?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:38:# TODO: Add messages to NonElementaryIntegralException errors
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:205:    # TODO: finish writing this and write tests
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:286:    # TODO: finish writing this and write tests
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:510:# TODO: better name for this function
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:653:            # TODO: Write a dummy function that does this idiom
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/rde.py:713:        # TODO: Is this check necessary, and if so, what should it do if it fails?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/integrals.py:772:        # check for regularity conditions (TODO), see issue 4215
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:201:        # TODO handle derivatives etc
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/transforms.py:745:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:119:    # TODO this needs more polar_lift (c/f entry for exp)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:164:    # TODO can do sin^n, sinh^n by expansion ... where?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:170:    # TODO can do t + a. but can also do by expansion... (XXX not really)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:187:    # TODO these only hold for positive p, and can be made more general
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:189:    # TODO also it would be nice to derive them recursively ...
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:202:    # TODO log(x)/(x+a) and log(x)/(x-1) can also be done. should they
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:204:    # TODO further formulae in this section seem obscure
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:207:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:230:    # TODO exp(-x)*erf(I*x) does not work
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:256:    # TODO all of the following should be derivable
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:282:    # TODO many more formulas. should all be derivable
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:286:    # TODO many more formulas. should all be derivable
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:524:    # TODO should this be a method of meijerg?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:852:    # TODO altered cases 4-7
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:876:    # TODO This leaves only one case from the three listed by Prudnikov.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:900:    # XXX TODO we should reduce order first
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:972:    # TODO should we try both?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:988:    # XXX TODO this is a testing *nightmare*
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/meijerint.py:1445:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/manualintegrate.py:2040:            # TODO: This is for future development, as currently
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:333:        # TODO: This probably doesn't need to be completely recomputed at
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:366:                    # TODO: Would there ever be any benefit from just
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:395:            # TODO: Just put it in self.Tfuncs
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:497:                    # TODO: Add something to backsubs to put exp(const*p)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:530:                        # TODO: give algebraic dependence in error string
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:779:    # TODO: Rewrite algorithms below to use this (?)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:781:    # TODO: Pass through information about why the integral was nonelementary,
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:798:    # TODO: This should go in densetools.py.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:855:    # TODO: Use this on the final result.  That way, we can avoid answers like
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1006:    # TODO: This algorithm appears to be faster in every case
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1007:    # TODO: Verify this and splitfactor() for multiple extensions
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1250:        # TODO also consider the complex roots which should
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1280:    # TODO: Use log_to_atan() from rationaltools.py
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1350:    # TODO: check what Lambda does with RootOf
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1365:    # TODO: verify that this is correct for multiple extensions
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1458:        # TODO: This does not do the right thing when b is False
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1621:    # TODO: Integral from k?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1622:    # TODO: split out nonelementary integral
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/risch.py:1691:    # TODO: This is useful in and of itself, because isinstance(result,
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:114:    # TODO: Merge this with the very similar special_denom() in rde.py
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:158:                        # TODO: Add test
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:822:        # TODO: implement this
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:878:    # TODO: finish writing this and write tests
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:921:        # TODO: We treat this as 'no solution', until the structure
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:952:    # TODO: Write the full algorithm using the structure theorems.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:957:        # TODO: This could be implemented more efficiently.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1035:        # TODO: What should really be done in this case?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1160:        # TODO: What should really be done in this case?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1185:            # TODO: But maybe we can tell if they're not rational, like
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1266:    # TODO: finish writing this and write tests
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/prde.py:1301:        # TODO: we can use more efficient residue reduction from ratint()
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:400:        # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:466:        # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/laplace.py:875:        # TODO not implemented yet, but also not important
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:977:        #  TODO : This part is quite hacky. Should be made more robust with
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/intpoly.py:978:        #  TODO : respect to symbol names and scalable w.r.t higher dimensions.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:235:    # TODO: Skip or make faster
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:250:    # TODO: Add tests for integrate_hyperexponential() from the book
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_risch.py:374:    # TODO: Add a test where two different parts of the extension use a
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:110:    # TODO: rules with sqrt(a*t) and sqrt(a/t) have stopped working after
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:698:    # TODO sinh/cosh shifted come out a mess. also delayed trig is a mess
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:699:    # TODO should this simplify further?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:714:    # TODO can we make erf(t) work?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_laplace.py:756:    # TODO LT of Si, Shi, Chi is a mess ...
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_trigonometry.py:32:    # TODO: remove conds='none' below. For this to work we would have to rule
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:328:    # TODO: Remove conds='none' below, let the assumption take care of it.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1140:    # TODO: Remove conds='none' below, let the assumption take care of it.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_integrals.py:1329:    # TODO: How to test risch=False?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:149:    # TODO what simplifications should be done automatically?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:165:    # TODO it would be nice to test the condition
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:245:    # TODO more orthogonality integrals
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:257:    # TODO can do higher powers, but come out as high order ... should they be
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:262:    # TODO more besseli when tables are extended or recursive mellin works
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:273:    # TODO how does besselj(0, a*x)*besselj(0, b*x) work?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:274:    # TODO how does besselj(0, x)**2*besselj(1, x)**2 work?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:275:    # TODO sin(x)*besselj(0, x) etc come out a mess
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:276:    # TODO can x*log(x)*besselj(0, x) be done?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:277:    # TODO how does besselj(1, x)*besselj(0, x+a) work?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:278:    # TODO more indefinite integrals when struve functions etc are implemented
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:374:    # TODO gammasimp cannot prove that the factor is unity
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:517:    # TODO conditions are a mess
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:523:    # TODO gamma, rayleigh
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:579:    # TODO are there other distributions supported on (-oo, oo) that we can do?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:658:    # TODO maybe simplify the inequalities? when the simplification
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:668:    # TODO FT(besselj(0,x)) - conditions are messy (but for acceptable reasons)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:105:    # TODO: when bound_degree() can handle this, test degree bound from that too
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:147:    # TODO: Add test for deg(b) <= 0 with b small
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:262:    # TODO: Add more tests
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_prde.py:280:    # TODO: Add more tests, including ones with exponentials
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:80:    # TODO does not work with bneg, argument wrong. Needs changes to matching.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:164:    # TODO we cannot currently do these (needs summation of 3F2(-1))
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:244:    # TODO we can't do any of these (delicate cancellation)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:253:    # TODO bessely(a, x)*besselk(a, x) is a mess
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:264:    # TODO products of besselk are a mess
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:271:    # TODO exp(x/2)*besselk(a, x/2) [etc] cannot currently be done
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:272:    # TODO various strange products of special orders
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:386:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:420:    # TODO this comes out as an amazing mess, but simplifies nicely
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:436:    # TODO this can be further simplified!
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:444:    # TODO more
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:466:    # TODO for this to work with real a, need to expand abs(a*x) to abs(a)*abs(x)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:479:    # TODO IFT is a *mess*
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:481:    # TODO IFT
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:492:    # TODO IFT without factoring comes out as meijer g
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:502:    # TODO IFT (comes out as meijer G)
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:504:    # TODO besselj(n, x), n an integer > 0 actually can be done...
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_transforms.py:506:    # TODO are there other common transforms (no distributions!)?
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:221:    # TODO: it looks like this used to work just by coincindence and
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:254:    # TODO: heurisch() is off by a constant: -3/4. Possibly different permutation
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_heurisch.py:343:# TODO: convert the rest of PMINT tests:
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:71:    # TODO: add more tests here
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:114:    # TODO: Add test for when the degree bound becomes larger after limited_integrate
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:115:    # TODO: Add test for db == da - 1 case
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:118:    # TODO: Add tests
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:119:    # TODO: Add test for when the degree becomes larger after parametric_log_deriv()
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:179:    # TODO: Add more exp tests, including tests that require is_deriv_in_field()
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:193:    # TODO: Add more primitive tests, including tests that require is_deriv_in_field()
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_rde.py:197:    # TODO: Add more tests for rischDE, including ones from the text
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:495:    # TODO: caching is significant factor for why permutations work at all. Change this.
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:700:        # TODO: Currently it's better to use symbolic expressions here instead
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/heurisch.py:726:                # TODO: Non-polynomial expression. This should have been
./api/search/.venv/lib/python3.12/site-packages/sympy/core/exprtools.py:1551:            # XXX TODO there should be a way to inspect what order the terms
./api/search/.venv/lib/python3.12/site-packages/sympy/core/facts.py:139:       TODO: write about
./api/search/.venv/lib/python3.12/site-packages/sympy/core/facts.py:310:        """process a -> b rule"""   # TODO write more?
./api/search/.venv/lib/python3.12/site-packages/sympy/core/facts.py:398:       # TODO b | c
./api/search/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:180:# TODO: we should use the warnings module
./api/search/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:278:# TODO caching with decorator, but not to degrade performance
./api/search/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1456:                #TODO: this can probably be optimized more
./api/search/.venv/lib/python3.12/site-packages/sympy/core/numbers.py:1885:    # TODO make it decorator + bytecodehacks?
./api/search/.venv/lib/python3.12/site-packages/sympy/core/expr.py:3692:        # TODO: Smarter heuristics
./api/search/.venv/lib/python3.12/site-packages/sympy/core/add.py:292:                seq.extend(o_args)  # TODO zerocopy?
./api/search/.venv/lib/python3.12/site-packages/sympy/core/function.py:212:        # TODO: Look at nargs
./api/search/.venv/lib/python3.12/site-packages/sympy/core/function.py:1416:            #TODO: check if assumption of discontinuous derivatives exist
./api/search/.venv/lib/python3.12/site-packages/sympy/core/function.py:1673:        # TODO: deprecate?  YES, make this 'enumerated_variables' and
./api/search/.venv/lib/python3.12/site-packages/sympy/core/function.py:1675:        # TODO: support for `d^n`?
./api/search/.venv/lib/python3.12/site-packages/sympy/core/symbol.py:637:    # TODO add check against another Wild
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_function.py:1447:    # TODO: Disable string inputs (https://github.com/sympy/sympy/issues/11003)
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_assumptions.py:410:    # TODO Change to x.is_nonzero is None
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_diff.py:138:    # TODO: assert diff(x**2, (x, n)) == x**(2-n)*ff(2, n)
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_args.py:3958:@SKIP("TODO: sympy.physics.quantum.shor: Cmod Not Implemented")
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_basic.py:208:    # TODO UndefinedFunction does not subclass Expr
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_facts.py:70:# TODO move me to appropriate place
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_expr.py:917:    # TODO UndefinedFunction does not subclass Expr
./api/search/.venv/lib/python3.12/site-packages/sympy/core/mul.py:435:            # TODO: Make non-commutative exponents not combine automatically
./api/search/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1049:        # TODO: Should these be self.func?
./api/search/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1190:        # TODO: Should this be self.func?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/numbers.py:2758:    # TODO: make this a class like bell()
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/combinatorial/factorials.py:423:        # TODO: extend this to complex numbers?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:283:        if arg.is_Add: # TODO, implement more if deep stuff here
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/hyperbolic.py:480:        if arg.is_Add: # TODO, implement more if deep stuff here
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/_trigonometric_special.py:3:TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/exponential.py:985:        # TODO new and probably slow
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:578:                # TODO simplify hi <= upto
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:498:        if arg.is_Add:  # TODO, implement more if deep stuff here
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:499:            # TODO: Do this more efficiently for more than two terms
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:867:        if arg.is_Add:  # TODO: Do this more efficiently for more than two terms
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1579:    # TODO refactor into TrigonometricFunction common parts of
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_piecewise.py:1223:    # TODO raise error if function is discontinuous at limit of
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/tests/test_complexes.py:938:    # TODO XXX why does abs(x)._eval_evalf() not fall back to global evalf?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/gamma_functions.py:687:                # TODO n == 1 also can do some rational z
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/bessel.py:25:# TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:47:# TODO should __new__ accept **options?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:48:# TODO should constructors should check if parameters are sensible?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:210:        # TODO should we check convergence conditions?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:543:        # TODO should we check convergence conditions?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/hyper.py:980:    # TODO this can be nicer
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/delta_functions.py:656:            # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:24:# TODO series expansions
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:25:# TODO see the "Note:" in Ei
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:1220:        # TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/error_functions.py:2738:            # TODO: is the series really correct?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:150:        # TODO Add more simplififcation here
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:179:        # TODO: Make sure n \in N
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:180:        # TODO: Assert |m| <= n ortherwise we should return 0
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:189:        # TODO: Make sure n \in N
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:190:        # TODO: Assert |m| <= n ortherwise we should return 0
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:197:        # TODO: Make sure theta \in R and phi \in R
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/spherical_harmonics.py:202:        # TODO: Handle deep and hints
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:150:            # TODO should something be polarified here?
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:179:        # TODO use minpoly instead of ad-hoc methods when issue 5888 is fixed
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/zeta_functions.py:181:            # TODO reference?
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/setexpr.py:84:        # TODO: this could be implemented straight into `imageset`:
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2486:                    know its dimensions. TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2555:    # TODO: check subsets (`func` in `setv`)
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/sets.py:2558:    # TODO: support more
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:46:        # TODO: handle unevaluated condition.
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:49:        # TODO: `s2 > s1` could be unevaluated.
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/power.py:85:    # TODO: add logic for open intervals?
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:34:    # TODO: some intervals containing 0 and oo will fail as 0*oo returns nan.
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/mul.py:41:    # TODO: handle symbolic intervals
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:38:    # TODO: handle functions with infinitely many solutions (eg, sin, tan)
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/functions.py:39:    # TODO: handle multivariate functions
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/handlers/intersection.py:371:            # TODO: Design a technique to handle multiple-inverse
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:29:    # TODO: add support for more functions in the future:
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_setexpr.py:206:    # TODO: some expressions cannot be calculated due to bugs (currently
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:124:                # TODO: is this break necessary?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:297:        # TODO: this assumes that all arguments are matrices, it may not be the case:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:448:    # TODO: check if subremoved should be permuted as well...
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_array_to_matrix.py:542:        # TODO: move this to ElementwiseApplyFunction
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_convert_array_to_matrix.py:189:    # TODO: this is returning a wrong result:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:50:    # TODO: not yet supported:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:54:    # TODO: not yet supported:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/tests/test_array_expressions.py:445:    # TODO: reverse operation starting with `PermuteDims` and getting down to `bb`...
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/from_indexed_to_array.py:113:        # TODO: check that Kronecker delta is only contracted to one other element:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:605:        # TODO: swap args positions in order to simplify the expression:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:606:        # TODO: this should be in a function
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:641:        # TODO: function in order to permute the args:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:842:        # TODO: add API for total rank and cumulative rank:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1263:        # TODO: add API for total rank and cumulative rank:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/expressions/array_expressions.py:1390:        # TODO: check that `expr` has `.subranks`:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/array_derivatives.py:91:        # TODO: this could be done with multiple-dispatching:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/array/ndim_array.py:567:        # TODO: add checks for dimensions for `value`?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2208:        # TODO: add possibility of metric after (spinors)
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:2590:            # TODO: what is the part which is not a coeff?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3064:        # TODO: this could be optimized by only swapping the indices
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3203:    # TODO: put this into TensExpr?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3209:    # TODO: put this into TensExpr?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3225:        # TODO: inefficient, this should be done at root level only:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3268:        # TODO: check data compatibility with properties of tensor.
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3344:        # TODO: replace .args[0] with .name:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3359:            # TODO: if there is no metric present, the derivative should be zero?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3661:    # TODO: this method should be private
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:3662:    # TODO: should this method be renamed _from_components_free_dum ?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4540:        # TODO: inherit dummies from expr
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:4563:        # TODO: can be improved:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tensor.py:5136:    # TODO: add a dum_to_components_map ?
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:89:#   TODO:  (some ideas for improvement)
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/indexed.py:375:         broadcasting.  (TODO)
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/tests/test_tensor.py:497:    # TODO: add check for *get_symmetric_group_sgs(0)
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/_compilation/__init__.py:9:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:920:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:956:    # TODO: Replace solve with solveset when it gives Lambert solution
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:966:    # TODO: x = [-1, 2*(+/-asinh(1)*I + n*pi}, 3*(pi/6 + n*pi/3)]
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:967:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1014:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1032:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1038:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1047:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1052:    # TODO: Replace solve with solveset, as of now test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1059:    # TODO: Replace solve with solveset which gives both [+/- current answer]
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1077:    # TODO: Replace solve with solveset, as of now
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1084:    # TODO: Replace solve with solveset, as of now
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1092:    # TODO: Replace solve with solveset, as of now
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1099:    # TODO: Replace solve with solveset, as of now
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1118:    # TODO: Replace solve with solveset, as of now
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:1194:    # TODO: Replace solve with solveset, as of now
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:2252:    # TODO: Replace solve with solveset, current test fails for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_wester.py:3082:    # TODO: Replace solve with solveset, when it works for solveset
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:382:    # TODO: fix pickling of Options class (see GroebnerBasis._options)
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:409:        check(c, exclude=[0, 1], check_attr=False) # TODO: Py3k
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:420:    # TODO: AssertionError: assert id(obj) not in self.memo
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:424:    # TODO: AssertionError: assert id(obj) not in self.memo
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:438:    # TODO: fix pickling of ModularInteger
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:444:    # TODO: fix pickling of RealElement
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:448:    # TODO: fix pickling of ComplexElement
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:457:    # TODO: fix pickling of ModularInteger
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:472:        # TODO: fix pickling of ModularInteger
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:489:    # TODO: fix pickling of RealElement
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:493:    # TODO: fix pickling of ComplexElement
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:500:    # TODO: AssertionError
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:504:    # TODO: AttributeError: 'PolyElement' object has no attribute 'ring'
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:526:    # TODO: Argh, Python is so naive. No lambdas nor inner function support in
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:559:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:563:    # TODO: TypeError: can't pickle instancemethod objects
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:612:    # TODO: PicklingError: Can't pickle <function <lambda> at 0x38578c0>: it's not found as __main__.<lambda>
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:622:    # TODO: TypeError: __init__() takes at least 3 arguments (1 given)
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:635:    # TODO: fix pickling of `symbols' flag
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_pickling.py:639:# TODO: def test_pickling_polys_rootisolation():
./api/search/.venv/lib/python3.12/site-packages/sympy/categories/diagram_drawing.py:2494:                # prop is a Symbol.  TODO: Find out why.
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/bivariate.py:34:    # TODO it would be good to pick the smallest divisible power
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:798:    # TODO: Use solveset here
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1072:            # TODO: Hint first order series should match only if d/e is analytic.
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/ode.py:1783:    # TODO: if two solutions are solved for f(x), we still want to be
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/single.py:204:    # TODO: Add methods that can be used by many ODE solvers:
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:359:    # TODO: improve solution testing
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/solvers.py:2902:# TODO: option for calculating J numerically
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:2566:    # TODO: pre-simplification: Not necessary but may simplify
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/diophantine/diophantine.py:3893:        # TODO: Fall back to diop_DN when k = 2
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:175:        # TODO : 'best' hint should be implemented when adequate
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:284:    # TODO : For now pde.py uses support offered by the ode_order function
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:521:    # TODO : For now homogeneous first order linear PDE's having
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:611:    # TODO : For now homogeneous first order linear PDE's having
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:323:    # TODO: Is the above solution set definitely complete?
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solveset.py:1862:    # TODO: add more simple testcases when solveset returns
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_solvers.py:1727:    # TODO: Investigate why currently solution [0] is preferred over [1].
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/tests/test_polysys.py:185:    # TODO: does this really have to be so complicated?!
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:694:        # TODO : We should not blindly recurse through all args of arbitrary expressions like this
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/solveset.py:1662:        # TODO Case: A-> function of symbol, can be extended here
./api/search/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:353:        # TODO: use |G:H| = |G|/|H| (currently H can't be made into a group)
./api/search/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:870:    # TODO:: Sims points out in [Sim94] that performance can be improved by
./api/search/.venv/lib/python3.12/site-packages/sympy/combinatorics/fp_groups.py:903:            # TODO: this should support input of a list of general words
./api/search/.venv/lib/python3.12/site-packages/sympy/combinatorics/coset_table.py:985:    # TODO: complete the docstring
./api/search/.venv/lib/python3.12/site-packages/sympy/combinatorics/tensor_can.py:1015:    TODO: use baseswap in the case in which if it fails in finding a
./api/search/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:666:        # TODO: Replace solve with nonlinsolve, when nonlinsolve will be able to solve in real domain
./api/search/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:919:        # TODO: Replace solve with solveset, when this line is tested
./api/search/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:927:                # TODO: Replace solve with solveset, when these lines are tested
./api/search/.venv/lib/python3.12/site-packages/sympy/geometry/ellipse.py:1290:            # TODO: Replace solve with solveset, when this line is tested
./api/search/.venv/lib/python3.12/site-packages/sympy/geometry/plane.py:412:                # TODO: Replace solve with solveset, when this line is tested
./api/search/.venv/lib/python3.12/site-packages/sympy/concrete/summations.py:607:        # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/concrete/tests/test_sums_products.py:1043:    # TODO Implement matrix geometric series summation.
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:78:#TODO debugging output
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/experimental_lambdify.py:403:    #TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:240:        # TODO The 3D stuff
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/backends/matplotlibbackend/matplotlib.py:304:        #TODO after fixing https://github.com/ipython/ipython/issues/1255
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/utils.py:159:    # TODO: prange check goes here
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:128:        # TODO: _process_piecewise check goes here
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:204:# TODO: Add color arrays for plots.
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:205:# TODO: Add more plotting options for 3d plots.
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/plot.py:206:# TODO: Adaptive sampling for 3D plots.
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:381:                # TODO: set cse=True once this issue is solved:
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1146:        # TODO: for now, I assume that numpy functions are going to succeed
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1156:                # TODO: what if points[k][idx]==e or points[k][idx+1]==e?
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1774:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1790:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1871:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:1972:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/plotting/series.py:2094:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:32:# TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/agca/modules.py:1281:        # TODO this can be done more efficiently
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/agca/ideals.py:102:    # TODO more
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/polyroots.py:761:    # TODO: This is fragile. Figure out how to make this independent of construct_domain().
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/ring_series.py:1977:    # TODO Use _parallel_dict_from_expr instead of sring as sring is
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:515:        # TODO better data structure!!!
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:675:        # TODO apply the product criterion?
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:683:        # TODO mergesort?
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/distributedmodules.py:726:    # (TODO again, better data structures)
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:450:        # TODO: implement this in from_ methods
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/domains/domain.py:459:        else: # TODO: remove this branch
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:9:# TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/domains/quotientring.py:142:        # TODO optionally disable reduction?
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/domains/polynomialring.py:40:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/domains/fractionfield.py:34:        # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:796:    # TODO: to improve performance, choose the main variable here
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/modulargcd.py:2129:# TODO: add support for algebraic function fields
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:163:    # TODO: rewrite this so that it doesn't use expand() (see poly()).
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:467:        # TODO: should AlgebraicField be a Composite domain?
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:1251:        elif len(self) <= 5: # TODO: use an actual density measure
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:2275:        else: # TODO: don't use dense representation (port PRS algorithms)
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/rings.py:3044:    # TODO: following methods should point to polynomial
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:173:    # TODO: Use a nontrivial pivoting strategy to control intermediate
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/matrices/dense.py:321:    # TODO: Use a non-trivial pivoting strategy. Even just row swapping makes a
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/matrices/normalforms.py:11:# TODO (future work):
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:23:# TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/matrices/_dfm.py:660:        # TODO: Implement similar algorithms for DDM and SDM.
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/matrices/rref.py:256:            # TODO: Add partial pivot support to the sparse implementations.
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_distributedmodules.py:50:# TODO test to_dict?
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/tests/test_heuristicgcd.py:53:    # TODO: assert heugcd(f, f.diff(x))[0] == g
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/heuristicgcd.py:124:    # TODO: don't expose poly repr implementation details
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/polyutils.py:378:        # TODO: Integrate this into expand() itself
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/basis.py:216:        # TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/modules.py:1839:        # TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/polys/numberfields/primes.py:678:    # TODO (future work):
./api/search/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:327:    # TODO: handle piecewise defined functions
./api/search/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:328:    # TODO: handle transcendental functions
./api/search/.venv/lib/python3.12/site-packages/sympy/calculus/util.py:329:    # TODO: handle multivariate functions
./api/search/.venv/lib/python3.12/site-packages/sympy/calculus/accumulationbounds.py:688:        # TODO : Devise a better method for Union of AccumBounds
./api/search/.venv/lib/python3.12/site-packages/sympy/vector/coordsysrect.py:702:            # TODO: trigsimp is needed here so that the matrix becomes
./api/search/.venv/lib/python3.12/site-packages/sympy/vector/operators.py:214:        # TODO: is case of many coord systems, this gets a random one:
./api/search/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:158:        # TODO: This gets a random coordinate system in case of multiple ones:
./api/search/.venv/lib/python3.12/site-packages/sympy/vector/functions.py:503:        # TODO : The following line introduces a performance issue
./api/search/.venv/lib/python3.12/site-packages/sympy/codegen/rewriting.py:330:    # TODO: We should be able to support more than 2 elements
./api/search/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:410:def test_optims_numpy_TODO():
./api/search/.venv/lib/python3.12/site-packages/sympy/codegen/tests/test_rewriting.py:442:    NUMBER_OF_DIGITS = 25   # TODO: this should ideally be automatically handled.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:526:    #TODO A class Complex may be implemented. The BeamParameter may
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:885:    #TODO add the other possible arguments
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:906:#TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/optics/gaussopt.py:911:#TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/vector/vector.py:735:        # TODO : Circular dependency if imported at top. Should move
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:47:    # TODO : The unit vectors should print with subscripts but they just
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/vector/tests/test_printing.py:50:    # TODO : The pretty print division does not print correctly here:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:35:    TODO: Handle condition such as symbols have subscripts/superscripts
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:94:    # TODO: Need to handle printing
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:172:        #TODO: Current version ignores the indices set for partial trace.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:189:        # TODO : improve this implementation
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/trace.py:192:    #TODO: Review if the permute method is needed
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:3:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:428:            # TODO: make sure the hilbert spaces of the bra and ket are
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operator.py:491:        # TODO if operands are tensorproducts this may be will be handled
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/shor.py:36:    TODO: implement a decompose property that returns how to do this in terms
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:3:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:417:            #TODO: Add support for sets of operators
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/represent.py:451:    TODO (?): Support for Muls and other types of expressions?
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cartesian.py:3:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixutils.py:141:# TODO: Move this into sympy.matrices.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/gate.py:242:            # TODO: This can be optimized to reduce the number of Qubit
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:104:    # TODO: don't expand the scalars in front of each Mul.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/qapply.py:251:    # TODO: I may need to expand before returning the final result.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/matrixcache.py:78:        # TODO: explore different sparse formats. But sparse.kron will use
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tensorproduct.py:151:        # TODO: disallow nested TensorProducts.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:145:        # TODO: add methods for uncoupling operators
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:157:    # TODO: move this to qapply_Mul
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:165:        #TODO: use options to use different j values
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:616:        # TODO: move evaluation up to represent function/implement elsewhere
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1017:            # TODO: better way to get angles of rotation
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/spin.py:1487:            # TODO: Need hilbert space fix, see issue 5732
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:1:#TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:486:    #TODO: Improve simplification method
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/cg.py:675:    # TODO: Check for symmetries
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_trace.py:82:    #TODO: needed while testing reduced density operations, etc.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_density.py:269:    #TODO: test for invalid arguments
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:3:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_printing.py:678:    # TODO: Fix non-unicode pretty printing
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/tests/test_cartesian.py:113:    # TODO: Add tests for representations
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/operatorset.py:13:TODO List:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/quantum/density.py:21:    TODO: Density operator support for Qubits
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:351:                # TODO: should this raise a warning?
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/dimensions.py:522:        #TODO: the inversion will fail if the system is inconsistent, for
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:206:    # TODO: decide whether to allow such expression in the future
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:227:    # TODO: Pow only support structural equality:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:244:    # TODO: need better simplification routine:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:249:    # TODO: need a better way to simplify expressions containing units:
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/units/tests/test_quantities.py:253:    # TODO: fix this, it should give `m` without `Abs`
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/kane.py:630:    # TODO : Remove `new_method` after 1.1 has been released.
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/mechanics/tests/test_particle.py:55:    # TODO make the result not be system-dependent
./api/search/.venv/lib/python3.12/site-packages/sympy/series/gruntz.py:633:    # TODO this should not be necessary
./api/search/.venv/lib/python3.12/site-packages/sympy/series/series_class.py:70:        TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/series/tests/test_formal.py:441:    f = x*exp(x)*sin(2*x)  # TODO: rsolve needs improvement
./api/search/.venv/lib/python3.12/site-packages/sympy/series/tests/test_order.py:162:    # TODO : A better output for Order(log(x) + 1/log(x))
./api/search/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:148:    # TODO zeta function series
./api/search/.venv/lib/python3.12/site-packages/sympy/series/tests/test_gruntz.py:152:    # TODO 8.35 - 8.37 (bessel, max-min)
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/matrices.py:655:        TODO: Implement algorithm for sparse matrices (SFF),
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/hadamard.py:165:# TODO Implement algorithm for rewriting Hadamard product as diagonal matrix
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:52:    # TODO: this is commented because it slows down the tests.
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:105:    # TODO: find a way to represent a four-dimensional zero-array:
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:225:    # TODO: TensorProduct is not supported
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:292:    # TODO: no support for TensorProduct.
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:407:    # TODO: restore this result (currently returning the transpose):
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:416:    # TODO: restore (currently returning the transpose):
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:435:    # TODO: not implemented
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:444:    # TODO: wrong
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/expressions/tests/test_derivatives.py:448:    # TODO: wrong
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/determinant.py:731:    TODO: Implement algorithm for sparse matrices (SFF),
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/tests/test_commonmatrix.py:1167:    # TODO: currently not working as ``_MinimalMatrix`` cannot be sympified:
./api/search/.venv/lib/python3.12/site-packages/sympy/matrices/matrixbase.py:3614:        TODO: Implement algorithm for sparse matrices (SFF),
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/matrices.py:70:    # TODO: Add handlers to make these keys work with
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/common.py:17:    # TODO: Add examples
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:238:    # TODO: Add examples
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:337:    # TODO: Add examples
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/sets.py:394:    # TODO: Add examples
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/predicates/calculus.py:57:    # TODO: Add examples
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/refine.py:53:        # TODO: this will probably not work with Integral or Polynomial
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:47:    # TODO: implement sathandlers system for the matrices.
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:77:    # TODO: implement sathandlers system for the matrices.
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/matrices.py:94:    # TODO: implement sathandlers system for the matrices.
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/handlers/order.py:218:    # TODO: This should be deducible from the nonzero handler
./api/search/.venv/lib/python3.12/site-packages/sympy/assumptions/satask.py:103:        # TODO: Run additional checks to see which combination of the
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/latex/lark/transformer.py:660:            # TODO: ANTLR refers to ISO 80000-2:2019. should we keep base 10 or base 2?
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/c/c_parser.py:520:            #TODO: No string type in AST
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:102:            # TODO: Arithmetic Assignment
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:151:            # TODO: Integer Binary Operations
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:239:            # TODO:Numbers when the LFortran ASR is updated
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/fortran/fortran_parser.py:257:            # TODO: Return statement, variable declaration
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:796:            # TODO: Currently only works with symbols. Make it work for dynamicsymbols.
./api/search/.venv/lib/python3.12/site-packages/sympy/parsing/autolev/_listener_autolev_antlr.py:1269:            # TODO** Parse block matrices
./api/search/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:1936:        # TODO parse integers as well ?
./api/search/.venv/lib/python3.12/site-packages/sympy/testing/runtests.py:2023:        # TODO: Should these be protected?
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:26:# TODO you are a bit excessive in the use of Dummies
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:27:# TODO dummy point, literal field
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:28:# TODO too often one needs to call doit or simplify on the output, check the
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1101:        # TODO: you need a real dummy function for the next line
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1309:                    if c:  # TODO this is ugly - the Commutator can be Zero and
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1438:    # TODO the calculation of signatures is slow
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1439:    # TODO you do not need all these permutations (neither the prefactor)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1594:        # TODO: you need a real dummy function for the next line
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1892:    # TODO Is this a good idea?
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1919:    # TODO move some of this to class methods.
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1920:    # TODO rewrite using the .as_blah_blah methods
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1965:    # TODO move some of this to class methods.
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/diffgeom.py:1966:    # TODO rewrite using the .as_blah_blah methods
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_hyperbolic_space.py:86:    #TODO - it would be nice to have index contraction built-in
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:103:    #TODO assert m == R2_r.transform(R2_p, R2_p.transform(R2_r, [a, b])).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:117:    #TODO assert m == R3_r.transform(R3_c, R3_c.transform(R3_r, m)).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:120:    #TODO assert m == R3_r.transform(R3_s, R3_s.transform(R3_r, m)).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:123:    #TODO assert m == R3_c.transform(R3_s, R3_s.transform(R3_c, m)).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:128:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_c, R3_c.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:131:        #TODO assert m == R3_r.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_r, m)).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_diffgeom.py:134:        #TODO assert m == R3_c.coord_tuple_transform_to(R3_s, R3_s.coord_tuple_transform_to(R3_c, m)).applyfunc(simplify)
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:19:    #TODO assert point.subs(x, 2) == Point(cs, [2, y])
./api/search/.venv/lib/python3.12/site-packages/sympy/diffgeom/tests/test_class_structure.py:20:    #TODO assert point.free_symbols == set([x, y])
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/str.py:962:        #TODO : Handle indices
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:107:    # TODO: a better class structure would avoid this mess:
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tensorflow.py:202:        # TODO: is this necessary?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/llvmjitcode.py:95:    # TODO - assumes all called functions take one double precision argument.
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:200:# TODO: Make brackets adjust to height of contents
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty_symbology.py:333:    # TODO robustify when no unicodedat available
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1574:        # TODO should exp_polar be printed differently?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1910:            #TODO: Move this code to prettyForm
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2239:        # TODO: the stuff to the left of the | and the stuff to the right of
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2602:        # TODO: copy-pasted from _print_Function: can we do better?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2671:                # TODO incorporate order
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:2808:        #TODO: Handle indices
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/stringpict.py:10:TODO:
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:4575:    # TODO: The "x in N" parts below should be centered independently of the
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7256:    # TODO: add support for ASCII pretty.
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/tests/test_pretty.py:7620:    # TODO: TBD polylog(s - 1, z)
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:238:    # TODO: merge this with the above, which requires a lot of test changes
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:1176:        # TODO should exp_polar be printed differently?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2585:                # TODO incorporate order
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2777:        # TODO: This expression is potentially confusing,
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2785:        # TODO nicer fractions for few generators...
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2802:        # TODO nicer fractions for few generators...
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/latex.py:2850:        # TODO: Handle indices
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:182:@SKIP  # TODO - this is currently not checked but should be implemented
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:236:    # TODO - matrix broadcasting?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_aesaracode.py:611:    # assert theq(aesara_code_(sy.Ne(x, y)), aet.neq(xt, yt))  # TODO - implement
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_latex.py:2079:    #TODO: Handle indices
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:172:@SKIP  # TODO - this is currently not checked but should be implemented
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:226:    # TODO - matrix broadcasting?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_theanocode.py:599:    # assert theq(theano_code_(sy.Ne(x, y)), tt.neq(xt, yt))  # TODO - implement
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:93:    # TODO more tests
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:646:    # TODO: Apply different strategies, considering expression pattern:
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1087:        # TODO: see if x*log(a)+x*log(a)*log(b) -> x*log(a)*(1+log(b))?
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/simplify.py:1247:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:50:#   TODO work this out in detail.
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:86:    # TODO see if this can work as Mod(x, 1); this will require
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:253:    # TODO branching
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:736:        # TODO with symbolic parameters, it could be advantageous
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1947:    # TODO tons of more formulae
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:1991:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2116:    # TODO for now, we use the following simple heuristic: inverse-shift
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2245:    # TODO the following would be possible:
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2250:    # TODO Also, we tend to create combinations of gamma functions that can be
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/hyperexpand.py:2443:    # TODO it would be helpful to give conditions under which the integral
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:121:    # TODO
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:116:    # TODO [a+1, aRational(-1, 2)], [2*a]
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:130:    # TODO hyperexpand(hyper([a], [2*a + 1], z))
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:131:    # TODO [S.Half, a], [Rational(3, 2), a+1]
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:135:    # TODO [a], [a - S.Half, 2*a]
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:949:    # TODO polys
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1011:    # TODO LOTS more
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/tests/test_hyperexpand.py:1039:    # TODO LOTS more
./api/search/.venv/lib/python3.12/site-packages/sympy/simplify/gammasimp.py:393:                    # TODO is there a better heuristic?
./api/search/.venv/lib/python3.12/site-packages/tqdm/gui.py:26:    # TODO: @classmethod: write() on GUI?
./api/search/.venv/lib/python3.12/site-packages/tqdm/utils.py:9:# TODO consider using wcswidth third-party package for 0-width characters
./api/search/.venv/lib/python3.12/site-packages/tqdm/cli.py:117:# TODO: add custom support for some of the following?
./api/search/.venv/lib/python3.12/site-packages/tqdm/cli.py:125:        TODO: find out why this is needed.
./api/search/.venv/lib/python3.12/site-packages/tqdm/rich.py:74:    # TODO: @classmethod: write()?
./api/search/.venv/lib/python3.12/site-packages/tqdm/std.py:1442:        # TODO: private method
./api/search/.venv/lib/python3.12/site-packages/tqdm/__init__.py:3:from .cli import main  # TODO: remove in v5.0.0
./api/search/.venv/lib/python3.12/site-packages/tqdm/__init__.py:4:from .gui import tqdm as tqdm_gui  # TODO: remove in v5.0.0
./api/search/.venv/lib/python3.12/site-packages/tqdm/__init__.py:5:from .gui import trange as tgrange  # TODO: remove in v5.0.0
./api/search/.venv/lib/python3.12/site-packages/tqdm/tk.py:31:    # TODO: @classmethod: write()?
./api/search/.venv/lib/python3.12/site-packages/anyio/_core/_fileio.py:416:        def info(self) -> Any:  # TODO: add return type annotation when Typeshed gets it
./api/search/.venv/lib/python3.12/site-packages/uvicorn/protocols/websockets/wsproto_impl.py:120:            # TODO: Remove `type: ignore` when wsproto fixes the type annotation.
./api/search/.venv/lib/python3.12/site-packages/sentence_transformers/backend.py:367:# TODO: Fill in the PR number
./api/search/.venv/lib/python3.12/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py:378:        # TODO: Ensure this primary_metric works as expected, also with bolding the right thing in the model card
./api/search/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:253:        # TODO: This is rather inefficient, as we load all data into memory. We might benefit from a more efficient solution
./api/search/.venv/lib/python3.12/site-packages/sentence_transformers/fit_mixin.py:323:            # load_best_model_at_end=save_best_model, # <- TODO: Look into a good solution for save_best_model
./api/search/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1405:# TODO: Fill in the PR number
./api/search/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:118:                # TODO: Consider following these steps automatically so we can load PEFT models with other backends
./api/search/.venv/lib/python3.12/site-packages/qdrant_client/local/local_collection.py:1600:        # TODO: use search_filter once with have an HasVector like condition
./api/search/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:238:                # TODO is this the right name for the data attribute ?
./api/search/.venv/lib/python3.12/site-packages/tokenizers/tools/visualizer.py:305:        # TODO I think there is an edge case here where an annotation's span might not close
./api/search/.venv/lib/python3.12/site-packages/torchvision/_utils.py:14:            # TODO: use `add_suggestion` from torchvision.prototype.utils._internal to improve the error message as
./api/search/.venv/lib/python3.12/site-packages/torchvision/utils.py:315:    # TODO: There might be a way to vectorize this
./api/search/.venv/lib/python3.12/site-packages/torchvision/ops/_utils.py:11:    # TODO add back the assert
./api/search/.venv/lib/python3.12/site-packages/torchvision/ops/poolers.py:36:# TODO: (eellison) T54974082 https://github.com/pytorch/pytorch/issues/26744/pytorch/issues/26744
./api/search/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:45:    # TODO: It's possible the masking here is unnecessary if y and
./api/search/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:80:# TODO: this doesn't actually cache
./api/search/.venv/lib/python3.12/site-packages/torchvision/ops/roi_align.py:81:# TODO: main library should make this easier to do
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video.py:155:        # TODO: we should change all of this from ground up to simply take
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video.py:190:        # TODO check if stream needs to always be the video stream here or not
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video.py:193:        # TODO add some warnings in this case
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video.py:206:        # TODO add a warning
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video.py:321:            # TODO raise a warning?
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:160:            # TODO: load metadata
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video_reader.py:166:            # TODO: add extradata exception
./api/search/.venv/lib/python3.12/site-packages/torchvision/datasets/kinetics.py:115:        # TODO: support test
./api/search/.venv/lib/python3.12/site-packages/torchvision/datasets/video_utils.py:388:            # TODO: Revert it once the bug is fixed.
./api/search/.venv/lib/python3.12/site-packages/torchvision/datasets/folder.py:267:# TODO: specify the return type
./api/search/.venv/lib/python3.12/site-packages/torchvision/datasets/celeba.py:173:                # TODO: refactor with utils.verify_str_arg
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:39:# TODO: Once torchscript supports Enums with staticmethod
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:1564:    # TODO: if image shape is [N1, N2, ..., C, H, W] and
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:70:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:94:        # TODO: replace with dtype.is_floating_point when torchscript supports it
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:392:        # TODO: Jit is failing on loading this op when scripted and saved
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:862:    # TODO: we should expect bincount to always be faster than histc, but this
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_color.py:36:    # TODO: Maybe move the validation that num_output_channels is 1 or 3 to this function instead of callers.
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/__init__.py:93:    hflip,  # TODO: Consider moving all pure alias definitions at the bottom of the file
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:186:    # TODO: Add _xywh_to_cxcywh and _cxcywh_to_xywh to improve performance
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_meta.py:242:    # TODO: Investigate if it makes sense from a performance perspective to have an implementation for every
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:250:            # TODO: when https://github.com/pytorch/pytorch/issues/68430 is fixed (possibly by https://github.com/pytorch/pytorch/pull/100373),
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1239:        # TODO: See https://github.com/pytorch/pytorch/issues/40763
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1259:# TODO: This should be removed once torch_pad supports non-scalar padding values
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1326:        # TODO: add support of other padding modes
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1591:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1846:    # TODO: add in docstring about approximation we are doing for grid inversion
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_geometry.py:1854:    # TODO: first cast to float if bbox is int64 before convert_bounding_box_format
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:107:    # TODO: consider deprecating integers from sigma on the future
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:221:        # TODO: remove this branch as soon as `dtype.is_floating_point` is supported by JIT
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_misc.py:360:    # TODO: Do we really need to check for out of bounds here? All
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_utils.py:91:# TODO: let's use torchvision._utils.StrEnum to have the best of both worlds (strings and enums)
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:15:# TODO: do we want/need to expose this?
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:377:                        # TODO: we don't need to enforce tensors, just that entries are indexable as t[bool_mask]
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/_presets.py:113:        # TODO: we could re-train the video models with antialias=True?
./api/search/.venv/lib/python3.12/site-packages/torchvision/__init__.py:74:        # TODO: better messages
./api/search/.venv/lib/python3.12/site-packages/torchvision/__init__.py:78:        # TODO: better messages
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/mobilenetv3.py:84:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/utils.py:38:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/shufflenetv2.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:51:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/googlenet.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:42:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:53:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:64:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:75:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:86:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/quantization/inception.py:120:    # TODO https://github.com/pytorch/vision/pull/4232#pullrequestreview-730461659
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:202:    # TODO: simplify when indexing without rank will be supported by ONNX
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:451:    # TODO : replace below with a dynamic padding when support is added in ONNX
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/roi_heads.py:744:                # TODO: https://github.com/pytorch/pytorch/issues/26731
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/generalized_rcnn.py:86:        # TODO: Move this to a function
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:43:            # TODO change this
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/anchor_utils.py:54:    # TODO: https://github.com/pytorch/pytorch/issues/26792
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:609:        # TODO: Move this to a function
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/detection/retinanet.py:629:        # TODO: Do we want a list or a dict?
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/_api.py:177:        # TODO: Replace ann.__args__ with typing.get_args(ann) after python >= 3.8
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/__init__.py:21:# TODO: we could / should document them publicly, but it's not clear where, as
./api/search/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:154:                # TODO: If we have documentation on how to do that, put a link in the error message.
./api/search/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/_dataset_wrapper.py:200:    # TODO: maybe we should use __getstate__ and __setstate__ instead of __reduce__, as recommended in the docs.
./api/search/.venv/lib/python3.12/site-packages/torchvision/tv_tensors/__init__.py:11:# TODO: Fix this. We skip this method as it leads to
./api/search/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:274:            # TODO: we don't go through the rebuild logic here directly because we don't want
./api/search/.venv/lib/python3.12/site-packages/pydantic/fields.py:55:    # TODO PEP 747: use TypeForm:
./api/search/.venv/lib/python3.12/site-packages/pydantic/fields.py:333:        # TODO check for classvar and error?
./api/search/.venv/lib/python3.12/site-packages/pydantic/fields.py:411:        # TODO check for classvar and error?
./api/search/.venv/lib/python3.12/site-packages/pydantic/fields.py:413:        # TODO infer from the default, this can be done in v3 once we treat final fields with
./api/search/.venv/lib/python3.12/site-packages/pydantic/fields.py:720:            # TODO: properly make use of the protocol (https://rich.readthedocs.io/en/stable/pretty.html#rich-repr-protocol)
./api/search/.venv/lib/python3.12/site-packages/pydantic/fields.py:797:    default: ellipsis,  # noqa: F821  # TODO: use `_typing_extra.EllipsisType` when we drop Py3.9
./api/search/.venv/lib/python3.12/site-packages/pydantic/deprecated/json.py:112:# TODO: Add a suggested migration path once there is a way to use custom encoders
./api/search/.venv/lib/python3.12/site-packages/pydantic/alias_generators.py:7:# TODO: in V3, change the argument names to be more descriptive
./api/search/.venv/lib/python3.12/site-packages/pydantic/functional_validators.py:213:            # TODO if `schema['serialization']` is one of `'include-exclude-dict/sequence',
./api/search/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:124:# TODO: ultimately, make this public, see https://github.com/pydantic/pydantic/pull/9459#discussion_r1628197626
./api/search/.venv/lib/python3.12/site-packages/pydantic/experimental/pipeline.py:592:            # TODO: is there a better way? should we just not do this?
./api/search/.venv/lib/python3.12/site-packages/pydantic/dataclasses.py:277:        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:303:        # TODO: in theory we should check that the schema accepts a serialization key
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:407:            # TODO this is an ugly hack, how do we trigger an Any schema for serialization?
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:613:        # TODO: note, this is a fairly common pattern, re lax / strict for attempted type coercion,
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1724:        # TODO: do we really need to resolve type vars here?
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:1743:                # TODO: something like https://github.com/pydantic/pydantic/issues/5952
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2005:        TODO support functional validators once we support them in Config
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2511:# TODO V3: this function is only used for deprecated decorators. It should
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:235:    # TODO: This could be unified with `get_standard_typevars_map` if we stored the generic metadata
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_generics.py:276:        # TODO remove parentheses when we drop support for Python 3.10:
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:91:    # TODO When we drop 3.9, use a match statement to get better type checking and remove
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:170:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_gather.py:176:        # TODO duplicate schema types for serializers and validators, needs to be deduplicated.
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_known_annotated_metadata.py:83:    # TODO: this is a bit redundant, we could probably avoid some of these
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_validators.py:44:    # TODO: refactor sequence validation to validate with either a list or a tuple
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:139:# TODO implement `is_finalvar_annotation` as Final can be wrapped with other special forms:
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:186:# TODO In 2.12, delete this export. It is currently defined only to not break
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:195:# TODO: Ideally, we should avoid relying on the private `typing` constructs:
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_typing_extra.py:445:        # TODO ideally recursion errors should be checked in `eval_type` above, but `eval_type_backport`
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:230:                # TODO we can also stop there if `__pydantic_fields_complete__` is False.
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:29:    TODO: Perhaps we should move this structure to pydantic-core. At the moment, though,
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_core_metadata.py:32:    TODO: It's unfortunate how functionally oriented JSON schema generation is, especially that which occurs during
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:236:            # TODO: should we merge the parent namespace here?
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_namespace_utils.py:263:        # TODO `typ.__type_params__` when we drop support for Python 3.11:
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:394:                    # TODO: We should probably do something with this so that validate_assignment behaves properly
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:406:                        # TODO: same note as above re validate_assignment
./api/search/.venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:433:            # was already evaluated. TODO: is this method relevant?
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:436:        TODO: the nested function definitions here seem like bad practice, I'd like to unpack these
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:505:        # TODO: I dislike that we have to wrap these basic dict updates in callables, is there any way around this?
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:713:            # TODO: should we add regex flags to the pattern?
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1117:        # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1240:        # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1281:                        # TODO: fixme - this is a workaround for the fact that we can't always resolve refs
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1320:        # TODO: Need to read the default value off of model config or whatever
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1321:        use_strict = schema.get('strict', False)  # TODO: replace this default False
./api/search/.venv/lib/python3.12/site-packages/pydantic/v1/utils.py:270:            # TODO: replace annotation with actual expected types once #1055 solved
./api/search/.venv/lib/python3.12/site-packages/pydantic/v1/networks.py:535:    # TODO: Needed to generic "Parts" for "Replica Set", "Sharded Cluster", and other mongodb deployment modes
./api/search/.venv/lib/python3.12/site-packages/pydantic/mypy.py:513:                    # TODO: Only do this if the first argument of the decorated function is `cls`
./api/search/.venv/lib/python3.12/site-packages/pydantic/mypy.py:622:                # TODO: We shouldn't be performing type operations during the main
./api/search/.venv/lib/python3.12/site-packages/pydantic/mypy.py:785:            # TODO this path should be removed (see https://github.com/pydantic/pydantic/issues/11119)
./api/search/.venv/lib/python3.12/site-packages/pydantic/main.py:4:# TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.
./api/search/.venv/lib/python3.12/site-packages/pydantic/main.py:1043:                    # TODO - matching error
./api/search/.venv/lib/python3.12/site-packages/pydantic/main.py:1689:    # TODO PEP 747: replace `Any` by the TypeForm:
./api/search/.venv/lib/python3.12/site-packages/pygments/formatters/terminal256.py:17:# TODO:
./api/search/.venv/lib/python3.12/site-packages/pygments/formatters/latex.py:334:        # TODO: add support for background colors
./api/search/.venv/lib/python3.12/site-packages/pygments/formatters/img.py:548:            # TODO: make sure tab expansion happens earlier in the chain.  It
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:445:            # TODO: these don't match the comments in docs, remove.
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:130:                # TODO unsure if ellipses are allowed elsewhere, see
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/textfmts.py:240:    # TODO: Make date regex more ISO 8601 compliant
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:755:            # TODO support other Python syntax like $foo['bar']
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:123:            # TODO: we should probably escape also here ''${ \${
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/nix.py:135:        # TODO: let/in
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/ada.py:116:            # TODO: use Name.Namespace if appropriate.  This needs
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:150:            # TODO: better logging
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:347:                # TODO: better handle multiline comments at the end with
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:588:            # TODO: Backslash escapes?
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/mips.py:28:    # TODO: add '*.s' and '*.asm', which will require designing an analyse_text
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:886:    # TODO / should divide keywords/symbols into namespace/rest
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/jvm.py:1341:            (r'\S+\s+', Text)   # TODO: make tests pass without \s+
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:390:            # TODO: Treat context-depedendent names specially
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/wgsl.py:396:            # TODO: templates start and end tokens.
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/urbi.py:34:    # TODO
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/dns.py:53:            # TODO, $GENERATE https://bind9.readthedocs.io/en/v9.18.14/chapter3.html#soa-rr
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:27:    # TODO String interpolation @VARNAME@ inner matches
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/meson.py:28:    # TODO keyword_arg: value inner matches
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/perl.py:35:    # TODO: give this to a perl guy who knows how to parse perl...
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/_asy_builtins.py:9:    TODO: perl/python script in Asymptote SVN similar to asy-list.pl but only
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:140:            # TODO: regexes can have other delims
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/textedit.py:191:        # TODO: builtins are only subsequent tokens on lines
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:648:            (r'^(\* )(TODO)( .*)',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:650:            (r'^(\*\*+ )(TODO)( .*)',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:656:            # Unordered lists items, including TODO items and description items
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:672:            # TODO: language-dependent syntax highlighting (see Markdown lexer)
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:701:            (_inline(r'=', r'='), String), # TODO token
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/javascript.py:133:            # TODO: should this include single-line comments and allow nesting strings?
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/testing.py:200:            (r'(?i)\bTODO\b', Comment.Preproc),
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:49:            # TODO: highlight references in fandocs
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/fantom.py:85:        'insideUri': [  # TODO: remove copy/paste str/uri
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/c_like.py:212:            # TODO: "correctly" parse complex code attributes
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/modula2.py:474:        'TODO', 'FFI', 'ADDR', 'VARGLIST', 'VARGC',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:24:    TODO:
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/inferno.py:85:# TODO:
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:123:                "varname",  # TODO varname the right fit?
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:273:                        "async for",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:274:                        "async with",  # TODO https://docs.modular.com/mojo/roadmap#no-async-for-or-async-with
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/mojo.py:702:        # TODO supported?
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/parsers.py:396:            # TODO finish implementing other possibilities for scope
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/css.py:555:            # TODO: broken, and prone to infinite loops.
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/rnc.py:36:            # TODO single quoted strings and escape sequences outside of
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/scripting.py:1502:            # TODO: JES3 statement
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/oberon.py:50:            # TODO: nested comments (* (* ... *) ... (* ... *) *) not supported!
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/dotnet.py:558:# TODO support multiple languages within the same source file
./api/search/.venv/lib/python3.12/site-packages/pygments/lexer.py:861:    TODO: clean up the code here.
./api/search/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/search/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/search/.venv/lib/python3.12/site-packages/timm/data/auto_augment.py:905:        # TODO the results appear in the right ballpark but they differ by more than rounding.
./api/search/.venv/lib/python3.12/site-packages/timm/data/naflex_dataset.py:5:TODO: 2. NaFlexIterableDatasetWrapper - Iterable dataset that yields batches with variable sequence lengths
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:373:        # TODO: use foreach_pow if/when foreach_pow is added
./api/search/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:342:        # TODO: use foreach_pow if/when foreach_pow is added
./api/search/.venv/lib/python3.12/site-packages/timm/layers/norm_act.py:99:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:104:        ValueError: if the string def not properly specified (TODO)
./api/search/.venv/lib/python3.12/site-packages/timm/models/tiny_vit.py:626:            # TODO: whether move this func into model for dynamic input resolution? (high risk)
./api/search/.venv/lib/python3.12/site-packages/timm/models/regnet.py:128:    # TODO dWr scaling?
./api/search/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:993:        block_fn = cfg.block_fn or Block  # TODO: Support configurable block_fn via string lookup
./api/search/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:994:        mlp_layer = cfg.mlp_layer or Mlp   # TODO: Support configurable mlp_layer via string lookup
./api/search/.venv/lib/python3.12/site-packages/timm/models/davit.py:813:# TODO contact authors to get larger pretrained models
./api/search/.venv/lib/python3.12/site-packages/timm/models/resnest.py:49:        assert aa_layer is None  # TODO not yet supported
./api/search/.venv/lib/python3.12/site-packages/timm/models/resnest.py:50:        assert drop_path is None  # TODO not yet supported
./api/search/.venv/lib/python3.12/site-packages/charset_normalizer/legacy.py:9:# TODO: remove this check when dropping Python 3.7 support
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:167:    TODO: handle a PIL.Image as input
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:168:    TODO: handle base64 as input
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_common.py:174:            yield get_session().get(content).content  # TODO: retrieve as stream and pipe to post request ?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:25:# Some TODO:
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:259:        # TODO: this should be handled in provider helpers directly
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_generated/_async_client.py:257:        # TODO: this should be handled in provider helpers directly
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_mcp/mcp_client.py:192:            # ^ TODO: should be handle `get_session_id_callback`? (function to retrieve the current session ID)
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:51:TODO: add support for `huggingface-cli delete-cache aaaaaa bbbbbb cccccc (...)` ?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:52:TODO: add "--keep-last" arg to delete revisions that are not on `main` ref
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:53:TODO: add "--filter" arg to filter repositories by name ?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:54:TODO: add "--limit" arg to limit to X repos ?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:55:TODO: add "-y" arg for immediate deletion ?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/commands/delete_cache.py:85:    # TODO: refactor this + imports in a unified pattern across codebase
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:25:    # TODO: deprecate when adapted in transformers/datasets/gradio
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:43:    # TODO: deprecate when adapted in transformers/datasets/gradio
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_hf_folder.py:58:    # TODO: deprecate when adapted in transformers/datasets/gradio
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:60:    TODO: could be useful to be able to set a custom error message.
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:91:    # TODO: add an argument to opt-out validation for specific argument?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4726:            # TODO: remove this in v1.0
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:4999:            # TODO: remove this in v1.0
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/_commit_api.py:796:                    # TODO: (optimization) download regular files to copy concurrently
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:323:    TODO: factorize logic with `read_download_metadata`.
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/_local_folder.py:380:            # TODO: can we do better?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:466:        # TODO - maybe handle this similarly to EvalResult?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/repocard_data.py:752:    # TODO - Check if there cases where this list is longer than one?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:476:                TODO - Some args above aren't used since we are calling
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/keras_mixin.py:494:        # TODO: change this in a future PR. We are not returning a KerasModelHubMixin instance here...
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/_oauth.py:158:    # TODO: handle generic case (handling OAuth in a non-Space environment with custom dev values) (low priority)
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/constants.py:138:hf_cache_home = HF_HOME  # for backward compatibility. TODO: remove this in 1.0.0
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/serialization/_torch.py:121:    >>> from huggingface_hub import load_torch_model  # TODO
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:327:        # TODO: use `commit_description` to list all the deleted paths?
./api/search/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:701:                    "tree_id": None,  # TODO: tree_id of the root directory?
./api/search/.venv/lib/python3.12/site-packages/pydantic_settings/utils.py:32:# TODO remove and replace usage by `isinstance(cls, type) and issubclass(cls, class_or_tuple)`
./api/search/.venv/lib/python3.12/site-packages/jinja2/ext.py:251:    # TODO: the i18n extension is currently reevaluating values in a few
./api/search/.venv/lib/python3.12/site-packages/torch/quantization/fuse_modules.py:10:# TODO: These functions are not used outside the `fuse_modules.py`
./api/search/.venv/lib/python3.12/site-packages/torch/quantization/__init__.py:42:    # 'fuse_fx', 'quantize_fx',  # TODO: add quantize_dynamic_fx
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/uniform.py:28:    # TODO allow (loc,scale) parameterization to allow independent constraints.
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/laplace.py:73:        # TODO: If we ever implement tensor.nextafter, below is what we want ideally.
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/constraint_registry.py:249:# TODO define a bijection for LowerCholeskyTransform
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:551:# TODO: Add Beta-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:590:# TODO: Add ContinuousBernoulli-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:649:# TODO: Add Exponential-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:694:# TODO: Add Gamma-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:726:# TODO: Add Gumbel-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:823:# TODO: Add Pareto-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/kl.py:920:# TODO: Uniform-Laplace KL Divergence
./api/search/.venv/lib/python3.12/site-packages/torch/functional.py:105:    # TODO Move this to C++ once the jit has better support for torch.Size.
./api/search/.venv/lib/python3.12/site-packages/torch/functional.py:1477:    # TODO: type dim as BroadcastingList when
./api/search/.venv/lib/python3.12/site-packages/torch/functional.py:1643:            _dim = [i for i in range(ndim)]  # noqa: C416 TODO: rewrite as list(range(m))
./api/search/.venv/lib/python3.12/site-packages/torch/functional.py:1646:    # TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:408:    # TODO(albanD) This needs to be updated when more than one level is supported
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:434:    # TODO: add an API to map real -> complex dtypes
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor_str.py:590:            # TODO: This implies that ellipses is valid syntax for allocating
./api/search/.venv/lib/python3.12/site-packages/torch/utils/backend_registration.py:7:# TODO: Should use `torch._C._get_privateuse1_backend_name()` to get
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_python_dispatch.py:12:# TODO: Limitations and things about enable_torch_dispatch_mode we should fix before exposing it:
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:629:                # TODO(https://github.com/pytorch/pytorch/issues/76750)
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:650:        # TODO: add limited pickling support for sharing an iterator
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/graph.py:22:# TODO(VitalyFedyunin): Make sure it works without dill module installed
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/snapshot.py:6:# TODO: Caveats
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/decoder.py:320:                # TODO: xinyu, figure out why Nvidia do this?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:36:            # TODO(VitalyFedyunin): Replacing with TorchArrow only API, as we are dropping pandas as followup
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/datapipes.py:120:        except Exception:  # TODO(VitalyFedyunin): Replace with better iterable exception
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:8:# TODO(VitalyFedyunin): Add error when two different traces get combined
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:53:#  TODO(VitalyFedyunin): Extract this list from the DFIterDataPipe registred functions
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:61:    # TODO: All operations are shared across entire InitialCapture, need to figure out what if we join two captures
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:78:        # TODO(VitalyFedyunin): Currently can't pickle (why?)
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:131:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:142:    # TODO(VitalyFedyunin): Add tests
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:143:    # TODO(VitalyFedyunin): Need to join context if one of them are empty because we used capture
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:146:        # TODO: Check if args or kwargs have more than one different context
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:148:            # TODO: Allow CaptureA to take context from mock
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:190:        # TODO(VitalyFedyunin): Do not use provate function here, copy own implementation instead.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:220:        # TODO: VitalyFedyunin execute kwargs and maybe nested structures
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:242:    # TODO(VitalyFedyunin): This should be atomic and thread safe
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:261:        # TODO(VitalyFedyunin): Make this calculation thread safe (as currently it updates pointer)
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/dataframe/dataframes.py:421:    # TODO(VitalyFedyunin): Must implement all special functions of datapipes
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:146:            # TODO: Add try-except to in-place reduce traceback from the Exception
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_hook_iterator.py:197:                # TODO: Simplify the traceback message to skip over `response = gen.send(None)`
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/gen_pyi.py:227:    TODO: The current implementation of this script only generates interfaces for built-in methods. To generate
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:67:    # TODO: Lambda for picking
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_decorator.py:167:    # TODO:
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/fileopener.py:54:        # TODO: enforce typing for each instance based on mode, otherwise
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:136:    # TODO(VitalyFedyunin): Verify that item is any sort of batch
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:138:        # TODO(VitalyFedyunin): Compact all batch dataframes into one
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:155:            # TODO(VitalyFedyunin): Add default collation into df_wrapper
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:166:    # TODO(VitalyFedyunin): We can dynamically extract types from the tuple_values here
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:167:    # TODO(VitalyFedyunin): Instead of ignoring mypy error, make sure tuple_names is not empty
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:227:        # TODO(VitalyFedyunin): Replace `Callable[..., Any]` with `Callable[[IColumn], Any]`
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:228:        # TODO(VitalyFedyunin): Replace with `Dict[Union[str, IColumn], Union[Callable, Enum]]`
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/callable.py:235:                # TODO(VitalyFedyunin): Validate passed dictionary
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/iter/combinatorics.py:104:        # TODO: Performance optimization
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:15:# TODO: Use TypeAlias when Python 3.6 is deprecated
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:206:# TODO: When PyTorch drops the support for Python 3.6, it can be converted
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:262:        # TODO: the statements below are not reachable by design as there is a bug and typing is low priority for now.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:280:    # TODO: Fix isinstance bug
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:327:    # TODO: Fix isinstance bug
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:336:    # TODO: Fix isinstance bug
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/datapipes/_typing.py:380:    # TODO:
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/__init__.py:1:# TODO(VitalyFedyunin): Rearranging this imports leads to crash,
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py:156:# TODO: Implement `SeedSequence` like object for `torch.random`
./api/search/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:496:    TODO:
./api/search/.venv/lib/python3.12/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py:8517:        # TODO: Undo this special-case; see the header for motivation behind this
./api/search/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:13:            # TODO: Remove this once ScriptModule supports registering None buffer
./api/search/.venv/lib/python3.12/site-packages/torch/utils/mkldnn.py:54:            # TODO: Remove this once ScriptModule supports registering None buffer
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_cxx_pytree.py:238:    # TODO(XuehaiPan): remove this condition when we make Python pytree out-of-box support
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:110:        # TODO: when the bounds have free variables, this may be
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:180:    # TODO: this doesn't work with bools but arguably it should
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:606:        # TODO: We should tighten value ranges
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:622:        # TODO: We should tighten value ranges
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/value_ranges.py:768:        # TODO A better way of doing this would be to assign them a range upon creation, as
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/reference.py:163:# sharing (TODO: considering splitting out a BaseReferenceAnalysis).
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:31:# TODO: Dedupe this with SYMPY_INTERP
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:36:    # TODO add CeilDiv (it doesn't appear in the index_expr)
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/interp.py:38:    # TODO default to some decompositions if the interpreter doesn't have them
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:144:                        # TODO if https://github.com/openai/triton/issues/619 is fixed
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:299:# TODO: As an indicator, this != 0 implies == 1 (and vice versa).
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_sympy/functions.py:312:        # TODO: it is possible to make progress evaluating this guard
./api/search/.venv/lib/python3.12/site-packages/torch/utils/weak.py:319:        # TODO, add _fix_weakref type binding
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:103:        # TODO: make storage support buffer protocol so this isn't
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:112:    # TODO: factor this into a random utility
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:153:    # TODO: offer some sort of non-blocking API to speed things up
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:158:        # TODO: consider not using torch.save for this; we don't actually
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_content_store.py:184:        # TODO: Support more advanced snapshotting of requires_grad/grad/etc
./api/search/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:33:    # TODO(#105471): Rename the count field
./api/search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:841:            # TODO: we can probably make this check stricter by checking that
./api/search/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1155:    # TODO: unify _is_compiling across all compile stacks
./api/search/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/summary.py:205:    # TODO: expose other parameters in the future.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:45:        # TODO; Specify a __slots__ for this class or potentially
./api/search/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:114:        # TODO: See if we can remove this in the future
./api/search/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:216:        # TODO: compute correct memory usage and CPU time once
./api/search/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/_pytorch_graph.py:344:    # TODO: See if we can extract GPU vs CPU information from the PyTorch model
./api/search/.venv/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py:72:        # TODO: See if we can remove this in the future if we are
./api/search/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:395:        # TODO: Should we do this even for non-contiguous tensors?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/bundled_inputs.py:405:        # TODO: Provide more useful diagnostics.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/dlpack.py:47:# TODO: add a typing.Protocol to be able to tell Mypy that only objects with
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:83:                # TODO: This creates a temporary file for every frame, but we
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_traceback.py:174:            # TODO: Maybe indicate that the traceback was elided?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:299:            # TODO: change this warning to an error after OSS/internal stabilize
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1407:# TODO(angelayi): remove this function after OSS/internal stabilize
./api/search/.venv/lib/python3.12/site-packages/torch/utils/_pytree.py:1413:# TODO(angelayi): remove this function after OSS/internal stabilize
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:74:      // TODO: Maybe check that compressed_size === file_size.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:81:  // TODO: Better formatting.  Right-align this.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:121:      // TODO: Maybe show simple lists and tuples on one line.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:125:      // TODO: Maybe show simple lists and tuples on one line.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:129:      // TODO: Maybe show simple (empty?) dicts on one line.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:217:    // TODO: Check stride and indicate if the tensor is channels-last or non-contiguous
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:218:    // TODO: Check size, stride, offset, and numel and indicate if
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:220:    // TODO: Maybe show key?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:268:        // TODO: Less copy/paste between this and normal dicts.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:308:  // TODO: Add human-readable sizes?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:309:  // TODO: Add sorting options?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:310:  // TODO: Add hierarchical collapsible tree?
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:481:// TODO: Maybe track by dtype as well.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/code.js:482:// TODO: Maybe distinguish between visible size and storage size.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:48:    - Fix various TODO comments in this file and the JS.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:179:            # TODO: Undo at least that second hack.  We should support string states.
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:293:                # TODO: Handle this case better.  TorchScript ranges are in bytes,
./api/search/.venv/lib/python3.12/site-packages/torch/utils/model_dump/__init__.py:326:                # TODO: handle errors here and just ignore the file?
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:278:        # TODO: Make this work with autograd
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:507:    # TODO: Figure out how to handle this better
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/ops.py:1055:    # TODO: Handle inference mode properly.
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:170:            # TODO: Don't guard on this!
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:236:# TODO: Remove ViewBufferFromNested, ViewNestedFromBuffer, and buffer_from_jagged once the
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:327:        # TODO: An alternative way to construct offsets is to use F.pad. This avoids creating
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:64:        # TODO: Figure out whether masks are actually supported for this layout or not
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:315:        # TODO: Explore performance impact of copying
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:320:        # TODO: Explore performance impact of copying
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:326:        # TODO: Explore performance impact when compiling
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:370:# TODO: Next iteration should add test cases and check it works
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:550:    # [TODO] K and V have to have the same Nnz, should probably torch_check
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:603:# TODO: coalesce with torch/nn/utils/attention.py
./api/search/.venv/lib/python3.12/site-packages/torch/nested/_internal/sdpa.py:605:    # TODO: Investigate why math.sqrt() isn't properly handled by Dynamo?
./api/search/.venv/lib/python3.12/site-packages/torch/nested/__init__.py:235:        # TODO: switch to as_nested_tensor(tensor) when it is available
./api/search/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:78:    # TODO: test the specs match; empirically  sometimes we have a tuple
./api/search/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:126:                # TODO: suppress guards
./api/search/.venv/lib/python3.12/site-packages/torch/_dispatch/python.py:136:        # TODO: This probably does the wrong thing if you're running other
./api/search/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:198:            # TODO: support get_autocast_gpu/cpu_dtype
./api/search/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:271:                    # TODO: is there a way to split by device and dtype without appending in the inner loop?
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:643:    # TODO: This feature could be added in the future
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:670:                # TODO: Once we decide to break serialization FC, this case
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:708:            # TODO: There's an issue here with FC. It might be impossible to
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:786:    # TODO: This feature could be added in the future
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:798:                # TODO: Once we decide to break serialization FC, this case
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:1138:                    # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:1150:                    # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:1206:                # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:1226:                    # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:1387:        # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:3881:    # TODO: handle out
./api/search/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5007:# TODO: Deduplicate this with canonicalize_dim
./api/search/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:5771:    # TODO: Query cudnnGetRNNTrainingReserveSize (expose to python)
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:1376:    # TODO: Properly support no-batch-dim inputs. For now, these are NOT supported; passing
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2400:            # TODO: Remove this once script supports type() calls
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2466:    # TODO: make use of reduce like below when JIT is ready with the missing features:
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:4524:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5412:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5421:        # TODO finish disentangling control flow so we don't do in-projections when statics are passed
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/prune.py:1284:    # TODO: consider removing this check and allowing users to specify
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:65:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/memory_format.py:136:    # TODO: expand this to `_ConvNd` when channels_last support is extended
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:20:    # TODO Make return type more specific
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/stateless.py:238:    # TODO allow kwargs such as unsafe and others for parametrization
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/parametrize.py:653:                        # TODO: Fix this for tensor subclasses that are parameters:
./api/search/.venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:171:        # TODO: Re-enable this check (.type isn't supported in TorchScript)
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:295:# TODO: ContrastiveNorm2d
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:296:# TODO: DivisiveNorm2d
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:297:# TODO: SubtractiveNorm2d
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:286:        padding_mode: str = 'zeros',  # TODO: refine this type
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:438:        padding_mode: str = 'zeros',  # TODO: refine this type
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1109:# TODO: Deprecate and remove the following alias `_ConvTransposeMixin`.
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1132:# TODO: Conv2dLocal
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1133:# TODO: Conv2dMap
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1134:# TODO: ConvTranspose2dMap
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:1300:        padding_mode: str = 'zeros',  # TODO: refine this type
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125:# TODO: fail fast on quantization API usage error, then remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:264:# TODO: PartialLinear - maybe in sparse?
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/padding.py:10:# TODO: grad_output size asserts in THNN
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1843:    # TODO: Change `*args` to `*` and remove the corresponding warning in docs when BC allows.
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1889:        # TODO: Remove `args` and the parsing logic when BC allows.
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:626:# TODO: remove the overriding implementations for LSTM and GRU when TorchScript
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1287:            ret = input  # TODO: remove when jit supports exception flow
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:57:        # TODO: check in THNN (if inplace == True, then assert value <= threshold)
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:153:            # TODO: if statement only here to tell the jit to skip emitting this when it is None
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1788:# TODO: L1HingeEmbeddingCriterion
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1789:# TODO: MSECriterion weight
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1790:# TODO: ClassSimplexCriterion
./api/search/.venv/lib/python3.12/site-packages/torch/nn/_reduction.py:18:        ret = -1  # TODO: remove once JIT exceptions support control flow
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/comm.py:122:    # TODO: When `len(inputs) == 1` and all inputs are on `destination`, just
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:89:    # TODO (rohan-varma): keep_low_precision_grads: bool = False
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:90:    # TODO (rohan-varma): APIs to allow users to run batchnorm and layernorm
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:147:        # TODO: Expand to remote RRefs.
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:290:        # TODO: make DDP uneven inputs context manager support buffer
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:840:            # params. TODO (rohan-varma): Make this compose with general
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1039:                        # TODO: when zero_grad(set_to_none=False) or in grad
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1511:            # TODO (rohan-varma) test this codepath.
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py:1548:        # TODO: DDPSink is currently enabled for unused parameter detection and
./api/search/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:126:    # TODO: update notes/cuda.rst when this class handles 8+ GPUs well
./api/search/.venv/lib/python3.12/site-packages/torch/nn/attention/bias.py:230:                    is_causal=True,  # TODO: Flash accepts causal = True and for this particular op it means lower right
./api/search/.venv/lib/python3.12/site-packages/torch/nn/attention/__init__.py:21:# TODO: Consider using this for sdpa regardless of subclasses
./api/search/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:969:    # TODO: __name__ not set for submodules in recursive script
./api/search/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:1368:# TODO support future
./api/search/.venv/lib/python3.12/site-packages/torch/library.py:146:            # TODO: in future, add more info about where the existing function is registered (this info is
./api/search/.venv/lib/python3.12/site-packages/torch/library.py:455:    # TODO(rzou): We're gonna need to stage this change with torchvision,
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_script.py:837:                # TODO: we don't have _concrete_type set after load(), and in general we lose constant information.
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_script.py:845:                # TODO: it's possible that the following is confusing:
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_script.py:996:    # TODO MAKE SURE THAT DISABLING WORKS
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:64:    TODO: To remove this check once Union support lands.
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_monkeytype_config.py:130:                    # TODO: To remove this check once Union suppport in TorchScript lands.
./api/search/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:443:        # TODO: this is hack to recognize NumberType
./api/search/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:449:        # TODO: Determine if the other cases need to be fixed as well
./api/search/.venv/lib/python3.12/site-packages/torch/jit/annotations.py:539:    # TODO: Consider not exporting these during wildcard import (reserve
./api/search/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:253:    # TODO: proper overriding analysis when implementing class inheritance
./api/search/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:382:# TODO: more robust handling of recognizing ignore context manager
./api/search/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:516:        # TODO: add input, output validator
./api/search/.venv/lib/python3.12/site-packages/torch/jit/frontend.py:755:            # TODO: try to recover the location of else:? Python doesn't give us useful
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:32:# TODO: there should be a more principled way of doing this.
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:300:            # TODO: We should really error in this case, but its bc-breaking so
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:319:            # TODO: We should really error in this case, but its bc-breaking so
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:400:            # TODO: could add more detail here. For example, what the user should do
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:680:            # TODO: Why skip this? Because @torch.jit._overload_method will
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:686:        # TODO: we don't currently do this functions that are recursively
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_recursive.py:843:    (TODO add a link when the rules are published).
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_decompositions.py:86:# TODO: replace torch.sigmoid -> aten.sigmoid
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_builtins.py:120:    # TODO: add support for more ops
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_serialization.py:164:    # TODO: Pretty sure this approach loses ConstSequential status and such
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:159:            # TODO: figure out one liner to .clone() and set requires_grad
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:228:    # TODO: In principle, we track device information in our trace, so it
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:232:    # TODO: Consider adding a utility function to torch.jit to test
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:272:        # TODO: I'm not sure if the clone here is necessary but it is safer
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_check.py:147:        # TODO @ansley: add `Union` once landed
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:39:            # TODO: only assertion error is bound in C++ compilation right now
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:94:            # TODO: only assertion error is bound in C++ compilation right now
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:405:    # TODO: return self
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:611:        # TODO: handling of slice
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:617:        # TODO: handling of slice
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:678:    # TODO: look into rewriting with early return and getting loop unrolling to fire
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:698:    # TODO: assertions could be expanded with the error messages
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1029:        # TODO: return self
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1037:    # TODO: use slicing when slice optimization has landed
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1439:# TODO: migrate over all of symbolic_shape_registry_util.cpp
./api/search/.venv/lib/python3.12/site-packages/torch/jit/_shape_functions.py:1454:# quantized_conv_prepack TODO
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:687:                # TODO: handle the other Ju
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:928:            # TODO: To cover more problematic cases, replace stride = 0 check with
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1720:    # TODO: properly handle case when u is tuple instead of only taking first element
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:1902:    # TODO: replicate https://github.com/pytorch/pytorch/pull/77743 for fast gradcheck as well
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/gradcheck.py:2194:    # TODO: do we want to test this too?
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/_functions/tensor.py:30:# TODO: deprecate this
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:598:        # TODO: TorchScript ignores standard type annotation here
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:618:        # TODO: Too slow with __torch_function__ handling enabled
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:655:        # TODO: Too slow with __torch_function__ handling enabled
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/profiler.py:921:        )  # TODO: find in sqlite database
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:71:            # TODO: We can remove this conditional once we uniformly use
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:538:        # TODO: Raise exception instead of converting value.  This is only for
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:563:        # TODO: Raise exception instead of converting value.  This is only for
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:626:        # TODO: Raise exception instead of converting value.  This is only for
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:674:    # TODO: Enable data-dependent checks with debug mode
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:675:    # TODO: This check does not work with FakeTensor inputs; See Issue #85834
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:754:    # TODO: raise exception instead of converting value
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:810:# TODO: This ref supports int reduction and out kwarg to be compatible with ATen:
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:812:# TODO: Could be rewritten to support complex:
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:896:        # TODO: Raise exception instead of converting value.  This is only for
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/nn/functional/__init__.py:1042:        # TODO: Raise exception instead of converting value.  This is only for
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/special/__init__.py:231:# TODO: add docstring
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:114:    "round",  # TODO: model kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:204:    "copy_to",  # TODO: add OpInfo (or implement .to)
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:386:    # TODO: make common validations available as utils
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:450:# TODO: add type promotion support
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:740:# TODO: if this is special maybe it should be defined there and imported here?
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:965:# TODO: register this as a real ref/decomposition once TorchInductor supports complex!
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1614:# TODO: skip unnecessary conversion of long to float
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1695:# TODO: consider refactoring this with add impl
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:1898:# TODO: implement alternate where
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2095:    # TODO: is_pinned is not currently supported in refs or fake_tensor
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2119:    # TODO: non_blocking should be handled by `copy_to`
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2151:            # TODO - this is true for eager mode currently, but it's wrong behavior for complex norms
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2782:        # TODO: fix this to work with meta tensors
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:2993:    # TODO: we could look at directing collapse_view to skip its meta function here (unsafe_collapse_view)
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3058:# TODO: This must return a sparse tensor if the input is sparse, but refs have
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:3222:# TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4416:    # TODO: Add sparse support
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:4544:# TODO: Turn this into a decomposition (currently fails on reshape meta tests)
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5343:    requires_grad: bool = False,  # TODO: unused
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5370:    # TODO: Use requires_grad.  All refs taking the requires_grad kwarg must
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:5970:    # TODO: fix inductor rand_like for integer, bool dtypes
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6004:# TODO: add support for functionalization aten.normal_functional
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6264:    # TODO: this is inaccurate, we actually test PySequence_Check
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6305:    # TODO: this is inaccurate, we actually test PySequence_Check
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6315:            # TODO: test this
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6373:    # TODO
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6377:    # TODO: test for numpy input with PyArray_Check
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6405:    # TODO (or not): support names kwarg
./api/search/.venv/lib/python3.12/site-packages/torch/_refs/__init__.py:6415:        {"device": "cpu"},  # TODO: use torch.get_default_tensor_type
./api/search/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:126:        # TODO: This solution is no ideal since we may miss some factory methods. In future
./api/search/.venv/lib/python3.12/site-packages/torch/_lazy/extract_compiled_graph.py:183:    # TODO: this part is TS backend specific for now and will be generalized to
./api/search/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:9:    TODO: This API is currently ts backend specific. We are working on
./api/search/.venv/lib/python3.12/site-packages/torch/_lazy/computation.py:23:    TODO: This API is currently ts backend specific. We are working on
./api/search/.venv/lib/python3.12/site-packages/torch/_lazy/__init__.py:16:    # TODO(whc) expand this to include backend hooks and align with XLA backend needs
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:222:    # TODO: Uhh.... it shouldn't matter, but changing this to true_fn results in
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/cond.py:225:    # TODO Sometimes the operands are not completely FakeTensor, something seems went wrong in
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:16:# TODO to figure out a more generic approach
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/out_dtype.py:48:        # TODO(ydwu4): Subclassing HigherOrderOperator causes __module__ to
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:21:# TODO: this is not really sufficient. While passes (hopefully) check
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/torchbind.py:77:# TODO: currently we just run the C++ implementation with fake tensors.
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:290:                # TODO(oulgen): add support for tt.reduce
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:325:    # TODO(oulgen):
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:723:    # TODO(oulgen): Preexisting bug, if two kernel inputs are views of each
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:758:    # TODO(oulgen): For performance reasons, we want to ensure that these
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/triton_kernel_wrap.py:774:    # TODO(oulgen): For performance reasons, we want to ensure that these
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/wrap.py:177:            # TODO: We want to use the same `checkpoint(Interpreter(gmod).run, *args, **kwargs)` here
./api/search/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/map.py:28:# TODO: We add this to prevent dymamo from tracing into map_wrapper,
./api/search/.venv/lib/python3.12/site-packages/torch/_utils.py:176:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./api/search/.venv/lib/python3.12/site-packages/torch/_utils.py:263:                # TODO: Validation currently involves an expensive traversal
./api/search/.venv/lib/python3.12/site-packages/torch/_utils.py:363:# TODO: Once we decide to break serialization FC, `storage` no longer needs to
./api/search/.venv/lib/python3.12/site-packages/torch/_utils.py:855:    TODO(khabinov): we should deprecate this function and use torch.compiler.is_compiling().
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_utils.py:97:            # TODO: there are many flatten/unflatten in IterGraph that
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:50:        # TODO: if we do ``deepcopy(_codegen)`` and the input argument contains
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:352:        # TODO: This is a temporary solution. We are going to remove DCE usage
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:598:        # TODO: remove this API after DCE is removed
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:614:        # TODO: remove this API after DCE is not used with IterGraph
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/iter_graph_module.py:739:        # TODO: remove this API once it is not used.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:59:# TODO(@fegin): Support multiple runs of graph optimization
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:60:# TODO(@fegin): With this design, circular imports will happen when a pass
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:215:    # TODO: populate all the tensor metadata and remove the default.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:218:        # TODO: support symbolic shapes
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:242:    # TODO: fix the memory_format
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:264:        # TODO: fix these value
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:324:                # TODO(@fegin): support symbolic shapes
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:485:        # TODO: determine the dtype
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:601:# TODO(fegin): Have a template class for all Block class.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:611:    # TODO(fegin): populate/generate the max_exp_avg_sqs if exists
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/graph_optimization.py:927:# TODO(fegin): The API only support fused adam now. Should extend it to support
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:165:            # TODO: figure out why turning on cudagraphs cause exceptions.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/partial_lower.py:193:    # TODO(yifu): apparently having a meta kernel is not a necessary
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/comm_tensor.py:141:                # TODO(ezyang): I don't really understand what's going on
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:483:    # TODO(@mrshenli): @yifuwang has a suggestion of conducting expansion and
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:496:# TODO: ensure the key is unique.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:553:                    # TODO: SPMD should provid a default and configurable
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/log_utils.py:47:        # TODO(anj): Add loggers for MPMD
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:39:        TODO(@wanchaol): some of these arguments are not necessary for
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:53:        # TODO: add more necessary arguments to this interface.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:93:        # TODO: what if user passes in a incorrect `input_batch_dim`, how should we
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:100:            # TODO: add a few default passes here.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:113:        # TODO: figure out a way to avoid explicit "cuda" mesh.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:132:        # TODO: add more necessary arguments to this interface.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:150:            # TODO: add a few default passes here.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:215:        # TODO: move the trasnformation passed to this function
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:227:    # TODO: provide schema_suggestions when placements do not match
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:393:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:141:    # TODO: this is broken because it won't redistributed potential tensors on the kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:480:    # TODO(anj): This depends on the call function node -> actual DTensor output
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:522:        # TODO(anj): We require mapping of the final DTensor output to the wait
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:540:                # TODO(anj): We are depending on the concrete DTensor output of the dummy add.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:730:            # TODO(anj): Pipe the output schema for the BW pass
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:158:    # TODO: Only NCCL supports AVG so using backend like Gloo would
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:358:                # TODO: Currently this specializes to fused optimizer ops, but we need
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:397:                    # TODO: optimizer parts should follow the dtensor prop logic
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/data_parallel.py:536:                    # TODO: add support for default mode
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:226:            # TODO(yeounoh) implement DeviceMesh backend and register XLA backend.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:246:            # TODO: if user want to pass pg_options, offer a way to do it
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:273:            # TODO(yifu): remove tag and ranks once we fully migrate to native
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/device_mesh.py:304:                        # TODO: Add two tests to cover internal tests scenarios and re-enable reuse subgroup if exists.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/nn/jit/templates/remote_module_template.py:60:# TODO: Merge these two templates together in the future once TorchScript syntax is improved.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/nn/api/remote_module.py:261:            # TODO: We need to change this to rpc.remote, and make it async (see the else branch below).
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:204:# TODO assert if ranks has duplicated entries
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:232:    # TODO add dim support?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:280:    # TODO add dim support?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:80:    # TODO: should we use pytree?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_state_dict_utils.py:149:                # TODO: support DTensor
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:89:        # TODO: figure out dynamo support for instance method and switch this to instance method
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:394:                    # TODO: re-enable the check once we fix the compile path
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/style.py:471:                    # TODO: re-enable the check once we fix the compile path
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/api.py:80:        # TODO: we should allow user to pass in the default seed from a config
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/_utils.py:23:    # TODO: Will follow up with dynamo POC to make warnings.warn working with dynamo.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:40:    # TODO: To add perf optimizations to this iterations
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/ddp.py:94:    # TODO: To add test cases and ensure that it works for nested modules
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/tensor/parallel/fsdp.py:350:            # TODO: this is a short term fix and we should make the get_unflat_views
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:20:        # TODO(@fegin): this variable is originally create for testing, we
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/replicate.py:131:    # TODO(fegin): using kwargs is not a good idea if we would like to make
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_init.py:129:    # TODO: De-duplicate with `_apply` after `swap_tensors` path lands:
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:146:        # TODO: Replace the sharded DTensor parameter construction logic with
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:148:        # TODO: Simplify the following sharded parameter padding logic after
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:178:            # TODO: Hard code FSDP + TP; need to support HSDP + TP
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/_fsdp_param.py:353:        # TODO: Prefer this DTensor to be read-only and generalize the
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/fsdp/fully_shard.py:218:        # TODO: Remove this padding logic once DTensor pads the local tensor:
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:18:# TODO: we can add additional info to RegistryItem to share across APIs. E.g.,
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:165:            # TODO: a stricter verification should also reject changing module
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:168:            # TODO: verify that installed distributed paradigms are compatible with
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_composable/contract.py:176:                {},  # TODO(@yhcharles): this is a temporary fix, need a better way
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_sgd.py:57:        # TODO: Once step_param interface is robust, refactor step to call
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/apply_optimizer_in_backward.py:71:            # TODO: Remove these attributes once we have a better way of accessing
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:58:    TODO: Add tutorial for _NamedOptimizer.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:59:    TODO: Add documentation in the docstring for the public attributes
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:313:        # TODO(chienchin): This API should be FSDP agnostic and should support
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/named_optimizer.py:322:        # TODO(chienchin): This API should be FSDP agnostic and should support
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:29:# TODO (wanchaol): remove this once we added TorchScript
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:60:# TODO (wanchaol): remove/merge this with ScriptLocalOptimizer once
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/optimizer.py:112:    # TODO: improve error propagation
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/zero_redundancy_optimizer.py:1535:        # TODO: Manually add `self.param_groups` if using a functional
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/optim/functional_adagrad.py:57:        # TODO: no union or any types in TorchScript, make step a scalar tensor instead
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/pipeline/sync/skip/skippable.py:241:# TODO(sublee): Move to above of Skippable class for better read flow.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_loader.py:33:        # TODO: test returning `load` here instead.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:9:TODO:
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_nested_dict.py:19:# TODO: Update Docstring for nested_dict.py
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:34:# TODO: update docstring for traverse.py
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_traverse.py:145:        # TODO: add local offset for _local_tensor in print_nested.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_sharded_tensor_utils.py:15:# TODO: We need to refactor this code.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:384:# TODO: integrate with distributed logging flag
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:60:# TODO: Update docstrings for default_planner.py
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:46:# TODO: Update docstrings for optimizer.py
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:189:            # TODO: The ReadItems will have a displaced MetadataIndex, fix it.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:190:            # TODO: we should change _create_sharded_read_items to have more ergonomic API
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:77:        # TODO: add logging for the gc details/time
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:373:        # TODO: make this faster.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:573:            # TODO: check if value is the same if exists.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:962:# TODO: correct the state_dict function signature.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:963:# TODO: this API is not yet fully tested. Make it private
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1017:# TODO: correct the load_state_dict function signature.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict.py:1018:# TODO: this API is not yet fully tested. Make it private
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/state_dict_saver.py:39:    # TODO: test returning `save` here instead.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/_dedup_tensors.py:30:# TODO add docstring for dedup_tensors
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:220:        # TODO replace with headq
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:269:            # TODO: Using the OverlappingCpuLoader with multiple threads creates significant
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:572:                # TODO sort by offset and cache the reading
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/format_utils.py:118:        # TODO: read on each host, instead of only the coordinator
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:317:            # But maybe we need to? TODO(voz): Look into this
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:579:        # TODO: Do not use the side stream for tensor copies for now; investigate
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:784:    # TODO: Post-backward prefetching does not support the multiple handles
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:961:    # TODO: Investigate why `NO_SHARD` breaks correctness when using
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:963:    # TODO (rohan-varma): When CPU offload and optimizer overlap,
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:994:                # TODO (rohan-varma): For CPU offload, this unfortunately
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1084:        # TODO (rohan-varma): this also waits for the overlapped optimizer step to finish
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py:1127:            # TODO: This already-resharded check is brittle:
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:155:    # TODO: need to check if this is always correct for composable FSDP.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:449:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:506:    # TODO: Add DTensor state_dict support for LOCAL_STATE_DICT.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626:            continue  # TODO: Improve unittesting for state_dict finetuning
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_wrap_utils.py:43:    # TODO: We may relax this no-nested-wrapping constraint to support manual
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:115:        # TODO: Move all the attributes to this class to enable typing for
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:195:    # TODO: This is a temporary hack for differentiate between code paths.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:238:    # TODO: Explicitly replacing the checkpoint wrapper prefix is not ideal as
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:337:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:422:                    # TODO: Remove this hack once DMP + FSDP is not supported.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:430:                            # TODO(voz): Don't graph break on this
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:511:            # TODO: We need to run this mixed precision ignored module in fp32,
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:559:        # TODO(voz): Extend a dynamo util to answer the above, unify the codepaths here.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:81:        # TODO: figure out the case for the composable APIs.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:96:        # TODO: figure out the case for the composable APIs.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:142:        # TODO: Rank 0 can broadcast the `FlatParameter` to allow all ranks to
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_unshard_param_utils.py:253:            # TODO (awgu): The traversal function does not traverse through
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1448:        # TODO: This solution is not general and only apply to PTD TP solution.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_optim_utils.py:1748:                # TODO: it is unclear if we need to do the same check with
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:80:        # TODO (awgu): We can broadcast the metadata of rank 0's `all_handles`
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:214:            # TODO (awgu): Since every module has at most one handle in the
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:218:                # TODO(voz): Don't graph break on this - dynamo hates the n1 != n2
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_exec_order_utils.py:244:                # TODO(voz): Don't graph break on this - dynamo hates the i1 != i2
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:39:    # TODO: Add any other composable APIs that are mutually exclusive.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_traversal_utils.py:46:# TODO (awgu): We may be able to remove this function if we retired the
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:115:# TODO: Define this for now to avoid circular imports. See if we can remove.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1566:                # TODO (awgu): Gradient accumulation outside `no_sync()`
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1607:            # TODO (rohan-varma): test for full precision with keep_low_precision_grads
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1616:        # TODO (awgu): We should replace these conditional checks to encode
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:1785:                # TODO: Change `_unpadded_unsharded_size` if we change the
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py:2293:        # TODO: If we want to handle shared parameters, we need to re-generate
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:77:# TODO (awgu): Refactor this later
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:321:    # TODO: FSDP's contract for buffers is not well-defined. They are
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:517:    # TODO: we need to add additional check once we support FSDP + PiPPy.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:657:            # TODO: We may relax this by taking the FSDP instance's wrapped
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:832:    # TODO: We need to establish a contract for FSDP and buffers. For now, we
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_init_utils.py:1052:# TODO: See how to deprecate!
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/utils/distributed.py:77:            # TODO properly map the exceptions in pybind (c10d/init.cpp)
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py:430:        # TODO log_line_prefixes can be exanded too
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:144:        # TODO: look into using weakref here instead.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:190:# TODO: we should probably handle a few additional errors,
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:248:        # TODO: look into using weakref here instead.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:919:        # TODO: implement timeout
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:84:    # TODO @kiuk - make entrypoint a required field
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py:701:        # TODO after stopping workers, wait at least monitor_interval*2 for
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py:100:# TODO: create an internal helper function and extract the duplicate code in FP16_compress and BF16_compress.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:72:            # not average. TODO: (rohan-varma) the div factor may be different
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/optimizer_overlap_hooks.py:77:            # TODO (rohan-varma): upcast as needed for DDP mixed precision,
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:593:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py:814:        # TODO: The above procedure does two matmul+allreduce steps per iteration --
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:285:    # TODO: Importing inside function to avoid circular import issue between FSDP and
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/algorithms/_optimizer_overlap/optimizer_overlap.py:76:    # TODO: register_fsdp once FSDP supports communication hook.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:241:    # TODO this should be done inside AsyncCollectiveTensor to delay the wait() call
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:698:        # TODO: it should run collective in the whole mesh instead of dim 0
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:967:    group,  # TODO add a type,
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:981:    op: str = "sum",  # TODO type is actually c10d ReduceOp. is this ok?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives.py:982:    group=None,  # TODO add a type
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/sharding_prop.py:173:        # scalar. TODO: figure out a better way to handle this
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:138:            # TODO: by default check tensor metas across rank
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:139:            # TODO: See if we need to make this run_check logic
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:181:            # TODO: return the redistributed local tensor directly without
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:185:        # TODO: backward is also differentiable now, add a test
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:248:        # TODO: consider all_gather the local tensors for better debugging
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/api.py:561:    # TODO: the value assignment to global variable is not the ideal solution
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_utils.py:16:# TODO: audit existing code base to see if we can safely remove this API.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:154:        # TODO: alltoall/permute reshuffling to change device_mesh if they are not the same
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/redistribute.py:212:                # TODO: enable this with all_to_all
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:718:        # TODO: we can avoid forcing the redistribution once we figure out
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:735:            # TODO: we can avoid forcing the redistribution once we figure out
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:752:            # TODO: we can avoid forcing the redistribution once we figure out
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:820:        # TODO: change the strategy to the following rule.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:827:            # TODO: now grad_out spec follows input spec. we may need
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/math_ops.py:871:            # TODO: now d_weight spec follows input spec w/ a reduction.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:663:            # TODO: optimize this. we shouldn't simply blindly replicate
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/utils.py:140:        # TODO: maybe we should determine is_shardable based on
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/random_ops.py:26:            # TODO: figure out how inplace random op should behave when it's partial
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/matrix_ops.py:151:    # TODO: sdpa might be a good candidate for us to explore decomposed sharding propagation
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:98:                # TODO: further merge the sharding properly (i.e. reshard one input to replicate)
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/common_rules.py:164:            # TODO: consider a more advanced heuristic to pick the best sharding
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:115:            # TODO: see if this is valid for the submesh case
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/basic_strategy.py:171:    # TODO: filter out invalid strategies, at this point we generate
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/pointwise_ops.py:527:# TODO: add all for_each ops
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:178:        aten.new_empty_strided.default,  # TODO: re-think new_empty_strided
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:183:    # TODO: maybe we should generate all possible shardings intead of just stay
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:294:    #   TODO: Ideally we'd like to make sure the output is re-sharded afterwards to keep input sharding.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:500:    TODO: exception: when the dtype of second input is "bool", then a torch.nonzero needs to be triggered first.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:775:    # TODO: tensor to split cannot have _Partial
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/tensor_ops.py:785:    # TODO: just like slice op, split replicates before
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:44:        # TODO: evaluate if we need to release the mask buffer or the buffer
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:177:    # TODO: implement rowwise sharding
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/embedding_ops.py:253:    # TODO: implement rowwise sharding backward
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/dispatch.py:238:        # TODO: the op schema should probably just remain flattened so that we can avoid this tree flatten
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/tp_conv.py:13:    # TODO: whether there requires data exchange is currently determined by padding
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/placement_types.py:358:        # TODO: if the reduce_op is min/max, etc. the _partition_value should be a
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/op_schema.py:214:    TODO: make this a frozen dataclass
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:26:# TODO: we need to migrate these APIs to be functional collectives
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:53:    # TODO: Ideally we should use the meta tensor way
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:109:    # TODO: Ideally we should use the meta tensor way
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:125:# TODO: test uneven split on GLOO and NCCL
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:142:        # TODO: pull the handle of uneven case in #492
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:207:                # TODO: see if we need to tweak this or offer a way for user
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/_collective_utils.py:268:        # TODO: see if we want to support this once there's cross mesh communication
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/api.py:165:        # TODO: figure out a generic and efficient way to scatter the shards for EnumerableShardingSpec
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/_internals.py:150:        # TODO: Can we improve this error message to point out the gaps?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding.py:287:    # TODO: Make the result a PartialTensor.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec_ops/embedding_bag.py:407:    # TODO: Make the result a PartialTensor and move the logic below there.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharding_spec/chunk_sharding_spec.py:66:        # TODO: support named dimension
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:79:        # TODO: implement state_dict
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:90:        # TODO: implement load_state_dict
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_optim/api.py:96:        # TODO: implement add_param_group
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:427:            # TODO make it as a view of out tensor
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:492:        # TODO: make this a __torch_function__ op once ShardedTensor becomes a
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/api.py:835:        # TODO: figure out what the API should behave when some rank have no shard
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_shard/sharded_tensor/_ops/tensor_ops.py:30:# TODO: set grad with a ShardedTensor that consists of all local grads
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:283:            # TODO: make async?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/rpc/backend_registry.py:342:        # TODO: add try-except and destroy _agent in all processes if any fails.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:245:        # TODO: remove this exception once UCC plugin is fully deprecated.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:482:        TODO don't expose the map, expose fine grained ops
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:492:        TODO don't expose the map, expose fine grained ops
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:502:        TODO don't expose the map, expose fine grained ops
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:512:        TODO don't expose the map, expose fine grained ops
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:522:        TODO don't expose group_count, use something else instead
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:611:            # TODO moco benchmark on CPU initializes pgnccl backend today, triggered this assert in CI before it was
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:816:# TODO: remove this once the ecosystem moves away from it.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:852:    # TODO(yifu): remove this function once ranks + tag is not a supported
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1506:            # TODO: remove this check after lazy initialization is supported
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1537:            # TODO: once UCC plugin is fully deprecated, remove
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1575:        # TODO: This defaults to the old behavior for PythonProcessGroups which overwrites the
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:3753:        # TODO(whc) aparently some existing test case for monitored_barrier passes in a timeout in float format?
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4225:    # TODO copy settings and timeout from default PG
./api/search/.venv/lib/python3.12/site-packages/torch/_torch_docs.py:5271:# TODO: Fix via https://github.com/pytorch/pytorch/issues/75798
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:43:# TODO: implement ref.cast with an option to enforce safe casting
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:172:# TODO: handle tuples of tensors
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:362:            # TODO: There is a subtle bug here: prims like copy_to
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:379:# TODO: when tracing this will add torch tensors and not TensorMeta objects
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:381:# TODO: this wrapper is currently untested
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:43:# TODO: Type[torch.SymInt], Type[torch.SymFloat]
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:45:# TODO: This needs a lot more type annotations
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:107:            # TODO: We should check that the symbols are consistent
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:134:# TODO: look at using torch.testing.assert_close instead with an option
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:164:        # TODO: we should review why this happens and see about fixing it
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:440:    # TODO: are these necessary?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:449:    # TODO: do channels last too
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1034:        # TODO: type error here is real, replace with sym_complex
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1053:    # TODO: sym_complex_float?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1195:# TODO: maybe unify with can_cast_to?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1349:# TODO: when NumberType contains the sym types, can simplify this
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1367:# TODO: document type promotion kinds
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1630:    # TODO: maybe inform the user of channels_last_3d if rank of the tensor is 5?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims_common/__init__.py:1923:    # TODO: a better way to handle this would be with a new op, "_unsafe_as_strided"
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:123:    # TODO: no real reason to restrict multiple outputs
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:167:        # TODO: file issue
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:195:    # TODO: I think this does the wrong thing if r is inp
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:247:    # TODO: remove me
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:276:        # TODO: consider a memo
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:309:        # TODO: Add a config knob to turn off this unsound behavior
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:559:            # TODO: We can make this a little more faithful with best effort
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:941:            # TODO: Minor optimization: track if the shapes
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:980:            # TODO: we don't need the compute type
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_impls.py:1002:        # TODO: is_non-overlapping_and_dense (not bound from Python
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/schema_check_mode.py:50:                # TODO: This is only OK if can't have NaN quantized; idk if
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_utils.py:109:                # TODO: enable_python_dispatcher() here
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:69:    # TODO (tmanlaibaatar) make it a tag
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:103:            # TODO: right now, _make_wrapper_subclass's dynamic shape interaction is not great.
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:288:            # TODO (tmanlaibaatar)
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:468:    # TODO: pull these from aot autograd
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:82:        # TODO: test if is resizable (no direct query for this atm)
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:83:        # TODO: audit AutogradMeta to see if it matches
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:84:        # TODO: test forward AD
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:216:            # TODO: make a dedicated UnknownSource for this?
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:415:                # TODO: Change this logic to use view replay for consistency?
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:593:                    # TODO: Handle this better in Dynamo?
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:872:                    # TODO: Use a valid grad-specific symbolic context instead of recycling
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:898:        # TODO: zero tensors?  We appear to have eliminated them by
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/meta_utils.py:913:                # TODO: sparse should support meta
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:50:# TODO: Hack to unblock https://github.com/pytorch/pytorch/pull/108186
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:416:    # TODO: Generalize this as needed, e.g., into a trie of memos
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1099:        # TODO: support caching sparse outputs?
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1386:                    # TODO: Remove these exclusions, so that we can remove
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1405:        # TODO - we should be use the prim aten impl
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1406:        # TODO - fix prims complex ops
./api/search/.venv/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1714:    # TODO: also check metadata change on inputs
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:13:# TODO: Add type annotations
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:14:# TODO: Check tensor types for ops
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:150:# TODO: Expose these directly to Python to avoid maintaining this list.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:206:    # TODO: Make this an enum.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:239:    # TODO: Support non-equal-rank broadcast where semantics match.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:264:    # TODO: Handle dilation
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:492:                # TODO: Improve this error message, possibly after converting
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1169:            # TODO: Possibly check scale and zero point.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1171:            # TODO: Possibly support variable-sized inputs.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1466:                # TODO: Support this by adding trailing 1 dims.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1496:        # TODO: Validate ceil_mode semantics.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1753:        # TODO: Transform at load time to share weights with CPU model.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1793:        # TODO: Support automatic reshape
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:1832:        # TODO: Transform at load time to share weights with CPU model.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/serializer.py:2055:        # TODO: Transform at load time to share weights with CPU model.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:72:            # TODO: See if it's possible to use those directly.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:84:            # TODO: See if it's possible to use those directly.
./api/search/.venv/lib/python3.12/site-packages/torch/backends/_nnapi/prepare.py:139:    # TODO: Maybe make these names match the original.
./api/search/.venv/lib/python3.12/site-packages/torch/_custom_op/autograd.py:46:# TODO(#101191): Use the actual C++ autograd not implemented fallback,
./api/search/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:24:# TODO: Maybe we should allow for some sub-hierarchy so you can control which
./api/search/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:113:    # flattens all the qnames together (TODO: consider memoizing?)
./api/search/.venv/lib/python3.12/site-packages/torch/_logging/_internal.py:1055:            # TODO: Actually, the rank probably should just be emitted once at
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset13.py:549:    # TODO: So far we don"t have a module using this method. We"ll keep
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1510:        # TODO: remove this as onnx opset 11 spec allows negative axes
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1561:    # TODO(justinchuby): Looks like this op is deprecated in torch
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2446:    # TODO: remove this as onnx opset 11 spec allows negative axes
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3451:# TODO(justinchuby): Support multiple quantized args in output
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3477:# TODO(justinchuby): Support multiple quantized args in output
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4261:# TODO(justinchuby): Support multiple quantized args in output
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4291:# TODO(justinchuby): Support multiple quantized args in output
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5376:    # TODO: remove this as onnx opset 11 spec allows negative axes
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:5856:            # TODO: If indexing is supported natively in ONNX in future opsets,
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6311:        # TODO: Might need a fix in torch group_norm module
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6820:# TODO: It would be better to export this as a chunk directly, as this is
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6822:# TODO: Once we have proper scoping, stop reimplementing chunk, delete this
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:6884:        # TODO(justinchuby): Use a public method in the helper module
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:112:# TODO(justinchuby): Add type checking by narrowing down the return type when input is None
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:252:            # TODO: Remove `check_shape` option once every shape inconsistent issue is addressed.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:435:        # TODO: remove this and treat mutating model separately. See #77679
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:619:    # TODO: refactor utils.py to remove duplicated code of context setup. See #78834
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:691:    # TODO: Below is doing aten graph to onnx. It should be abstracted as a
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:873:        # TODO(#77679): remove this and treat mutating model separately.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:921:    # TODO: Only copy the argument if mutation is detected in Graph.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1278:            # TODO: A more compact graph printer.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/verification.py:1853:    # TODO: Copied from utils.py `export` until `_optimize_graph`.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_experimental.py:14:    TODO: Adopt this in `torch.onnx.export` api to replace keyword arguments.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:39:        # TODO(thiagocrepaldi): handle overload_name?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_onnx_supported_ops.py:45:        # TODO(thiagocrepaldi): handle overload_name?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:16:                        TODO: test coverage for mixed types inputs.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:19:                        TODO: bfloat16 support.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset15.py:22:                        TODO: optional start/end attribute.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:156:    # TODO(justinchuby): Replace insinstance with _is_value once we figure out mypy
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:432:            # TODO(justinchuby): Only single output is supported for now. We may want to
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1346:        # TODO(justinchuby): Check if dtype is indeed a int.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:1718:# TODO: remove these once we support Type's in the JIT IR and we can once again
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:75:# TODO(justinchuby): Remove dependency to this global variable from constant_fold.cpp
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1127:    # TODO: can we simplify this to always return a tuple of Tensor or None?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1379:            # TODO(justinchuby): Create a way to check if an op is fully supported.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1625:            # TODO: Don't allocate a in-memory string for the protobuf
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1851:        # TODO(justinchuby): Update the module name of GraphContext when it is public
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/utils.py:1952:                # TODO Wrap almost identical attrs assignment or comment the difference.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:134:        # TODO: get opset version from torchlib
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:362:        from torch.onnx._internal.fx import (  # TODO: Prevent circular dep
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1017:            # TODO: Should this be part of the serializer?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1080:        # TODO: Should we populate ONNXProgram with more info, such _model_torch for easier debug?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1119:    # TODO: Design the passes API
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1154:        # TODO: https://github.com/pytorch/pytorch/issues/107714
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1164:        # TODO: Defer `import onnxscript` out of `import torch` path
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1174:            # TODO: Defer `import onnxscript` out of `import torch` path
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:1451:    # TODO: Import here to prevent circular dependency
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/registration.py:149:    # TODO(justinchuby): Add @functools.lru_cache(maxsize=None) if lookup time becomes
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:119:    # TODO: select a good default based on the capabilities of the host
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:683:    # TODO(wschin): Make it to inference session level flag.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:774:        # TODO(wschin): this is a naive implementation of cache without proper guard
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:951:            # TODO(wschin): enable external allocators.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/onnxruntime.py:1079:                # TODO(wschin): use a better way to identify fused submodule
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:4:# TODO(justinchuby): Move more of the symbolic helper functions here and expose
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:359:# TODO: Expose this to user when migrating symbolic helper functions to here.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:7:# TODO: Remove after https://github.com/huggingface/safetensors/pull/318
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/patcher.py:41:    TODO: Should this really be a global patcher? Can we make it a local patcher?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:98:# TODO: generalize to allow more checkpoints formats (torch or gguf)
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:39:        # TODO: Figure out how to retrieve commit hash.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:188:    TODO(bowbao): Add more overridable methods in call hierarchy
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/_pass.py:189:    TODO(bowbao): Create an example once more overridable methods are added.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/onnxfunction_dispatcher.py:315:            # TODO(titaiwang): aten::sym_size has overload, but fx graph is using
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/op_validation.py:92:            # TODO(titaiwang): How to bound indices/dim: INT64
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:38:# TODO(bowbao): move to type utils.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/type_promotion.py:1267:        # TODO(bowbao): diagnostic.emit and diagnostic.set_message api.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/decomp.py:54:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/passes/functionalization.py:109:        # TODO: May need revisit for user fake mode export + dynamic shape scenario.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/diagnostics.py:129:    # TODO: Compact display of `param_schema`.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:56:    TODO(bowbao): Create fx utils module and move this function there.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:321:    # TODO: aten::sym_size has overload, but fx graph is using
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:400:    TODO: Convert methods to @staticmethod when the diagnostic system supports it
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:409:        # TODO: Diagnostics API should be revised to get rid of this attribute.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:567:        # TODO: Fix FakeTensorMode limitation asap
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:761:        # TODO(wechi): Support call_method.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:818:        # TODO: We may want to consider other naming styles. The goal is to be stable and
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/torch_export_graph_extractor.py:106:        # TODO: Import here to prevent circular dependency
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:125:# TODO: Migrate to `DynamoExporter` after fake model tracing is supported.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:159:        # TODO: plumb ``concrete_args`` to symbolic_trace call at ``generate_fx``
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:24:# TODO(bowbao): Add diagnostics for IO adapters.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:152:# TODO: make_fx lose stack info https://github.com/pytorch/pytorch/issues/90276
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:182:    # TODO(bowbao): Turn this check into diagnostic. Consider warning instead of error.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:493:                    "markdown": 'This error occurs when the ONNX converter is unable to find a corresponding symbolic function\nto convert a "call_function" node in the input graph to its equivalence in ONNX. The "call_function"\nnode represents a normalized function call in PyTorch, such as "torch.aten.ops.add".\n\nTo resolve this error, you can try one of the following:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/tutorials/beginner/onnx/onnx_registry_tutorial.html#overview) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n',
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/_rules.py:518:                    "markdown": "This error indicates that an FX graph contains one or more unsupported nodes. The error message\nis typically accompanied by a list of the unsupported nodes found during analysis.\n\nTo resolve this error, you can try resolving each individual unsupported node error by following\nthe suggestions by its diagnostic. Typically, options include:\n\n- If exists, apply the auto-fix suggested by the diagnostic. TODO: this part is not available yet.\n- Rewrite the model using only supported PyTorch operators or functions.\n- Follow this [guide](https://pytorch.org/docs/stable/onnx.html#onnx-script-functions) to write and\n  register a custom symbolic function for the unsupported call_function FX node.\n",
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:104:            # TODO(bowbao): by default diagnostic doesn't have stack.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:158:# TODO(bowbao): decorator to report only when failed.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:280:    # TODO(bowbao): Implement this.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:406:            # TODO(bowbao): Create builtin-rules and create diagnostic using that.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/diagnostics/infra/_infra.py:264:    # TODO: Implement this.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:30:# TODO(After 1.13 release): Remove the deprecated SymbolicContext
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/__init__.py:146:# TODO(justinchuby): Deprecate these logging functions in favor of the new diagnostic module.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset10.py:763:    # TODO(justinchuby): Extract all the cast ops into a helper function.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/utils.py:75:                # TODO(avik): Assert the following property in the IR verifier:
./api/search/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:30:    # TODO(angelayi): remove this in favor of _check_val
./api/search/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:42:        elif isinstance(val, (FakeTensor, torch.Tensor)):  # TODO(zhxchen17) Remove Tensor.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:161:            # TODO Remove this allowlist.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:170:                # TODO (tmanlaibaatar)
./api/search/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:199:                # TODO(T140410192): should have fake tensor for all dialects
./api/search/.venv/lib/python3.12/site-packages/torch/_export/verifier.py:247:                # TODO(zhxchen17)
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/upgrade.py:109:        # TODO(larryliu0820): Add support for custom ops
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:234:        storage_offset=serialize_sym_int(0),  # TODO needs to be fixed.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:271:        # TODO: this should be fixed by deserialization instead.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:402:            # TODO(zhxchen17) Maybe provide a function name helper in FX.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:406:        else:  # TODO(zhxchen17) Don't catch all here.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:439:                # TODO: create a new tensor_values here, meta might have faketensor info
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:476:                # TODO: This is not ideal, we should fix this.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:858:            raise AssertionError("TODO")
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1119:        # TODO: Directly serialize exported_program.constants once
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1179:        if serialized_target.startswith("_operator"):  # TODO(zhxchen17) Follow up on this.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1185:        else:  # TODO(zhxchen17) Don't catch all here.
./api/search/.venv/lib/python3.12/site-packages/torch/_export/serde/serialize.py:1886:            # TODO(larryliu0820): Add support for upgrader & downgrader
./api/search/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:102:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./api/search/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:107:                        # TODO we should allocate static shapes
./api/search/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:116:                        # TODO: This is just a workaround to get over the
./api/search/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:135:                        # TODO (tmanlaibaatar) properly support Quantized FakeTensor
./api/search/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:143:                        # TODO: This is just a workaround to get over the
./api/search/.venv/lib/python3.12/site-packages/torch/_export/pass_base.py:275:        # TODO(angelayi): Update this with what we decide to do for metadata in
./api/search/.venv/lib/python3.12/site-packages/torch/_export/passes/replace_view_ops_with_view_copy_ops_pass.py:16:# TODO (tmanlaibaatar) remove this after https://github.com/pytorch/pytorch/pull/100749
./api/search/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:104:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./api/search/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:181:    # TODO(avik): refactor Dynamo to avoid duplication of the following code
./api/search/.venv/lib/python3.12/site-packages/torch/_export/non_strict_utils.py:213:        # TODO(avik): Maybe record the constraint violation error instead and replay later?
./api/search/.venv/lib/python3.12/site-packages/torch/_export/exported_program.py:8:# TODO(ycao): This is added to avoid breaking existing code temporarily.
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/context.py:53:        # TODO: Should these methods be mapped some other way?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:233:        # TODO: This looks wrong, a number that is wrapped into a tensor
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:338:# TODO: implement dtype validation here, too, or on the corresponding refs
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:420:    # TODO: fix number type promotion (bool, complex->float)
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:950:# TODO: complex needs a special meta to account for its float -> complex behavior
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1456:        # TODO: this is only here to support the unsqueeze ref
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1644:# TODO: make stride SymInt
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1695:# TODO: consider renaming split_dim_view
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:1903:# TODO: review stride logic
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2054:        # TODO: update meta objects so this can be acquired directly
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2118:# TODO: create a new return type for scalars?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2150:# TODO: create a new return type for scalars?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2182:# TODO: create a new return type for scalars?
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2203:    # TODO: move this as an option on the reference
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2225:# TODO: Remove safe casting and implement on reference instead
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2288:# TODO: review support arbitrary resizes
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2438:# TODO: layout, pin_memory, memory_format
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2439:# TODO: model requires_grad on TensorMeta
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2486:# TODO: layout, pin_memory, memory_format
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2487:# TODO: model requires_grad on TensorMeta
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2529:# TODO: add layout, pin_memory
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2584:# TODO: add layout, pin_memory
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2624:# TODO: add layout
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2707:# TODO: add layout and pin_memory support
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2748:    # TODO The MAGMA backend returns V, so this is wrong if used with the MAGMA backend
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2875:# TODO: we should more seriously review randomness modeling and prims
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/executor.py:53:        # TODO: caching
./api/search/.venv/lib/python3.12/site-packages/torch/masked/maskedtensor/reductions.py:127:        # TODO: autograd.Function doesn't support kwarg
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:524:    assert mask.dense_dim() == input.dense_dim()  # TODO: eliminate this restriction
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:816:    # TODO: implement sparse CSR specific where operator for efficiency
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1381:            # TODO: compute count analytically
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1605:            # TODO: compute count analytically
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1621:        # TODO: replace torch.subtract/divide/square/maximum with
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1785:    # TODO: eliminate mask_input as unnecessary when using masked divide.
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1789:        # TODO: replace torch.maximum with masked maximum when available.
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:1791:        # TODO: replace torch.divide with masked divide when available.
./api/search/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:112:        # TODO(avik): use sympy value range analysis instead?
./api/search/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:126:        # TODO(avik): use sympy value range analysis instead?
./api/search/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:188:    # TODO: We don't need t_id; we can get it off of w_tensor
./api/search/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:287:        # TODO: A better way is needed. Currently we use 't_id' to map the constraint,
./api/search/.venv/lib/python3.12/site-packages/torch/export/dynamic_shapes.py:364:        # TODO(avik): clean this up
./api/search/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:277:            # TODO(suo): untangle this.
./api/search/.venv/lib/python3.12/site-packages/torch/export/unflatten.py:281:                # TODO(suo): The FlatArgsAdapter returns a list of flat args,
./api/search/.venv/lib/python3.12/site-packages/torch/export/_unlift.py:246:    # TODO(suo) this should not be optional, but is since we still ahve
./api/search/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:129:                # TODO(suo): this is horrible.
./api/search/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:270:        # TODO Make this tuple.
./api/search/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:281:        # TODO Make this tuple.
./api/search/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:302:        # TODO Make this tuple.
./api/search/.venv/lib/python3.12/site-packages/torch/export/graph_signature.py:312:        # TODO Make this tuple.
./api/search/.venv/lib/python3.12/site-packages/torch/export/_trace.py:133:    # TODO properly use the cached fake tensor
./api/search/.venv/lib/python3.12/site-packages/torch/export/_trace.py:186:                    # TODO Figure out why sometimes we have root sometimes we don't.
./api/search/.venv/lib/python3.12/site-packages/torch/export/_trace.py:208:                    except Exception:  # TODO(zhxchen17) Remove this.
./api/search/.venv/lib/python3.12/site-packages/torch/export/_trace.py:413:    transform=lambda x: x,  # TODO(zhxchen17) Revisit if this is needed later.
./api/search/.venv/lib/python3.12/site-packages/torch/export/_trace.py:446:    # TODO unfortunately preserving graph-level metadata is not
./api/search/.venv/lib/python3.12/site-packages/torch/export/_trace.py:496:            # TODO: this branch is likely wrong, all permissible ConstantArgument type
./api/search/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:138:        verifier: Optional[Type[Any]] = None,  # TODO Change typing hint to Verifier.
./api/search/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:141:        ] = None,  # TODO: deprecate this
./api/search/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:478:        # TODO(zhxhchen17) Return the new graph_signature directly.
./api/search/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:543:        # TODO unfortunately preserving graph-level metadata is not
./api/search/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:584:        # TODO(zhxchen17) Remove this.
./api/search/.venv/lib/python3.12/site-packages/torch/export/exported_program.py:675:    # TODO(zhxchen17) Formalize this.
./api/search/.venv/lib/python3.12/site-packages/torch/_numpy/_unary_ufuncs_impl.py:71:# TODO set __name__ and __qualname__
./api/search/.venv/lib/python3.12/site-packages/torch/_numpy/random.py:162:    # TODO: check a.dtype is integer -- cf np.random.choice(3.4) which raises
./api/search/.venv/lib/python3.12/site-packages/torch/optim/radam.py:466:            # TODO(mlazos): we should try and get a foreach_where op https://github.com/pytorch/pytorch/issues/117884
./api/search/.venv/lib/python3.12/site-packages/torch/optim/_functional.py:19:# TODO: use foreach API in optim._functional to do all the computation
./api/search/.venv/lib/python3.12/site-packages/torch/optim/adam.py:51:            # TODO(crcrpar): [low prec params & their higher prec copy]
./api/search/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:59:            # TODO(crcrpar): [low prec params & their higher prec copy]
./api/search/.venv/lib/python3.12/site-packages/torch/package/importer.py:81:            # TODO: I guess we should do copyreg too?
./api/search/.venv/lib/python3.12/site-packages/torch/package/package_exporter.py:918:                # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:246:                # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/package/package_importer.py:283:        # TODO from zdevito:
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:27:# TODO: The mechanism we are using to register decompositions doesn't
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_jvp.py:97:# TODO: do these also belong here?
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:27:# TODO - We have to register many more distributions here, and also higher level
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions_for_rng.py:168:        # TODO: Investigate if there is be a better way to wrap the tuple in a
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:59:        # TODO: pretty sure this is not quite right
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:387:# TODO: None of these loss castings are quite correct, see
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1413:# TODO: this doesn't appear to have enough precision in bfloat16
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1591:# TODO: Take a closer look at the type promotion semantics
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1798:# TODO: this decomposition is NOT here to stay. We would much prefer replacing native_batch_norm
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1965:    assert not layout or layout == torch.strided, "TODO"
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1966:    assert not pin_memory, "TODO"
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:2257:            # TODO make minimum accept scalars
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/decompositions.py:4055:        # TODO: handling of slice
./api/search/.venv/lib/python3.12/site-packages/torch/_decomp/__init__.py:23:# TODO: relax key type here; torch registrations should be possible to; but
./api/search/.venv/lib/python3.12/site-packages/torch/cpu/amp/autocast_mode.py:34:    # TODO: discuss a unified TorchScript-friendly API for autocast
./api/search/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:293:    # TODO: Handle distinguishing between subclass and non-subclass versions of NT better
./api/search/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:592:    # TODO: Maybe this should be in tensor_classes? :)
./api/search/.venv/lib/python3.12/site-packages/torch/_lobpcg.py:993:        # TODO use torch.linalg.cholesky_solve once it is implemented
./api/search/.venv/lib/python3.12/site-packages/torch/_deploy.py:24:                # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/_deploy.py:68:            # TODO: Once we decide to break serialization FC, we can
./api/search/.venv/lib/python3.12/site-packages/torch/_guards.py:60:    # TODO: consider also tracking the recompilation count
./api/search/.venv/lib/python3.12/site-packages/torch/_guards.py:779:# TODO(voz): Consider a toplevel torch/_source.py
./api/search/.venv/lib/python3.12/site-packages/torch/__init__.py:32:# TODO(torch_deploy) figure out how to freeze version.py in fbcode build
./api/search/.venv/lib/python3.12/site-packages/torch/__init__.py:566:                # TODO: fix their module from C++ side
./api/search/.venv/lib/python3.12/site-packages/torch/__init__.py:651:            # TODO: Call like get_device_index() method corresponding to
./api/search/.venv/lib/python3.12/site-packages/torch/__init__.py:1507:        # TODO: Once the undocumented FC window is passed, remove the line bellow
./api/search/.venv/lib/python3.12/site-packages/torch/__init__.py:1937:# TODO: remove the function for PyTorch v 1.15.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:390:            # TODO: binary search
./api/search/.venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:634:            # TODO: type annotations for *args and **kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:132:        # TODO node_name_to_scope will be depreciated in favor of
./api/search/.venv/lib/python3.12/site-packages/torch/fx/proxy.py:479:                # TODO: Define how to symbolically trace HigherOrderOperators
./api/search/.venv/lib/python3.12/site-packages/torch/fx/operator_schemas.py:73:        # TODO: Figure out if this is safe. It seems like when generating the type signatures for
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/meta_tracer.py:194:            # TODO
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_transformation.py:141:    TODO: we have to check if this is the case for all HF models
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:370:    # TODO: add the extra check mentioned here:
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:393:        # TODO: review this rule; should input = dyn; output = dyn be included here?
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:519:            # TODO: we should figure out why there is a key-error here.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:780:# TODO normalize index
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/migrate_gradual_types/constraint_generator.py:884:        # TODO generate add constraints for scalar addition
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/schema_type_annotation.py:48:                # TODO: can we emit the union of these? What are the implications on TorchScript
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/accelerator_partitioner.py:354:                # TODO: add different size support for sparse_nn_partition
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:472:    TODO: Make Dynamo handle this appropriately if this is seen in Dynamo-ed
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:477:    TODO: I didn't support min/max because I didn't have a use case where this
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:540:    that doesn't have a lot of safety guarantees (TODO: provide higher level
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:580:    # TODO: Shouldn't we install a guard if the symbol is backed?  Or is the
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:599:    # TODO: this does not install a deferred runtime assert yet
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:601:    # TODO: Maybe dedupe this with _maybe_guard_rel?
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:610:        # TODO: Actually, we can support this as long as one of them is a symbol.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:657:        # TODO: check perf implications of this
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:782:        # TODO: better printing for -oo and oo
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:939:    # TODO: add storage offset and stride symbolic_context
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:967:# TODO(voz): Shape env validation
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:991:    # TODO(voz): consider a weakref to the shape_env here
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1038:# TODO: Deduplicate this with torch/_prims_common/__init__.py
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1354:        # TODO(avik): https://github.com/pytorch/pytorch/issues/101093
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1756:                    # TODO(avik) Maybe we should generate an assertion here?
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:1764:                    # TODO(avik) Maybe warn that `arg` in not in `signature`?
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2383:        # TODO: make this configurable from outside symbolic_context; we made a symbolic_context
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2388:        # TODO: This should be DYNAMIC, using DUCK for BC
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:2904:        # TODO: Make this more efficient by binding all the size/stride/offsets
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3566:        # TODO: when unbacked_only, can sometimes early return even when there
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3603:        # TODO it would seem that this pass is not necessary given the
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3667:        # TODO: in a Dynamo context, having user code, and having the
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3695:            # TODO: Help text about how to use our runtime tests to fix this
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:3748:            # TODO: Should we propagate size-like-ness?
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4053:        # TODO: split conjunctions and evaluate them separately
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4126:                # TODO: dedupe this with _maybe_evaluate_static
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4175:                # TODO: If we successfully eliminate a symbol via equality, it
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4187:                # TODO: deal with duplicate guards somehow
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4247:        # TODO: split conjunctions and evaluate them separately
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py:4285:            # TODO: Do this in a way that is less janky than int(s.name[1:])
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/merge_matmul.py:116:        # TODO: Properly handle aliasing caused by get_attr. For now,
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/_sym_dispatch_mode.py:50:        # TODO: properly compute types
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/graph_gradual_typechecker.py:184:    # TODO. We leave it like this till we add a type to represent tensor sizes
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/_config.py:30:# TODO: Perhaps consider allowing unions for the configs below (so you can hit
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:154:            # TODO: This doesn't properly track storages.  A more robust
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:261:    # TODO: figure out if this API generally makes sense and bake it into the
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:306:    # TODO: we could use types to test this
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:332:        # TODO: maybe constant SymInts should also be allowed?  Not sure if
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:603:            # TODO(tmanlaibaatar): we should systematically couple it with expoert verifier,
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:737:# TODO: I'm not sure what the point of this class is; you can just
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:756:        # TODO handle case where the first character of target is '*'
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1042:            # TODO: it would be nice to line these up with the names
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1068:            # TODO: Would be nice to fix this at the source...
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:1083:        # TODO: kind of a bad way to do it, should maybe figure out a better way
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:62:# TODO: An incomplete list
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:350:        # TODO: use the file/line for some useful diagnostic on why a
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:360:        # TODO: use the file/line for some useful diagnostic on why a
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:372:        # TODO: use the file/line for some useful diagnostic on why a
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:389:        # TODO: file/line here is very important, because the assert has been
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:420:        # TODO: use the file/line for some useful diagnostic on why a
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:444:# TODO: this probably needs the sizes-strides eval functions
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:817:# NB: There is a TODO in C++ to allow omitting the batch dim.  If that
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:882:    # TODO: These could also be done with indicators, maybe it is better
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:914:    # TODO: let C++ also take advantage of this
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:957:        # TODO: consider constant prop here
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1002:        # TODO: consider constant prop here
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1103:            # TODO: Remove the args construction below if a different sentinel is used by FX.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1163:    # TODO: This is technically hotpath, but in the ideal end state
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/sym_node.py:1184:            # TODO: this is an awful implementation
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/optimization.py:121:# TODO: Determine whether this can be removed after type inference.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:90:        # TODO: assert pattern is a connected graph
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:110:        # TODO(tmanlaibaatar) should probably make this actual API
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/matcher_utils.py:212:        # TODO: use a more efficient way to check if gn is matched before: two-way dict
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/utils/fuser_utils.py:133:            # TODO: do we really need copy the get_attr node into the graph?
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/fake_tensor_prop.py:49:                # TODO: How is it possible that we get a non fake tensor?  We
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:11:    # TODO: why is submodules passed here
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/backends/cudagraphs.py:51:    # TODO: single node partition may be wrong due to the pessimization
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/split_module.py:295:        # TODO currently placeholders/parameters aren't put into random partitions,
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/pass_manager.py:210:        # TODO(alexbeloi): add constraint management/validation
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:129:# TODO: this should be beefed up to be able to properly re-inplace with:
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:132:# TODO: we should also figure this info out using torchgen.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/passes/reinplace.py:538:                # TODO: later, add the optimization for handling `copy_()` calls in the graph.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/node.py:42:# TODO: Either refactor this into 2 functions 1 dce for functional graphs and 1 dce for all graphs,
./api/search/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py:127:    # TODO: we shold handle __reduce_deploy__ the same way as __reduce_package__,
./api/search/.venv/lib/python3.12/site-packages/torch/hub.py:290:    # TODO: Remove `None` option in 2.0 and change the default to "check"
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:280:        # TODO: Instead of always upcasting to int64, it would be sufficient to cast to the next higher dtype to avoid
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:787:        # TODO: Remove this conversion as soon as all operations are supported natively by the MPS backend
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_comparison.py:1522:        # TODO: compose all metas into one AssertionError
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:324:        ),  # TODO: Move out to testing in param_group?
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:345:# TODO: consider tensor LR! See multi_tensor_optimizer_configs in test_optim.py --> tensor LR should work
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_optimizers.py:831:        ),  # TODO: Move out to testing in param_group?
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:87:# TODO: due to case sensitivity problems, for now list these files by hand
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:701:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:707:            # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/nn/api/remote_module_test.py:733:        # TODO: Once the RPC backend can support directly sending GPU tensors, the expected device type should be "cuda:0".
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/multi_threaded_pg.py:29:TODO:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:1547:            # TODO: now that nccl send/recv is supported, there does not seem to
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:2546:            # TODO: move this test to use torch.profiler once kineto issues are
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:3593:            # TODO: Instead we should probably go through _rank_not_in_group
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:6436:            # TODO: NCCL backend does not work correctly for bitwise reduction ops
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8408:            # TODO: enable this for general training use cases:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:8637:            # TODO(#54879): Provide ability to wait and report all failed ranks
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:374:        # TODO: dist tensor need to support quantized and sparse
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:411:        # TODO: add multi mesh choices
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:928:        # TODO, need more investigation
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/jit/rpc_test.py:1152:            # TODO: Can't get a reliable time for this profiling event since
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/dist_autograd_test.py:1566:        # TODO, need more investigation
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:548:    # TODO: use torch.futures.collect_all
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:1421:        # TODO: with TCP init, rank 0 raises Address already in use because
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:3462:        # TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:5106:        # TODO: Cuda RPC is failing due to:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1037:        raise unittest.SkipTest('TODO: Memory availability checks for XLA?')
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_device_type.py:1522:# TODO: the "all" in the name isn't true anymore for quite some time as we have also have for example XLA and MPS now.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:144:    # TODO: reference function
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:151:        # TODO(#50743): Figure out the error. "RuntimeError: Unrecognized tensor type ID: Batched"
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2519:        # TODO(#50743): figure out the error
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2802:            # TODO: This code can path can be removed if #61309 is resolved
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3174:# TODO : Fix these discrepancies
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3317:            # TODO: compare structure (ensure analytic jacobian has correct shape)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3436:                # TODO: do this with in-memory files as soon as torch.save will support it
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3732:                # TODO: torch.complex32 when properly supported
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3814:    # TODO: check that criterions don't ignore grad_output
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:45:# TODO: TensorBase should work
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/logging_tensor.py:61:            # TODO: clone storage aliasing
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:105:# TODO: Expand this class to handle abritrary settings in addition to boolean flags?
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:1261:# TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2349:# TODO: Revisit the relaxed pairs and check how much work it is to fix the tests that would fail without the relaxation.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2715:        # TODO: sure looks like we unconditionally initialize the context here
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2788:        # TODO: Remove this; this is grandfathered in because we suppressed errors
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3486:    # TODO: add args/kwargs for passing to assertEqual (e.g. rtol, atol)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3547:            # TODO: default this to True
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3621:            # TODO: compose all metas into one AssertionError
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3705:    # TODO: Support context manager interface
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4094:# TODO: consider more complicated noncontiguity schemes
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4115:# TODO: remove this (prefer make_symmetric_matrices below)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4165:# TODO: remove this (prefer make_symmetric_pd_matrices below)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:341:    # TODO(future PR): consider combining with skipIfNoQNNPACK,
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:975:            # TODO: make img_data a single example instead of a list
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1488:        # TODO: remove this check and define two fuse_modules function on this module
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1710:# TODO: self.fc should be self.conv
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1724:# TODO: self.fc should be self.conv
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1741:# TODO: self.fc should be self.conv
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:1890:        # TODO: remove this check and define two fuse_modules function on this module
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantization.py:2427:        # TODO: remove this check and define two fuse_model function on this module
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:62:    # TODO: FSDP non-recursive wrapping
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_fsdp.py:1350:        # TODO: Disable checking the parameters for pure FP16 due to floating
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/hypothesis_utils.py:131:    # TODO: Maybe embed the enforced zero_point in the `torch.iinfo`.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_quantized.py:166:# TODO: Update all quantization tests to use this decorator.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:532:        # TODO: check gradients for parameters, not just inputs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:688:# TODO(suo) remove
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:752:# TODO: Remove me once https://bugs.python.org/issue42666 is resolved
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:821:        # TODO: inplace tests currently fail, fix and add inplace variant
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_utils.py:825:    # TODO: find better way to standardize on op registration itself..
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:492:    # flaky test - TODO fix
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/jit_metaprogramming_utils.py:530:# TODO: delete this list once we make all nn_tests work
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_cuda.py:53:# TODO(eqy): gate this against a cuDNN version
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:53:        "aliases": None,  # TODO add a check for alias coverage
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/refs.py:55:        "inplace_variant": None,  # TODO: add a check for inplace coverage
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:754:    # TODO: rename this to supports_bwgrad_bwgrad to be consistent with below
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:835:    # TODO: rename supports_sparse to supports_sparse_coo
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1414:    # TODO(@heitorschueroff) Once all reduction operators are using
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:1418:    # TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:2363:# TODO: in the future generalize the reference generators to handle n-ary elementwise operations
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1534:        # TODO: backward uses in-place operations that vmap doesn't like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2394:            # TODO: is this really needed?
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:150:                # TODO: remove this if-block after gh-98495 is fixed.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:215:            # TODO: remove this if-block after gh-98495 is fixed.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/sparse.py:248:            # TODO: remove this if-block after gh-98495 is fixed.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:42:# TODO: Consolidate `i0e` with sample_inputs_unary when `make_tensor`,
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:70:        # TODO: eliminate low after gh-106692 is fixed:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:771:            # TODO Move fftshift to decomps
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:780:            # TODO Move ifftshift to decomps
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/signal.py:302:            # TODO: same as this?
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:791:        # TODO: we should pipe the exception of the failed subprocess here.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:925:        # TODO: get test name from kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_distributed.py:1025:        # TODO: figure out a better way to do this
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:364:    # TODO: Uncomment when negative weights is supported.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_modules.py:1507:        # TODO: add pos_weight to the definition here and corresponding SampleInputs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1313:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1320:        # TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1408:# TODO: add reduction kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1870:        # TODO: no layout
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:1878:    # TODO: no layout
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2128:        # TODO: fix bug in the documentation for svd_lowrank:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3231:            # TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4405:    # TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:5034:    # TODO: can't switch `to.device` overload to use positional arguments
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:7564:# TODO: add reference inputs for where(condition) signature
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8904:        # TODO: remove once the issue is resolved
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10179:                       # TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10821:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:10832:               # TODO: update sample inputs with for_inplace_variant kwarg to support this test
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12524:           # TODO: some signatures of median do support out
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12532:           # TODO: some signatures of nanmedian do support out
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12540:           # TODO: some signatures of var_mean do support out
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12553:           # TODO: some signatures of var_mean do support out
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12565:           # TODO: some signatures of std_mean do support out
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12578:           # TODO: some signatures of var_mean do support out
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13032:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13052:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13081:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13246:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13288:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13336:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13386:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13446:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13488:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13521:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13565:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13582:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13603:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13653:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13670:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13687:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13940:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13959:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:13987:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14033:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14049:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14077:           # TODO: add shape checks
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14142:           # TODO: add shape checks
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14146:           # TODO: investigate nondeterminism
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14261:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14350:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14400:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14481:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14508:            # TODO: Do not work even on MI200 because of stride mismatching.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14522:            # TODO Need to understand what this is testing and why it doesn't work
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14525:            # TODO skip this for now since we can't skip on runtime arch support
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14582:            # TODO: Do not work on MI200 because of stride mismatching.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14603:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14648:    # TODO: combine this with the nn.functional.silu OpInfo when
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14726:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14825:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14831:        # TODO(whc) should not need sample_inputs_func, but without it
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14922:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14946:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14965:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15132:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15287:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15889:               # TODO: Investigate this more
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16191:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16266:           # TODO(@heitorschueroff) update SampleInput to handle such cases
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:16379:    # TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17332:               # TODO: same as this?
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17424:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17510:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17570:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17591:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17607:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17632:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17643:           # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:17887:    OpInfo('trapz',  # TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18131:               # TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18315:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18403:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18451:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18478:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18511:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18544:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18569:        # TODO Benchmark again with the new implementation
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18680:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18693:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18830:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18867:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18881:            # TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18908:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18959:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18962:    # TODO: delete this OpInfo once we add meta support for grid_sampler_3d
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18970:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19326:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19375:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19450:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19526:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19544:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19639:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19661:        # TODO: Avoid COW materialize
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19838:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19839:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19867:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19868:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19899:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19900:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19926:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19927:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19953:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19954:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19982:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19983:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20012:            # TODO: RuntimeError: no _refs support for torch.rand_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20013:            DecorateInfo(unittest.skip("TODO: RuntimeError: no _refs support for torch.rand_like"),
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:20946:    PythonRefInfo(  # TODO: Port this to an UnaryOpInfo
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21663:        # TODO: Uses minimum and clamp
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21691:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21699:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21707:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21718:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21748:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21756:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21764:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21772:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21783:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21794:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21805:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21813:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21821:        # TODO: If self already has the correct dtype and device, then self is
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22680:# TODO: review porting these to make_tensor
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_subclass.py:7:# TODO: Move LoggingTensor here.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:227:        # TODO(future PR): consider designing this better, as the difference
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:233:        # TODO(future PR): consider refactoring this to better reuse the parent
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:260:        # TODO(future PR): make the comparison function configurable
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:396:    # TODO(future PR): expose these
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:423:    # TODO(future PR): do not observe nodes we do not care
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:509:    # TODO(future PR): expose these
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:536:        # TODO(future PR): better check when scripted
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:583:# TODO(future PR): align on naming
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:664:    # TODO(future PR): expose these
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:805:    High level TODOs for future PRs:
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:840:    # TODO(future PR): deduplicate repeating entries
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:864:# TODO(future PR): we should rethink the names of all the PNP APIs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:940:# TODO(future PR): we should rethink the names of all the PNP APIs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:963:# TODO(future PR): consider aligning API signature with other similar quantization
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:973:# TODO(future PR): consider aligning API signature with other similar quantization
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/_numeric_suite_fx.py:996:        # TODO(future PR): consider matching in a safer way than
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:487:# TODO(future PR): clean this up
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/mappings.py:530:        # TODO(future PR): implement shadowing for binary ops and
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:10:    # TODO(future PR): make this work correctly for methods
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:33:# TODO(future PR): reuse existing mapping instead of creating a new one
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:112:    # TODO(future PR): try reversed(list(matches.items()))
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:166:            # TODO(future PR): make this code less confusing,  see discussion
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:242:    # TODO(future PR): reconsider the design to make this more intuitive.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:307:            # TODO(future): some graphs could have placeholders which are unrelated
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:346:            # TODO(future PR): handle non-normalized kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:373:            # TODO(future PR): this is not handling complicated graphs correctly, need to
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:375:            # TODO(future PR): this is ignoring kwargs, will need to support kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:459:    # TODO(future PR): move logger classes to utils to remove circular dependency
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:491:        # TODO(future PR): deduplicate equivalent qconfigs that come from
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:528:            # TODO(future PR): handle fusion patterns where non-first nodes
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:547:                    # TODO(future PR): clarify why we are adding kwargs to args
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:588:    # TODO(future PR): implement this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:609:        # TODO(future PR): add a test case for this once we have an easy
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:623:    # TODO(future): consider making this configurable
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:702:    # TODO(future PR): move logger classes to utils to remove circular dependency
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:800:                # TODO(future PR): make this support all possible args/kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:815:                        # cur_node_orig.name,  # TODO(future PR): set name explicitly
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:992:    # TODO(future PR): move this to config
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1006:        # TODO(future PR, if needed): support kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1007:        # TODO(future PR, if needed): support multiple shadow users
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1011:            # TODO(before land): fix string match
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1086:# TODO(future PR): redesign this to make it easier to consume outputs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1172:# TODO(future PR): redesign this to make it easier to consume outputs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/n_shadows_utils.py:1252:# TODO(future PR): redesign this to make it easier to consume outputs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:23:# TODO(future PR): consider deleting this enum and using the torch types
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:30:    # TODO(future PR): while these functions can support multiple dtypes,
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:35:    # TODO(future PRs): dynamic quant, fake quant, etc
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:45:    # TODO(future PR): clean this up
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:196:        # TODO(future PR): handle more functionals
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:197:        # TODO(future PR): handle functional ops which inherit qparams from input
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/utils.py:314:        # TODO(future PR): use relationship map instead of hardcoding
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/ns_types.py:18:# TODO(future PR): see if we can use typing_extensions's TypedDict instead
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:240:        # TODO(future PR): determine the actual dtype of node_c,
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:303:                # TODO(future PR): add handling for quantize_per_tensor
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:320:# TODO(future PR): look into using copy_node API instead
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:449:    TODO(before land): real docblock
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:480:            # TODO(future PR): enable multiple inputs for nodes which are not at start of subgraph
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_passes.py:842:                    # TODO: explain this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:72:    # TODO(future PR): make more generic, handle everything
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/weight_utils.py:149:    # TODO(future PR): why does packed_weight.unpack() not work?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:24:    # TODO(future PR): allow customizations
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:25:    # TODO(future PR): reuse existing quantization mappings
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:26:    # TODO(future PR): add the rest of modules and ops here
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:69:    # TODO(future PR): allow customizations from default patterns.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:74:        # TODO: this is a temporary hack to flatten the patterns from quantization so
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/pattern_utils.py:90:        # TODO(future PR): if needed, implement matching for a node
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:183:    # TODO(next): make this code handle matching by what is before the base op
./api/search/.venv/lib/python3.12/site-packages/torch/ao/ns/fx/graph_matcher.py:211:                # TODO(future PR): check for matches start_op_node and base_op_node
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:342:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:474:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:590:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:640:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_fx.py:691:        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:49:    # TODO: deprecated, remove
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:247:            # TODO: make this compatible with xnnpack constraints
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig.py:368:            # TODO: make this compatible with xnnpack constraints
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:171:        # TODO: keeping self.quant_min/max for BC; remove after a couple releases
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:274:    # TODO: rename observer to observer_ctr
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fake_quantize.py:395:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:37:# TODO: replace all usages with these constants
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:44:# TODO: derive this map from the BackendConfig
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:112:    # TODO Currently it's required that separate ops in a fused op/module have the same qconfig.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:126:    # TODO: add assert for backend choices
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:294:    # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/qconfig_mapping.py:321:    # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:20:# TODO(future PR): improve this.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:27:# TODO: not sure if typing supports recursive data types
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:33:# TODO: maybe rename this to MatchInputNode
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:115:# TODO: not used now, remove
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:117:    # TODO: reuse is_fixed_qparam_node after we move this function to _lower_to_native_backend.py
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:360:    # TODO(jerryzh): Figure out why custom quant_min/quant_max are still adjusted.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:533:# (last update over 1 year ago) and when torchscript is fully deprecated we can refactor. TODO(jakeszwe, jerryzh168)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:591:        # TODO: switch to scale.item() after adding JIT support
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/utils.py:594:        # TODO: switch to zero_point.item() after adding JIT support
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/quantizer.py:122:    # TODO: change the value to QuantizationSpec in a separate PR
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:147:        # TODO: qat + per channel?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:272:        # TODO: move this to BoltNNQuantizer?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:379:        # TODO: implement the support for None to be canceling out previous annotations
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer.py:396:        # TODO: implement the support for None to be canceling out previous annotations
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:129:    # TODO: Add more supported operators here.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:502:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:559:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:606:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/x86_inductor_quantizer.py:641:                # TODO<leslie> Remove the annotate of output in QAT when qat util support pattern matcher.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:55:    # TODO: remove, since we can use observer_or_fake_quant_ctr to express this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:488:        # TODO: annotate the uses of input, weight, and bias separately instead
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:902:# TODO: remove Optional in return type, fix annotated_partitions logic
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:918:            # TODO: change this to AnnotationException
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:958:        # TODO: remove?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantizer/xnnpack_quantizer_utils.py:1002:# TODO: make the list of ops customizable
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:32:# TODO remove this once BC is no longer required to avoid a SEV
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:204:        # TODO remove Dropout special after codebase stable
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:226:            # TODO: These are the modules that cannot be observed
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:304:    # TODO: remove allow_list
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:322:    # TODO: maybe we should change activation_post_process to _activation_post_process
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize.py:342:# TODO: rename to something more general
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:169:# TODO: rename this to _is_conv_node
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:179:# TODO: rename this to _is_conv_transpose_node
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:284:    # TODO: move this information to fx node itself
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/utils.py:513:# TODO: Handle this in export itself and don't wrap the model in another GraphModule
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:78:    # TODO: change to mul.Scalar
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:83:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:125:    # TODO: use out_dtype(mul, ...) here when the op is ready
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:245:    # TODO: change to mul.Scalar when we make x_scale/weight_scale etc. Scalar values
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:288:    # TODO: change this to mul.Scalar?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:328:    # TODO: use out_dtype op
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:398:    # TODO: use out_dtype(mul, ...) here when the op is ready
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:427:    # TODO: use out_dtype op
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/representation/rewrite.py:429:    # TODO: debug the implementation later when torchdynamo time out issue is resolved
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:100:    # TODO(Leslie): This function still fails to support custom momentum and eps value.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/export_utils.py:162:# TODO: expose these under this namespace?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:27:# TODO: make pt2e folder private?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:125:    # TODO: add assertions for types of root qspecs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:263:            # TODO: maybe edge_or_node_to_qspec should be edge_or_node_to_root_qspec, this will simplify
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/prepare.py:474:        # TODO: simplify logic for inserting observers
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:95:# TODO: merge this with the `no_conv_bias` case
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:111:        # TODO: allow setting eps
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:142:        # TODO: allow setting eps
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:196:    # TODO: allow setting eps
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:240:    # TODO: allow setting eps
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:427:# TODO: this is error prone, use the replace_literals_with_placeholders hack instead
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:555:    # TODO: use the public replace_pattern API once it also returns replacement nodes
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/pt2e/qat_utils.py:598:    #       TODO: do this for literal args for batchnorm as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:102:    # TODO: check qconfig_mapping to make sure conv and bn are both configured
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:104:    # TODO: (maybe) rewrite this with subgraph_rewriter
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantize_pt2e.py:179:    # TODO: only fuse if conv and bn are both configured to be quantized
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:80:            # TODO: currently it only works for modules,
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/qconfig_mapping_utils.py:82:            # TODO: currently it only works for object_type configurations,
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:235:# TODO: correct the namespace for these modules
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:241:# TODO: merge with STATIC_LOWER_MODULE_MAP after we merge
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:268:    # TODO: LinearLeakyReLU is registered as global but it is only fused and
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:354:# TODO: add tests for lowering these ops
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:733:        # TODO: maybe define a WeightedDynamicallyQuantizedModule
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:756:        # TODO: WeightedQuantizedModule is currently assuming static quant apis
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:759:        # TODO: maybe define a WeightedWeightOnlyQuantizedModule
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1021:        # TODO: add safety checks that users for the ref_node and dq_node needs to be one
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1024:            # TODO: add a warning or error out here? (bc-breaking if error out)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1032:            # TODO: add a warning or error out here? (bc-breaking if error out)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_lower_to_native_backend.py:1054:        # TODO: enable we have patterns that needs to swap the modules
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:47:# TODO: revisit this list. Many helper methods shouldn't be public
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:305:                        # TODO(future PR): remove this entire function  and
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:322:                    # TODO(future PR): remove this entire function  and
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:726:        TODO: traverse upwards from the output and handle the case when tuple is not a
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:802:    # TODO: log warnings only when the user enabled a debug flag
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:810:        # TODO: for now, just use the existing eps value as scale_min. In the future, we should
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/utils.py:845:            # TODO: handle fp16 qconfigs properly
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:103:# TODO: remove other variants and keep this one
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:173:        # TODO: investigate why
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:213:# TODO: remove other variants and keep this one
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:465:        # TODO: investigate why
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:547:# TODO: move this to https://github.com/pytorch/pytorch/blob/main/torch/ao/quantization/fx/_decomposed.py
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:729:    # TODO: support fp16
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:739:# TODO: dtype is ignored for now
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/_decomposed.py:760:    # TODO: check for dtype, currently we can't express torch.int4 so it's omitted
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:18:# TODO: replace all usages with these constants
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:168:    # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:330:    # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/custom_config.py:397:    # TODO: remove this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:100:        # TODO: change the signature for fuser_method to take matched module patterns
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse_handler.py:118:            # TODO: is this logic right?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:270:    # TODO: instead of instantiating the instance, we can use inspect to get the default args
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:292:    # TODO: support check for standalone module
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:300:        # TODO(future PR): remove the cast to bool below after figuring
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:308:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:318:        # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:333:    # TODO: move dtype check into `_qconfig_satisfies_dtype_config_constraints` as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:335:    # TODO: we should check is_dynamic here as well, the code from _is_input_arg_dtype_supported_by_backend
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:341:    # TODO: this is a hack because we can only specify one activation_obs_or_fq for
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:508:        # TODO: refactor the following code in terms of apply a qconfig to a pattern
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:555:    TODO(future PR, if needed): explicitly spell out the non-Tensor
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:759:    # TODO: move this to a separate function
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:769:            # TODO: we are assuming "target_dtype_info" exists here, maybe
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:829:        # TODO: this is looking into how the value is used in the future
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1071:            # TODO: this does not handle dynamic quantization yet
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1128:    # TODO: probably need to remove `is_general_tensor_value_op`
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1261:    # TODO(future PR): delete the orphaned observer modules
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1367:    # TODO: we probably don't need this counter since each graph will only have
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1417:            # TODO(future PR): update the output_quantized_idxs API to match
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1422:            # TODO(future PR): support more dtypes in model outputs, if necessary
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1443:        # TODO: we might want to handle these more uniformly with the default path
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1473:    # TODO: reuse placeholder_node_to_input_index and output_node_to_output_index
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1480:    # TODO: change this to insert obs/fq by pattern instead of by node
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1512:            # TODO: take a closer look to see if we can remove this check
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1581:                            # TODO: This currently diverges from how custom modules are handled today,
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/prepare.py:1802:    # TODO: support regex as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:26:# TODO(future PR): the 1st argument is typed as `List[Node]`, but a better type
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/match_utils.py:141:    # TODO: 1. merge with fuse matcher 2. document the code
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:40:    # TODO: We should make this private in the future
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:80:    # TODO: change this to inplace changes to graph, since we no longer construct
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:109:            # TODO: add validation that root_node is a module and has the same type
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/fuse.py:133:    # TODO: dedup with quantization matching function in match_utils.py
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:141:        # TODO: probably should cleanup this condition check, it's hard
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:186:                # TODO: we can add the information of whether a value needs to
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:196:                    # TODO: maybe need more complex attr name here
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:296:                # TODO: we can add the information of whether a value needs to
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:377:        # TODO: probably should cleanup this condition check, it's hard
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:402:                # TODO: we can add the information of whether a value needs to
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:406:                    # TODO: maybe need more complex attr name here
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:424:        # TODO: get reduce range from observer
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:447:                # TODO: we can add the information of whether a value needs to
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:461:# TODO: DeQuantStubs are currently inserted only after custom module LSTM, while observers are inserted
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:548:    TODO: this logic is hacky, we should think about how to remove it or make it more
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:582:        # TODO: it's not used, so actually we can skip quantization
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:633:    # TODO: remove is_reference flag
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:666:    # TODO: allow convert_custom_config to override backend_config
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:723:    # TODO: rename weight_is_statically_quantized to weight_is_int8_quantized
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:738:    # TODO: move this to the reference quantized module
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:854:        TODO: maybe we want to redesign this part to align with reference model design
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:880:            # TODO: This is the first step in enabling the full fx custom module
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:991:    # TODO refactor this code once we update the prepare logic to have additional information on
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1120:    # TODO: maybe move this to quantize_fx.py
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/convert.py:1124:    # TODO: this looks hacky, we want to check why we need this and see if we can
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:145:# TODO: remove this class, this is still exposed in torch.ao.quantization
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:153:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:157:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:161:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:165:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:169:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:173:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:179:# TODO: remove this class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:183:# TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:187:# TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:191:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/quantize_handler.py:195:# TODO: not used, can be removed after torch.ao.quantization namespace is deprecated
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/pattern_utils.py:14:# TODO(future PR): fix the typing on QuantizeHandler (currently a circular dependency)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:19:# TODO: move all LSTM util functions from fx/utils.py to this file
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/fx/lstm_utils.py:92:    # TODO: maybe make this work for layer_bw as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:327:        # TODO(jakeszwe, jerryzh168)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:371:            # TODO: switch to scale.item() after adding JIT support
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:374:            # TODO: switch to zero_point.item() after adding JIT support
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:392:# TODO(after v1.13): delete this
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:479:        # TODO: MinMaxObserver by itself doesn't support dynamic quantization, but
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1239:            # TODO: For some reason, this is required for it to pass torchscript test
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1393:        quant_min: minimum value in quantized domain (TODO: align behavior with other observers)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1670:# TODO(future PR): remove these defaults and enforce activation functions
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1676:# TODO: the following 2 variables are kept for backwards compatibility; remove after a few releases
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:1:# TODO: rename executorch to qnnpack_executorch since executorch is a general runtime
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:262:        # TODO: we can add fusion for torch.relu as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/executorch.py:306:        # TODO: this is not used right now since we have extra check in prepare
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/native.py:158:    # TODO: express this BackendConfig as a union of the FBGEMM and QNNPACK BackendConfigs
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/utils.py:158:# TODO(future PR): move backend_config_dict to use dataclass and move this logic to
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/qnnpack.py:80:# TODO: add additional restriction on qscheme to ensure it
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/fbgemm.py:25:# TODO: For now, these DTypeConfigs are identical to the ones defined in native.py
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/tensorrt.py:26:    TODO: add a README when it's more stable
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:23:    # TODO: need to fix the way we insert observers for this pattern
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:88:    # TODO: remove when functionalization is supported in PT2 mode
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:130:        # TODO: this is not used right now since we have extra check in prepare
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_qnnpack_pt2e.py:141:            # TODO: remove when functionalization is supported in pt2_mode
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:28:# TODO: rename to be more explicit, e.g. qat_conv_relu
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:86:        # TODO: this is not used right now since we have extra check in prepare
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/_common_operator_config_utils.py:323:        # TODO: we can add fusion for torch.relu as well
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:46:# TODO: maybe rename this to something that's not related to observer
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/backend_config/backend_config.py:263:    # TODO: refer to NativeBackendConfig once that is implemented
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quant_type.py:22:# TODO: make this private
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:181:# TODO: merge with default static mapping
./api/search/.venv/lib/python3.12/site-packages/torch/ao/quantization/quantization_mappings.py:329:# TODO: merge with get_static_quant_module_class
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/rnn.py:86:        # TODO: make this tanh a member of the module so its qparams can be configured
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantizable/modules/activation.py:308:        # TODO: This method has some duplicate lines with the
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:237:        # TODO: dedup with __init__ of RNNBase
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:924:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:939:        # TODO: these can be simplified to one level? e.g. using weight_ih as key
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/dynamic/modules/rnn.py:1005:            ret = input  # TODO: remove when jit supports exception flow
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:118:    # TODO: maybe change to this when https://github.com/pytorch/pytorch/pull/32958 is landed
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/activation.py:221:        # TODO: This is a potential source of accuracy drop.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:144:    # TODO: add an util function for converting qdtype to dtype
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:165:        # TODO: torch.quint4x2 is not supported
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:191:    # TODO: get the quant_min and quant_max from activation_post_process
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:197:    # TODO: add an util function for converting qdtype to dtype
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/utils.py:218:        # TODO: torch.quint4x2 is not supported
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:44:        # TODO(jerryzh168): maybe make this arg a required arg
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:66:            # TODO: refactor the duplicated code to utils.py
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:126:    # TODO: refactor nn.RNNCell to have a _forward that takes weight_ih and weight_hh as input
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:153:            ret = input  # TODO: remove when jit supports exception flow
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:292:        # TODO(jerryzh168): maybe make this arg a required arg
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/reference/modules/rnn.py:539:        # TODO: maybe we can try inheriting from that class and define get_flat_weights
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/dynamic/modules/linear_relu.py:36:            # TODO check if we should set reduce_rage = True by default here
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:41:        # TODO: Add qat support for BNReLU2d
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/bn_relu.py:77:        # TODO: Add qat support for BNReLU3d
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:18:# TODO: factor out the common parts to ConvNd
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:220:        # TODO(jerryzh): extend
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:102:        # TODO: Need to add options to qconfig to avoid the calibration.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:103:        # TODO: Add calibration for the sparsity
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/dynamic/linear.py:117:        # TODO (zaf): Mask might not be part of the qconfig (T83295194)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:8:# TODO (zaf): Inherit from `quantized.LinearPackedParams` (T83294430)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:66:# TODO (zaf): Inherit from `quantized.Linear` (T83294430)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:155:        TODO(zaf): Need to add the sparse params to the qconfig
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:165:        # TODO: Need to add options to qconfig to avoid the calibration.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/sparse/quantized/linear.py:166:        # TODO: Add calibration for the sparsity
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:28:# TODO update desc with new config args
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:95:        TODO: Need a clean way of loading the state of the "prepared" module
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:165:        self.model = model  # TODO: Need to figure out how to load without this.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:172:        # TODO: Remove the configuration by reference ('module')
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/base_sparsifier.py:297:                # TODO handle multiple tensor being quantized on a single module, where to store sparse_params?
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/sparsifier/utils.py:40:        # TODO Fix this typing, as Type[Module] has no attribute "from_dense"
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/pruner/base_structured_sparsifier.py:108:        # TODO LSTM Structured pruning does not support returned state currently.
./api/search/.venv/lib/python3.12/site-packages/torch/ao/pruning/_experimental/activation_sparsifier/activation_sparsifier.py:320:        TODO: Might have to treat functions (reduce_fn, mask_fn etc) in a different manner while serializing.
./api/search/.venv/lib/python3.12/site-packages/torch/cuda/amp/autocast_mode.py:43:    # TODO: discuss a unified TorchScript-friendly API for autocast
./api/search/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:225:        # TODO(torch_deploy): this accesses linecache, which attempts to read the
./api/search/.venv/lib/python3.12/site-packages/torch/_library/utils.py:104:    TODO: torchgen/model.py's FunctionSchema.parse is the source of truth for this,
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/pytree_hacks.py:9:# TODO: remove this file when the migration of the pytree utility is done
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:175:        # TODO: Resolve this so we always have matching real / symbolic tensors / metadata.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/schemas.py:251:    # TODO: we should kill this
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:301:        # TODO: we should apply the below "detach inputs if their gradients are statically known to be None"
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:777:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:856:                        # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:884:            # TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:915:        # TODO: Check aliasing relationships
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:916:        # TODO: Check strides for metadata mutation
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:193:# TODO: UNUSED. delete?
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/subclass_utils.py:225:    #   TODO: add a test case to assert we error when this happens, instead of getting silent correctness
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:117:    # TODO: should factor this into a separate function for export that always only returns just the graph.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:184:    # TODO: in AOTAutograd, we create metadata like _indices_of_inps_to_detach to detect
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/utils.py:115:            # TODO: Please remove soon
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:515:    # TODO (tmanlaibaatar) revisit this if we ever need to turn on non-strict joint graph export
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:562:    # TODO: add subclass guards (later PR).
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py:652:        # TODO: handle Tensor returns
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:155:                    #     TODO: discuss on the PR and decide if we want to tr to
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:261:                # TODO: handle the custom autograd function case here.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:524:    # TODO: Can avoid the zip here too, probably
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:540:        # TODO(voz): This structure is 1:1, we could consider an alternate structure like
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:608:        # TODO: work out how to setup this assert correctly
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:15:# TODO: It would be nice to reset the numbering every time aot_id goes
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/logging_utils.py:47:    # TODO: Don't shove the aot_id in here; set it in the context
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:74:    # TODO: refactor to kill this flag
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/collect_metadata_analysis.py:174:            #     TODO: discuss this in the PR. Both supporting this, and detecting + erroring out,
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:319:    # isn't actually true.  (TODO: Could this cause problems for Inductor?)
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:96:        # TODO: Remove the following hack for namedtuples
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/compilers.py:162:            # TODO: There is some sort of problem where we record that an
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:181:        # TODO: update following link from master to stable once that's out
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:274:            # TODO: Update link to stable once that's out
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/autograd_function.py:286:        # TODO: Update link to stable once that's out
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:346:        # TODO: What is to_size_hint suppose to be?
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:808:            # TODO: Investigate why this hack helps.
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py:809:            # TODO: Investigate the interaction with compiler assisted
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:279:        # TODO: We don't need to copy the model to create a stateless copy
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/make_functional.py:330:        # TODO: We don't need to copy the model to create a stateless copy
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:438:    # TODO: Chillee argues that dynamo itself should pass in fake tensors to
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:513:                    # TODO: Ensure that this codepath is never exercised from
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:549:                    # TODO: refactor the subclass path of run_functionalized_fw_and_collect_metadata
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:612:        # TODO: Do this properly
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:909:    # TODO: There is something deeply wrong here; compiled_fn running with
./api/search/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1167:    # TODO: we might have to temporarily patch config.functionalize_rng
./api/search/.venv/lib/python3.12/site-packages/torch/__config__.py:12:# TODO: In principle, we could provide more structured version/config
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor.py:96:            # TODO: skipping storage copy is wrong for meta, as meta
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor.py:149:                    # TODO: Once we decide to break serialization FC, no longer
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor.py:316:            # TODO: Once we decide to break serialization FC, no longer
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor.py:372:                # Ideally, we'd use a private API for this instead. TODO: Switch to this if
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor.py:413:                # TODO: Once we decide to break serialization FC, no longer
./api/search/.venv/lib/python3.12/site-packages/torch/_tensor.py:1130:            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/dependencies.py:247:            # TODO(jansel): explore this further normalization
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:116:# TODO(jansel): ezyang says we won't need this in the future, try removing it
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:132:    # TODO(jansel): add quantized types?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:275:        # TODO maybe we need to use pytrees here
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:837:        # TODO: It would be better to realize the input if any of its sizes
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1144:        # TODO <leslie> Remove this fallback when we support vectorization
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1206:    # TODO: We observed negative performance impact of pointwise_cat optimization on CPU so disabled it.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1315:        # TODO: We don't have to guard on sizes per se, but the number
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1400:    # TODO: don't guard on static shape here
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2182:# TODO(jansel): we should implement decomps or lowerings for these
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2457:    # TODO(jansel): memory format
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3448:            # TODO: Need to support more reduction type
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:3672:            # TODO(Lezcano) Here we may not need to set-up a device_size
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4025:    # TODO(jansel): should we force these to be realized?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4059:        # TODO will need a better way of determining if inputs are channels-last
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4323:    # TODO: should we force these to be realized?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4685:            # TODO(jansel): optimize to do `int(x<h)` rather than `x<h?1:0`
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:4694:    # TODO(jansel): should we force these to be realized?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:41:    TODO will it be necessary to tune multiple fields simultaneously.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/coordinate_descent_tuner.py:44:    TODO: what if both increasing and decreasing a field can improve perf.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:319:        TODO(ezyang): I think, in principle, every IRNode should have an
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:743:            # TODO the best heuristic currently has XBLOCK (corresponding to numel_hint) 128
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:842:            # TODO this will fail for something like ((1, N) * (N, 1)).sum()
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:867:            # TODO determine splits when all inputs are broadcast
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1257:        # TODO(jansel): realize the reduction so we can do dynamic indexing
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1422:        # TODO: Unrolled reduction
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1592:        # TODO: Can combine_fn/reindex close over unbacked symbols? If so, we
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1655:            # TODO: CPU support
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:1720:        # TODO: custom splitting heuristic for scan
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:2115:        # TODO: a new class for FixedTransferLayout that output layout is constrained by input layout
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3148:        TODO(jansel): A better algorithm here would look at downstream consumers of this
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3802:        # TODO(jansel): replace this with dynamic shape formulas
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3829:        # TODO: Unconditionally do this, not just when example_output has
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3905:            # TODO(jansel): impose layout preference on realized buffer
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3949:        # TODO - Storage to InputBuffer
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4456:        assert isinstance(new_size, int), "TODO: dynamic shapes"
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4661:    # TODO: handle bools carefully
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5399:        # TODO <Leslie> cleaned up the fake_tensor trace as Linear implementation
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:5693:        # TODO: op.call: input[0] should be at::Tensor&
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7318:        # TODO(whc) i'm not sure what's going on here, this probably means I missed something upstream
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7382:            # TODO: avoid more than one ref of the same pg (even though they are cached inside the api)
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7429:        # TODO: A better fix is to figure out how to propagate the aliases properly,
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7798:# TODO(yifu): replace the CollectiveKernel IR hierarchy with _CollectiveKernel.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:7879:    # TODO(yifu): add a pre-grad pass to validate the correctness of collective
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:8056:        # TODO: might be necessary to do some pretty printing on
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:545:                # TODO: migrate all disable reasons to stack trace, refactor
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:601:    # TODO: Should we actually dump this?  It should be redundant with the aot
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:864:    # TODO(jansel): figure out why this version doesn't work:
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:948:                    # TODO - could make one single op of multiple slices
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1303:    # TODO: can add logging before/after the call to create_aot_dispatcher_function
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1344:    # TODO(voz): It would be nice to enable this assert, but there are lots of tests that
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1357:    # TODO(voz): Should we always have one anyway?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:39:# TODO: A superclass that does desugaring for operations like
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:180:    # TODO: Better explain how the "collective" semantics of these ops;
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:202:    # TODO: in practice, this seems to actually return None, but not returning
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:218:        # TODO: Improve the description with some pseudocode
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ops_handler.py:465:    # TODO(ezyang): Is this really the best way to do this?  What if we have
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/index_propagation.py:80:            # TODO: Inductor doesn't handle floating point in sympy expressions well at the moment
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/utils.py:218:    # TODO: There is a bug in a call to this function, to repro:
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:45:    # TODO (tmanlaibaatar) figure out why this is different
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/freezing.py:105:    # TODO - further restrict cse ? right now needed to dedup aliasing ops
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1078:    # TODO: Revisit the functionalize_rng_ops for lowmem dropout
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/pattern_matcher.py:1357:    # TODO - look into using aot autograd, asserting no mutating ops here
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/triton_helpers.py:340:    # TODO(isuruf): use inline_asm_elementwise here
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:60:    # TODO when we drop support for Python < 3.10, we can use
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:143:# TODO(xmfan): reuse an existing mapping for this if it exists, or formalize this into ir.py:ExternKernel
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:385:                            # but TODO this might be a convenient place to signal to the Collective kernels to inplace
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:453:            # TODO(voz): Should the pragma be constant somewhere?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:474:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:625:                    # TODO(xmfan): find a better heuristic to model FLOPS/latency relationship
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:665:            # TODO make this a property of the IR
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1597:        # TODO: ideally, we should deduplicate .users and .node_users,
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/scheduler.py:1724:            # TODO support benchmarking epilogue fusion
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:156:            # TODO: this should not be needed once #93059 lands
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:158:            # TODO: make a dedicated UnknownSource for this?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:419:            # TODO - get different values per hardware
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:746:        # TODO(jansel): handle input aliasing
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:948:                # TODO: this is sus, it probably should be handled in the
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1049:                # TODO(jansel): introduce a store vs inline choice
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1124:            # TODO(Eikan): Only support mixing cpu and other device now.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1191:            # TODO: reuse self.scheduler from the first pass to speed up the second pass
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/graph.py:1262:        # TODO. Revisit this once the logging API is more mature
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:423:        # TODO: These tensors don't currently pickle, so we can't cache a
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:654:    # TODO(masnesral): Investigate whether it's beneficial to store compiled graphs
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:920:    # TODO: When making an API that can save compiled models e2e to disk
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:179:    - 8 gpus per node  # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/comm_analysis.py:187:    # TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:553:    # we could also generate all these patterns in 3d.. TODO
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/fuse_attention.py:685:            # TODO: Enable CUDA after solving Bert accuracy issue of calling efficient attention
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/freezing_patterns.py:55:        # TODO: remove the need to run fake_tensor_prop on the whole model.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:59:        # TODO - decompose/type promote to avoid this
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:85:        # TODO handle Tensor-Scalar adds, it's a different schema
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/joint_graph.py:182:        # TODO - we could also Tensors which get replaced with arange here
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/split_cat.py:127:        # TODO dynamic_shapes with assume_static_by_default=False fails while AOT Autograd tracing.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/decompose_mem_bound_mm.py:22:# TODO: need a better strategy for decomposing mm
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:173:            # TODO: support scalar case
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:191:        # TODO: support scalar case
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/binary_folding.py:269:                # TODO: support linear?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/serialized_patterns/central_index.py:111:    # TODO - could add more validation that the same set of decomps used when
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:762:                # TODO: Haozhe investigate how add guard here
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:890:            # TODO: Support dynamic shape case for MKLDNN conv transpose.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/mkldnn_fusion.py:1186:        # TODO: aarch64: enable op fusion for acl once it supports fused operators. Disabling it for now.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pre_grad.py:313:                # TODO: support kwargs.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/reinplace.py:475:                # TODO(yifu): this doesn't properly remove copy epilogues for
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:249:    # TODO - finetune coefficient here. As a reference point, Triton mm model assumes
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/pad_mm.py:402:        # TODO: Build a learned model which would be better than this heuristic
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/fx_passes/post_grad.py:377:    # TODO(jansel): rewrite this as a bmm?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cuda.py:195:        # TODO: only works for constant now, need type info
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:470:                        # TODO: input shape checking for regular tensor interface as well?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1077:        # TODO: support other overload for cpp wrapper and remove the below assertions
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1204:            # TODO: Add buf name directly into check_inf_and_nan.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1647:        # TODO: Only support tensor(s) returns for now, SymInt is not implemented yet
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1302:    # TODO: these look dead, but with all the getattr it's hard to tell...
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:1429:        # TODO: hoist this to top level
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:587:        # TODO(jgong5): A more accurate way of deciding the dtype of the variables is to
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1280:    # TODO: this seems to be dead
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:1393:        # TODO(jgong5): support conversion for other types
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2427:            self._load_mask is None  # TODO: support transposition with mask
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:2773:            # TODO(Eikan): To record, deduce and propagate the data type of every expression.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3059:                # TODO(Eikan): Regarding get_index and index_expr, we should conclude the
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3380:            # TODO(jgong5): support alternative tiling factors and data types
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3546:        # TODO(jansel): allow fusion pointwise (vars1, ()) suffix?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3565:        # TODO: we can extend fusion support with compatible ranges for FusedSchedulerNode
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3589:        # TODO: we can fix if it allows us to CSE at least one of the variables
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3682:        # TODO: support kernel profile on other platforms
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3713:        # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp.py:3912:            # TODO(jansel): look into chunk size and other schedules
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:210:                # TODO mlazos: support dynamic shapes
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_foreach.py:243:            # TODO: refactor generate_kernel_call
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:284:            # TODO(jansel): we could try harder here by merging overlapping in space
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/memory_planning.py:677:                # TODO(jansel): we should support reusing buffers created via ExternKernelAlloc
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:51:    # TODO(ipiszy): remove this hack when CUTLASS solves Python scripts packaging structure issues.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_utils.py:122:    # TODO: these three look dead?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cutlass_epilogue_gen.py:135:        # of a previous epilogue node, a constant or (TODO) an auxiliary input.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:219:        TODO: Will add needed args to pass it in if it is dynamic.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:243:        TODO: Will add needed args to pass it in if it is dynamic.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:263:        TODO: Will add needed args to pass it in if it is dynamic.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/cuda_kernel.py:319:        )  # @TODO: Hack for ensuring that Cutlass Kernel is preferred
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:400:        # TODO(ipiszy): Check whether it's necessary to swap X/W.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:482:        # TODO: update epilogue functor according to epilogues.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cuda/gemm_template.py:682:            # TODO: Support split_k.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1628:        # TODO instead of trying to blindly find complicated exprs, we should hoist the
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1701:            # TODO(jansel): it is sometimes possible to do higher dimensional block_ptrs with
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:1800:            # TODO(jansel): do we need a reshape here?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2904:        # TODO(jansel): if there are constants, we shouldn't bother passing them as args
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3504:                    # TODO - use split ranges ?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3533:            # TODO(voz): Ostensibly, we should not need this. But there are cases where C++ codegen does
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3582:            # TODO: Maybe unify CUDATemplateKernel to also use PartialRender for flexible epilogue fusion.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:3737:            # TODO(jansel): should we tile reductions?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:136:# TODO: Move to a well known place
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:705:        # TODO: Add check for python too.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:725:                # TODO: integrate memory planning & stack allocation?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:778:            # TODO: this seems legit, NullLine has no node
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1068:            # TODO(aakhundov): add None args to constants, too. currently, this
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/wrapper.py:1187:        # This is handled in `generate_args_decl` which has a correct comment of: TODO: only works for
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:13:        # TODO: Remove fp8 special handling when Triton supports PyTorch fp8 dtypes.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton_utils.py:90:            # TODO(voz): These are kinda redundant, if we can solve out statically_known_multiple_of with
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:186:    # TODO - remove, prevents cleanup
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:207:    TODO: in the future, we would like to do the following once storage weak refs land
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:253:        # TODO - when issue #91395 is landed, we can set a weakref on
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:924:        # TODO - one jit kernel across multiple inputs
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1452:        # TODO: - should we make the storage resizable ?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1535:            lambda: "TODO: graph recording observed an input tensor deallocate during graph "
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:1659:    # TODO: make generation increment configurable, warn on overwrite.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/cudagraph_trees.py:2078:        # TODO: we could also allow the these weak refs to continue to be allocated,
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/sizevars.py:506:                # TODO(jansel): should we use sympy.diff here?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1293:        # TODO: this may only be beneficial when each iteration of the reduction
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/triton_heuristics.py:1348:    # TODO(jansel): we should be able to improve these heuristics
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:114:        # TODO - fix errors with this
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:121:        # TODO - constant folding triton kernel returns the inputs -- fix this
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/constant_folding.py:130:        # TODO - more complicated strategy
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:509:                # TODO(nmacchioni): fix sympy division by zero
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/select_algorithm.py:820:        # TODO(nmacchioni): remove once CI tests are fixed
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:377:    # TODO: check if it's beneficial to convert Conv1d to Conv2d and then
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:382:        # TODO maybe we can convert weights to channels last just once before
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/conv.py:454:                # TODO(jansel): try unroll for bigger kernels once fixed:
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm.py:170:        # TODO: Re-enable eager mode implementation once cuBLAS is fixed
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/kernel/mm_plus_mm.py:208:        # TODO(jansel): support different K values when this is fixed:
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:329:# TODO: fork is not safe in a multithreaded environment, we should evaluate changing
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:406:# TODO: remove later
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/config.py:510:    # TODO - need to debug why this prevents cleanup
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:624:        # TODO: Support non-zero workspace_size.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/autotune_process.py:637:            None,  # set workspace ptr, TODO: update it to a real ptr if workspace_size > 0
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:97:# TODO: for now, inductor doesn't handle asserts
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:324:    assert not self.is_complex(), "TODO: implement this"
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/decomposition.py:386:    # TODO: _to_copy tensor to stride permutation
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:50:    # TODO - there are dominated uses whose dtype does not depend on whether
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:71:                    # TODO - not sure if we should be doing int/float casts while tracing,
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/optimize_indexing.py:109:    # TODO - if dominated node of one to_dtype is not expressible in int32,
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:39:   TODO: Define a parent class / protocol that defines all of the operations
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:128:            # TODO: To be honest, I feel we probably should just error in this
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/virtualized.py:159:)  # TODO: improve type
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:43:    TODO: We might want to adjust this in the future to account for memory limitations.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:99:    TODO: Come up with a better approach
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/comms.py:259:                # TODO: Smarter heuristics here
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:331:        # TODO - Running exec generated frame seems propagates f_globals to the
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:354:                assert recompile_reasons, "TODO(whc) any other recompile reasons?"
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:832:# TODO mlazos: add support for same args, or record them
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:877:            # TODO: the first condition is not covered by any test
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:214:            # TODO: replace `same` function with the one in testing
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:269:        # TODO: maybe should just pass the entire f_code in here?  Not
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:306:            # TODO (tmanlaibaatar) Remove this once we always lift params and buffers
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:461:    # TODO(rzou): can delete after we refactor speculate_subgraph to use nested GraphTracer.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:538:        # TODO - Consider having a torch level API for torch_function_state. As
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:658:            # TODO: don't readd symint if we already have it in graph
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1158:            # TODO(voz): The way export uses gm, and fake tensors, is not supported with us resetting
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1162:            # TODO(voz): Ostensibily, this should be scoped and
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1206:            # TODO: Why isn't this stored in meta :think:
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1324:    # TODO: this is a generic pass that should live outside of Dynamo
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1334:        # TODO: Request simplification on runtime asserts before emitting them
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1496:                            # TODO: Remove relaxing assert on unbacked_symint https://github.com/pytorch/pytorch/issues/119689
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1507:                                # TODO: use ra.msg here, but it's pretty
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:237:                # TODO(whc)
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/distributed.py:350:            # TODO - better way of doing this?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:58:                    # TODO: not correct for args that contain tensors in a struct
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/cudagraphs.py:64:        # TODO: error on unrecognized nodes
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/tvm.py:86:            # TODO(shingjan): This could be replaced by tvm.contrib.torch.optimize_torch
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:733:    # TODO: this is questionable
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1467:     * (TODO)confirming which functions got compiled/skipped
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:1956:            from tabulate import tabulate  # TODO: Check that this is installed
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:2172:    # TODO - This is a temporary situation where we have two versions of
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:112:            # TODO: Maybe complain if this isn't a int/bool/float variable
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:129:        # TODO: The default repr is pretty bad, do better
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:132:    # TODO: API for adding a custom guard
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:217:        # TODO: improve printing
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:228:        # TODO: improve by improving the VariableTracker printing
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/comptime.py:259:        # TODO: improve print format, current guard format is extremely
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_analysis.py:11:    # TODO(jansel): double check exception handling
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/types.py:85:        # TODO(whc) how do I annotate a _RecordFunction here?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/source.py:538:# TODO: can probably write a generic "test this on everything in the chain"
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:91:    # TODO(jansel): we should move guarded_backend_cache to C++
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:687:# TODO(voz): Consider making "explain" output alongside a run / part of a run
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:691:        # TODO(voz): Do we want a decorator for this?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:727:        # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:748:        # TODO(voz): Do we want a decorator for this?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:803:                    # TODO(zhxchen17) Also preserve all the user constraints here.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:903:            # TODO: option to print ALL of the stack traces at once
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1309:            # TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/_trace_wrapped_higher_order_op.py:52:# TODO(jansel): need to ensure this does not get DCEed
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/test_minifier_common.py:129:            # TODO: return a more appropriate data structure here
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:802:                # TODO(voz):
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:833:                # TODO(jansel): returning None here is wrong, it should be
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:912:        # TODO: Should we allow non SymTypes here?  Today it is allowed
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/tensor.py:1024:            unimplemented(f"TODO: add support for ndarray.{name}")
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:179:    # TODO: storing a SymInt here but not a FakeTensor is a pretty strange
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:656:            # TODO: this doing it manually is bad
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:665:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:669:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:673:            # TODO: see if we need to add custom guard instead of a simple ID_MATCH
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:769:            # TODO(whc): Why do we limit this to methods on NNModules?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:797:                # TODO(jansel): combine this case with the one above
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:929:            # TODO(whc) We could add a guard on the opposite case, where a user compiled/ran
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1227:                # TODO: This should be dynamic, as we in general do not
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1236:                    # TODO: dynamic_dim = DimDynamic.STATIC should work but
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1460:        # TODO: not sure about this fake mode test
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:1722:    # TODO: index export_constraints ahead of time so we don't have to
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:218:    TODO: make it possible to use ProcessGroupVariable as input to simple functions
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:223:    TODO: should we make this inherit VT instead of UDOV? Do we want any of the default behaviors
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/distributed.py:251:        # TODO should this just raise unimplemented?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:417:            # TODO: support pytree output
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:569:        # TODO(voz): Support fake tensor dispatch for recursive
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:636:            # TODO: Support kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:924:        # TODO: Support kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1020:        # TODO: Support `fn` with kwargs.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1056:        # TODO: Support kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1300:        # TODO (tmanlaibaatar) support pytree here
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1597:        # TODO: assert that bwd_graph didn't capture values that were
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/higher_order_ops.py:1600:        # TODO(oulgen): Ideally, we would not do a linear search for output
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:287:                # TODO: If we expand this to handle tensor args, we need to manually
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1331:                    # TODO(voz): Make it work properly
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:471:            # TODO(voz): This is rewritten as a call_method because
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:481:        # TODO: These special cases shouldn't be necessary; we should
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:606:            # TODO: this probably should be folded somewhere else but I'm not
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:608:            # TODO: some of the other symbolic_shapes special tools can also
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:641:            # TODO(voz): Replace w/ dynamic shape rewrite table.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:660:                    # TODO: there maybe other recursive structures you need to
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:270:                # TODO: Use named_children when it supports remove_duplicate=False.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:323:                    # TODO: do we want to support __call__ for GM's?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:91:        # TODO(jansel): there is a small chance this could trigger user code, prevent that
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:209:        # TODO: support an expression form as well
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/misc.py:739:            # TODO Add all the functions that go from constants to constants to can_constant_fold_through
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:72:            # TODO Temorarily remove to figure out what keys are we breaking on
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:98:            # TODO: Put this in utils and share it between variables/builtin.py and here
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:579:            # TODO(jansel): implement unpacking logic in ModelOutput.__post_init__
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/dicts.py:779:    # TODO(voz): Upstream to transformers lib
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:299:            )  # TODO(voz): These can invoke user code!
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:302:            )  # TODO(voz): These can invoke user code!
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:305:            and len(kwargs) == 0  # TODO(ybliang): support kwargs
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:575:                # TODO(jansel): add a guard to check for monkey patching?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/user_defined.py:880:        # TODO this should probably be merged with the dict handling
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/testing.py:169:        # TODO: shouldn't this be f_locals/f_globals from frame?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:159:        # TODO - Assuming that all modules can be safely repr'd. Check if that assumption is correct.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:214:        # TODO - Keep this code for now. But, I don't think we will need this.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:531:# TODO: Support bundling the entire repro into a zip file for ease of
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:558:                    # TODO: transfer it to the right device?  But failing this
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:620:        # TODO: consider ensuring tensor and storage counters line up?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:654:        # TODO: being optional on device is kind of pointless as the default
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/debug_utils.py:699:    # TODO: this doesn't actually symint atm
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/cache_size.py:74:    TODO(janimesh) - Consider adding a map from tuple_of_match_ids to count -
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3120:    # TODO: Once we require py3.9 use removesuffix instead.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:856:# TODO use the actual object instead, can interface from eval_frame.c
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/resume_execution.py:467:            # TODO(jansel): add dead code elimination here
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:266:        # TODO: something here
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:367:            # TODO(janimesh) - This is currently restricted to nn.Module objects
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:474:        # the internal types match.  (TODO: what about nested lists?)
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:494:        # TODO: It feels like it would be better to just implement our own
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:574:    # TODO(voz): Deduplicate w/ AOTAutograd dupe input guards
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:748:            # TODO(voz): Either populate a dispatch_key check into the guards, or error on users passing in an unsupported
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:752:            # TODO(voz): We are missing storage offset in all our tensor guards?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1041:                # TODO: we could make use of 'DefaultsSource' and offer a .guard.is_defaults() API
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1053:        # TODO(janimesh) - Currently this information is stored as an attr on
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1187:        # TODO: the "guard" here is actually just the top level SHAPE_ENV
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1232:        # TODO(whc) maybe '.code_parts' was only kept around for the guard callback? so we don't need both
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/guards.py:1481:        # TODO(voz): Combine local and global guard builders.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/external_utils.py:21:    TODO(khabinov): we should deprecate this function and use one of these two:
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:159:    TODO(voz): We now have allow_in_graph, disallow_in_graph, forbid_in_graph - some more robust
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:222:        # TODO: Make this configurable via a supported public API
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:231:        # TODO(voz): Should we bounds check?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:249:        # TODO: Make this configurable via a supported public API
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:255:        # TODO(voz): Should we bounds check?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:286:        # TODO: Make this configurable via a supported public API
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:292:        # TODO(voz): Should we bounds check?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:321:# TODO: we should delete this whole _allow_in_graph_einops logic by approximately 2024 Q2
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/compiled_autograd.py:86:        # TODO(jansel): are all these modes needed?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:330:            # TODO maybe should respect DtoH sync intention of users later??
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:463:                # TODO link the torch.cond doc later
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:504:                # TODO: Also report the traceback from the parent frame
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2157:        # TODO(jansel): check the id of the cell rather than the contents
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2357:        # TODO: mlazos, add support for enabling multiple artifact logs
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2555:        # TODO(jansel): figure out why this is needed, it isn't in the docs for YIELD_VALUE
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2578:                    # TODO(voz): Unclear if we need the push None in YIELD_VALUE?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:150:    # TODO: Figure out why torch.compile'd hash isn't work on this codepath
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:156:            # TODO: improve these names with FQN
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:236:    # TODO: factor this out
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:263:    # TODO: It's inconsistent to pass SymInt inputs but REAL tensors.
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:424:            # TODO: disable clone
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:76:        # TODO: why do we need to deepcopy the original graph?
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:85:            # TODO: Failures here are troublesome because no real inputs,
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:236:            # TODO: improve these names with FQN
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:315:    # TODO: factor this out
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:480:    # TODO: speed this up
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:555:    # TODO: The logic for cloning inputs/models here is intentionally
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:644:    # TODO: check eager determinism
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:711:# TODO: lazily load the inputs or something, rather than cloning them
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:860:    # TODO: make this an option for --analyze too
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:102:# TODO(janimesh, voz): Remove both of these flags (or atleast guard_nn_modules)
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/config.py:180:# TODO: Detect this situation automatically so the user doesn't need
./api/search/.venv/lib/python3.12/site-packages/torch/contrib/_tensorboard_vis.py:137:        # TODO: handle attrs
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:58:        # TODO: The cache is NOT currently used by HigherOrderOperator, but it should!
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:103:                # TODO(voz): Should we replace setting torch._C.DispatchKey.Python entirely with setting mode keys?
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:276:        # TODO (tmanlaibaatar) Make it generic fallback mechanism
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:660:                # TODO: We also need to handle tensor subclasses here
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:661:                # TODO(voz): We should walk all the nodes here / turn it into a list, topmode is ok for now.
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:667:                    # TODO: This path is slow, should generally encourage this
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:670:                # TODO(voz): The idea behind this is that we do not yet support dispatch by key + mode, only key.
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:705:                            # TODO: need to double check the semantics of the "types" argument to torch_dispatch.
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:713:                        # TODO: check that I got these args correct (in C++, we pass in "0000"??)
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:731:        # TODO: We could potentially have lots of debugging wrappers against
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:766:    # TODO: add more methods to expose information about input and output arguments
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:828:            # TODO: disallow access to overloads registered by JIT
./api/search/.venv/lib/python3.12/site-packages/torch/_ops.py:856:    # TODO: use this to make a __dir__
./api/search/.venv/lib/python3.12/site-packages/torch/sparse/_triton_ops.py:91:        # TODO: investigate if contiguity along other axes than the
./api/search/.venv/lib/python3.12/site-packages/torch/sparse/semi_structured.py:261:            # TODO in the future we can add in padding to support sparse dimensions that aren't perfect multiples
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/xpu/XPUEvent.h:112:    // TODO: provides the ability to time the execution of commands in a SYCL
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/CUDAFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:29:// TODO: Add constructors for all of the descriptors
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:99:  // TODO: Figure out why const-correctness doesn't work here
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cudnn/Descriptors.h:369:        "TODO: support more cuDNN activation modes");
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradNestedTensorFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:62:// [TODOs]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/TracerMode.h:111:// TODO: move this from `at::` to `jit::torch::` after
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/Utils.h:93:    // TODO: is this necessary?  We used to treat nullptr-vs-not in IntList
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/CPUFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/quantized/QTensorImpl.h:33:  // TODO: Expose in PyTorch Frontend
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/ATen.h:35:// TODO: try to remove this
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/symbol.h:77:  // TODO: eliminate me
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/DispatchKeyExtractor.h:41:  // TODO: It's a bit irritating that we have to do logical ORs here, it would
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dispatch/Dispatcher.h:187:  // TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:256:  // TODO Use list_element_from?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List_inl.h:282:  // TODO Use list_element_from?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:69:  // TODO(jerryzh): add a Get(c10::DeviceType) function?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:78:    // TODO: after we add Get<Tensor>(c10::DeviceType)
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/blob.h:108:      // TODO Re-enable logging
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TransformationHelper.h:129:  // TODO: must be investigated and unified!!!
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:13:// TODO: consider storing namespace separately too
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/operator_name.h:20:  // TODO: These two functions below are slow!  Fix internal data structures so
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PythonOpRegistrationTrampoline.h:5:// TODO: this can probably live in c10
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/stack.h:9:// TODO move this to c10 namespace
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:132:    // TODO(min-jean-cho) change to Polar method, a more efficient version of Box-Muller method
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/PhiloxRNGEngine.h:133:    // TODO(voz) We use std:: below, and thus need a separate impl for CUDA.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:1764:// TODO this is deprecated but we don't throw a warning because a lot of ops in
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:196:  // TODO: temporarily disabled
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:235:  // TODO: Deprecate me
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBody.h:1368:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:273:   * TODO: need to support customizing equality
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:345:    // TODO: Find way to expose alias info for opaque tensors.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:465:    // TODO (after Tensor merge) If we pass in a Blob holding a Tensor, extract
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1085:        // TODO: Find way to expose alias info for opaque tensors.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue.h:1120:  // TODO: There are several places that recurse over IValue. This is fragile.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/dynamic_type.h:133:  // TODO Change Ptr to DynamicTypePtr when all migrations are done.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/function_schema.h:506:  // TODO remove the mutation here
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/List.h:457:  // TODO Test use_count
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:576:// TODO: investigate making this SingletonOrSharedTypePtr<TensorType>
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2098:  // TODO: static_assert that a templated function exists, and throw a friendly
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/jit_type.h:2105:  // TODO: static_assert that a templated function exists, and throw a friendly
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/Generator.h:51: * TODO: Look into changing the threading semantics of Generators in ATen (e.g., making
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/BoxedKernel.h:130:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:15:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:209:  // TODO: it probably would be good to tighten this up quite a bit more with
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:268:    // TODO static_assert(AllowDeprecatedTypes, "You tried to register a kernel with an unsupported output type: std::vector<T>. Please use List<T> instead.");
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h:432:  // TODO Delete this once kernels don't do that anymore
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/test_helpers.h:29:  // TODO: We add this to simulate the ideal case where we only have Autograd backend keys
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/impl/boxing.h:80:  // TODO Reuse stack vector instead of allocating?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:13:using Stack = torch::jit::Stack; // TODO Instead of this, move torch::jit::Stack to the c10 namespace.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/boxing/KernelFunction.h:157:   * TODO: This will only be useful if we write a backend fallback that plumbs dispatch keys (currently there are none)
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:404:  // TODO: once modules support arbitrary ivalue attributes, we don't need this
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/class_type.h:406:  // TODO: This is better represented as an OrderedDict, but alas it is not yet
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:551:  /// TODO: it's not in native_functions.yaml yet as it's not exposed to python
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:589:  // TODO(#97856) Make this return a const pointer. This currently
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/TensorBase.h:612:  // TODO(#97856) Make this return a const pointer. This is currently
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:9:// TODO: Clean up what remains here
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/LegacyTypeDispatch.h:70:// TODO: AutoNonVariableTypeMode should be removed in release 1.10.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/adaption.h:49:  // TODO: Remove this once the following issue is addressed:
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:249:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:278:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:293:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:308:        // TODO Do schema inference without relying on WrapFunctionIntoFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:349:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:390:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:528:       // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:559:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_registration.h:576:        // TODO Do schema inference without relying on WrapFunctionIntoRuntimeFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/op_registration/op_allowlist.h:3:// TODO: unify to C10_MOBILE. In theory this header could be used in OSS.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/NestedIntSymNodeImpl.h:40:  // the higher-level API in python instead (TODO: actually introduce that).
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/detail/CUDAHooksInterface.h:59:// TODO: Consider putting the stub definitions in another class, so that one
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/FunctionalTensorWrapper.h:207:  // TODO: maybe it's possible to arrange for that to happen automatically
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:31:// TODO: Move the MPSGuardImpl to inherit from NoOpDeviceGuardImpl
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:64:    // TODO: Currently setting only device 0
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSGuardImpl.h:81:      //TODO: extend it for multi-device case
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:19:// TODO: Unify the logic with CUDACachingAllocator and remove redundant code.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:119:    // TODO: check the caching performance of write-combined mode
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/mps/MPSAllocator.h:316:  // TODO: make a common function to do size unit conversions in PyTorch.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:46:  // TODO: don't expose private implementation details like this; in
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:52:  // TODO: don't expose private implementation details like this
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:112:  // TODO: numel_custom and is_contiguous_custom can be profitably overridden
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/NestedTensorImpl.h:170:  // TODO: maybe we can remove this metadata since
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradNonFunctionalFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpp_custom_type_hack.h:93:  at::AutoDispatchBelowADInplaceOrView guard; // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_int.h:747:      // TODO<leslie> We can use _mm512_zextsi128_si512 in the furture,
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_double.h:159:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_float.h:574:// TODO(jgong5): rewrite with ATEN vectorized (need to add unpack and shuffle)
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_bfloat16.h:1053:// TODO(Leslie): Add the AVX2 Version of transpose_mxn for BFloat16 and Float16
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec512/vec512_complex_float.h:654:  // TODO: hadd_pd() & hsub_pd() may have scope for improvement.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:118:    // TODO
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_float_neon.h:273:  // this should be removed. TODO (kimishpatel)
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256_int.h:686:      // TODO<leslie> We can use _mm256_zextsi128_si256 in the furture,
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:196:  // TODO: can we support caching this?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cpu/vec/vec256/vec256.h:240:  // TODO: can we support caching this?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/MetaFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/utils/Factory.h:13:// TODO: Remove this function when at::native::empty() is modified to accept a
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:47:// TODO: Figure out if we need a non-moving wrap_buffer()
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/nested/NestedTensorUtils.h:287:// TODO: Add static assert to verify lambda arguments match nested_node types
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:15:// TODO: make all operations that resize given outputs use this function
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/AffineQuantizerBase.h:11:// TODO combine this with quantize_val once the numerics for ARM are aligned
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/fbgemm_utils.h:312:// TODO: Remove functions below when ChannelsLast3d is ready.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:339:// TODO: Move it to third_party/ideep
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/quantized/cpu/OnednnUtils.h:394:  // TODO Support more OSs.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/OperationUtils.h:194:// TODO: Improve the overall design of MPSGraphCache.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/mps/MPSGraphVenturaOps.h:4:// TODO: Remove me when moved to MacOS 13
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:19:// TODO: This file only supports AVX2. We could split the AVX kernels into
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:178:  // TODO: we may want to merge that into the fallback code (currently called
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:254:  // TODO: we may want to merge that into the fallback code (currently called
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:293:// future improvement that can be done: look for the TODOs in this file.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cpu/UpSampleKernelAVXAntialias.h:1197:  // TODO: Do we also need block 4 ???
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:55:// TODO: put this into the public API
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SparseTensorUtils.h:67:// TODO: Expose this for real in ATen, some day?
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:36:// TODO: CPU instruction set selection should be folded into whatever
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:212:    // TODO: make this point at hip_dispatch_ptr
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DispatchStub.h:296:// TODO: cut this over to HIP dispatch once we stop pretending that CUDA
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/MaxPooling.h:64:// TODO(Heitor) Template by dimension
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:350:  // TODO: instead of variable name 'sigma', use 'gamma' or 'scale'
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/DistributionTemplates.h:384:  // TODO: Fix resize_as_. See pytorch/pytorch#11665.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:27:  // TODO: remove this special case for HIP when issue is fixed:
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/SharedReduceOps.h:38:  // TODO: remove this special case for HIP when issue is fixed:
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:17:// TODO: update and add a usage example after https://github.com/pytorch/pytorch/pull/58092 lands.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:25:            // TODO: figure out how to make compiler happy without dynamic casts
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/CPUFallback.h:33:            // TODO: get std::forward<> to work
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:302:    // TODO: Our current linear mode impls use unbound indices
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:202:  // TODO: check that output->size() matches output_sizes
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:203:  // TODO: check that weight matches output->sizes()
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/ConvUtils.h:362:  // TODO: Remove PYTORCH_MIOPEN_SUGGEST_NHWC once ROCm officially supports NHWC in MIOpen
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:209:  // TODO: implement negative step
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorIndexing.h:314:  // TODO: check scalarType
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/DynamicLayer.h:39:// TODO: we can excise DynamicLayer in favor of Interpreter,
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/LegacyVmapTransforms.h:102:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/PlumbingHelper.h:59:  // TODO: should really check this
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/functorch/BatchedTensorImpl.h:156:// TODO: should probably contain more (or all?) backend keys
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/LegacyVmapTransforms.h:95:// a logical BatchedTensor. (TODO(rzou): some of these are not yet implemented).
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/cuda/detail/CUDAHooks.h:8:// TODO: No need to have this whole header, we can just put it all in
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/TensorUtils.h:58:// TODO: Consider generalizing this into a call stack.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeExplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/CompositeImplicitAutogradFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torch/include/caffe2/serialize/versions.h:92:// risk of breaking existing clients. TODO: A better way would be to allow
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/GeneratorImpl.h:44: * TODO: Look into changing the threading semantics of Generators in ATen (e.g.,
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:214:  /// TODO: This function encourages bad behavior (assuming CUDA is
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:403:  // TODO: Deprecate this
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:436:  // TODO remove after TensorOptions rationalization
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorOptions.h:545:  // TODO: MemoryFormat is not implemented in this way
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/Storage.h:92:  // TODO: remove later
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/Scalar.h:138:  // TODO: Support ComplexHalf accessor
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymBool.h:81:  // TODO: optimize to union
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymbolicShapeMeta.h:162:  // TODO: should the SymBool cases avoid the short circuit?  Need to reason
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/StorageImpl.h:107:  // TODO: remove later
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineDeviceGuard.h:251:  // TODO: Consider reading Tensor and TensorList constructors here, when
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/SizesAndStrides.h:25:  // TODO: different iterator types for sizes & strides to prevent
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/impl/InlineStreamGuard.h:72:    // TODO: make a version that takes an impl argument.  Unfortunately,
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:179:  // TODO: put this in BackendComponents
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:183:  // TODO: put this in BackendComponents
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:192:  Vulkan, // TODO: put this in BackendComponents
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:193:  Metal, // TODO: put this in BackendComponents
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:209:  // TODO: Make Mkldnn a functionality key, so we can give it Meta
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:236:  // TODO: delete this in favor of Python-implemented fake tensor
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:262:  // TODO: delete this once torchdim lands in functorch
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DispatchKey.h:354:  // TODO: make Autocast a functionality key
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/CPUAllocator.h:12:// TODO: rename to c10
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:255:      // TODO dim == 3 case will be enabled once it is fully tested
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/MemoryFormat.h:271:      // TODO dim == 4 case will be enabled once it is fully tested
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarTypeToTypeMeta.h:8:// TODO move to typeid.h (or codemod away) when TypeMeta et al
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:98:// TODO: To add unsigned int types here, we must define accumulate type.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/ScalarType.h:167:    /* TODO: remove once the bug is fixed. */                                \
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:380:    // TODO: Replace the link to the documentation once it's available.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:534:  // TODO: When Variable is added, delete these constructors
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:637:  // TODO: does C++14 have a stdlib template for this?
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:743:    // TODO: maybe this should be toggled by strides
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:911:      // TODO: provide stride_custom, symmetrically with size_custom.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:968:    // TODO: We could add support to Python dispatch here.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:969:    // TODO: We could call into aten::size.int instead of
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:976:    // TODO: We could add support to Python dispatch here.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:977:    // TODO: We could call into aten::size.int instead of
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1218:  // TODO: remove this once we don't automatically enabled Autograd dispatch
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1285:      // TODO: implement layout() as native function/method so that
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1748:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1767:   * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1794:    // TODO: this should probably consult policy
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:1891:    // TODO: at some point, we should kill this field completely.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:2140:    // TODO: A useful internal assert would be to show that device_opt_ is null
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/TensorImpl.h:3050://    strong refcount           TODO: pack these into one word
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymFloat.h:107:  // TODO: optimize to union
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:57:      // TODO dim == 3 case will be enabled once it is fully tested
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/Contiguity.h:86:      // TODO dim == 4 case will be enabled once it is fully tested
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymInt.h:55:  // TODO: these implementations are not optimal because they allocate a
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/SymIntArrayRef.h:16:// TODO: a SymIntArrayRef containing a heap allocated large negative integer
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/Backend.h:284:// TODO: This probably shouldn't actually be static inline
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/core/DeviceGuard.h:49:  /// TODO: The consistency check here is inconsistent with StreamGuard's
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/ApproximateClock.h:79:// TODO: We should use
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/Deprecated.h:27:// TODO Is there some way to implement this?
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:345:// TODO: Brian Vaughan observed that we might be able to get this to work on
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/Exception.h:563:// TODO: We're going to get a lot of similar looking string literals
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeList.h:158:  // TODO Direct implementation might be faster
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:14:// TODO Make it work for more compilers
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeIndex.h:67:  // TODO Disallow this and rather use std::unordered_map/set everywhere
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/TypeCast.h:169:// Trigger tests for D25440771. TODO: Remove this line any time you want.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:622:  // TODO: Use std::bit_cast once C++20 becomes available.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/C++17.h:92:// TODO This is an incomplete implementation of std::apply, not working for
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:43:// TODO(xiaofeng): Define GOOGLE_PROTOBUF_HAS_CONSTEXPR when constexpr is
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/int128.h:143:// TODO: perhaps it would be nice to have int128, a signed 128-bit type?
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:46:  // TODO Making operator== noexcept if underlying type is noexcept equality
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/IdWrapper.h:55:  // TODO Making operator!= noexcept if operator== is noexcept doesn't work with
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/Half.h:395:// TODO : move to complex.h
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/intrusive_ptr.h:572:   * TODO: https://github.com/pytorch/pytorch/issues/56482
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/MathConstants.h:13:// TODO: Replace me with inline constexpr variable when C++17 becomes available
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:110:    // TODO: split out
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/string_view.h:530:    // TODO At some point this should probably be done, including tricks
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex_utils.h:20:// TODO: Write in more idiomatic C++17
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:140:// TODO(@zasdfgbnm): c10::complex<c10::Half> is not currently supported,
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:581:// TODO(@zasdfgbnm): implement them as c10::conj
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/complex.h:589:// TODO(@zasdfgbnm): implement it by ourselves
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/ArrayRef.h:75:  // TODO Make this explicit
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/hash.h:58:// TODO: Compare vs OpenSSL and/or CryptoPP implementations
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:37:// TODO: This file is still in the caffe2 namespace, despite living
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/typeid.h:87:// TODO Disallow this and rather use std::unordered_map/set everywhere
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/cuda/CUDACachingAllocator.h:36:// TODO: Turn this into an honest to goodness class. I briefly attempted to do
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/macros/Macros.h:125:// TODO: It's possible this is still triggering
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class_detail.h:137:  // TODO We shouldn't use c10::impl stuff directly here. We should use the
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/custom_class.h:401:      // TODO: we need to figure out how to profile calls to custom functions
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:108:  // TODO: This is morally the same thing as KernelRegistrationConfig, but it's
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:167:        // TODO: Don't go through WrapRuntimeKernelFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:184:        // TODO: Don't go through WrapRuntimeKernelFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:201:        // TODO: Don't go through WrapRuntimeKernelFunctor
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:681:    // TODO: need to raise an error when you impl a function that has a
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/library.h:702:    // TODO: need to raise an error when you impl a function that has a
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/throughput_benchmark-inl.h:57:  // TODO: add GUARDED_BY once it is available
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:388:// TODO: this can return MaybeOwned
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/utils/python_arg_parser.h:1168: * TODO: we could use different names for the following 'handle_torch_function'
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/model.h:249:    // TODO: Handle shared storage case.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/arrayref_tensor.h:40:  // TODO Make this explicit
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/interface.h:22:// TODO: Deprecate this API. This was kept for BC compatibility.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runner/model_container_runner.h:78:  // TODO: need an OSS proxy executor implementation. For now,
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/tensor.h:40:    // TODO(alanwaketan): Remove this ctor. This is a
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:109:  // TODO: even though this API is currently used **only** in codegen to
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:136:  // TODO(alanwaketan): Revisit if all of them need to be accessible to
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/lazy_graph_executor.h:264:  // TODO(alanwaketan): Add a registry such that we don't need to make all
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_metadata.h:35:// TODO(whc) is this going to be used outside of in IR decompositions?
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/trie.h:46:  // TODO: Because we don't expect user to explicitly call this function via
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:19:// TODO(alanwaketan): Consolidate it with c10::scope_exit.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/util.h:68:// TODO(alanwaketan): This is clever, but is there really no std or c10
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir_builder.h:140:// TODO: this should return Value
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/ir.h:209:  // TODO: Some IR classes share the same opkind, such as Mean and MeanDim, so
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/core/helpers.h:16:// TODO: Consolidate this file with util.h
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_node.h:85:// TODO(whc) once Shape() API is moved to Node base, also make it virtual, and
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/config.h:4:// TODO(whc) unclear if this is useful, has only been tested as true
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:21:  // TODO: Scalar node is not currently used by ts_backend. Enable reusing
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ir_builder.h:55:  // TODO: verify if IR node reusing works for Dynamic shape ops
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:31:        "TODO(whc) implement TS computation shapes or change interface");
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/ts_backend/ts_lowering_context.h:41:        "TODO(whc) implement TS computation shapes or change interface");
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:82:  // TODO(whc) need to keep this?
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/lazy/backend/backend_interface.h:131:  // TODO(whc)
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/instruction.h:89:  // TODO: check for overflow
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:53: * TODO Instead of doing it this way, we should only have pure-jit ops in
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:146:    // TODO: some sort of caching mechanism?
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/operator.h:178:                  // TODO What if it gets set later?
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/runtime/register_ops_utils.h:360:    // TODO: remove when possible, since it just slows down
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/flatbuffer_loader.h:132:// no op, TODO(qihan) delete
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/observer.h:39:  // TODO: Kimish
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/mobile/code.h:27:  // TODO After we actually export CALL instructions we can remove this.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:583:// TODO: supports only single comprehension for now
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:597:  // TODO: no ifs for now
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:607:// TODO: supports only single comprehension for now
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/tree_views.h:624:  // TODO: no ifs for now
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/source_range.h:368:    // TODO: c10::optional<>::value returns an rvalue ref so can't use it here??
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:74:  // TODO @wconstab refactor to use ModuleValue::asTuple instead of new API
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/frontend/sugared_value.h:425:  // TODO holding this thing is creepy
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/graph_opt.h:104:// TODO: add error reporting for graphs that can't be converted.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/reduction.h:268:  // TODO possible to remove this arg by deferring the init value until we
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:393:  // TODO: add memory types.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:841:// TODO: move to this an internal IR.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/stmt.h:842:// TODO: make IR nodes extensible.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:141:  //     loop variable. TODO: Remove this constraint.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:144:  //     TODO: Remove this constraint.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:473:  // TODO: Add an IR verifier check to detect invalidly compressed buffers.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/loopnest.h:584:// TODO: Revisit this once we decide on how dependencies analysis should look
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/external_functions_registry.h:20:// case we need to run aten ops (TODO: support different devices). The first
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/codegen.h:69:  // TODO: Figure out how to unify these call interfaces.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/mem_dependency_checker.h:245:  // TODO: this will return only the AccessInfo for A. It's included for
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:171:  // TODO: unique_name
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/expr.h:215:  // TODO: unique_name
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:263:// TODO: add TORCH_API
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/tensorexpr/ir.h:287:// TODO: add TORCH_API
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/python_list.h:39:  // TODO: Do these make sense?
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind.h:140:    // TODO: Is there a way to py::cast that doesn't raise an exception on
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:635:      // TODO: this message is not correct anymore, since this InferredType is
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:971:// TODO: Remove once we clean up the GraphExecutor usage.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/python/pybind_utils.h:1105:  // TODO: we could add __torch_function__ dispatch here but I don't know
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/quantization_patterns.h:553:  // TODO: add %dtype after when https://github.com/pytorch/pytorch/issues/34351
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:138:// TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:142:// TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:148:// TODO: refactor all current uses of this function to the Opt one
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/quantization/helper.h:186:// TODO: add a macro to declare the filters
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/symbolic_shape_cache.h:10:  // TODO: Consider in the future if it is reasonable to
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/passes/value_refinement_utils.h:18:// TODO: vector may be faster
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickle.h:39:///  // TODO: when tensors are stored in the pickle, delete this
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/pickler.h:249:  // TODO: only use this if necessary (add a pass to find all shared ivalues,
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/flatbuffer_serializer.h:90:// TODO(qihan): delete
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/serialization/export.h:258:// TODO remove these switches once interface call is rolled out.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:41: *  - Pattern graph nodes cannot alias. TODO: the check not implemented yet.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/subgraph_matcher.h:43: * found matches, no nodes in the subgraph alias with each other). TODO: check
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:249:  // TODO: make this more const correct
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1746:  // TODO: return iterator
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/ir/ir.h:1822:  // TODO: return iterator
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/function_impl.h:141:  // TODO: add more executors
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/jit/api/compilation_unit.h:173:    // TODO: class types cannot be redefined because we have no way right now
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:22:    // TODO: Nested Tensor does not have an implementation of detach. The
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/utils/grad_layout_contract.h:44:        // TODO: Actually detect views in the accumulateGrad function so that
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/VariableTypeUtils.h:134:// TODO: Blegh, bare references
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/function.h:561:  /// TODO: it might be possible to handle cases where backward is
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/custom_function.h:271:  // TODO Add tracing here
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/forward_grad.h:205:  // TODO(albanD): replace this with a SmallVector
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:167:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:185:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:204:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/variable_factories.h:220:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/generated/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/autograd/variable.h:853:/// TODO: Eliminate this function as much as possible, as it can be expressed
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/dynamo/compiled_autograd.h:141:    // TODO(jansel): Here we unpack the SavedVariable exactly once.  This might
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:491:    // TODO: HACK for backend name to get sequence number for that backend.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:512:    // TODO: HACK for backend name to get sequence number for that backend.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:581:    // TODO: if nccl was specified then use it
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroup.hpp:626:    // TODO: should we add these entries after the backend setting succeeds?
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/logger.hpp:70:  // TODO to support single process multiple devices and multi device modules,
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:124:  // TODO this function makes broadcast communication call and
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/reducer.hpp:396:    // TODO(@pietern)
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/Utils.hpp:537:    // TODO: see if we should add overflow protection for offset
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/tensorpipe_agent.h:314:  // TODO: To achieve better performance we can have a pipe pool per
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_proto.h:15:// TODO: Remove all these messages and use rpc + registered functions instead.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_context.h:201:  // TODO: make this a context guard
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:75:// TODO: current RRef implementation does not tolerate failures
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:88:// TODO: RRef internal messages are not yet idempotent
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:186:// TODO: make RRef an IValue, and edit createStackForSchema accordingly
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/rpc/rref_impl.h:187:// TODO: make RRef system messages idempotent and retry on failures.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/tensor/python_tensor.h:27:// TODO: This is nuts!  There is no reason to let the default tensor type id
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/CudaIPCTypes.h:71:  // TODO: Can be changed to FIFO in order to avoid full traverse on every
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/nn/parallel/data_parallel.h:89:      // TODO: use nccl reduce
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/types.h:10:// TODO: These don't really belong here but torchvision builds in CI need them
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/util.h:17:// TODO: replace with pytorch/rfcs#43 when it is ready.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/containers.h:180:  // TODO: cbegin and cend()
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/profiler/collection.h:476:    TensorListBegin, // TODO: generalize to other lists.
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:188:    // TODO PYBIND11_DEPRECATED(
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/pytypes.h:1365:// TODO: After the deprecated constructors are removed, this macro can be simplified by
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/common.h:357:/// Compatibility macros for Python 2 / Python 3 versions TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/detail/type_caster_base.h:482:        // TODO: is this still true for pure Python 3.6?
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/tensor.h:503:    // TODO: Move to std::optional once std::optional has more support
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/eigen/matrix.h:94:          // TODO: when Eigen bug #747 is fixed, remove the tests for non-negativity.
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1295:    using module_def = PyModuleDef; // TODO: Can this be removed (it was needed only for Python 2)?
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:1322:        // TODO: Should be reinterpret_steal for Python 3, but Python also steals it again when
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2346:                    // TODO consolidate the erasure code in pybind11_meta_dealloc() in class.h
./api/search/.venv/lib/python3.12/site-packages/torch/include/pybind11/pybind11.h:2433:    // TODO: state captures only the types of Extra, not the values
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:141:            # TODO: find a better way to identify cudaLaunchKernel
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:145:            # TODO: find a better way to identify CUDA Kernel
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_utils.py:367:# TODO(dberard) - deprecate / remove workaround for CUDA >= 12, when
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:167:        # TODO(robieta): Move away from load bearing names
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:305:        # TODO(robieta):
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_memory_profiler.py:1061:        # TODO: Write a faster serialize (orjson not available in CI)
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:181:        # TODO: We should also check tensor identities
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:216:        # TODO: Check if tensor is reused
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:418:        # TODO: fixme! Due to lifetime issues of the function name, this field might
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:437:        # TODO: We should also check if the loader is bottleneck.
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/_pattern_matcher.py:483:        # TODO: We should also check if the optimizer's numerical behavior will change.
./api/search/.venv/lib/python3.12/site-packages/grpc/beta/_client_adaptations.py:85:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./api/search/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:43:        pass  # TODO(https://github.com/grpc/grpc/issues/4078): design, implement.
./api/search/.venv/lib/python3.12/site-packages/grpc/beta/_server_adaptations.py:413:                return None  # TODO(nathaniel): call the multimethod.
./api/search/.venv/lib/python3.12/site-packages/grpc/_auth.py:37:    # TODO(xuanwn): Give credentials an actual type.
./api/search/.venv/lib/python3.12/site-packages/grpc/_server.py:1182:        # TODO(https://github.com/grpc/grpc/issues/6597): eliminate these fields.
./api/search/.venv/lib/python3.12/site-packages/grpc/_server.py:1238:# TODO(https://github.com/grpc/grpc/issues/6597): delete this function.
./api/search/.venv/lib/python3.12/site-packages/grpc/_server.py:1463:        # TODO(xuanwn): We should validate method_handlers first.
./api/search/.venv/lib/python3.12/site-packages/grpc/_channel.py:257:# TODO(xuanwn): Create a base class for IntegratedCall and SegregatedCall.
./api/search/.venv/lib/python3.12/site-packages/grpc/_channel.py:1835:    # TODO(xuanwn): Refactor this: https://github.com/grpc/grpc/issues/31704
./api/search/.venv/lib/python3.12/site-packages/grpc/_channel.py:2253:        # TODO(https://github.com/grpc/grpc/issues/12531): Several releases
./api/search/.venv/lib/python3.12/site-packages/grpc/_observability.py:271:    # TODO(xuanwn): use channel args to exclude those metrics.
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_server.py:87:        # TODO(xuanwn): Implement this for AsyncIO.
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:409:                # TODO(lidiz) drop this hack after 3.8 deprecation
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:484:    # TODO(xuanwn): Implement this method after we have
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:489:    # TODO(xuanwn): Implement _registered_method after we have
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:509:    # TODO(xuanwn): Implement _registered_method after we have
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:529:    # TODO(xuanwn): Implement _registered_method after we have
./api/search/.venv/lib/python3.12/site-packages/grpc/aio/_channel.py:549:    # TODO(xuanwn): Implement _registered_method after we have
./api/search/.venv/lib/python3.12/site-packages/psutil/_psaix.py:56:    cext.SSWAP: _common.STATUS_RUNNING,  # TODO what status is this?
./api/search/.venv/lib/python3.12/site-packages/psutil/_psaix.py:180:    # TODO - the filtering logic should be better checked so that
./api/search/.venv/lib/python3.12/site-packages/psutil/_psaix.py:256:        # TODO: rewrite this in C (entstat forks, so use truss -f to follow.
./api/search/.venv/lib/python3.12/site-packages/psutil/_psaix.py:531:        # TODO rewrite without using procfiles (stat /proc/pid/fd/* and then
./api/search/.venv/lib/python3.12/site-packages/psutil/_pswindows.py:866:                # TODO: the C ext can probably be refactored in order
./api/search/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:230:    # TODO - the filtering logic should be better checked so that
./api/search/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:288:        # TODO: refactor and use _common.conn_to_ntuple.
./api/search/.venv/lib/python3.12/site-packages/psutil/_pssunos.py:639:        # TODO: rewrite this in C (...but the damn netstat source code
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1004:    # TODO: #595
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_process.py:1041:    # TODO: #595
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:564:    # TODO: remove this once 1892 is fixed
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_system.py:841:                        # TODO: skip AF_INET6 for now because I get:
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_osx.py:122:    # TODO: remove this once 1892 is fixed
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:254:        # TODO: UNIX sockets are temporarily implemented by parsing
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:368:    # TODO: remove this once 1892 is fixed
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_memleaks.py:386:    # TODO: remove this skip when this gets fixed
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_unicode.py:116:        # TODO - this is quite random and I'm not sure why it happens,
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_aix.py:60:        # TODO maybe try to use "swap -l" to check "used" too, but its units
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_bsd.py:7:# TODO: (FreeBSD) add test for comparing connections with 'sockstat' cmd.
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_linux.py:2028:    # TODO: re-enable this test.
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_process_all.py:284:        # TODO: check ntuple fields
./api/search/.venv/lib/python3.12/site-packages/psutil/tests/test_contracts.py:235:    # TODO: remove this once 1892 is fixed
./api/search/.venv/lib/python3.12/site-packages/click/_termui_impl.py:525:    # TODO: This never terminates if the passed generator never terminates.
./api/search/.venv/lib/python3.12/site-packages/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./api/search/.venv/lib/python3.12/site-packages/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./api/search/.venv/lib/python3.12/site-packages/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./api/search/.venv/lib/python3.12/site-packages/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./api/search/.venv/lib/python3.12/site-packages/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./api/search/.venv/lib/python3.12/site-packages/pluggy/_hooks.py:411:        # TODO: Document, or make private.
./api/search/.venv/lib/python3.12/site-packages/pluggy/_hooks.py:417:    # TODO: Document, or make private.
./api/search/.venv/lib/python3.12/site-packages/pluggy/_hooks.py:421:    # TODO: Document, or make private.
./api/search/.venv/lib/python3.12/site-packages/yaml/scanner.py:187:        # TODO: support for BOM within a stream.
./api/search/.venv/lib/python3.12/site-packages/yaml/scanner.py:761:        # TODO: We need to make tab handling rules more sane. A good rule is
./api/search/.venv/lib/python3.12/site-packages/distlib/wheel.py:839:            # TODO version verification
./api/search/.venv/lib/python3.12/site-packages/distlib/version.py:267:        TODO: fill this out
./api/search/.venv/lib/python3.12/site-packages/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./api/search/.venv/lib/python3.12/site-packages/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./api/search/.venv/lib/python3.12/site-packages/distlib/locators.py:922:                # TODO SHA256 digest
./api/search/.venv/lib/python3.12/site-packages/distlib/util.py:401:        # TODO check k, v for valid values
./api/search/.venv/lib/python3.12/site-packages/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./api/search/.venv/lib/python3.12/site-packages/distlib/metadata.py:560:    # TODO could add iter* variants
./api/search/.venv/lib/python3.12/site-packages/distlib/metadata.py:984:        # TODO: any other fields wanted
./api/search/.venv/lib/python3.12/site-packages/pydantic_core/core_schema.py:1135:            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported
./api/search/.venv/lib/python3.12/site-packages/botocore/client.py:94:        # TODO: Migrate things away from scoped_config in favor of the
./api/search/.venv/lib/python3.12/site-packages/botocore/client.py:665:            # TODO: fallback partition_name should be configurable in the
./api/search/.venv/lib/python3.12/site-packages/botocore/client.py:743:        # TODO: This normalization logic is duplicated from the
./api/search/.venv/lib/python3.12/site-packages/botocore/utils.py:2314:                # TODO: Update message to reflect use_arn_region
./api/search/.venv/lib/python3.12/site-packages/botocore/docs/bcdoc/style.py:321:        # TODO: Need to control the bullets used for LI items
./api/search/.venv/lib/python3.12/site-packages/botocore/discovery.py:276:        # TODO: Improve eviction behavior to only evict the bad endpoint if
./api/search/.venv/lib/python3.12/site-packages/botocore/handlers.py:973:# TODO: Remove this class as it is no longer used
./api/search/.venv/lib/python3.12/site-packages/botocore/auth.py:245:            # TODO: We should set the host ourselves, instead of relying on our
./api/search/.venv/lib/python3.12/site-packages/botocore/auth.py:943:        TODO: Do we need this?
./api/search/.venv/lib/python3.12/site-packages/botocore/serialize.py:71:    # TODO: Unknown protocols.
./api/search/.venv/lib/python3.12/site-packages/botocore/retryhandler.py:157:        # TODO: send a signal.
./api/search/.venv/lib/python3.12/site-packages/botocore/response.py:102:            # TODO: the url will be None as urllib3 isn't setting it yet
./api/search/.venv/lib/python3.12/site-packages/botocore/response.py:119:            # TODO: the url will be None as urllib3 isn't setting it yet
./api/search/.venv/lib/python3.12/site-packages/botocore/response.py:203:    # TODO: Unfortunately, we have to have error logic here.
./api/search/.venv/lib/python3.12/site-packages/botocore/retries/special.py:17:# TODO: This is an ideal candidate for the retryable trait once that's
./api/search/.venv/lib/python3.12/site-packages/botocore/endpoint.py:347:        # TODO: avoid naming conflicts with ResponseMetadata and Error
./api/search/.venv/lib/python3.12/site-packages/h2/windows.py:116:        # TODO: Can the window be smaller than 1024 bytes? If not, we can
./api/search/.venv/lib/python3.12/site-packages/h2/utilities.py:417:    # TODO: We should also guard against receiving duplicate Host headers,
./api/search/.venv/lib/python3.12/site-packages/httpx/_auth.py:267:        # TODO: implement auth-int
./api/search/.venv/lib/python3.12/site-packages/typing_extensions.py:3261:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:26:  # TODO: Remove this import after fix api_implementation
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:271:    # TODO: Add function to calculate full_name instead of having it in
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:474:# TODO: We should have aggressive checking here,
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:480:# TODO: for this and other *Descriptor classes, we
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:539:  # TODO: Find a way to eliminate this repetition.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:563:  # TODO: Find a way to eliminate this repetition.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor.py:600:  # TODO: Find a way to eliminate this repetition.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:139:    # TODO: implement this API.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_database.py:143:    # TODO: implement this API.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/descriptor_pool.py:1360:  # TODO: This pool could be constructed from Python code, when we
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/pyext/cpp_message.py:21:# TODO: Remove this import after fix api_implementation
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:100:        # TODO: Remove this check here. Duplicate extension
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message_factory.py:140:      # TODO: Remove this check here. Duplicate extension
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:88:    # TODO: fail back to python
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/api_implementation.py:135:# TODO: Remove the API, it returns a constant. b/228102101
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:10:# TODO: Helpers for verbose, common checks like seeing if a
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:215:  # TODO: Escape Python keywords (e.g., yield), and test this support.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:230:  # TODO:  Remove this method entirely if/when everyone agrees with my
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:464:    # TODO: This may be broken since there may not be
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:717:    # TODO: This may be broken since there may not be
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:767:  # TODO: Remove duplication with similar method
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:824:  # TODO: Migrate all users of these attributes to functions like
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:827:    # TODO: Use cls.MESSAGE_FACTORY.pool when available.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:977:  # TODO: Don't use the factory of generated messages.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:989:  # TODO: For now we just strip the hostname.  Better logic will be
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/python_message.py:1035:    # TODO: Fix UnknownFieldSet to consider MessageSet extensions,
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/builder.py:96:  # TODO: Remove this on-op
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:37:# TODO: Unify error handling of "unknown extension" crap.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/extension_dict.py:38:# TODO: Support iteritems()-style iteration over all
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:98:# TODO: Remove this. BaseContainer does *not* conform to
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/internal/containers.py:214:# TODO: Constrain T to be a subtype of Message.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/symbol_database.py:136:    # TODO: Fix the differences with MessageFactory.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:22:# TODO Import thread contention leads to test failures.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:477:          # TODO: refactor and optimize if this becomes an issue.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1081:        # TODO: Change to _allow_singular_overwrites.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/text_format.py:1637:# TODO: Migrate violators to textformat_tokenizer.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:8:# TODO: We should just make these methods all "pure-virtual" and move
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:43:  # TODO: Link to an HTML document here.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:45:  # TODO: Document that instances of this class will also
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:49:  # TODO: Document these fields and methods.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:66:    # TODO: Remove this once the UPB implementation is improved.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:182:  # TODO: MergeFromString() should probably return None and be
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:217:    # TODO: Document handling of unknown fields.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:218:    # TODO: When we switch to a helper, this will return None.
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:263:  # TODO: Decide whether we like these better
./api/search/.venv/lib/python3.12/site-packages/google/protobuf/message.py:269:  # TODO: Be sure to document (and test) exactly
./api/search/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:578:        # TODO: Add optional support for socket.gethostbyname checking.
./api/search/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1095:        # TODO revise this, see https://github.com/urllib3/urllib3/issues/2791
./api/search/.venv/lib/python3.12/site-packages/urllib3/http2/__init__.py:38:    # TODO: Offer 'http/1.1' as well, but for testing purposes this is handy.
./api/search/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:144:        # TODO SKIPPABLE_HEADERS from urllib3 are ignored.
./api/search/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:234:                # TODO: Arbitrary read value.
./api/search/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:282:            # TODO this is often present from upstream.
./api/search/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:325:    # TODO: This is a woefully incomplete response object, but works for non-streaming.
./api/search/.venv/lib/python3.12/site-packages/urllib3/http2/connection.py:332:        decode_content: bool = False,  # TODO: support decoding
./api/search/.venv/lib/python3.12/site-packages/urllib3/exceptions.py:306:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./api/search/.venv/lib/python3.12/site-packages/urllib3/util/url.py:454:    # TODO: Remove this when we break backwards compatibility.
./api/search/.venv/lib/python3.12/site-packages/urllib3/util/request.py:229:    # File-like object, TODO: use seek() and tell() for length?
./api/search/.venv/lib/python3.12/site-packages/urllib3/connection.py:330:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./api/search/.venv/lib/python3.12/site-packages/urllib3/connection.py:436:        # object later. TODO: Remove this in favor of a real
./api/search/.venv/lib/python3.12/site-packages/urllib3/connection.py:561:        # TODO should we implement it everywhere?
./api/search/.venv/lib/python3.12/site-packages/urllib3/response.py:1005:                # TODO make sure to initially read enough data to get past the headers
./api/search/.venv/lib/python3.12/site-packages/urllib3/_base_connection.py:20:    # TODO: Remove this in favor of a better
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:499:        # TODO should we eliminate the recursion?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:503:                    # TODO check whether we need to call `list_hook`
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:511:            # TODO is the interaction between `list_hook` and `use_list` ok?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/msgpack/fallback.py:516:                    # TODO check whether we need to call hooks
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py:715:        # different tokens.  TODO: DelegatingLexer should support this
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py:863:    TODO: clean up the code here.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/truststore/_macos.py:558:            # TODO: Not sure if we need the SecTrustResultType for anything?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:29:    # TODO: Can we test whether something is contained within a requirement?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/requirements.py:32:    # TODO: Can we normalize the name and extra name?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/tags.py:378:        # TODO: Need to care about 32-bit PPC for ppc64 through 10.2?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:204:        # TODO: The spec doesn't say anything about if the keys should be
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/packaging/metadata.py:805:    description: _Validator[str | None] = _Validator()  # TODO 2.1: can be in body
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/wheel.py:839:            # TODO version verification
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:267:        TODO: fill this out
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/version.py:516:    # TODO: unintended side-effect on, e.g., "2003.05.09"
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:760:        XXX TODO Note: this cache is never actually cleared. It's assumed that
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/locators.py:922:                # TODO SHA256 digest
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/util.py:401:        # TODO check k, v for valid values
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:239:    # TODO document the mapping API and UNKNOWN default key
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:560:    # TODO could add iter* variants
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:984:        # TODO: any other fields wanted
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:1020:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/typing_extensions.py:3568:                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connectionpool.py:522:        # TODO: Add optional support for socket.gethostbyname checking.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/exceptions.py:289:    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:31:# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:261:        # TODO: Deprecated, remove in v2.0
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:323:        # TODO: If already given in **kw we use what's given to us
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:454:        # TODO: For now favor if the Retry implementation sets its own method_whitelist
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/retry.py:608:            # TODO: Remove this deprecated alias in v2.0
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/url.py:402:    # TODO: Remove this when we break backwards compatibility.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:659:        # TODO: should I do clean shutdown here? Do I have to?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:819:        # TODO: Well, crap.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/securetransport.py:829:        # TODO: Update in line with above.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/connection.py:199:            # TODO: Fix tunnel so it doesn't depend on self.sock state.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/requests/hooks.py:19:# TODO: response is the only one
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1:# TODO: Add Generic type annotations to initialized collections.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:122:_ResourceStream = Any  # TODO / Incomplete: A readable file-like object
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3308:            # TODO: remove this except clause when python/cpython#103632 is fixed.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3598:        # TODO: Add a deadline?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/controller.py:227:        # TODO: There is an assumption that the result will be a
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py:67:        # TODO: Add some logging here...
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/commands/inspect.py:60:            # TODO tags? scheme?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/cache.py:278:                # TODO: use DirectUrl.equivalent when
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:227:        # TODO performance: this means we iterate the dependencies at least twice,
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/candidates.py:362:        # TODO: Supply reason based on force_reinstall and upgrade_strategy.
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:201:        # TODO: Check already installed candidate, and use it if the link and
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/factory.py:622:        # TODO: Are there more cases this needs to return True? Editable?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/index/collector.py:344:        # TODO: In the future, it would be nice if pip supported PEP 691
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/network/lazy_wheel.py:174:        # TODO: Get range requests to be correctly cached
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py:204:        # TODO: Try to get these passing down from the command?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/models/installation_report.py:50:            # TODO: currently, the resolver uses the default environment to evaluate
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/models/selection_prefs.py:6:# TODO: This needs Python 3.10's improved slots support for dataclasses
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:107:    # TODO: replace this with slots=True when dropping Python 3.9 support.
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:526:    # TODO: handle space after '\'.
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/constructors.py:285:        # TODO: The is_installable_dir test here might not be necessary
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/req_set.py:75:        TODO remove this property together with the legacy resolver, since the new
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:37:from pip._internal.utils.compat import stdlib_pkgs  # TODO: Move definition here.
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:167:        # TODO: this property is relatively costly to compute, memoize it ?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/metadata/base.py:177:                # TODO: get project location from second line of egg_link file
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:557:        # TODO: separate this part out from RequirementPreparer when the v1
./api/search/.venv/lib/python3.12/site-packages/_pytest/compat.py:115:    # TODO(RonnyPfannschmidt): This function should be refactored when we
./api/search/.venv/lib/python3.12/site-packages/_pytest/python.py:296:        # TODO: Improve the type of `parent` such that assert/ignore aren't needed.
./api/search/.venv/lib/python3.12/site-packages/_pytest/python.py:1532:    # TODO: If escaping is turned off and the user passes bytes,
./api/search/.venv/lib/python3.12/site-packages/_pytest/python.py:1705:    # TODO: Type ignored -- breaks Liskov Substitution.
./api/search/.venv/lib/python3.12/site-packages/_pytest/junitxml.py:512:            # TODO: breaks for --dist=each
./api/search/.venv/lib/python3.12/site-packages/_pytest/assertion/rewrite.py:881:            # TODO: This assert should not be needed.
./api/search/.venv/lib/python3.12/site-packages/_pytest/legacypath.py:389:        # TODO: This assert is probably not valid in all cases.
./api/search/.venv/lib/python3.12/site-packages/_pytest/cacheprovider.py:242:                # TODO: pass ignore_cleanup_errors=True when we no longer support python < 3.10.
./api/search/.venv/lib/python3.12/site-packages/_pytest/cacheprovider.py:575:        # TODO: evaluate generating upward relative paths
./api/search/.venv/lib/python3.12/site-packages/_pytest/mark/structures.py:158:            # TODO: Refactor to fix this type-ignore. Currently the following
./api/search/.venv/lib/python3.12/site-packages/_pytest/doctest.py:316:    # TODO: Type ignored -- breaks Liskov Substitution.
./api/search/.venv/lib/python3.12/site-packages/_pytest/doctest.py:346:            # TODO: ReprFileLocation doesn't expect a None lineno.
./api/search/.venv/lib/python3.12/site-packages/_pytest/raises.py:495:    # TODO: harmonize with ExceptionInfo.match
./api/search/.venv/lib/python3.12/site-packages/_pytest/raises.py:513:            # TODO: it instructs to use `-v` to print leading text, but that doesn't work
./api/search/.venv/lib/python3.12/site-packages/_pytest/raises.py:698:    # TODO: move common code into superclass
./api/search/.venv/lib/python3.12/site-packages/_pytest/terminal.py:1539:        # TODO: Revisit after marks scope would be fixed.
./api/search/.venv/lib/python3.12/site-packages/_pytest/reports.py:466:    # TODO: Check if this is actually reachable.
./api/search/.venv/lib/python3.12/site-packages/_pytest/reports.py:518:        # TODO: Investigate whether the duck typing is really necessary here.
./api/search/.venv/lib/python3.12/site-packages/_pytest/nodes.py:514:    # TODO: This omits the style= parameter which breaks Liskov Substitution.
./api/search/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:159:# TODO: Try to use FixtureFunctionDefinition instead of the marker
./api/search/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1249:# TODO: paramspec/return type annotation tracking and storing
./api/search/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1535:        # TODO: The order of the FixtureDefs list of each arg is significant,
./api/search/.venv/lib/python3.12/site-packages/_pytest/fixtures.py:1937:        # TODO: Fix this type ignore.
./api/search/.venv/lib/python3.12/site-packages/_pytest/capture.py:708:        # TODO: This type error is real, need to fix.
./api/search/.venv/lib/python3.12/site-packages/_pytest/main.py:945:                        # TODO: Remove parametrized workaround once collection structure contains
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:36:    BaseTy.float: "double",  # TODO: how about other floating point types?
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:97:            # TODO: BaseTy.Dimname, BaseTy.Generator, etc.
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:98:            raise NotImplementedError(f"TODO: add support for arg type {repr(typ)}")
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:203:                f"TODO: add support for return type {repr(ret.type)}"
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_aoti_c_shim.py:316:        # TODO: No need to generate C shim for Inductor lowered ops.
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:48:    # TODO: Matching on CType seems wrong; should be matching on Type
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:60:                # TODO: I don't understand when you should put lazy_ in the name
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:72:                f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:447:                # TODO(alanwaketan): Maybe we want to apply GetLtcTensorOrCreateForWrappedNumber here, but hold it
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:455:                    f"TODO not sure if there are other valid types to handle here ({arg.lazy_type})"
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:540:            # TODO: this is trolling
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/lazy_ir.py:581:            # TODO(whc) remove this if XLA switches to using static method for creation
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:39:# TODO: use BackendIndex
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:75:        # TODO: don't hardcode; return type will be inferred based on tags on
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/ufunc.py:501:        # TODO: don't hardcode ufunc:: namespace here, should be centralized smh
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:160:      // TODO: avoid the redispatch here
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:428:            # TODO: dedupe this with the structured codegen
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:453:                    # TODO: handle in place on tensor list
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:662:            # TODO: Make sure out argument is guaranteed to be self
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:708:            # TODO: Move to OptionalMPSGuard.
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:720:            f"      return {output_value};\n",  # type: ignore[possibly-undefined]  # TODO: audit
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:722:            f"    std::array<{output_type}, {len(f.func.returns)}> outputs_;",  # type: ignore[possibly-undefined]  # TODO: audit
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:723:            f"{textwrap.indent(proxy_field, indent)}",  # type: ignore[possibly-undefined]  # TODO: audit
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:739:        # TODO: Now, there is something interesting going on here.  In the code below,
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:762:        # (e.g., at::cpu::add).  We don't generate methods (TODO: do this
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:815:                # TODO: dedup this branch
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:893:                        # TODO: Stop hardcoding that the output type is a Tensor.  Note
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:908:                # TODO: https://github.com/pytorch/pytorch/issues/53023
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:918:                # TODO: I think this means structured won't work with method
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:947:            # TODO: Do this in translate instead
./api/search/.venv/lib/python3.12/site-packages/torchgen/dest/register_dispatch_key.py:965:            sig_body.append(f"return {ret_expr};")  # type: ignore[possibly-undefined]  # TODO: audit
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:342:        # TODO: for ops with structured_delegate it should check the dispatch table of
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:786:# TODO: This was historically used to help some JIT interop code
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:1041:# TODO: Get rid of dynamic_type, after getting tools/autograd
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:1310:        # TODO: What exactly is the semantics of the 'dispatch' field?
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:1424:    # TODO: how come ValuesView isn't a Sequence lol
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:2227:                    # TODO: this condition is a bit questionable
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:2723:    # TODO: --op-registration-whitelist will be removed when all call-sites
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen.py:2790:    # TODO: stop generating CUDA kernels for non-CUDA builds
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_backend_stubs.py:139:            # TODO: allow structured external backends later.
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_functionalization_type.py:789:        # TODO: The below ops all have "problematic" schemas that prevent them from
./api/search/.venv/lib/python3.12/site-packages/torchgen/utils.py:60:# TODO: Use a real parser here; this will get bamboozled
./api/search/.venv/lib/python3.12/site-packages/torchgen/utils.py:98:        # TODO: this does the wrong thing with KeyError
./api/search/.venv/lib/python3.12/site-packages/torchgen/utils.py:108:# TODO: put this somewhere else, maybe
./api/search/.venv/lib/python3.12/site-packages/torchgen/utils.py:159:            # TODO: Update the comment reference to the correct location
./api/search/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:272:        # TODO: remove the skip after these two operators schemas are fixed
./api/search/.venv/lib/python3.12/site-packages/torchgen/operator_versions/gen_mobile_upgraders.py:327:            # TODO: remove the skip after these two operators schemas are fixed
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:23:# TODO: Duplicated Subset from codegen.tool.gen_oplist, remove declaration in codegen
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:64:        type_alias_map: Dict[str, List[str]],  # TODO: Support unwrapped str val
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/model.py:91:            # TODO: Support inlined arguments
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:130:                )  # TODO: fix this discrepancy
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:140:        # TODO: keeping these special cases for Tensor[] and Tensor?[] so that we can hookup with ATen kernels.
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/api/et_cpp.py:215:        # TODO: Consider incorporating this into the data model
./api/search/.venv/lib/python3.12/site-packages/torchgen/executorch/api/custom_ops.py:94:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_executorch.py:368:    # TODO larryliu: evaluate if this code is still needed. If yes let it handle ETKernelIndex.
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:149:    # TODO(whc) add a check for shape inference functions that have meta kernels implement and should be retired.
./api/search/.venv/lib/python3.12/site-packages/torchgen/gen_lazy_tensor.py:368:        TODO(alanwaketan): Remove this sorting hack once all ops are grouped properly.
./api/search/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:75:        # TODO: these ones got added recently and need manual inspection
./api/search/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:252:        # TODO: stop doing type tests by converting to C++ and then testing
./api/search/.venv/lib/python3.12/site-packages/torchgen/static_runtime/generator.py:278:    # TODO: stop type testing by converting to C++
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:476:    # TODO: figure out what this does
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:684:            # TODO: verify that the tag is valid and has an entry in tags.yaml
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:763:                # TODO: maybe it's better to test the return
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:926:        # TODO: probably better to accumulate these errors and report them all
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:1293:            # TODO: This discrepancy isn't required; we could also generated
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:1359:    # TODO: Need to handle collisions with argument names at some point
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:1733:        # TODO: implement a proper parser if this gets more ugly
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:1856:    ConstQuantizerPtr = auto()  # TODO: rename
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:1996:        # TODO: deduplicate annotation matching with Return
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:2281:        # TODO: Use a real parser here; this will get bamboozled
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:2400:        # TODO: These invariants are weirdly asymmetric?
./api/search/.venv/lib/python3.12/site-packages/torchgen/model.py:2401:        # TODO: Fancier types?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:228:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:251:        # [old codegen] TODO: remove this? doesn't rename in codegen, it's just
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:298:    # TODO: maybe don't need keep scattered out fields for python signature?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:322:                # TODO: shouldn't this be OptionalType[ListType[...]], since it defaults to None?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:337:    # TODO: create a dedicated SelfArgument type for 'self'?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:354:    # TODO: maybe create a PythonTensorOptionsArgument?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:723:        # TODO: directly translate a.default to python default
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:775:    # [old codegen] TODO: because these aren't guaranteed to be 100% faithful
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:946:            # TODO: this doesn't seem right...
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1095:# TODO: This is to keep same byte-for-byte result as the old codegen - maybe unnecessary?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1127:            # TODO: avoid this special handling?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1405:            # TODO: why this needs to be special case?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1426:            # TODO: make this part of something more general, or get rid of it.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/python.py:1480:    # TODO: maybe move to the generator side as it's not related to binding.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/native.py:47:    # TODO: delete this!
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/native.py:114:        # TODO: Not sure why the arguments assigned here are for
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:149:        # TODO: My kingdom for a pattern matcher
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:152:        # TODO: This could get us in recomputation trouble if b.expr is nontrivial.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:253:        # TODO: These are referentially equal, shouldn't have to do this;
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/translate.py:368:            # TODO: You might also want to solve this from longSymVec_ctype or
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:120:            raise AssertionError(f"TODO add support for type {repr(typ)}")
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:125:            # TODO(whc) is this actually correct? or should it use a Vector like above
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:131:            # TODO: return a value type.  The problem here is analogous to
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:146:# TODO: Determining this based off of CType is bad; this should be computed
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:166:        # TODO: report True for this
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:192:# TODO: dedupe with Type.is_generator_like
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:209:    # TODO: this is lies, it is false for symint list
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:229:            # TODO: lists of symints are not currently treated as value types
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:306:# TODO: This is not idiomatic with how other torchgen APIs transform on schema.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/lazy.py:314:    # TODO: Need to handle collisions with argument names at some point
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:164:                )  # TODO: fix this discrepancy
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:181:        # TODO: remove these special cases, ArrayRef fallthrough works fine
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:285:        # TODO: Consider incorporating this into the data model
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/cpp.py:422:                default = "at::kLong"  # TODO: this is wrong
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:114:    # TODO: maybe the logic to search for all variants is no longer necessary?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:233:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:241:#   TODO: some cpp naming logic (e.g. resolving name conflict) might be irrelevant?
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:250:    # TODO: only to keep it byte-for-byte compatible with the old codegen, should remove.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:261:# TODO: Update comment below since it is out of date.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:348:# TODO(crcrpar): Avoid hard coding "Default" ideally.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/autograd.py:632:            # TODO(crcrpar): Avoid hard coding "Default" ideally.
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:85:    # TODO: Kill this when we eventually remove it!
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:188:    # TODO: Kill this when we eventually remove it!
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:211:    # TODO: maybe don't represent default here
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/types/types_base.py:246:    # TODO: Kill this when we eventually remove it!
./api/search/.venv/lib/python3.12/site-packages/torchgen/api/structured.py:76:        # TODO: delete these special cases; see torchgen.api.cpp--these
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/RegisterBackendSelect.cpp:31:  // TODO: fetch scalar type from Tensor? But it doesn't really matter...
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:196:  // TODO: temporarily disabled
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:235:  // TODO: Deprecate me
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:337:  // TODO: The Python version also accepts arguments
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/TensorBody.h:539:  // TODO: remove following two after at::kDouble and its friends are TypeMeta's.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:19:// TODO: rename this file to something more generic.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/CompositeViewCopyKernels.cpp:50:// TODO: this doesn't handle restriding empty tensors correctly; see
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/DispatchKeyFunctions.h:3:// TODO Undo all logic introduced for Note [Avoiding Include Cycles In Static Dispatch]
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/FunctionalInverses.h:26:// TODO: Change codegen to generate these. See the following link:
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/ATen/templates/Functions.cpp:10:   AutoDispatchBelowADInplaceOrView guard{}; // TODO: Remove.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:110:    # TODO: byte-for-byte compatible with old codegen behavior - should clean up
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:302:    # TODO: clean up old codegen behavior
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:256:    # TODO: Should handle optional here?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:261:    # TODO: Should handle optional here?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:338:    return f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:355:    # TODO: Clean this logic up if we get rid of reverse view funcs or reify them.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:174:# TODO: Why is this going through CppSignatureGroup, that doesn't make sense...
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:395:            # TODO we are trolling
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:592:        # TODO: do we need eagerly calculate and save it here? Can it be derived
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/load_derivatives.py:653:    # TODO: maybe the logic to handle the legacy schema is no longer necessary?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:943:            # TODO: it would be nice to not have these special cases
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1079:        # TODO: `cpp_type` is only to keep it byte-for-byte compatible with the old codegen, should remove.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1100:                    # TODO(crcrpar): Make it simpler.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1221:            # TODO: process all derivative formulas!!!
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1345:            # TODO: should be `arg.type.is_tensor_like()`?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1605:            base_name = f.func.name.name.base  # TODO: should be str(f.func.name.name)?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1729:        # TODO: flatten allocates a std::vector, which could be expensive
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1857:                # TODO update this when inplace namings are unified
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_type.py:1967:                    # TODO(crcrpar): Should this (= the foreach specific logic) be refactored somehow?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_autograd_functions.py:441:# TODO: This is probably not exhaustive, but it's a start
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1250:        # TODO: should use some canonical form instead of 'str(arg.type)' - see comments
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_python_functions.py:1338:        # TODO: Checking `ps.method and ('requires_grad' in parser_outputs)` is a hacky
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_variable_factories.py:22:# TODO: maybe update the cpp argument API to take optional namespace argument?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:73:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:91:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:110:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/variable_factories.h:126:    at::AutoDispatchBelowAutograd guard;  // TODO: remove
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:156:    // TODO: consider factoring this out
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:371:  // TODO: change the condition to `self_.dim() != 0` once we expose scalars
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:416:  // TODO: Make this call the TensorOptions version, maybe?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/python_variable_methods.cpp:422:  // TODO: Make this call the TensorOptions version, maybe?
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/templates/Functions.h:32:    // TODO(crcrpar): Use `std::move(saved_for)` to avoid incrementing refcount, which would need refactoring.
./api/search/.venv/lib/python3.12/site-packages/requests/adapters.py:686:                # TODO: Remove this in 3.0.0: see #2811
./api/search/.venv/lib/python3.12/site-packages/requests/hooks.py:19:# TODO: response is the only one
./api/search/.venv/lib/python3.12/site-packages/einops/einops.py:52:    # TODO add support for added_axes
./api/search/.venv/lib/python3.12/site-packages/einops/tests/test_einsum.py:352:    # TODO: Include check for giving normal einsum pattern rather than einops.
./api/search/.venv/lib/python3.12/site-packages/iniconfig/__init__.py:80:    # TODO: investigate possible mypy bug wrt matching the passed over data
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:167:# TODO: add support for `axis` tuples
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_correlation.py:10:# TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:44:# TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1262:    # TODO: properly avoid NaN when y is negative infinity
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1263:    # TODO: silence warning with taking log of complex nan
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:1264:    # TODO: deal with x == y better
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3015:    # TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:3453:        # TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_distribution_infrastructure.py:4442:    # TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_morestats.py:2627:    # TODO: calculate exact distribution considering ties
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_qmc.py:456:        # TODO consider returning both the mean and the standard deviation
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_page_trend_test.py:322:    if ranks.ndim != 2:  # TODO: relax this to accept 3d arrays?
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:193:    # TODO: add more where possible with test coverage,
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:321:    # TODO: add more where possible with test coverage,
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_fast_gen_inversion.py:144:# TODO: add more distributions
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous_basic.py:136:        # TODO: multiple checks in this function are not robust, tweaking the
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:26:    # Check that `var` keyword returns a value.  TODO: check whether returned
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_extras.py:43:    # TODO: check that implementation is correct.
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2367:    # TODO: add method "pearsonr" after fix overflow issue
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_morestats.py:2387:    # TODO: add method "pearsonr" after fix overflow issue
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_mstats_basic.py:1260:# TODO: for all ttest functions, add tests with masked array inputs
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:5780:        # These are excluded by the filters below. TODO: Rewrite tests so that
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_continuous.py:890:    # TODO: add `supported` method and check here
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_stats.py:79:    # TODO: write these tests to handle missing values properly
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs.py:221:    # TODO use a better error approximation
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:38:#TODO renovate or move this class when scipy operators are more mature
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/_matfuncs_inv_ssq.py:73:#TODO renovate or move this function when SciPy operators are more mature
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_lapack.py:1941:                # TODO: Add a test for ONB?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/pyprima/cobyla/geometry.py:24:    TODO: Check whether it improves the performance if JDROP = NUM_VARS is allowed when
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:181:        # TODO: Does this depend on device?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/cupy/_info.py:243:        # TODO: Does this depend on device?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/torch/_aliases.py:833:    # TODO: is the return type a list or a tuple
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:42:    # TODO: import from typing (requires Python >=3.13)
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:119:    # TODO: Should we reject ndarray subclasses?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:264:    # TODO: Account for other backends.
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:293:        # TODO: drop support for numpy<2 which didn't have __array_namespace__
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:300:        # TODO: drop support for jax<0.4.32 which didn't have __array_namespace__
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:642:            # TODO: Support Python scalars?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:876:        # TODO: What if our array is on the GPU already?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:16:    # TODO: import from typing (requires Python >=3.13)
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:309:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_aliases.py:381:    # TODO: np.clip has other ufunc kwargs
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:32:# TODO: use the QR wrapper once dask
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/linalg.py:59:    # TODO: can't avoid computing U or V for dask
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:65:    # TODO: respect device keyword?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:96:    # TODO: respect device keyword?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:163:    # TODO: respect device keyword?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/dask/array/_aliases.py:224:    # TODO: This won't handle dask unknown shapes
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_at.py:23:    # TODO import from typing (requires Python >=3.11)
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:36:    # TODO import from typing (requires Python >=3.12 and >=3.13)
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:307:    TODO this helper should be eventually removed once all the special cases
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/testing.py:23:    # TODO import override from typing (requires Python >=3.12)
./api/search/.venv/lib/python3.12/site-packages/scipy/differentiate/_differentiate.py:372:    # TODO (followup):
./api/search/.venv/lib/python3.12/site-packages/scipy/cluster/hierarchy.py:1385:        # TODO ARRAY_API complex indexing not supported
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_direct_py.py:256:    # TODO: fix disp argument
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py:349:        # TODO: Use more advanced strategies from [2]_
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/qp_subproblem.py:54:    # TODO: Use a symmetric indefinite factorization
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:61:    # TODO: revert this once the warning bug fix in sksparse is merged/released
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_trustregion_constr/projections.py:101:    # TODO: Use a symmetric indefinite factorization
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_ip.py:92:                # TODO: revert this suppress_warning once the warning bug fix in
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2050:    # TODO: add hessp (callable or FD) to ScalarFunction?
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_chandrupatla.py:7:# TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:72:    # TODO: test redundant row removal better
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:73:    # TODO: make solve more efficient with BGLU? This could take a while.
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_rs.py:376:        # TODO: cythonize?
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:477:        pass  # TODO
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:716:                    # self.n #TODO: Should always be self.n, this is
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1176:        # TODO: Only do this if global mode
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo.py:1502:            # TODO: Uncertain if n_prc needs to add len(self.LMC.xl_maps)
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_chandrupatla.py:970:        # # TODO: Test zero tolerance
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test_optimize.py:3063:        # TODO this test should really be equivalent to factorized version
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__remove_redundancy.py:5:# TODO: add tests for:
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:579:        # TODO: Make default n higher for faster tests
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__shgo.py:715:        # TODO: This test doesn't cover anything new, it is unknown what the
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1179:            sign_det_A_11 = -1  # TODO: Choose another det of j instead?
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1180:            # TODO: Unlikely to work in many cases
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1187:            # TODO: Note that scipy might be faster to add as an optional
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1191:            # TODO: Note if sign_det_A_j0 == then the point is coplanar to the
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1217:        # TODO: Is checking the projection of one vertex against faces of other
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1220:        # TODO: Literature seems to suggest using proj.T, but why is this
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_shgo_lib/_complex.py:1222:        if np.linalg.det(proj) == 0.0:  # TODO: Replace with tolerance?
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_remove_redundancy.py:423:        v = U[:, -1]  # TODO: return these so user can eliminate from problem?
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:862:        if rr and A_eq.size > 0:  # TODO: Fast sparse rank check?
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_linprog_util.py:876:        try:  # TODO: use results of first SVD in _remove_redundancy_svd
./api/search/.venv/lib/python3.12/site-packages/scipy/special/_support_alternative_backends.py:125:            # TODO use xpx.lazy_apply to add jax.jit support
./api/search/.venv/lib/python3.12/site-packages/scipy/special/_lambertw.py:146:    # TODO: special expert should inspect this
./api/search/.venv/lib/python3.12/site-packages/scipy/special/tests/test_sf_error.py:34:    # TODO: special expert should correct
./api/search/.venv/lib/python3.12/site-packages/scipy/special/tests/test_basic.py:2448:        # TODO: cannot use N itself yet; factorial uses `gamma(N+1)` resp. `(hi+lo)//2`
./api/search/.venv/lib/python3.12/site-packages/scipy/io/_harwell_boeing/hb.py:12:# TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:21:# TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/io/arff/_arffread.py:842:        # TODO: this is where we are spending time (~80%). I think things
./api/search/.venv/lib/python3.12/site-packages/scipy/io/_netcdf.py:20:# TODO:
./api/search/.venv/lib/python3.12/site-packages/scipy/interpolate/_fitpack_impl.py:19:TODO: Make interfaces to the following fitpack functions:
./api/search/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_legendre.py:56:        # TODO: current converting to/from numpy
./api/search/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:78:        # TODO: Currently only support for degree 7 Genz-Malik cubature, should aim to
./api/search/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_genz_malik.py:134:        # TODO: Currently only support for the degree 5 lower rule, in the future it
./api/search/.venv/lib/python3.12/site-packages/scipy/integrate/_rules/_gauss_kronrod.py:83:        # TODO: nodes and weights are currently hard-coded for values 15 and 21, but in
./api/search/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:82:    # TODO: Optimize for hermitian and real?
./api/search/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:194:    # TODO: Optimize for hermitian and real?
./api/search/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/tests/test_basic.py:865:# TODO: Is this test actually valuable? The behavior it's testing shouldn't be
./api/search/.venv/lib/python3.12/site-packages/scipy/fft/tests/test_real_transforms.py:110:    # TODO write an array-agnostic pad
./api/search/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:885:    # TODO: Why are we using _as_euler_from_matrix here? As a sanity check? It is not
./api/search/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:920:    # TODO: Same as before: Remove _as_euler_from_matrix?
./api/search/.venv/lib/python3.12/site-packages/scipy/spatial/transform/tests/test_rotation.py:2083:    # TODO: Do we want to support this for all Array API frameworks?
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:412:    # TODO: delete next 15 lines [combine with _eye()] once spmatrix removed
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:541:    # TODO: delete next 10 lines and replace _sparse with _array when spmatrix removed
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:627:    # TODO: delete next 8 lines and replace _sparse with _array when spmatrix removed
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:684:    # TODO remove this if-structure when sparse matrices removed
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:134:                # TODO infer shape here
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_bsr.py:346:        # TODO eliminate zeros
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/tests/test_svds.py:626:            # TODO: arpack crashes when v0=v0, which="SM"
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/minres.py:357:            break  # TODO check this
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:20:# TODO check that method preserve shape and type
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:21:# TODO test both preconditioner methods
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:366:    # TODO: minres / tfqmr. It didn't historically use absolute tolerances, so
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py:369:        pytest.skip("TODO: Add atol to minres/tfqmr")
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:145:        #TODO this test seems to give estimates that match the table,
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:146:        #TODO even though no attempt has been made to deal with
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/linalg/tests/test_onenormest.py:147:        #TODO complex numbers in the one-norm estimation.
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_dok.py:474:            # TODO implement resize across dimensions
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:227:        # TODO check for duplicates?
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:700:        # TODO: don't fall back to fancy indexing here
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_compressed.py:967:            # TODO: only sort where necessary
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_base.py:656:            # TODO sparse broadcasting
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_csr.py:229:        # TODO: uncomment this once it's faster:
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_data.py:18:# TODO implement all relevant operations
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:238:                # TODO: make sparse matrix indexing work for sparray
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/_index.py:303:            # TODO: handle this for nD (adjacent arrays stay, separated move to start)
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_construct.py:23:#TODO check whether format=XXX is respected
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:297:# TODO test prune
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:298:# TODO test has_sorted_indices
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:4733:        # TODO: properly handle this assertion on ppc64le
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_base.py:5469:        # TODO check that NC has duplicates (which are not explicit zeros)
./api/search/.venv/lib/python3.12/site-packages/scipy/sparse/tests/test_spfuncs.py:16:        #TODO expose through function
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:516:                and n_fft > 0):  # TODO: review threshold acc. to benchmark?
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:1643:    # TODO in the near future:
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/_filter_design.py:4886:# TODO: Make this a real public function scipy.misc.ff
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/_ltisys.py:1996:    # TODO: This could use some more work.
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:604:        # TODO: add meaningful test where X0 is a list
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_ltisys.py:676:        # TODO: add meaningful test where X0 is a list
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2565:        # TODO: Why so inaccurate?  Is reference flawed?
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2570:        # TODO: Why so inaccurate?  Is reference flawed?
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2580:        # TODO: Why so inaccurate?  Is reference flawed?
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_filter_design.py:2585:        # TODO: Why so inaccurate?  Is reference flawed?
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_windows.py:820:    @xfail_xp_backends(np_only=True, reason='TODO: make resample array API ready')
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:211:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_signaltools.py:884:    @xfail_xp_backends(np_only=True, reason="TODO: swapaxes")
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:290:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:305:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:319:    @skip_xp_backends(np_only=True, reason="TODO: convert this test")
./api/search/.venv/lib/python3.12/site-packages/pre_commit/store.py:234:            # TODO: eventually remove this and only create in _create
./api/search/.venv/lib/python3.12/site-packages/pre_commit/hook.py:50:        # TODO: have cfgv do this (?)
./api/search/.venv/lib/python3.12/site-packages/pre_commit/languages/julia.py:71:        # TODO: Support language_version with juliaup similar to rust via
./api/search/.venv/lib/python3.12/site-packages/pre_commit/languages/golang.py:93:    # TODO: 3.9+ .removeprefix('go')
./api/search/.venv/lib/python3.12/site-packages/pre_commit/repository.py:97:        # TODO: remove v1 state writing, no longer needed after pre-commit 3.0
./api/search/.venv/lib/python3.12/site-packages/uvloop/_testbase.py:291:        # TODO This warning has to be fixed in asyncio.
./api/search/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:221:# TODO at some point, we could switch to an enum flag, so that multiple sources
./api/search/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:224:    # TODO if/when https://peps.python.org/pep-0767/ is accepted, add 'read_only'
./api/search/.venv/lib/python3.12/site-packages/typing_inspection/introspection.py:319:        # TODO use a match statement when Python 3.9 support is dropped.
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:473:            # TODO: what happens if we don't have a filename?
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1464:        # TODO: verify that we're in the state MultipartState.END, otherwise throw an
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1655:                # TODO: check for error here.
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1685:                # TODO: handle mixed case
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1692:                # TODO: check for errors
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1703:                # TODO: check that we properly handle 8bit / 7bit encoding.
./api/search/.venv/lib/python3.12/site-packages/python_multipart/multipart.py:1764:        # TODO: check the parser's return value for errors?
./api/search/.venv/lib/python3.12/site-packages/numpy/_typing/_dtype_like.py:61:_DTypeLikeNested = Any  # TODO: wait for support for recursive types
./api/search/.venv/lib/python3.12/site-packages/numpy/_typing/_array_like.py:56:# TODO: Wait until mypy supports recursive objects in combination with typevars
./api/search/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1795:    # TODO: are there no other tests for cholesky?
./api/search/.venv/lib/python3.12/site-packages/numpy/core/getlimits.py:367:    TODO: MachAr should be retired completely ideally.  We currently only
./api/search/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs.py:2312:        assignment examples; TODO).
./api/search/.venv/lib/python3.12/site-packages/numpy/core/arrayprint.py:1466:        # TODO: Custom repr for user DTypes, logic should likely move.
./api/search/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:170:        # TODO: this path can never be reached
./api/search/.venv/lib/python3.12/site-packages/numpy/core/_dtype.py:179:    # TODO: this duplicates the C metastr_to_unicode functionality
./api/search/.venv/lib/python3.12/site-packages/numpy/core/_add_newdocs_scalars.py:320:# TODO: work out how to put this on the base class, np.floating
./api/search/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:80:        # TODO: Optimize case when `where` is broadcast along a non-reduction
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_scalarmath.py:97:        # TODO: It would be nice to resolve this issue.
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:7434:# TODO: test for multidimensional
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:452:        # TODO: This discrepancy _should_ be resolved, either by relaxing the
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_coercion.py:892:    # TODO: This is arguably weird/wrong, but seems old:
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:12:# TODO: branch cuts (use Pauli code)
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:13:# TODO: conj 'symmetry'
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:14:# TODO: FPU exceptions
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:23:# TODO: replace with a check on whether platform-provided C99 funcs are used
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:26:# TODO This can be xfail when the generator functions are got rid of.
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:122:    # TODO This can be xfail when the generator functions are got rid of.
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:479:    # TODO This can be xfail when the generator functions are got rid of.
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_casting_unittests.py:782:        # TODO: While this test is fairly thorough, right now, it does not
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_api.py:163:# TODO: remove when fastCopyAndTranspose deprecation expires
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:1544:        # TODO: Allowing unsafe casting by
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_datetime.py:2520:        # TODO: add absolute (gold standard) time span limit strings
./api/search/.venv/lib/python3.12/site-packages/numpy/core/numeric.py:480:    # TODO: this works around .astype(bool) not working properly (gh-9847)
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1873:    /* TODO: Make this definition public in the API, as soon as its settled */
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:221: * TODO: Due to the fact that `resolve_descriptors` is also used for `can_cast`
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:366:// TODO: These slots probably still need some thought, and/or a way to "grow"?
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/_dtype_api.h:398: * TODO: These two functions are currently only used for experimental DType
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:821:        // TODO: do something better than 128 bit math
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/random/libdivide.h:855:        // TODO: do something better than 128 bit math
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/mixins.py:163:    # TODO: handle the optional third argument for __pow__?
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:73:# TODO: .zip support, .tar support?
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:335:        # TODO: Doesn't handle compressed files!
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:401:        # TODO:  This should be more robust.  Handles case where path includes
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:515:        # TODO: There is no support for opening a file for writing which
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:518:        # TODO: Add a ``subdir`` parameter for specifying the subdirectory
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:3543:        # TODO: Note that times have dubious rounding as of fixing NaTs!
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_function_base.py:4101:        # TODO: Median does not support Datetime, due to `mean`.
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/tests/test_io.py:311:                sup.filter(ResourceWarning)  # TODO: specify exact message
./api/search/.venv/lib/python3.12/site-packages/numpy/ma/core.py:207:        # TODO: This is probably a mess, but should best preserve behavior?
./api/search/.venv/lib/python3.12/site-packages/numpy/ma/core.py:4673:        # TODO: We don't actually support K, so use A instead.  We could
./api/search/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_core.py:5430:    # TODO: Test masked_object, masked_equal, ...
./api/search/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/_isocbind.py:55:# TODO: See gh-25229
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:134:TODO:
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2066:    TODO:
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2505:                    # TODO: test .eq., .neq., etc replacements.
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2551:                outmess(f'get_parameters[TODO]: '
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/crackfortran.py:2594:        # TODO: use symbolic from PR #19805
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:723:        /* TODO: change the type of `len` so that we can remove this */
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:783:            // TODO: update when numpy will support 1-byte and
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:808:        /* TODO: This error (and most other) error handling needs cleaning. */
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/cfuncs.py:830:# TODO: These should be dynamically generated, too many mapped to int things,
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:248:    # TODO: support Fortran `len` function with optional kind parameter
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/capi_maps.py:504:        # TODO: Evaluate intent_flags here.
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:23:# TODO: support logical constants (Op.BOOLEAN)
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:24:# TODO: support logical operators (.AND., ...)
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:25:# TODO: support defined operators (.MYOP., ...)
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:520:                # TODO: other kind not used
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:570:        # TODO: implement a method for deciding when __call__ should
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:811:            # TODO: determine correct kind
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:846:            # TODO: determine correct kind
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:896:            # TODO: denom kind not used
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/symbolic.py:1108:            # TODO: find common divisor of coefficients
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/src/fortranobject.c:1358:  // TODO: detect the size of buf and make sure that size(buf) >= size(localbuf).
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:395:    # TODO: Clean up to prevent passing --overwrite-signature
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:494:    TODO: Test to ensure this has no effect without --latex-doc
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:638:    TODO: Document this in the help string
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:662:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:671:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:727:    # TODO: f2py2e should not call sys.exit() after printing the version
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:752:# TODO: These should be tested separately
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:759:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:767:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:775:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:783:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:791:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:799:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:807:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:815:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:823:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:831:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:839:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:847:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:855:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:863:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:871:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:879:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:887:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_f2py2e.py:895:    # TODO: populate
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/tests/test_docs.py:55:    # TODO: implement test methods for other example Fortran codes
./api/search/.venv/lib/python3.12/site-packages/numpy/f2py/f2py2e.py:448:    # TODO: Remove all this when scaninputline is replaced
./api/search/.venv/lib/python3.12/site-packages/numpy/array_api/_set_functions.py:15:# TODO in this implementation as this behavior may be reverted in np.unique().
./api/search/.venv/lib/python3.12/site-packages/numpy/array_api/__init__.py:98:Still TODO in this module are:
./api/search/.venv/lib/python3.12/site-packages/numpy/array_api/_creation_functions.py:69:        # to an object array. TODO: This won't handle large integers in lists.
./api/search/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_array_object.py:387:    TODO: Find and use appropriate __setitem__() case.
./api/search/.venv/lib/python3.12/site-packages/numpy/array_api/tests/test_data_type_functions.py:29:    # TODO: These will require https://github.com/numpy/numpy/issues/23883
./api/search/.venv/lib/python3.12/site-packages/numpy/polynomial/_polybase.py:436:        # TODO: we're stuck with disabling math formatting until we handle
./api/search/.venv/lib/python3.12/site-packages/numpy/random/tests/test_random.py:1062:    # TODO: Include test for randint once it can broadcast
./api/search/.venv/lib/python3.12/site-packages/transformers/commands/add_new_model_like.py:688:    # TODO: Find some kind of fallback if there is no _CHECKPOINT_FOR_DOC in any of the modeling file.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:41:# TODO: This doesn't work for all packages (`bs4`, `faiss`, etc.) Talk to Sylvain to see how to do with it better.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:48:            # TODO: Once python 3.9 support is dropped, `importlib.metadata.packages_distributions()`
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:71:                # TODO: remove once `importlib.metadata.packages_distributions()` is supported.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:401:    # TODO check if some bugs cause push backs on the exact version
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:578:        # TODO: more precise exception matching, if possible.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:602:        # TODO: more precise exception matching, if possible.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1048:        # TODO: Bump the requirement to 2.1.0 once released in https://github.com/ROCmSoftwarePlatform/flash-attention
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/attention_visualizer.py:188:            if "token_type_ids" in inputs:  # TODO inspect signature of update causal mask
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/quantization_config.py:1803:                # TODO: Remove this check once configuration version is handled natively by Quark.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:93:# TODO: clean this for v5?
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:530:# TODO cyril: Deprecated and should be removed in 4.51
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:197:    # TODO: add support for them as it should be quite easy to do so (small blocking issues).
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:389:    # TODO: infer shape without performing the computation, this might be quite hard.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:582:        # TODO: infer shape without performing the computation.
./api/search/.venv/lib/python3.12/site-packages/transformers/utils/fx.py:1351:            # TODO: solves GraphModule creation.
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:336:        # TODO: remove this hack when the legacy code that initializes generation_config from a model config is
./api/search/.venv/lib/python3.12/site-packages/transformers/processing_utils.py:1117:                    # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:371:        # TODO (Joao): this function might trigger XLA retracing as `cur_len` increases. Fix it if it becomes
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/tf_logits_process.py:428:        # TODO (joao): enable XLA on this logits processor. See discussion and attempts in
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/logits_process.py:1942:        # TODO(Patrick): Make sure that official models have max_initial_timestamp_index set to 50
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:317:# TODO (joao): remove the equivalent classes and typing shortcuts below in v5
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:519:        # 8. Remove unexpected `generate` inputs (TODO @joao: fix trainer and examples)
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:800:                # TODO (joao): remove output/input mismatch when these old models (xlnet, reformer) are deprecated
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1082:            # TODO (sanchit): move this exception to GenerationConfig.validate() when TF & FLAX are aligned with PT
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1088:        # TODO (joao): find a strategy to specify the order of the processors
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1353:        # TODO(joao): remove this function in v4.50, i.e. when we remove the inheritance of `GenerationMixin` from
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1428:            # TODO: A better way to handle this.
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1564:        # TODO (joao): per-model generation config classes.
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1821:        # TODO(joao): support static caches in assisted generation. assisted generation needs to roll back caches,
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2135:            # TODO (joao): generalize this check with other types of inputs
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3331:                # TODO (joao): this OP throws "skipping cudagraphs due to ['incompatible ops']", find solution
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3386:        TODO: standardize cache formats and make all models compatible with `Cache`. It would remove the need
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3505:        # TODO (joao): This function should take an optional beam scorer function, to manipulate the scores after
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3669:        # TODO (joao): standardize special cases
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1627:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:1911:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2254:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/tf_utils.py:2789:        # TODO (Joao): fix cache format or find programatic way to detect cache index
./api/search/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:537:        # TODO joao: find out a way of not depending on external fields (e.g. `assistant_model`), then make this a
./api/search/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:54:# TODO: Move BatchFeature to be imported by both image_processing_utils and image_processing_utils
./api/search/.venv/lib/python3.12/site-packages/transformers/image_processing_base.py:71:# TODO: (Amy) - factor out the common parts of this and the feature extractor
./api/search/.venv/lib/python3.12/site-packages/transformers/image_utils.py:1325:        # TODO raise a warning here instead of simply logging?
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1496:            # TODO Matt: This is a workaround for older versions of datasets that are missing the `cols_to_retain`
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2025:        # TODO (joao): flagged for replacement (by `_v2_resized_token_embeddings`) due to embeddings refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2065:        # TODO (joao): flagged for delection due to embeddings refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2096:        # TODO (joao): flagged for replacement (by `_v2_resize_token_embeddings`) due to embeddings refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2133:            # TODO (joao): this one probably needs a v2 version with other models
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2156:        # TODO (joao): flagged for replacement (by `_v2_get_resized_lm_head_bias`) due to embeddings refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2283:        # TODO (joao): flagged for replacement (by `_v2_get_resized_embeddings`) due to embeddings refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:2954:            # TODO Matt: This is a temporary workaround to allow weight renaming, but requires a method
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:3335:    # TODO (joao): flagged for delection due to embeddings refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/loss/loss_for_object_detection.py:197:        # TODO use valid to mask invalid areas due to padding in loss
./api/search/.venv/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:210:        # TODO: randomness could apply a random seed, ex. rng = random.Random(random_seed)
./api/search/.venv/lib/python3.12/site-packages/transformers/data/processors/squad.py:179:        encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic
./api/search/.venv/lib/python3.12/site-packages/transformers/integrations/executorch.py:201:        # TODO: The default inputs only work for text models. We need to add support for vision/audio models.
./api/search/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:227:        # TODO: figure out dynamo support for instance method and switch this to instance method
./api/search/.venv/lib/python3.12/site-packages/transformers/integrations/tensor_parallel.py:261:        # TODO: figure out dynamo support for instance method and switch this to instance method
./api/search/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:876:        # TODO clean this up at some point (probably by switching to fast tokenizers)
./api/search/.venv/lib/python3.12/site-packages/transformers/audio_utils.py:381:# TODO This method does not support batching yet as we are mainly focused on inference.
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py:279:        # TODO: Remove the `query_length != 1` check once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/onnx/convert.py:141:            # TODO: Check when exporting QA we provide "is_pair=True"
./api/search/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:516:        # TODO: should we set seq_length = 1 when self.use_past = True?
./api/search/.venv/lib/python3.12/site-packages/transformers/onnx/config.py:702:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/tf_utils.py:70:    # TODO: When the issue linked above gets sorted, add a check on TF version here and use the original function if
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer.py:271:    # TODO: @AjayP13, @younesbelkada replace this check with version check at the next `accelerate` release
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer.py:1542:                # TODO Change dtypes back to M=FP32, Var = BF16, Kahan = False once they can be cast together in torchdistx.
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer.py:2865:            # TODO: in the future support only specific min PEFT versions
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer.py:2959:                    # TODO: in the future support only specific min PEFT versions
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer.py:3785:        # TODO: this needs to be fixed and made cleaner later.
./api/search/.venv/lib/python3.12/site-packages/transformers/trainer.py:4561:                    # TODO: this needs to be fixed and made cleaner later.
./api/search/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:545:        # TODO this is fairly slow to improve!
./api/search/.venv/lib/python3.12/site-packages/transformers/tokenization_utils.py:1103:        # TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_string
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:213:    TODO(Patrick): Delete safety argument `_enable=True` at next major version. .
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1760:# TODO (joao): remove `GenerationMixin` inheritance in v4.50
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4065:            # TODO: we can relax this check when we support taking tp_plan from a json file, for example.
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:160:        # TODO try and retrieve it in a nicer way from _sanitize_parameters.
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:103:    # TODO: Update task_summary docs to include an example with document QA and then update the first sentence
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:379:            # TODO: check why slower `LayoutLMTokenizer` and `LayoutLMv2Tokenizer` don't have this key in outputs
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:467:        # TODO: A lot of this logic is specific to Donut and should probably be handled in the tokenizer
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1301:        # TODO hack by collating feature_extractor and image_processor
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1344:        # TODO make the get_iterator work also for `tf` (and `flax`).
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1419:        # TODO hack by collating feature_extractor and image_processor
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:103:    # TODO  Use a faster algorithm this can probably be done in O(n)
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:969:    # TODO: we need to make `NO_IMAGE_PROCESSOR_TASKS` and `NO_FEATURE_EXTRACTOR_TASKS` more robust to avoid such issue.
./api/search/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:341:# TODO need to add the __repr__ that shows that it is a colwise parallel
./api/search/.venv/lib/python3.12/site-packages/transformers/sagemaker/training_args_sm.py:29:# TODO: should be moved to `utils` after refactoring of SageMakerTrainer
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:61:        # TODO: deprecate this function in favor of `cache_position`
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:453:        # TODO: deprecate this function in favor of `cache_position`
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:596:    # TODO (tmanlaibaatar) This won't be needed in torch 2.7.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1021:        # TODO: deprecate this function in favor of `cache_position`
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1172:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1276:        # TODO: deprecate this function in favor of `cache_position`
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1356:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1567:    # TODO(gante, sanchit-gandhi): move following functionality into `.generate`
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1659:    # TODO (joao): dive deeper into gemma2 and paligemma -- there are reports of speed loss with compilation. Revert
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1663:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1806:        # TODO: deprecate this function in favor of `cache_position`
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1865:    # TODO (joao): remove `=None` in non-optional arguments in v4.46. Remove from `OBJECTS_TO_IGNORE` as well.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1866:    # TODO (joao): add layer_device_map arg and update code in `generate` accordingly
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2044:        # TODO(gante): Remove this.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2078:            # TODO(gante): Remove this.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2136:        # TODO(gante): Remove this.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2148:        # TODO(gante): Remove this.
./api/search/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:2160:        # TODO(gante): Remove this.
./api/search/.venv/lib/python3.12/site-packages/transformers/training_args.py:223:# TODO: `TrainingArguments` users rely on it being fully mutable. In the future see if we can narrow this to a few keys: https://github.com/huggingface/transformers/pull/25903
./api/search/.venv/lib/python3.12/site-packages/transformers/training_args.py:2162:        # those deprecated arguments are removed from TrainingArguments. (TODO: v5)
./api/search/.venv/lib/python3.12/site-packages/transformers/image_transforms.py:791:# TODO (Amy): Accept 1/3/4 channel numpy array as input and return np.array as default
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:133:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:261:    # TODO (joao): use the new `original_max_position_embeddings` from rope_scaling
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:414:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_rope_utils.py:459:    # TODO (joao): update logic for the inclusion of `original_max_position_embeddings`
./api/search/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1218:                # TODO: Remove once eetq releases a fix and this release is used in CI
./api/search/.venv/lib/python3.12/site-packages/transformers/testing_utils.py:1506:    # TODO (if possible): Avoid exceptional cases
./api/search/.venv/lib/python3.12/site-packages/transformers/agents/agents.py:1094:                # TODO: observation naming could allow for different names of same type
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:269:            # TODO: When tracing with TorchDynamo with fullgraph=True, the model is recompiled depending on the input
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:297:                # TODO: maybe revisit this with https://github.com/pytorch/pytorch/pull/114823 in PyTorch 2.3.
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:375:    # TODO: For dynamo, rather use a check on fullgraph=True once this is possible (https://github.com/pytorch/pytorch/pull/120400).
./api/search/.venv/lib/python3.12/site-packages/transformers/models/superpoint/image_processing_superpoint.py:66:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./api/search/.venv/lib/python3.12/site-packages/transformers/models/helium/modeling_helium.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/shieldgemma2/processing_shieldgemma2.py:153:        # TODO(ryanmullins): Support images from PIL or URLs.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/rwkv/modeling_rwkv.py:274:    # TODO: maybe jit, otherwise move inside forward
./api/search/.venv/lib/python3.12/site-packages/transformers/models/pegasus/tokenization_pegasus.py:33:# TODO ArthurZ refactor this to only use the added_tokens_encoder
./api/search/.venv/lib/python3.12/site-packages/transformers/models/emu3/modeling_emu3.py:1234:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:279:        # TODO: remove the redundant computation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_led.py:394:        # TODO replace this with
./api/search/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:467:        # TODO: This code is most likely not very efficient and should be improved
./api/search/.venv/lib/python3.12/site-packages/transformers/models/led/modeling_tf_led.py:2473:        # TODO (Joao): investigate why LED has numerical issues in XLA generate
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmo/modeling_olmo.py:311:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:188:            # TODO: figure this case out.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/configuration_blenderbot_small.py:287:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py:317:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:251:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granite/modeling_granite.py:346:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:99:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:356:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:461:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/stablelm/modeling_stablelm.py:525:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:300:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:428:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:203:            # TODO: figure this case out.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:302:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/processing_grounding_dino.py:319:                    # TODO: @pavel, set labels to None since v4.51.0 or find a way to extract ids
./api/search/.venv/lib/python3.12/site-packages/transformers/models/grounding_dino/modeling_grounding_dino.py:1582:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./api/search/.venv/lib/python3.12/site-packages/transformers/models/esm/configuration_esm.py:26:# TODO Update this
./api/search/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:364:# TODO: ^ interpret this
./api/search/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/residue_constants.py:418:    # TODO: this file should be downloaded in a setup script
./api/search/.venv/lib/python3.12/site-packages/transformers/models/esm/modeling_esmfold.py:2007:# TODO Add information to the docstring about any methods that convert to PDB format, or otherwise prepare
./api/search/.venv/lib/python3.12/site-packages/transformers/models/esm/tokenization_esm.py:65:        # TODO, all the tokens are added? But they are also part of the vocab... bit strange.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:330:        # `sqrt` in order to prevent NaNs during training in bfloat16. TODO a bit annoying
./api/search/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:347:    # TODO refactor
./api/search/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:709:        if use_cache and inputs_embeds.shape[1] != 1:  # TODO let's maybe only call in the `generate`?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:776:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->RECURRENTGEMMA,Llama->RecurrentGemma,llama->gemma
./api/search/.venv/lib/python3.12/site-packages/transformers/models/recurrent_gemma/modeling_recurrent_gemma.py:866:        # Soft-cap the logits TODO remove if always done.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py:324:        # TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:971:        # TODO: deal with head_mask
./api/search/.venv/lib/python3.12/site-packages/transformers/models/funnel/modeling_funnel.py:1046:        # TODO: deal with head_mask
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mluke/tokenization_mluke.py:344:        # TODO check if the t5/llama PR also applies here
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:156:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py:629:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:210:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:239:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_audio/modeling_qwen2_audio.py:310:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:424:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:612:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:685:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/jetmoe/modeling_jetmoe.py:740:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics3/modeling_idefics3.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/phi/modeling_phi.py:307:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:431:        # TODO: @yoni, change in v4.48 (use_fast set to True by default)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:496:        # TODO: @yoni, change logic in v4.50 (when use_fast set to True by default)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py:262:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/modernbert/modeling_modernbert.py:270:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/dpt/image_processing_dpt.py:608:        # TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/instructblip/modeling_instructblip.py:1295:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./api/search/.venv/lib/python3.12/site-packages/transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py:504:                # TODO: Should we use the pre-trained projection as well ?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py:669:            # TODO (joao): the `TFBaseModelOutput` wrapper should not be needed after the generate refactor is complete
./api/search/.venv/lib/python3.12/site-packages/transformers/models/beit/image_processing_beit.py:487:        # TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:346:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/musicgen_melody/modeling_musicgen_melody.py:475:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/sam/modeling_tf_sam.py:687:        # TODO Matt: What is going on here? Why is a non-trainable weight randomly initialized?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/llama/tokenization_llama_fast.py:244:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./api/search/.venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:117:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:268:# TODO: (Amy) Move to image_transforms
./api/search/.venv/lib/python3.12/site-packages/transformers/models/maskformer/image_processing_maskformer.py:661:        # TODO: (Amy)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:618:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:747:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1577:        >>> # TODO: Add full pretraining example
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech_sat/modeling_unispeech_sat.py:1594:        # TODO(PVP) - add pretraining logic and add to tests
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:338:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:562:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:573:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:622:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:679:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moshi/modeling_moshi.py:700:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:203:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bark/modeling_bark.py:1709:        # TODO (joao):workaround until nested generation config is compatible with PreTrained Model
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bark/generation_configuration_bark.py:245:    # TODO (joao): nested from_dict
./api/search/.venv/lib/python3.12/site-packages/transformers/models/owlvit/image_processing_owlvit.py:462:        # TODO: (amy) add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py:628:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py:158:        # TODO ArthurZ fairseq_ids_to_tokens should be removed
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:423:        # TODO fix this
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:516:        # TODO find a better way of exposing other arguments
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/deta/modeling_deta.py:1152:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:216:            # TODO: Support arbitrary patch sizes.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/nat/modeling_nat.py:931:                # TODO can we simplify this?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py:1345:        # TODO (Qian): is it possible to revert the original cell if it is in the final answer?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:388:        self.t2u_variance_predictor_embed_dim = t2u_variance_predictor_embed_dim  # TODO: add to docstrings
./api/search/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:389:        self.t2u_variance_predictor_hidden_dim = t2u_variance_predictor_hidden_dim  # TODO: add to docstrings
./api/search/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:390:        self.t2u_variance_predictor_kernel_size = t2u_variance_predictor_kernel_size  # TODO: add to docstrings
./api/search/.venv/lib/python3.12/site-packages/transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py:391:        self.t2u_variance_pred_dropout = t2u_variance_pred_dropout  # TODO: add to docstrings
./api/search/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:354:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/modeling_m2m_100.py:483:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/m2m_100/configuration_m2m_100.py:274:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:197:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:399:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:412:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:510:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_moe/modeling_qwen2_moe.py:531:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:313:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/cohere2/modeling_cohere2.py:78:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py:504:# TODO: Implement attention with SDPA for TimeSeriesTransformer.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_tf_wav2vec2.py:461:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:664:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:793:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt2/configuration_gpt2.py:202:            # TODO: how to do that better?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:300:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/canine/modeling_canine.py:388:            # TODO add support for MLM
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modular_gemma3.py:572:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:170:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gemma3/modeling_gemma3.py:637:        # TODO: raushan fix this after RoPE refactor. For now we hack it by reassigning thetas
./api/search/.venv/lib/python3.12/site-packages/transformers/models/big_bird/modeling_big_bird.py:839:            # TODO(PVP): need to verify if below code is correct
./api/search/.venv/lib/python3.12/site-packages/transformers/models/byt5/tokenization_byt5.py:97:            additional_special_tokens=additional_special_tokens,  # TODO extra ids are not used :sweatywmile:
./api/search/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:414:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:506:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/clip/modeling_tf_clip.py:1446:        # TODO: As is this currently fails with saved_model=True, because
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bridgetower/configuration_bridgetower.py:279:        # TODO: remove this once the Hub files are updated.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:287:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:504:    _supports_static_cache = False  # TODO: needs a HybridCache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:330:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/musicgen/modeling_musicgen.py:458:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:63:# TODO: Update before the merge
./api/search/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:1263:    _supports_static_cache = False  # TODO: @raushan more involved due to local/global attn
./api/search/.venv/lib/python3.12/site-packages/transformers/models/longt5/modeling_longt5.py:2227:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py:696:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:390:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:595:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:817:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:936:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1830:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/configuration_qwen2_5_vl.py:248:        # TODO: @raushan update config in the hub
./api/search/.venv/lib/python3.12/site-packages/transformers/models/dinat/modeling_dinat.py:216:            # TODO: Support arbitrary patch sizes.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:129:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/zoedepth/image_processing_zoedepth.py:232:        # TODO support align_corners=True in image_transforms.resize
./api/search/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/sew/modeling_sew.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mobilevit/image_processing_mobilevit.py:457:        # TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:307:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:414:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modeling_diffllama.py:651:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:176:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:230:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/diffllama/modular_diffllama.py:337:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmo2/modeling_olmo2.py:312:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/superglue/image_processing_superglue.py:73:    Converts an image to grayscale format using the NTSC formula. Only support numpy and PIL Image. TODO support torch
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:96:# TODO(joao): add me back asap :)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:149:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: this may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:280:    # TODO(joao): add me back asap :)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:374:# TODO(joao): add me back asap :)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:385:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:437:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim].
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:511:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/chameleon/modeling_chameleon.py:593:# TODO(joao): add me back asap :)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:124:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:313:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:324:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:371:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:428:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:450:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nemotron/modeling_nemotron.py:1010:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaForCausalLM with LLAMA->NEMOTRON,Llama->Nemotron,llama->nemotron
./api/search/.venv/lib/python3.12/site-packages/transformers/models/ijepa/modeling_ijepa.py:585:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:140:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:266:        # TODO (raushan): remove in v4.46 (RoPE is computed in the model, not in the decoder layers)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:472:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:511:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/falcon/modeling_falcon.py:1024:        # TODO: As of torch==2.2.0, the `attention_mask` passed to the model in `generate` is 2D and of dynamic length even when the static
./api/search/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:306:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/tokenization_xlm_roberta.py:258:        # TODO check if the t5/llama PR also applies here
./api/search/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:342:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/siglip2/modeling_siglip2.py:434:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:51:# TODO @ArthurZucker bring copied from back
./api/search/.venv/lib/python3.12/site-packages/transformers/models/biogpt/modeling_biogpt.py:262:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py:303:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:305:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/table_transformer/modeling_table_transformer.py:413:        # TODO find a better way of exposing other arguments
./api/search/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:253:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/modeling_smolvlm.py:287:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:391:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/jamba/modeling_jamba.py:496:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deberta_v2/tokenization_deberta_v2.py:352:    # TODO add a deprecation cycle as this can have different behaviour from our API
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:188:            # TODO: figure this case out.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mbart/configuration_mbart.py:287:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:297:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mbart/modeling_mbart.py:426:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_sw3/tokenization_gpt_sw3.py:213:                # TODO: Check if this is needed, as it ensures that decode(encode(doc)) != doc by adding extra whitespace in the decoded document
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:131:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:630:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:749:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:941:    _supports_static_cache = False  # TODO (joao): fix. torch.compile failing probably due to `cache_positions`
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/modeling_qwen2_vl.py:1707:        # if we get 4D attention mask we cannot calculate rope deltas anymore. TODO @raushan fixme
./api/search/.venv/lib/python3.12/site-packages/transformers/models/qwen2_vl/configuration_qwen2_vl.py:237:        # TODO: @raushan update config in the hub
./api/search/.venv/lib/python3.12/site-packages/transformers/models/sew_d/modeling_sew_d.py:594:        # TODO: We should check if the opset_version being used to export
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mt5/modeling_mt5.py:1967:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./api/search/.venv/lib/python3.12/site-packages/transformers/models/videomae/modeling_videomae.py:103:    # TODO: make it with torch instead of numpy
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gptj/modeling_gptj.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gptj/configuration_gptj.py:148:            # TODO: how to do that better?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deit/modeling_deit.py:595:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/barthez/tokenization_barthez.py:34:# TODO this class is useless. This is the most standard sentencpiece model. Let's find which one is closest and nuke this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/phi3/modeling_phi3.py:353:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:82:        # TODO maybe make it torch compatible later on. We can also just slice
./api/search/.venv/lib/python3.12/site-packages/transformers/models/pixtral/modeling_pixtral.py:112:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:279:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:313:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:863:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics2/modeling_idefics2.py:874:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/codegen/modeling_codegen.py:168:        # TODO(enijkamp): factor out number of logical TPU-v4 cores or make forward pass agnostic
./api/search/.venv/lib/python3.12/site-packages/transformers/models/codegen/configuration_codegen.py:159:            # TODO: how to do that better?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/moonshine/modeling_moonshine.py:345:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_tf_whisper.py:1672:        # TODO: Implement `WhisperTimeStampLogitsProcessor`.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:366:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:423:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]
./api/search/.venv/lib/python3.12/site-packages/transformers/models/whisper/modeling_whisper.py:491:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/whisper/tokenization_whisper.py:1005:                    # TODO Handle when language is different from the previous
./api/search/.venv/lib/python3.12/site-packages/transformers/models/persimmon/modeling_persimmon.py:93:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/aria/modeling_aria.py:762:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/yolos/image_processing_yolos.py:1436:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/zamba2/modeling_zamba2.py:251:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:208:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/opt/modeling_opt.py:243:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/vit/modeling_vit.py:604:        # TODO: maybe have a cleaner way to cast the input (from `ImageProcessor` side?)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/blip_2/modeling_blip_2.py:2349:            # TODO (joao, raushan): refactor `generate` to avoid these operations with VLMs
./api/search/.venv/lib/python3.12/site-packages/transformers/models/plbart/modeling_plbart.py:348:# TODO: Implement attention with SDPA for PLBart.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:375:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:638:            # TODO(PVP): need to verify if below code is correct
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:210:            # TODO: figure this case out.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py:309:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mixtral/modeling_mixtral.py:422:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/glm/modeling_glm.py:292:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/camembert/modeling_camembert.py:323:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/camembert/tokenization_camembert.py:194:        # TODO decode outputs do not match between fast and slow
./api/search/.venv/lib/python3.12/site-packages/transformers/models/instructblipvideo/modeling_instructblipvideo.py:1289:    _keep_in_fp32_modules = ["query_tokens"]  # TODO @ArthurZucker I don't know why this is required for FP8
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:263:# TODO: (Amy) Move to image_transforms
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mask2former/image_processing_mask2former.py:660:        # TODO: (Amy)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/flava/modeling_flava.py:607:        # TODO: Check fp32 layer norm possiblity
./api/search/.venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:454:        # TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/rt_detr/modeling_rt_detr.py:49:# TODO: Replace all occurrences of the checkpoint with the final one
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:242:        # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:545:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:754:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:1012:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mllama/modeling_mllama.py:2202:        # TODO: we have no attention_mask so this won't work, check if we really won't need attention mask and find another way
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mllama/processing_mllama.py:265:            TODO: add aspect_ratio_ids and aspect_ratio_mask and cross_attention_mask
./api/search/.venv/lib/python3.12/site-packages/transformers/models/nougat/tokenization_nougat_fast.py:537:        # TODO Come up with footnote formatting inside a table
./api/search/.venv/lib/python3.12/site-packages/transformers/models/oneformer/image_processing_oneformer.py:661:        # TODO: (Amy)
./api/search/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:659:        # TODO: remove the redundant computation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:774:        # TODO replace this with
./api/search/.venv/lib/python3.12/site-packages/transformers/models/longformer/modeling_tf_longformer.py:1031:        # TODO: This code is most likely not very efficient and should be improved
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:394:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:593:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:604:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:648:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:705:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:726:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/speech_to_text/modeling_tf_speech_to_text.py:1415:        # TODO (Joao): investigate why Speech2Text has numerical issues in XLA generate
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:317:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5.py:40:# TODO(PVP) - this should be removed in Transformers v5
./api/search/.venv/lib/python3.12/site-packages/transformers/models/t5/tokenization_t5_fast.py:38:# TODO(PVP) - this should be removed in Transformers v5
./api/search/.venv/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1942:            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:188:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:404:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:448:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:522:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/olmoe/modeling_olmoe.py:865:# TODO: re-enable check: Copied from transformers.models.llama.modeling_llama.LlamaModel with Llama->Olmoe
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:58:# TODO: Could have better fused kernels depending on scaling, dropout and head mask.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:284:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:521:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:636:# TODO - (Amy) make compatible with other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:659:# TODO - (Amy) make compatible with other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1039:    # TODO (Amy) - update to use `rescale_factor` instead of `scale`
./api/search/.venv/lib/python3.12/site-packages/transformers/models/detr/image_processing_detr.py:1500:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:475:        # TODO find a better way of exposing other arguments
./api/search/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:495:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/data2vec/modeling_data2vec_audio.py:624:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:601:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:730:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1560:        >>> # TODO: Add full pretraining example
./api/search/.venv/lib/python3.12/site-packages/transformers/models/unispeech/modeling_unispeech.py:1597:        # TODO(PVP) - add negative sampling & loss computation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:400:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:411:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:450:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:508:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:530:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoeshared/modeling_granitemoeshared.py:783:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_idefics.py:1261:                # TODO(ls): Add cross attention values to respective lists
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics/modeling_tf_idefics.py:1434:                # TODO(ls): Add cross attention values to respective lists
./api/search/.venv/lib/python3.12/site-packages/transformers/models/groupvit/modeling_tf_groupvit.py:2127:        # TODO: As is this currently fails with saved_model=True, because
./api/search/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:451:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/siglip/modeling_siglip.py:543:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:107:# TODO:
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fsmt/modeling_fsmt.py:1247:            # TODO(SS): do we need to ignore pad tokens in labels?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:188:            # TODO: figure this case out.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/marian/configuration_marian.py:288:            # TODO: test this.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bloom/configuration_bloom.py:156:            # TODO: how to do that better?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py:64:    TODO @thomasw21 this doesn't work as nicely due to the masking strategy, and so masking varies slightly.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bloom/tokenization_bloom_fast.py:113:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./api/search/.venv/lib/python3.12/site-packages/transformers/models/starcoder2/modeling_starcoder2.py:305:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/perceiver/tokenization_perceiver.py:182:    # TODO @ArthurZ refactor this as well....
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:193:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:523:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:534:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:573:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout [batch_size, sequence_length, num_heads, head_dim]. We would need to refactor the KV cache
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:631:# TODO cyril: modular
./api/search/.venv/lib/python3.12/site-packages/transformers/models/granitemoe/modeling_granitemoe.py:653:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:153:        # TODO @ArthurZucker this can only work one way for now, to update later-on. Tests should also properly
./api/search/.venv/lib/python3.12/site-packages/transformers/models/cohere/tokenization_cohere_fast.py:502:    # TODO ArthurZ let's rely on the template processor instead, refactor all fast tokenizers
./api/search/.venv/lib/python3.12/site-packages/transformers/models/cohere/modeling_cohere.py:111:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:505:            # TODO(Patrick): if we train more RAG models, I want to put the input first to take advantage of effortless truncation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/rag/retrieval_rag.py:506:            # TODO(piktus): better handling of truncation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/xlm/tokenization_xlm.py:415:            # TODO: make sure we are using `FacebookAI/xlm-mlm-enro-1024`, since XLM-100 doesn't have this step
./api/search/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_tf_hubert.py:431:        # TODO Matt: Assigning to attributes in call() is deeply sinful in TensorFlow, as it should be idempotent.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:569:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/hubert/modeling_hubert.py:698:            # TODO: Improve this warning with e.g. `model.config._attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:331:        # TODO: Should be removed once Flash Attention for RoCm is bumped to 2.1.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:385:        # TODO: These transpose are quite inefficient but Flash Attention requires the layout
./api/search/.venv/lib/python3.12/site-packages/transformers/models/dbrx/modeling_dbrx.py:458:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fuyu/image_processing_fuyu.py:579:        # TODO refer to https://github.com/ArthurZucker/transformers/blob/0f0a3fe5ca5697ee58faeb5b53f049af720b5e98/src/transformers/models/vit_mae/modeling_vit_mae.py#L871
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:120:        # TODO Remove this logic in a subsequent release since subsequences are not supported.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:353:        self.max_position_embeddings = 16384  # TODO Can't derive this from model files: where to set it?
./api/search/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:375:            self.register_buffer("inv_freq", inv_freq, persistent=False)  # TODO joao: may break with compilation
./api/search/.venv/lib/python3.12/site-packages/transformers/models/phimoe/modeling_phimoe.py:445:            # TODO: Improve this warning with e.g. `model.config.attn_implementation = "manual"` once this is implemented.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:526:            qlen: TODO Lysandre didn't fill
./api/search/.venv/lib/python3.12/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py:527:            mlen: TODO Lysandre didn't fill
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:526:        # TODO find a better way of exposing other arguments
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py:1123:            # TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36
./api/search/.venv/lib/python3.12/site-packages/transformers/models/deformable_detr/image_processing_deformable_detr.py:1525:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/image_processing_conditional_detr.py:1527:    # POSTPROCESSING METHODS - TODO: add support for other frameworks
./api/search/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:489:        # TODO find a better way of exposing other arguments
./api/search/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:272:        # Tokenizer arguments TODO: eventually tokenizer and models should share the same config
./api/search/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:396:            # TODO (joao): this should be an exception if the user has modified the loaded config. See #33886
./api/search/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_eetq.py:62:                # TODO: Update message once eetq releases a fix
./api/search/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:317:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./api/search/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_awq.py:125:            model._awq_is_fused = True  # TODO: consider storing this flag in model.config instead
./api/search/.venv/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_8bit.py:274:        # TODO: consider bringing replace_with_bnb_linear() code from ..integrations/bitsandbyter.py to here
./api/search/.venv/lib/python3.12/site-packages/mdurl/_parse.py:168:            # v0.12 TODO(isaacs): This is not quite how Chrome does things.
./api/search/.venv/lib/python3.12/site-packages/markdown_it/rules_core/replacements.py:26:# TODO:
./api/search/.venv/lib/python3.12/site-packages/markdown_it/parser_inline.py:96:            # TODO: remove this workaround when CM standard will allow nested links
./api/search/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py:25:        self.debug = debug  # TODO: We ought to handle 404 cases if debug is set.
./api/search/.venv/lib/python3.12/site-packages/joblib/numpy_pickle_utils.py:237:    TODO python2_drop: is it still needed? The docstring mentions python 2.6
./api/search/.venv/lib/python3.12/site-packages/joblib/pool.py:49:    TODO python2_drop : can this be simplified ?
./api/search/.venv/lib/python3.12/site-packages/joblib/memory.py:44:# TODO: The following object should have a data store object as a sub
./api/search/.venv/lib/python3.12/site-packages/joblib/memory.py:53:# TODO: Same remark for the logger, and probably use the Python logging
./api/search/.venv/lib/python3.12/site-packages/joblib/memory.py:583:            # TODO (pierreglaser): do the same with get_func_name?
./api/search/.venv/lib/python3.12/site-packages/joblib/_store_backends.py:209:                        # TODO(1.5) turn into error
./api/search/.venv/lib/python3.12/site-packages/joblib/_memmapping_reducer.py:164:        # TODO: check scipy sparse datastructure if scipy is installed
./api/search/.venv/lib/python3.12/site-packages/joblib/parallel.py:2054:            # TODO: this iterator should be batch_size * n_jobs
./api/search/.venv/lib/python3.12/site-packages/joblib/test/common.py:18:# TODO straight removal since in joblib.test.common?
./api/search/.venv/lib/python3.12/site-packages/joblib/test/common.py:44:# TODO: Turn this back on after refactoring yield based tests in test_hashing
./api/search/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:146:    # TODO: test that the cache related to the function cache persists across
./api/search/.venv/lib/python3.12/site-packages/joblib/test/test_memory.py:170:            # TODO when Python 3.11 is the minimum supported version, use
./api/search/.venv/lib/python3.12/site-packages/joblib/compressor.py:235:    TODO python2_drop: is it still needed since we dropped Python 2 support A
./api/search/.venv/lib/python3.12/site-packages/joblib/externals/cloudpickle/cloudpickle.py:1342:        # TODO: decorrelate reducer_override (which is tied to CPython's
./api/search/.venv/lib/python3.12/site-packages/joblib/externals/loky/_base.py:20:# TODO investigate why using `concurrent.futures.Future` directly does not
./api/search/.venv/lib/python3.12/site-packages/joblib/externals/loky/backend/synchronize.py:11:# TODO: investigate which Python version is required to be able to use
./api/search/.venv/lib/python3.12/site-packages/joblib/func_inspect.py:168:        # TODO: Maybe add a warning here?
./api/search/.venv/lib/python3.12/site-packages/rich/text.py:562:        # TODO: This is a little inefficient, it is only used by full justify
./api/search/.venv/lib/python3.12/site-packages/boto3/resources/factory.py:586:                    # TODO: Make this configurable in the future?
./api/search/.venv/lib/python3.12/site-packages/boto3/resources/response.py:151:        # TODO: Remove the '$' check after JMESPath supports it
./api/search/.venv/lib/python3.12/site-packages/dateutil/rrule.py:1182:                    # TODO: Check -numweeks for next year.
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:55:# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:265:                ("Tue", "Tuesday"),     # TODO: "Tues"
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:267:                ("Thu", "Thursday"),    # TODO: "Thurs"
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:272:              ("Feb", "February"),      # TODO: "Febr"
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:291:    # TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:777:                                # TODO: not hit in tests
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:815:                    # TODO: check that l[i + 1] is integer?
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:823:                        min_offset = int(l[i + 3])  # TODO: Check that l[i+3] is minute-like?
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:910:                # TODO: Check if res attributes already set.
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:934:                # TODO: checking that hour/minute/second are not
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:941:            value = self._to_decimal(tokens[idx + 2])  # TODO: try/except for this?
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1032:            # TODO: Are we sure this is the right condition here?
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1100:        # TODO: Every usage of this function sets res.second to the return
./api/search/.venv/lib/python3.12/site-packages/dateutil/parser/_parser.py:1112:        # TODO: Is this going to admit a lot of false-positives for when we
./api/search/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:25:    except IOError as e:  # TODO  switch to FileNotFoundError?
./api/search/.venv/lib/python3.12/site-packages/dateutil/zoneinfo/__init__.py:76:# TODO: Remove after deprecation period.
./api/search/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:839:            # TODO: What could we test if loss.approx_hessian?
./api/search/.venv/lib/python3.12/site-packages/sklearn/_loss/tests/test_loss.py:874:                # TODO: What could we test if loss.approx_hessian?
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_plotting.py:167:        # TODO(1.9): Remove deprecated **kwargs
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:258:    # TODO: test with intercept
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:259:    # TODO: test with multiple responses
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:789:            TODO(1.8): remove return value
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:831:    # TODO(1.8): remove generate_only
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:1117:        # TODO There are a few errors in SearchCV with array-api-strict because
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3454:    # TODO: find out why PLS and CCA fail. RANSAC is random
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3795:        # TODO(devtools): this should be a separate check.
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/estimator_checks.py:3827:                    # TODO(devtools): separately check that the constructor doesn't
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:499:# TODO(devtools): allow third-party developers to pass test specific params to checks
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:501:    # TODO(devtools): check that function names here exist in checks for the estimator
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:565:    # TODO(1.9) simplify when averaged_inverted_cdf is the default
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:604:            # TODO: dual=True is a stochastic solver: we cannot rely on
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:824:    # TODO(devtools): enable this behavior for third party estimators as well
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:853:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:862:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:871:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:880:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:893:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:902:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:941:        # TODO: investigate failure see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:950:        # TODO: investigate failure see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:983:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:992:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1001:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1015:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1027:        # TODO: replace by a statistical test when _dual=True, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1039:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1048:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1057:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1067:        # TODO: fix sample_weight handling of this estimator when probability=False
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1068:        # TODO: replace by a statistical test when probability=True
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1081:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1095:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1104:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1126:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1135:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1148:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1157:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1179:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1188:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1197:        # TODO: replace by a statistical test, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1229:        # TODO: fix sample_weight handling of this estimator when probability=False
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1230:        # TODO: replace by a statistical test when probability=True
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1240:        # TODO: fix sample_weight handling of this estimator, see meta-issue #16298
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1258:# TODO: remove when scipy min version >= 1.11
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1285:        # TODO: remove when scipy min version >= 1.16
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:35:# TODO: We can consider removing the containers and importing
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:58:# TODO: Remove when SciPy 1.11 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:71:# TODO: Remove when Scipy 1.12 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:84:# TODO : remove this when required minimum version of scipy >= 1.9.0
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:116:# TODO: Fuse the modern implementations of _sparse_min_max and _sparse_nan_min_max
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:224:# TODO: Adapt when Pandas > 2.2 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:238:# TODO: remove when SciPy 1.12 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:285:# TODO: remove when SciPy 1.12 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:355:# TODO: Remove when Scipy 1.12 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:200:    # TODO(1.9) remove UserList when the force_int_remainder_cols param
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:315:        # TODO: we should probably use _is_pandas_df_or_series(X) instead but:
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_indexing.py:372:            # TODO(1.3): check if the warning is still raised or remove the filter.
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:22:# TODO: complete __all__
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:572:    # TODO: Update to use `__array_namespace__info__()` from array-api v2023.12
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:673:    # TODO: Remove this once https://github.com/scipy/scipy/issues/21736 is fixed
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:682:    # TODO: refactor once nan-aware reductions are standardized:
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:702:    # TODO: refactor once nan-aware reductions are standardized:
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:722:    # TODO: refactor once nan-aware reductions are standardized:
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:850:    # TODO: once sufficiently adopted, we might want to instead rely on the
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:986:    # TODO: update if bincount is ever adopted in a future version of the standard:
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_testing.py:1373:        # TODO: remove when pyamg > 5.0.1
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/optimize.py:95:        # TODO: It seems that the new check for the sum of absolute gradients above
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:654:    # TODO: Remove when the minimum version of SciPy supported is 1.12
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2408:        # TODO: remove the pandas-specific branch once the minimum supported
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_extmath.py:226:    # more accurate but slow (TODO find realistic settings here)
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_plotting.py:217:# TODO(1.9) : Remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:24:# TODO: add this estimator into the _mocking module in a further refactoring
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_validation.py:2338:# TODO(1.8): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:40:# TODO(1.8): Update when implementing __sklearn_tags__ is required
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_tags.py:92:# TODO(1.8): Update this test to check for errors
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_array_api.py:297:# TODO: add cupy to the list of libraries once the following upstream issue
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:127:# TODO(1.8): remove force_all_finite and change the default value of ensure_all_finite
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:251:# TODO(1.8): Remove this function
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:327:        # TODO(1.8): turn the warning into an error
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/stats.py:116:# TODO: refactor to do the symmetrisation inside _weighted_percentile to avoid
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:292:        # TODO(1.9): remove and switch to quantile_method="averaged_inverted_cdf"
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:360:                    # TODO: make _weighted_percentile and
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2351:        # TODO: This should be refactored because binarize also calls
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:480:    ## TODO: change to averaged inverted cdf, but that means we only get bin
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_discretization.py:519:    # TODO this check is redundant with common checks and can be removed
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:957:        # TODO: Remove this condition, once scipy 1.10 is the minimum version.
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1120:            # TODO: Remove this conditional error when the minimum supported version of
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/_polynomial.py:1144:            # TODO: Remove ones scipy 1.10 is the minimum version. See comments above.
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:108:    # TODO: Use loss.fit_intercept_only where appropriate instead of
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:257:            # TODO: Multiply here by learning rate instead of everywhere else.
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:449:        # TODO: Without oob, i.e. with self.subsample = 1.0, we could call
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:672:        y = column_or_1d(y, warn=True)  # TODO: Is this still required?
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_base.py:23:    # TODO(SLEP6): remove if-condition for unrouted sample_weight when metadata
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:116:    # TODO: (slep6) remove if condition for unrouted sample_weight when metadata
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_bagging.py:155:        # TODO(SLEP6): remove if condition for unrouted sample_weight when metadata
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py:140:        # TODO: consider always using platform agnostic dtypes for fitted
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:15:# TODO(1.8) remove the filterwarnings decorator
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:107:        # TODO: We are not entirely satisfied with this lax comparison, but the root
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:125:# TODO(1.8) remove the filterwarnings decorator
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py:202:# TODO(1.8) remove the filterwarnings decorator
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:90:    # TODO: Ideally this should be computed in parallel over the leaves using something
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:125:    TODO: in the future, we could explore the possibility to extend the scorer
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:572:            # TODO: remove when PDP supports sample weights
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:682:                # TODO: incorporate sample_weight in sampling here, as well as
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1086:        # TODO: incorporate sample_weights here in `resample`
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:2225:        # TODO: This could be done in parallel
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py:327:        # TODO: complexity is O(n_categorical_features * 255). Maybe this is
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:490:    # TODO(1.8): remove "algorithm" entry
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:745:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py:1129:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_weight_boosting.py:635:# TODO(1.8): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/isotonic.py:164:        # TODO: remove this branch when Scipy 1.12 is the minimum supported version
./api/search/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:655:                # TODO: incorporate sample_weight in sampling here.
./api/search/.venv/lib/python3.12/site-packages/sklearn/neural_network/_base.py:211:    # TODO: Decide what to do with the term `xlogy(y_true, y_true) - y_true`. For now,
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:330:            # TODO: systematize this mapping of metric for
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:338:                # TODO: Implement efficient multi-output solution
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:363:                    # TODO: adapt the heuristic for `strategy="auto"` for
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:36:# TODO: implement a brute force version for testing purposes
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:37:# TODO: create a density estimation base class?
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/_kde.py:330:        # TODO: implement sampling for other valid kernel shapes
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:378:        # TODO: also test radius_neighbors, but requires different assertion
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1623:# TODO: remove when NearestNeighbors methods uses parameter validation mechanism
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:1727:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2253:# TODO: Remove ignore_warnings when minimum supported SciPy version is 1.17
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_neighbors.py:2488:    # TODO: if score is refactored to evaluate models for other scoring
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_lof.py:252:    # TODO: compare results on dense and sparse data as proposed in:
./api/search/.venv/lib/python3.12/site-packages/sklearn/calibration.py:329:            # TODO(1.8): Remove this code branch and cv='prefit'
./api/search/.venv/lib/python3.12/site-packages/sklearn/calibration.py:863:        # TODO: Remove casting to np.float64 when minimum supported SciPy is 1.11.2
./api/search/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:658:    # TODO(1.9): Remove base_estimator
./api/search/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:676:    # TODO(1.8): This is a temporary getter method to validate input wrt deprecation.
./api/search/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:791:            # TODO: remove this condition check when the minimum supported scipy version
./api/search/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1037:    # TODO(1.9): Remove base_estimator from __init__
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:372:        # TODO: for Scipy <= 1.10, `isspmatrix(X)` returns `True` for sparse arrays.
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:1060:# TODO this class should fit on either p-values or scores,
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:225:    # TODO(1.8) remove this property
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:791:    # TODO(1.8): remove `groups` from the signature after deprecation cycle.
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:377:                # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_from_model.py:461:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/_optics.py:621:    # TODO: handle working_memory somehow?
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:772:                # TODO: Support np.nan in Cython implementation for precomputed
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:834:                # TODO: Benchmark KD vs Ball Tree efficiency
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/_hdbscan/hdbscan.py:938:                # TODO: Implement weighted argmin PWD backend
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_birch.py:245:# TODO(1.8): Remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:30:# TODO: AffinityPropagation must preserve dtype for its fitted attributes
./api/search/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:114:    # TODO: we should handle missing values (i.e. `np.nan`) specifically and store them
./api/search/.venv/lib/python3.12/site-packages/sklearn/inspection/_partial_dependence.py:716:            # TODO(1.9): raise a ValueError instead.
./api/search/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:682:    # TODO: extend to HistGradientBoosting once sample_weight is supported
./api/search/.venv/lib/python3.12/site-packages/sklearn/inspection/tests/test_partial_dependence.py:705:    # TODO: remove/fix when PDP supports HGBT with sample weights
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:510:    # TODO(1.8): Remove this attribute
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:583:    # TODO(1.8): Remove this attribute
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:659:    # TODO(1.8): Remove this attribute
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:1012:    # TODO(1.8): Remove this attribute
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:1062:    # TODO(1.8): Remove this attribute
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:1202:    # TODO(1.8): Remove this check
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:1242:    # TODO(1.8): Remove this check
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:1284:    # TODO(1.8): Remove this check
./api/search/.venv/lib/python3.12/site-packages/sklearn/base.py:1309:    # TODO(1.8): Remove this check
./api/search/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:551:    # TODO We can do this cheaper; sorted_indices copies the whole matrix.
./api/search/.venv/lib/python3.12/site-packages/sklearn/datasets/_svmlight_format_io.py:570:        # TODO: simplify interfaces and implementations in _svmlight_format_fast.pyx.
./api/search/.venv/lib/python3.12/site-packages/sklearn/datasets/_arff_parser.py:67:    # TODO: improve for efficiency
./api/search/.venv/lib/python3.12/site-packages/sklearn/datasets/_openml.py:341:        # TODO: feature request OpenML.
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:640:        # TODO (1.8): remove this once the deprecation is removed. In the meantime,
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:654:            # TODO (1.8): remove this once the deprecation is removed to keep only
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:663:            # TODO (1.8): remove this once the deprecation is removed to keep only
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/_iterative.py:684:                # TODO (1.8): remove this `if` branch once the following issue is
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:468:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/_base.py:571:            # TODO(1.8): Remove FutureWarning and add `np.nan` as a statistic
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:13:    # TODO: remove this check once the estimator is no longer experimental.
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/__init__.py:19:# TODO: remove this check once the estimator is no longer experimental.
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:413:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:429:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:459:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:495:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1550:# TODO (1.8): check that `keep_empty_features=False` drop the
./api/search/.venv/lib/python3.12/site-packages/sklearn/impute/tests/test_impute.py:1761:        # TODO(1.8): Remove the condition and still call getattr(imputer, method)(X)
./api/search/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1259:        TODO: Remove when ``set_config(enable_metadata_routing=False)`` is no
./api/search/.venv/lib/python3.12/site-packages/sklearn/compose/tests/test_column_transformer.py:975:# TODO(1.9): remove this test
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:50:    TODO(1.8): remove this context manager and replace with check_is_fitted.
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:406:    # TODO(1.8): Remove this property
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:780:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:896:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:943:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:981:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1027:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1082:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1127:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1178:        # TODO(1.8): Remove the context manager and use check_is_fitted(self)
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1902:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1951:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:2024:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:446:                # TODO: tree shouldn't need this in this case
./api/search/.venv/lib/python3.12/site-packages/sklearn/tree/_classes.py:624:                # TODO: the tree shouldn't need this param
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:170:        # TODO(slep006): remove when metadata routing is the only way
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:239:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:251:        # TODO(slep006): remove when metadata routing is the only way
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:296:        # TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:456:                # TODO (1.8): scoring="max_error" has been deprecated in 1.6,
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:498:        # TODO(slep006): remove when metadata routing is the only way
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:738:# TODO (1.8): remove in 1.8 (scoring="max_error" has been deprecated in 1.6)
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2200:    # TODO(1.9): When `raise_warning` is removed, the following changes need to be made:
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/_supervised.py:1256:    # TODO(1.9): remove the sparse parameter
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/cluster/tests/test_supervised.py:515:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:398:    TODO: use a float64 accumulator in row_norms to avoid the latter.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1972:        # TODO: do it also for other norms.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:80:            # TODO: implement a stable simultaneous_sort.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:128:                # TODO: support CSR matrices without non-zeros elements
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:131:                # TODO: support CSR matrices with int64 indices and indptr
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:476:            # TODO: implement Euclidean specialization using GEMM.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:644:            # TODO: implement Euclidean specialization using GEMM.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1398:    # TODO: remove when enable_metadata_routing is deprecated
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_score_objects.py:1656:# TODO(1.8): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_classification.py:762:# TODO(1.9): remove test
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:366:# TODO: Handle multi_class metrics that has a labels argument as well as a
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_common.py:975:            # TODO those metrics doesn't support string label yet
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:179:        # TODO Fix manhattan_distances to preserve dtype.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:190:        # TODO Fix manhattan_distances to preserve dtype.
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise.py:1672:# TODO(1.8): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:709:    # TODO: support CSR matrices without non-zeros elements
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:716:    # TODO: support CSR matrices with int64 indices and indptr
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:913:    # TODO: introduce assertions on UserWarnings once the Euclidean specialisation
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:80:            # TODO: Inspect slight numerical discrepancy
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_dist_metrics.py:164:            # TODO: Inspect slight numerical discrepancy
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/roc_curve.py:581:        # TODO(1.9): remove after the end of the deprecation period of `y_pred`
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:325:# TODO(1.9): Remove in 1.9
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:334:# TODO(1.9): Remove in 1.9
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:926:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_roc_curve_display.py:939:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_plot/tests/test_common_curve_display.py:167:# TODO: remove this test once classes moved to using `name` instead of
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:229:        # TODO: if alpha=0 check that X is not rank deficient
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:401:        # TODO: Adapt link to User Guide in the docstring, once
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:405:        # TODO: make D^2 a score function in module metrics (and thereby get
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/_newton_solver.py:398:            # TODO:
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:47:# TODO: bayesian_ridge_regression and bayesian_regression_ard
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:154:        Always an array of ones. TODO: refactor the code base to make it
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:205:# TODO: _rescale_data should be factored into _preprocess_data.
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_base.py:832:            # TODO: instead of warning and recomputing, we could just center
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:16:    # TODO: This "sandwich product" is the main computational bottleneck for solvers
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1251:        # TODO(1.8) remove multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1362:        # TODO: Refactor this to avoid joblib parallelism entirely when doing binary
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1923:        # TODO(1.8) remove multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:813:        # TODO: better names for these variables: z
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:870:                # TODO: this could be updated
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:882:                # Cov_n = Cov_j + x_j * X + increment(betas) TODO:
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:888:                # TODO: this could be updated
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1685:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1714:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1732:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_coordinate_descent.py:1750:# TODO(1.9): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_theil_sen.py:298:# TODO(1.8): Remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_common.py:66:        # TODO: FIx SAGA which fails badly with sample_weights.
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:150:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:202:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:254:# TODO(1.8): remove whole test with deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:279:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:619:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:705:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1306:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1350:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1486:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1746:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1794:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1833:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1963:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2137:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2182:# TODO(1.8): remove filterwarnings after the deprecation of multi_class
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2360:# TODO(1.8): remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:2427:# TODO(1.8): check for an error instead
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_sag.py:490:    # TODO: uncomment when sparse Ridge with intercept will be fixed (#4710)
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:29:# TODO: use another dataset that has multiple drops
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:120:# TODO: remove warning filter when numpy min version >= 2.0.0
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_least_angle.py:132:# TODO: remove warning filter when numpy min version >= 2.0.0
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1500:        # TODO(1.9): remove "warn" and None options.
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1607:        # TODO(1.9): remove n_alphas and alphas={"warn", None}; set alphas=100 by
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_omp.py:1065:            # TODO(SLEP6): remove when metadata routing cannot be disabled.
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:164:        # TODO(1.8) remove None option
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:166:        # TODO(1.8) remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:195:        # TODO(1.8) remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:206:        # TODO(1.8): remove and only keep clone(self.estimator)
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:217:        # TODO(1.8) remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/_self_training.py:622:        # TODO(1.8): remove the condition check together with base_estimator
./api/search/.venv/lib/python3.12/site-packages/sklearn/semi_supervised/tests/test_self_training.py:349:# TODO(1.8): remove in 1.8
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:60:    # TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:86:# TODO(SLEP6): To be removed when set_config(enable_metadata_routing=False) is not
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:364:                # TODO(SLEP6): also pass metadata to the predict method for
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1182:                # TODO(SLEP6): also pass metadata for the predict method.
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1637:                # TODO(SLEP6): also pass metadata to the predict method for
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1982:                # TODO(SLEP6): also pass metadata to the predict method for
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:480:    # TODO(1.8) remove this property
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:862:        # TODO(slep006): remove when metadata routing is the only way
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:46:    # TODO: remove this check once the estimator is no longer experimental.
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/__init__.py:90:# TODO: remove this check once the estimator is no longer experimental.
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_validation.py:2471:# TODO(1.8): remove `learning_curve`, `validation_curve` and `permutation_test_score`.
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:1117:    # Test the IID parameter  TODO: Clearly this test does something else???
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:192:# TODO(1.9): change default `n_init` to 1, see PR #31117
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/_mds.py:430:# TODO(1.9): change default `n_init` to 1, see PR #31117
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:341:    # TODO: compare results on dense and sparse data as proposed in:
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_t_sne.py:1068:        # TODO: re-enable this test if/when `manhattan_distances` is refactored to
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:122:# TODO(1.9): remove warning filter
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:136:# TODO(1.9): remove warning filter
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:175:# TODO(1.9): remove warning filter
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:202:# TODO(1.9): remove warning filter
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_mds.py:225:# TODO(1.9): delete this test
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:48:    # TODO: rewrite this test to make less sensitive to the random seed,
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_locally_linear.py:121:    # TODO check that it actually does something useful
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_spectral_embedding.py:107:# TODO: investigate why this test is seed-sensitive on 32-bit Python
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:148:    # TODO check that it actually does something useful
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/tests/test_isomap.py:234:    # TODO: compare results on dense and sparse data as proposed in:
./api/search/.venv/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:94:        # TODO(jjerphan): Once SciPy 1.11.3 is the minimum supported version, use
./api/search/.venv/lib/python3.12/site-packages/sklearn/conftest.py:212:        # TODO: configure numpy to output scalar arrays as regular Python scalars
./api/search/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:315:            # TODO: add keyword copy to copy on demand
./api/search/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_helper.c:158:     * TODO: does this provoke memory leaks (we just malloc'ed them)?
./api/search/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:84: * TODO: precomputed kernel.
./api/search/.venv/lib/python3.12/site-packages/sklearn/svm/src/libsvm/libsvm_sparse_helper.c:386: * TODO: merge in the cython layer
./api/search/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_svm.py:4:TODO: remove hard coded numerical results when possible
./api/search/.venv/lib/python3.12/site-packages/sklearn/svm/tests/test_bounds.py:17:# TODO(1.8): remove filterwarnings after the deprecation of liblinear multiclass
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_metaestimators.py:279:# TODO: remove data validation for the following estimators
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstrings.py:191:    # TODO: this detection can be improved. Currently we assume that we have
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:867:# TODO(1.9):  remove when deprecated `base_estimator` is removed
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:124:# TODO(1.8): remove test when generate_only is removed
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:229:                # TODO: FIX MLP to not check validation set during MLP
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_common.py:272:# TODO: As more modules support get_feature_names_out they should be removed
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:2063:# TODO(1.8): change warning to checking for NotFittedError
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:308:    # TODO(1.8): Remove cv="prefit" options here and the @ignore_warnings of the test
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_calibration.py:1119:    # TODO(1.8): remove me once the deprecation period is over.
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_metadata_routing.py:912:    # TODO: these test classes can be moved to sklearn.utils._testing once we
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_base.py:271:# TODO(1.8): Remove this test when the deprecation is removed
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:203:        # TODO(devtools): use _tested_estimators instead of all_estimators in the
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:223:    # TODO(1.9) remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_docstring_parameters.py:227:    # TODO(1.9) remove
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:171:        # TODO: Does this depend on device?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/cupy/_info.py:233:        # TODO: Does this depend on device?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:63:    # TODO: Should we reject ndarray subclasses?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:95:    # TODO: Should we reject ndarray subclasses?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:123:    # TODO: Should we reject ndarray subclasses?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:238:    # TODO: Account for other backends.
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:580:            # TODO: Support Python scalars?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:793:        # TODO: What if our array is on the GPU already?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:277:    # TODO: The standard is not clear about what should happen when x.ndim == 0.
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_aliases.py:334:    # TODO: np.clip has other ufunc kwargs
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:36:# TODO: use the QR wrapper once dask
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/linalg.py:60:    # TODO: can't avoid computing U or V for dask
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:67:    # TODO: respect device keyword?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:97:    # TODO: respect device keyword?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:168:    # TODO: respect device keyword?
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/dask/array/_aliases.py:229:    # TODO: This won't handle dask unknown shapes
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_at.py:21:    # TODO import from typing (requires Python >=3.11)
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_utils/_helpers.py:20:    # TODO import from typing (requires Python >=3.13)
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/testing.py:20:    # TODO import override from typing (requires Python >=3.12)
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:564:        # TODO: remove the following two lines when scikit-learn only depends
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:617:            # TODO: remove the following two lines when scikit-learn only
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:778:        # TODO: update this code to either:
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:142:        # TODO: Make verbosity argument for Lasso?
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/_dict_learning.py:158:            # TODO: move this handling (which is currently too broad)
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/_lda.py:462:        # TODO: make Parallel._effective_n_jobs public instead?
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:617:    # TODO: explain what this is testing
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_pca.py:634:    # TODO: explain what this is testing
./api/search/.venv/lib/python3.12/site-packages/sklearn/decomposition/tests/test_nmf.py:992:        # TODO: use the provided W when init="custom".
./api/search/.venv/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:116:        # TODO: Explore the choice of using bincount + add.at as it seems sub optimal
./api/search/.venv/lib/python3.12/site-packages/fsspec/asyn.py:347:        # TODO: implement on_error
./api/search/.venv/lib/python3.12/site-packages/fsspec/asyn.py:511:        # TODO: on_error
./api/search/.venv/lib/python3.12/site-packages/fsspec/asyn.py:998:    # TODO: readahead might still be useful here, but needs async version
./api/search/.venv/lib/python3.12/site-packages/fsspec/generic.py:327:        # TODO: special case for one FS being local, which can use get/put
./api/search/.venv/lib/python3.12/site-packages/fsspec/generic.py:328:        # TODO: special case for one being memFS, which can use cat/pipe
./api/search/.venv/lib/python3.12/site-packages/fsspec/utils.py:302:    # TODO: allow length to be None and read to the end of the file?
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:78:            # TODO: tarfile already implements compression with modes like "'r:gz'",
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:92:        # TODO: load and set saved index, if exists
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/tar.py:101:        # TODO: save index to self.index_store here, if set
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/cached.py:322:            # TODO: action where partial file exists in read-only cache
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/smb.py:394:        # TODO: use transaction support in SMB protocol
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/cache_metadata.py:158:                # TODO: consolidate blocks here
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/http.py:104:        # TODO: Maybe rename `self.kwargs` to `self.request_options` to make
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:147:        # TODO: derive fs from `root`
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:473:        # TODO: only save needed columns
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:546:        # TODO: only clear those that we wrote to?
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:748:            # TODO: warning here, since this can be very expensive?
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:884:        # TODO: if references is lazy, pre-fetch all paths in batch before access
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/reference.py:985:        # TODO: we make dircache by iterating over all entries, but for Spec >= 1,
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:352:    # TODO: if all incoming paths were posix-compliant then separator would
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py:393:                # TODO: check if path is writable?
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:105:        # TODO: encoding from headers
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:883:    # TODO: not allowed in JS
./api/search/.venv/lib/python3.12/site-packages/fsspec/implementations/http_sync.py:896:    # TODO:
./api/search/.venv/lib/python3.12/site-packages/fsspec/spec.py:493:        # TODO: allow equivalent of -name parameter
./api/search/.venv/lib/python3.12/site-packages/fsspec/compression.py:13:# TODO: files should also be available as contexts
./api/search/.venv/lib/python3.12/site-packages/fsspec/caching.py:94:        # TODO: use rich for better formatting
./api/search/.venv/lib/python3.12/site-packages/fsspec/caching.py:502:        # TODO: only set start/end after fetch, in case it fails?
./api/search/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:214:    # TODO allow pos to be None and use a nice TikZ default
./api/search/.venv/lib/python3.12/site-packages/networkx/drawing/nx_latex.py:277:        # TODO -- handle bending of multiedges
./api/search/.venv/lib/python3.12/site-packages/networkx/drawing/nx_pylab.py:2499:        # TODO should this be list or array (as in a numpy array)?
./api/search/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:792:            Ai = A.getrowview(i).toarray()  # TODO: revisit w/ sparse 1D container
./api/search/.venv/lib/python3.12/site-packages/networkx/drawing/layout.py:1152:    # TODO: Rm csr_array wrapper in favor of spdiags array constructor when available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:75:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/bethehessianmatrix.py:77:    # TODO: Rm csr_array wrapper when eye array creation becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:128:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:238:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:244:    # TODO: rm csr_array wrapper when spdiags can produce arrays
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:341:        # TODO: rm csr_array wrapper when spdiags creates arrays
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:344:        # TODO: rm csr_array wrapper when spdiags creates arrays
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:436:    # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:498:        # TODO: Rm csr_array wrapper when spdiags array creation becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/laplacianmatrix.py:503:            # TODO: Rm csr_array wrapper when identity array creation becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:192:        # TODO: rm csr_array wrapper when spdiags array creation becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:279:                # TODO: rm csc_array wrapping when spdiags array becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/linalg/algebraicconnectivity.py:296:                # TODO: rm csr_array wrapping when spdiags array becomes available
./api/search/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:129:    # TODO: Remove between the lines when `link` deprecation expires
./api/search/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:274:    # TODO: Remove between the lines when `link` deprecation expires
./api/search/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/tests/test_node_link.py:27:    # TODO: To be removed when signature change complete
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:463:    # TODO: csr_array
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/assortativity/tests/test_connectivity.py:138:        # TODO Is this really the intended behavior for providing a
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:94:    # TODO: csr_array
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/node_classification.py:173:    # TODO: csr_array
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/dag.py:1175:    # TODO In Python 3, this would be better as `yield from ...`.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/efficiency_measures.py:118:    # TODO This can be made more efficient by computing all pairs shortest
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/distance_regular.py:184:# TODO There is a definition for directed strongly regular graphs.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/dominating_set.py:22:# TODO Why doesn't this algorithm work for directed graphs?
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/approximation/traveling_salesman.py:805:            # TODO: this branch does not restore original_edge_weights of G!
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/clique.py:300:# TODO Should this also be not implemented for directed graphs?
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/walks.py:72:    # TODO: Use matrix_power from scipy.sparse when available
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/coloring/equitable_coloring.py:163:        # TODO: Checking whether a color has been visited can be made faster by
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/similarity.py:686:    # TODO: support DiGraph
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:111:    # TODO This can be trivially parallelized.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/centrality/reaching.py:206:    # TODO This can be trivially parallelized.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/weighted.py:1135:    # TODO This can be trivially parallelized.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:181:    # TODO This can be trivially parallelized.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:475:    # TODO This can be trivially parallelized.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:276:            # TODO - The lines between --- were unused and were thus commented
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:282:            #     # TODO Why is extra inner loop necessary?
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/matching.py:287:            # TODO Originally, this function returned a three-tuple:
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/redundancy.py:93:    # TODO This can be trivially parallelized.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/bipartite/tests/test_matching.py:110:        # TODO Assert that the vertices are the correct ones.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:124:        # TODO This can be parallelized, both in the outer loop over
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/mst.py:132:        # TODO This loop can be parallelized, to an extent (the union
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/tree/branchings.py:11:# TODO: Implement method from Gabow, Galil, Spence and Tarjan:
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/cycles.py:841:                if thisnode not in B[nextnode]:  # TODO: use set for speedup?
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/isomorphvf2.py:217:        # TODO:
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:292:        # TODO: graph and subgraph setter methods that invalidate the caches.
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:293:        # TODO: allow for precomputed partitions and colors
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/tests/test_swap.py:40:    # TODO: Rewrite function to explicitly check for impossible swaps and raise error
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:97:            # TODO: investigate https://arxiv.org/abs/1412.6466 for k=2
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/connectivity/edge_kcomponents.py:314:    # @not_implemented_for('multigraph')  # TODO: fix decor for classmethods
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/traversal/beamsearch.py:77:        # TODO The Python documentation states that for small values, it
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:19:# TODO STILL NEED TO UPDATE ALL THE DOCUMENTATION!
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:322:# TODO What is the generalization to two arguments, S and T? Does the
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/cuts.py:362:# TODO What is the generalization to two arguments, S and T? Does the
./api/search/.venv/lib/python3.12/site-packages/networkx/conftest.py:102:# TODO: The warnings below need to be dealt with, but for now we silence them.
./api/search/.venv/lib/python3.12/site-packages/networkx/generators/geometric.py:190:    # TODO Is this function just a special case of the geographical
./api/search/.venv/lib/python3.12/site-packages/networkx/generators/community.py:1034:    # TODO The original code incremented the number of iterations each
./api/search/.venv/lib/python3.12/site-packages/networkx/generators/tests/test_expanders.py:37:    # TODO The second largest eigenvalue should be smaller than a constant,
./api/search/.venv/lib/python3.12/site-packages/networkx/generators/degree_seq.py:671:    # TODO Does this need to be sorted in reverse order?
./api/search/.venv/lib/python3.12/site-packages/pynvml/nvml.py:1089:#     # TODO handle the error
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/expintegrals.py:265:            # TODO: reasonable sign of infinity
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/factorials.py:112:    # TODO: fixme, obviously
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/theta.py:926:    # TODO: write _jacobi_theta2a and _jacobi_theta3a using fixed-point
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:18:    # TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:313:        # TODO: something else is required here
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/orthogonal.py:373:    # TODO: correct evaluation at singularities
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:28:        # TODO: the integer special-casing shouldn't be necessary.
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:147:    # TODO: avoid cancellation for imaginary arguments
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:384:# TODO: do this more generically?
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:423:# TODO: could be expressed more elegantly using triple factorials
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:468:        # TODO: limits
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:521:                # TODO: asymptotic series for derivatives
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:562:        # TODO: limits
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:718:    # TODO: check that chop=True chops when and only when it should
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:757:    # TODO: check that chop=True chops when and only when it should
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:833:    TODO: this can be optimized, e.g. by reusing evaluation points.
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/bessel.py:878:                # TODO: use v <= j'_{v,1} < y_{v,1}?
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:238:# TODO: fix the interface wrt contexts
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:287:# TODO: for bernpoly and eulerpoly, ensure that all exact zeros are covered
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:385:# TODO: this should be implemented low-level
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:620:    # TODO: implement for derivatives
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/zeta.py:697:            # TODO: the following could perhaps be tidied a bit
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:11:        # Avoid division by zero in leading factors (TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:284:            # TODO: handle the all-real case more efficiently!
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:285:            # TODO: figure out how much precision is needed (exponential growth)
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:404:        # TODO: the following logic can be simplified
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:760:    # TODO: much of the following could be shared with 2F3 instead of
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:832:    # TODO: much of the following could be shared with 2F3 instead of
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1091:    # TODO: continuation
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/hypergeometric.py:1107:    # TODO: continuation
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:174:# TODO: tests; improve implementation
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:182:    # TODO: accurately eval the smaller of the real/imag parts
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:212:    # TODO: accurately eval the smaller of the real/imag part
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:257:            # TODO: this can be done *much* faster
./api/search/.venv/lib/python3.12/site-packages/mpmath/functions/functions.py:604:    # TODO: the following could be generalized into a perfect
./api/search/.venv/lib/python3.12/site-packages/mpmath/identification.py:273:        # slowly (e.g. a factor 1-10) with each step TODO: we could
./api/search/.venv/lib/python3.12/site-packages/mpmath/ctx_mp.py:306:    # TODO: add more of these, make consistent, write docstrings, ...
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:171:    (TODO: find a better solution to this problem.)
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/extrapolation.py:1969:            # TODO: we are evaluating log(1+eps) -> eps, which is
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/differentiation.py:364:    TODO: most exponents are zero, so maybe a sparse representation
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/odes.py:219:    **TODO**
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:264:            # TODO: maybe refactoring with function for divided differences
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:289:# TODO: consider raising a ValueError when there's no sign change in a and b
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:418:                # TODO: better condition (when f is very flat)
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:457:# TODO: check whether it's possible to combine it with Illinois stuff
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:503:                # TODO: better condition (when f is very flat)
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:560:            # TODO: decide not to use convergence acceleration
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:573:# TODO: add Brent
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:601:# TODO: test with user-specified jacobian matrix
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:665:            # damping step size TODO: better strategy (hard task)
./api/search/.venv/lib/python3.12/site-packages/mpmath/calculus/optimization.py:984:        if verify and norm(f(*xl))**2 > tol: # TODO: better condition?
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:99:# TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:136:                if current > biggest: # TODO: what if equal?
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:218:                    # TODO: necessary to check also b?
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:239:            raise RuntimeError("need n*n matrix") # TODO: really?
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/linalg.py:372:    # TODO: implement this
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:4:# TODO: interpret list as vectors (for multiplication)
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/matrices.py:208:        COMMENT: TODO: the above "doctest:+SKIP" may be removed as soon as we
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:3:# TODO: should use diagonalization-based algorithms
./api/search/.venv/lib/python3.12/site-packages/mpmath/matrices/calculus.py:14:        TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/math2.py:207:        # TODO: sinpi
./api/search/.venv/lib/python3.12/site-packages/mpmath/math2.py:221:        # TODO: sinpi
./api/search/.venv/lib/python3.12/site-packages/mpmath/math2.py:359:# TODO: could implement complex erf and erfc here. Need
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:273:    # TODO: many more tests
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:404:    # TODO: need many more tests
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/torture.py:27:TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/test_matrices.py:57:    # TODO remove exec() wrapper as soon as we drop support for Python <= 3.5
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/test_gammazeta.py:599:    # TODO: more tests for polyexp
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/test_linalg.py:1:# TODO: don't use round
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/runtests.py:57:# TODO: add a flag for this
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:54:TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:199:        # TODO: when there are several real parameters and just a few complex
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:332:# TODO: mpf_erf should call mpf_erfc when appropriate (currently
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:355:        # TODO: interval rounding
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:617:            # TODO: could return finite imaginary value at -inf
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:911:# TODO: for extremely large x, we could use an asymptotic
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:914:# TODO: recompute at higher precision if the fixed-point mantissa
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1046:    TODO:
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libhyper.py:1081:    # TODO: for |x| << 1/2, one could use fall back to
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:4:TODO: rename, cleanup, perhaps move the gmpy wrapper code
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:129:# TODO: speed up for bases 2, 4, 8, 16, ...
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libintmath.py:458:    TODO: speed up using factorization
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:342:    # TODO: handle rnd direction of the logarithm carefully
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:711:        # TODO: if close enough to 1, we could use Taylor series
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:876:# TODO: cleanup the special cases
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1158:        # TODO: the best cutoff depends on both x and the precision.
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libelefun.py:1249:    # TODO: optimize division precision
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:179:    # formula to the tail. TODO: choose more intelligently
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:626:TODO: the current estimation of N for m > 0 is *very suboptimal*.
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:628:TODO: implement the reflection formula for m > 0, Re(z) << 0.
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:633:TODO: maybe use exact algorithms to compute psi for integral
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1160:# TODO: optimize / cleanup interface / unify with list_primes
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1383:    TODO: this is currently only used for gamma, but could
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/gammazeta.py:1942:    # a fixed-point value. TODO: determine a precise cutoff of validity
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:498:    # TODO: handle cancellation when c ~=  -1 and ch ~= 1
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpc.py:584:# TODO: avoid loss of accuracy
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:124:# TODO: optimize
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:367:    # TODO: combine evaluation code to avoid duplicate modulo
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:631:    # TODO: optimize for real/imag cases
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:643:    # TODO: optimize for real/imag cases
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:670:    # TODO: accuracy for small x
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:759:    # TODO: recognize/speed up real cases, integer y
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:848:        # TODO: reflection formula
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpi.py:885:            # TODO: reflection formula
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1175:    # TODO: account for precision when doing this
./api/search/.venv/lib/python3.12/site-packages/mpmath/libmp/libmpf.py:1320:    TODO: the rounding does not work properly for large exponents.
./api/search/.venv/lib/python3.12/site-packages/fastapi/openapi/utils.py:344:                # TODO: probably make status_code a default class attribute for all
./api/search/.venv/lib/python3.12/site-packages/fastapi/openapi/models.py:147:    # TODO: uncomment and remove below when deprecating Pydantic v1
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:36:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:150:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:236:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:320:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:406:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:490:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:606:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/params.py:690:        # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:55:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:380:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:684:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1000:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1327:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1642:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/param_functions.py:1956:    # TODO: update when deprecating Pydantic v1, import these types
./api/search/.venv/lib/python3.12/site-packages/fastapi/routing.py:367:            # TODO: remove this scope later, after a few releases
./api/search/.venv/lib/python3.12/site-packages/fastapi/routing.py:523:            # TODO: remove when deprecating Pydantic v1
./api/search/.venv/lib/python3.12/site-packages/fastapi/encoders.py:36:# TODO: pv2 should this return strings instead?
./api/search/.venv/lib/python3.12/site-packages/fastapi/encoders.py:217:        # TODO: remove when deprecating Pydantic v1
./api/search/.venv/lib/python3.12/site-packages/fastapi/encoders.py:239:            # TODO: remove when deprecating Pydantic v1
./api/search/.venv/lib/python3.12/site-packages/fastapi/applications.py:877:        # TODO: remove when discarding the openapi_prefix parameter
./api/search/.venv/lib/python3.12/site-packages/fastapi/security/oauth2.py:12:# TODO: import from typing when deprecating Python 3.9
./api/search/.venv/lib/python3.12/site-packages/fastapi/_compat.py:203:            # TODO remove when deprecating Pydantic v1
```

### FIXME Items

```
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:464:            # FIXME this rejects UNKNOWN, is that right?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:955:                # FIXME handle the case where zipfile is not available
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:1866:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2949:    # FIXME: 'Distribution.insert_on' is too complex (13)
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:248:        # FIXME: handle?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:249:        # FIXME: magic signatures?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/build_env.py:201:                # FIXME: Consider direct URL?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:490:            # FIXME: need a test for this elif block
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/req_install.py:375:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/req/req_file.py:247:            # FIXME: it would be nice to keep track of the source
./qdrant/extraction-legacy/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:624:            # FIXME: https://github.com/pypa/pip/issues/11943
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PixarImagePlugin.py:61:        # FIXME: to be continued...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:178:                # FIXME: the fill decoder is not implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:216:                # FIXME: jpeg tables are tile dependent; the prefix
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:78:# FIXME: add support for pilfont2 format (see FontFile.py)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:133:        self.info = []  # FIXME: should be a dictionary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:225:        # FIXME: use service provider instead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageQt.py:140:        # FIXME - is this really the best way to do this?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:152:            # FIXME: this may read whole file if not a text file
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:249:        self._fp = self.fp  # FIXME: hack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:102:            # FIXME: fix Fill2 to properly support matte for I+F images
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:129:            # FIXME: should add a font repository
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/TiffTags.py:209:    # FIXME add more tags here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/MpoImagePlugin.py:128:        self._fp = self.fp  # FIXME: hack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageDraw2.py:54:        # FIXME: add support for bitmap fonts
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PdfImagePlugin.py:57:    # FIXME: Should replace ASCIIHexDecode with RunLengthDecode
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/SpiderImagePlugin.py:161:        self._fp = self.fp  # FIXME: hack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PngImagePlugin.py:445:            icc_profile = None  # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:962:        # FIXME What about tagdata?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:229:    raise NotImplementedError(msg)  # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:260:    # FIXME: supports GIMP gradients only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/Image.py:544:        # FIXME: take "new" parameters / other image?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/Image.py:1796:                # FIXME: use self.size here?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/Image.py:1932:            # FIXME: _imaging returns a confusing error message for this case
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/Image.py:2790:    # FIXME: the different transform methods need further explanation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/MspImagePlugin.py:184:    header[12] = checksum  # FIXME: is this the right field?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:341:            # FIXME: This is a hack to handle TIFF's JpegTables tag.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:638:    # FIXME: make MAXBLOCK a configuration parameter
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/GifImagePlugin.py:120:        self._fp = self.fp  # FIXME: hack
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageOps.py:54:        # FIXME: apply to lookup table, not image data
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PSDraw.py:44:        # FIXME: incomplete
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/McIdasImagePlugin.py:55:            # FIXME: add memory map support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PsdImagePlugin.py:40:    (7, 8): ("L", 1),  # FIXME: multilayer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/XVThumbImagePlugin.py:17:# FIXME: make save work (this requires quantization support)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PcdImagePlugin.py:49:        self._size = 768, 512  # FIXME: not correct for rotated images!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/ImageCms.py:1103:        # FIXME: I get different results for the same data w. different
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/PcxImagePlugin.py:96:            # FIXME: hey, this doesn't work with the incremental loader !!!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:110:        self.info["flashpix"] = s  # FIXME: value will change
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:238:    # FIXME: The quantization tables can be used to estimate the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:798:    # FIXME: issue a warning if the wrong form is used (post-1.1.7)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1290:    # FIXME: simplify(E(X)) seems to hang without extended_positive=True
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/deltafunctions.py:144:            #FIXME: the second term tells whether is DeltaDirac or Derivative
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:544:    # FIXME: If alpha, beta are not declared as finite the line below hangs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/facts.py:330:        # (?) FIXME this is only correct when b & c != null !
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1182:    # FIXME: The line below should be True rather than None
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1198:    # FIXME: Should the line below be True rather than None?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:2171:    # FIXME: This evaluates as:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:617:    # FIXME: could replace with random selection after test passes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:643:    # FIXME: could replace with random selection after test passes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:925:    # FIXME: The test below fails because (-infx).is_extended_positive is True
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1617:            # FIXME: is_positive/is_negative is False doesn't take account of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:456:        # FIXME: Currently complex intervals are not supported.  A possible
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1226:        # FIXME: currently tan(pi/2) return zoo
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_delta_functions.py:37:    # FIXME: this is generally undefined @ x=0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_bessel.py:514:    # FIXME: could have these return NaN; for now just fix infinite recursion
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1424:            # FIXME: This should probably be handled with something like:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:152:    # FIXME: This doesn't yet work:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:120:    contravariant and covariant Idx subclasses.  (FIXME: this is not yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:150:    # FIXME: symmetries from power needs to check special cases, else nothing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:168:    FIXME: Add support for Numpy broadcasting
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:196:        # FIXME: search for symmetries
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:279:            # FIXME:  No support for Piecewise yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:295:            "FIXME: No specialized handling of type %s" % type(expr))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:449:        # FIXME:  No support for Piecewise yet
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:469:        "FIXME: No specialized handling of type %s" % type(expr))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:249:    "complex": DataType("double", "COMPLEX*16", "complex", "", "", "float") #FIXME:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1530:        # FIXME: this is probably general enough for other high-level
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen.py:16:#FIXME: Fails due to circular import in with core
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:85:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:235:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:83:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:225:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:89:    # FIXME: how to pass inline to the RustCodePrinter?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:248:    # FIXME: how to pass inline to the RustCodePrinter?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:911:    # FIXME: The solution here should be O((x-2)**3) so is incorrect
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:929:    # FIXME: Solution should be O((x+2)**6)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:948:    # FIXME: checkodesol fails for this solution...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:956:    # FIXME: checkodesol fails for this solution...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2480:    # FIXME: assert checksysodesol(eq3, sol3) == (True, [0, 0])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2485:    # FIXME: assert checksysodesol(eq4, sol4) == (True, [0, 0])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2516:    # FIXME: assert checksysodesol(eq1, sol1) == (True, [0, 0, 0])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2524:    # FIXME: assert checksysodesol(eq2, sol2) == (True, [0, 0, 0])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/recurr.py:564:            # FIXME: The call to rsolve_ratio below should suffice (rsolve_poly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:937:    # FIXME: Find lcm() of all the divisors and divide with it, instead of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/paulialgebra.py:144:    # FIXME don't work for -I*Pauli(2)*Pauli(3)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/hep/gamma_matrices.py:315:    gctr = 4  # FIXME specific for d=4
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2221:    FIXME: This is a bottle-neck, can we do it faster?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2758:        # FIXME: If we arrive here, there are no ordered dummies. A method to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/external/tests/test_codegen.py:184:            "FIXME: filename extension unknown for language: %s" % language)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/maple.py:8:FIXME: This module is still under actively developed. Some functions may be not completed.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/julia.py:68:    # assignment (if False).  FIXME: this should be looked a more carefully
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:85:    # assignment (if False).  FIXME: this should be looked a more carefully
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:258:        # FIXME: how to do better, e.g., for octave_code(2*GoldenRatio)?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1375:        # FIXME: Refactor this code and matrix into some tabular environment.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1442:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1490:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:243:    # FIXME: is it worth worrying about this?  Its not wrong, just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:358:    # FIXME?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:339:    # FIXME: sT fails because Cycle is not immutable and calling srepr(Cycle(1, 2))
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:184:    # FIXME: is it worth worrying about this?  Its not wrong, just
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:293:    # FIXME?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:243:                            "FIXME: no support for contractions in factor yet")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:255:                        # syntax is currently undefined.  FIXME: What would be
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:261:                            raise ValueError("FIXME: lhs present in rhs,\
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/io/video.py:186:        # FIXME this is kind of a hack, but we will jump to the previous keyframe
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/transforms/autoaugment.py:103:# FIXME: Eliminate copy-pasted code for fill standardization and _augmentation_space() by moving stuff on a base class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:74:            # FIXME: Is this needed? SqueezeNet should only be called from the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:75:            # FIXME: squeezenet1_x() functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:76:            # FIXME: This checking is not done for the other models
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:491:        # FIXME We don't know if we should expect this to happen
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1552:            # FIXME: why are there type ignores here? We support two signatures for json_schema_extra callables...
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:363:    FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:1403:            # FIXME: I want to make these keywords but still parse attributes.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:223:    # FIXME: use inheritance
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/julia.py:195:            # FIXME: This escape pattern is not perfect.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:536:            # FIXME: aren't the offsets wrong?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:998:            # FIXME: Use ABC lexer in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:41:            # FIXME when e is present, no decimal point needed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:172:            # FIXME when e is present, no decimal point needed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/lexers/typst.py:135:            # FIXME: make this work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/utils/distributed.py:114:        # FIXME: verify that ROCm transform nccl to rccl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/loss/binary_cross_entropy.py:44:            # FIXME should off/on be different for smoothing w/ BCE? Other impl out there differ
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/imagenet_info.py:40:            # FIXME at some point pretrained_cfg should include dataset-tag,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:141:        # FIXME WIP, not completed. Downstream support in model needed for non-contiguous valid patches
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:154:            # patch dropout mode, completely remove dropped patches (FIXME needs downstream support in model)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:324:                # FIXME we could vectorize patch mode across batch, worth the effort?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/dataset_factory.py:218:        # FIXME support more advance split cfg for ImageFolder/Tar datasets in the future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/naflex_loader.py:376:            # FIXME add crop args when sequence transforms support crop modes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_image_in_tar.py:89:        cache_tarinfo = True if tar_bytes > 10*1024**3 else False  # FIXME magic number, 10GB
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:210:            # _logger.info(f'shuffle seed: {self.seed}, {seed}, epoch: {epoch}')  # FIXME temporary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:434:        # _logger.info(f'start {i}, {self.worker_id}')  # FIXME temporary debug
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:441:        # _logger.info(f'end {i}, {self.worker_id}')  # FIXME temporary debug
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:22:    # FIXME improve the selection right now just tfds prefix or fallback path, will need options to
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:40:        # FIXME support split here or in reader?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:146:        self.input_key = input_key  # FIXME support tuples / lists of inputs and targets and full range of Feature
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:179:        # FIXME need to determine if reinit_each_iter is necessary. I'm don't completely trust behaviour
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:249:                num_replicas_in_sync=self.dist_num_replicas  # FIXME does this arg have any impact?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/data/transforms_factory.py:146:            # FIXME integration of RKR is a WIP
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/kron.py:106:        deterministic: Deterministic behaviour across save / load (resume). FIXME slow, needs work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adamp.py:33:        # FIXME this is a problem for PyTorch XLA
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/lars.py:106:                    # FIXME nested where required since logical and/or not working in PT XLA
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:187:    #@_use_grad_for_differentiable  # FIXME internal context mgr, can't use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:454:#@_disable_dynamo_if_unsupported(single_tensor_fn=_single_tensor_adopt)  # FIXME internal context mgr, can't use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/_param_groups.py:87:        # FIXME interface needs more work
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:87:        # FIXME try to check if momentum dtype is appropriate for device? Torch API not great for this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:119:                    # FIXME this is a bit of a hack, optimizer.load_state_dict appears to upcast
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:298:                # FIXME not 100% sure if this remains capturable?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/mars.py:183:                # FIXME add multi-tensor (if usage warrants), make more standard
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:267:                # FIXME not 100% sure if this remains capturable?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/lamb.py:229:                    # FIXME nested where required since logical and/or not working in PT XLA
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/optim/sgdw.py:92:    # FIXME figure out how to make _use_grad_for_differentiable interchangeable with no_grad decorator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/mlp.py:180:            hidden_features = hidden_features // 2  # FIXME base reduction on gate property?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pool2d_same.py:16:    # FIXME how to deal with count_include_pad vs not for external padding?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/attention2d.py:136:            # FIXME dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/squeeze_excite.py:98:        x_se = x.mean((1, 2), keepdims=True)  # FIXME avg dim [1:n-1], don't assume 2D NHWC
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:183:# FIXME to remove, keeping for comparison for now
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:596:#     FIXME WIP
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/drop.py:137:        self.fast = fast  # FIXME finish comparisons of fast vs not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/lambda_layer.py:127:            # FIXME relative pos embedding path not fully verified
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:73:    # FIXME add support for unflattened spatial dim?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:194:        # FIXME support nD
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/attention_pool.py:83:            # FIXME interpolate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:67:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:81:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:87:#group_std = group_std_tpu  # FIXME TPU temporary
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:28:    assert k_size is None, 'Different q & k sizes not currently supported'  # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:39:    #     # FIXME different q vs k sizes is a WIP, need to better offset the two grids?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:98:        src_size = (src_size, src_size)  # FIXME could support non-equal src if argument passed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:481:        # FIXME change to not use one-hot/einsum?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:149:        # FIXME not clear if this stride behaviour is what the paper intended
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:189:        # FIXME figure out how to switch impl between this and conv2d if XLA being used.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:146:    force_in_chs = int(options['fc']) if 'fc' in options else 0  # FIXME hack to deal with in_chs issue in TPU def
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:471:                    # FIXME s2d is a WIP
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_hub.py:132:    # FIXME I may change @ -> # and be parsed as fragment in a URI model name scheme
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:95:    aa_layer: Optional[str] = None  # FIXME support string factory for this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:180:        # FIXME partial shortcut needed if first block handled as per original, not used for my current impl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:298:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:310:        # FIXME this 1x1 expansion is pushed down into the cross and block paths in the darknet cfgs. Also,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:377:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:444:                nn.AvgPool2d(2) if stride == 2 else nn.Identity(),   # FIXME dilation handling
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:525:    FIXME is there a more common 3x3 + 1x1 conv block to name this after?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:977:        # FIXME need to dilate self attn to have dilated network support, moop moop
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/res2net.py:62:            # FIXME this should probably have count_include_pad=False, but hurts original weights
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/hrnet.py:536:        assert output_stride == 32  # FIXME support dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:1428:    # FIXME experimental
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:2139:# FIXME experimental group cong / GroupNorm / EvoNorm experiments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/fastvit.py:349:        # FIXME output of this act was not used in original impl, likely due to bug
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_helpers.py:24:    # FIXME replace with 3.9 stdlib fn when min at 3.9
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/ghostnet.py:657:        # FIXME init
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_manipulate.py:22:        # FIXME this a bit of a quick and dirty hack to skip classifier head params based on ordering
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mobilenetv3.py:650:    FIXME untested, this is a preliminary impl of some FBNet-V3 variants.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/regnet.py:1207:    # FIXME invalid weight <-> model match, mistake on their end
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/metaformer.py:552:                # FIXME not actually returning mlp hidden state right now as pre-logits.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:297:        # FIXME MFSA and forward_intermediates overlap, they both take indices from specific features
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:320:        # FIXME see note above
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:359:                # FIXME fix grad checkpointing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:545:            # FIXME fix grad checkpointing
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/dpn.py:173:        assert output_stride == 32  # FIXME look into dilation support
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/efficientvit_mit.py:1171:# FIXME will wait for v2 SAM models which are pending
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:93:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:147:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:236:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:344:        # FIXME dilation isn't right w/ extra ks > 1 convs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:351:                dilation=dilation,  # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:379:                dilation=dilation,  # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:668:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_factory.py:26:        # FIXME may use fragment as revision, currently `@` in URI path
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_features.py:156:    FIXME This works well in eager Python but needs redesign for torchscript.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_features.py:305:                    # FIXME this may need to be more generic / flexible for some nets
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_features.py:359:    FIXME this does not currently work with Torchscript, see FeatureHooks class
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/crossvit.py:73:        # FIXME look at relaxing size constraints
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/senet.py:11:FIXME I'm deprecating this model and moving them to ResNet as I don't want to maintain duplicate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/vovnet.py:193:        assert output_stride == 32  # FIXME support dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/twins.py:431:        # FIXME slice block/pos_block if < max
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/twins.py:471:        # FIXME add block pruning
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:162:    # FIXME confirm we want 'channels last' in the patch channel layout, egg ph, ph, C instead of C, ph, hw
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:455:            # k = h << 16 | w  # FIXME can get jit compat with this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:459:            # h, w = k >> 16, k & 0xFFFF  # FIXME can get jit compat with this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:1225:        # FIXME unfinished / untested
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/davit.py:589:        # FIXME generalize this structure to ClassifierHead
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/davit.py:787:        # FIXME cleaner approach to missing head norm?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:1772:        # hf_hub_id='timm/vit_base_patch32_clip_224.openai_ft_in12k_in1k',  # FIXME weight exists, need to push
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2668:        # FIXME Google FlexiViT pretrained models have a strong preference for bilinear patch / embed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2674:    # FIXME attn pool (currently only in siglip) params removed if pool disabled, is there a better soln?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/vision_transformer_sam.py:590:                    # FIXME only apply to final? Need experiments
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/coat.py:551:            parallel_blocks=[  # FIXME (partially?) overlap parallel w/ serial blocks??
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:863:        # FIXME slice block/pos_block if < max
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:905:        # FIXME add stage pruning
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_registry.py:217:        # FIXME should this be default behaviour? or default to include_tags=True?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/pit.py:365:        # FIXME need to update resize for PiT impl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/mlp_mixer.py:300:        # FIXME drop_path (stochastic depth scaling rule or all the same?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/_prune.py:98:            # FIXME extra checks to ensure this is actually the FC classifier layer and not a diff Linear layer?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:566:            # FIXME handle dilation of avg pool
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:676:        # FIXME handle dilation?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/edgenext.py:350:            # FIXME support dilation / output_stride
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/densenet.py:357:                (r'^features\.transition(\d+)', MATCH_PREV_GROUP)  # FIXME combine with previous denselayer
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/dla.py:280:        assert output_stride == 32  # FIXME support dilation
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:116:        meta_hidden_dim: int = 384,  # FIXME what's the optimal value?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:137:            drop=(0.125, 0.)  # FIXME should there be stochasticity, appears to 'overfit' without?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:374:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:402:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:759:        # FIXME more experiments needed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:897:    # FIXME WIP determining if there's a better weight init
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/h11/_writers.py:54:    # XX FIXME: could at least make an effort to pull out the status message
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/h11/_events.py:310:# XX FIXME: "A recipient MUST ignore (or consider as an error) any fields that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/h11/_readers.py:186:            # XX FIXME: we discard chunk extensions. Does anyone care?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/mixture_same_family.py:120:        # FIXME this may have the wrong shape when support contains batched
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/wishart.py:38:        >>> # xdoctest: +SKIP("FIXME: scale_tril must be at least two-dimensional")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributions/multinomial.py:35:        >>> # xdoctest: +SKIP("FIXME: found invalid values")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1455:                # FIXME: Unfortunately, for Windows, we are missing a worker
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:475:    """FIXME: Temporarily replace std:: invocations of math functions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:220:    # FIXME: Once 3.7 is the minimum version, type annotate `other` per PEP 563
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/cpp_jit.py:81:    # FIXME: Remove when back testing is no longer required.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:647:        # FIXME: the docs say that persistent_id should only return a string
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/serialization.py:790:        # FIXME: the docs say that persistent_id should only return a string
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:531:    # FIXME should probably check that lengths and offset aren't both set, but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5464:        assert not (is_causal and attn_mask is None), "FIXME: is_causal not implemented for need_weights"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1073:# FIXME (by @ssnl): Improve adaptive pooling docs: specify what the input and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:923:    # FIXME: copy.deepcopy() is not defined on nn.module
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/channelshuffle.py:20:        >>> # xdoctest: +IGNORE_WANT("FIXME: incorrect want")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/_functions.py:79:            # FIXME: https://github.com/pytorch/pytorch/issues/78656 describes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1606:    >>> # xdoctest: +SKIP("FIXME: Would call backwards a second time")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1742:        >>> # xdoctest: +SKIP("FIXME: error in doctest")
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/autograd/forward_ad.py:92:    # FIXME: We specify that __debug__ must be True because
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:153:    # FIXME: support multiple parameter groups
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:341:    # FIXME(@mrshenli): support multiple nn.Module instances
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:342:    # FIXME(@mrshenli): support multiple Optiimzer instances
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:343:    # FIXME(@mrshenli): need to broadcast model to sync parameters
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:405:    # FIXME: Using symbolic tracing to work around in DTensor expand mode.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:438:        # FIXME(@mrshenli): functionalization does not work for our use
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:167:        # FIXME: allow other sharding schemas
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:31:    # FIXME(@mrshenli): for sqrt, this is only mathematically correct for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:430:        # FIXME(@wanchaol, @mrshenli): the above seems to accidentally captured
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:626:                        # FIXME(@mrshenli): This is a temporary solution enable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:239:    # FIXME gloo doesn't support _allgather_base
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:373:    # FIXME (kumpera) torch.load fails if we wrap with io.BufferedReader
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:342:        # FIXME the type of planner is wrong in load_state_dict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:547:    # FIXME record_stream doesn't work with non-cuda tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:308:                # FIXME: there are a few things that fall under this like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:389:    # FIXME: this is wrong when dim=None and one of the dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:665:            # FIXME: this can be wrong for situations where we have
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset11.py:1362:    # FIXME(justinchuby): We need to handle what happens when we call b.op on a node return
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1249:        # FIXME(justinchuby): can index be an int and not a value?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1875:            # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1886:            # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1941:            # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1956:        # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2514:        # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2586:        # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3122:    # FIXME(justinchuby): Get rid of the try catch here to improve readability
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3126:        # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4273:        # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:7177:        # FIXME(justinchuby): report correct name for symbolic being executed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:285:                # FIXME(justinchuby): Avoid catching Exception.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset12.py:368:        # FIXME(justinchuby): cond is unused?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:128:        # FIXME: Avoid importing onnxscript into torch
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:86:        # FIXME(justinchuby): Add the return type back once we know how to handle mypy
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:41:    # FIXME: Avoid importing onnx into torch.onnx.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:138:    # FIXME: Avoid importing onnx into torch.onnx.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:50:        # FIXME: This is a hack to tracing through if-else Python blocks.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:185:        # FIXME: Bug in `dynamo.export`. Sometimes outputs returned in 'list' instead of 'tuple'.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:187:        # FIXME: Bug in `dynamo.export`. Sometimes single function return is wrapped in list.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2119:# FIXME: currently returns integers for boolean tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2151:# FIXME: currently returns integers for boolean tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2183:# FIXME: currently returns integers for boolean tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:658:            # FIXME: Implement reductions for dense dimensions for ops with non-zero reduction identities
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:705:        # FIXME: temporary workaround for issue with bfloat16/float16 remove when acctype is implemented for scatter_reduce
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:736:    # FIXME: when dense dimensions are implemented for CSR tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:527:        # FIXME and they have the same dtype, device, etc
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_numpy/testing/__init__.py:19:# from .testing import assert_allclose    # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:405:    # FIXME(Mario) Doesn't np.quantile accept a tuple?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/__init__.py:1683:            # FIXME: CUDA Graph does not work well with CUPTI teardown.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:942:        # FIXME (tmanlaibaatar)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:65:FIXME_inductor_non_strict = {
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5218:            # FIXME: Add testing for gloo/CUDA
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:239:        # FIXME dist.barrier deadlocks with multiple threads and NCCL: https://github.com/pytorch/pytorch/issues/95895
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:241:        # FIXME can't use the above all_reduce as it causes hangs on bionic and focal. It hangs:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py:28:        # FIXME Once we consolidate the error messages returned by the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4667:    # FIXME Merge this test with the corresponding one in RpcTest.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4688:    # FIXME Merge this test with the corresponding one in RpcTest.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4712:    # FIXME Merge this test with the corresponding one in RpcTest.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4745:        # FIXME We wait until the remote completed creating the OwnerRRef
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4795:        # FIXME We wait until the remote completed creating the OwnerRRef
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2637:            # FIXME: remove after implementing reflection pad 3d
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3412:        self.FIXME_no_cuda_gradgrad_comparison = \
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3413:            kwargs.get('FIXME_no_cuda_gradgrad_comparison', False)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3547:            if self.check_gradgrad and not self.FIXME_no_cuda_gradgrad_comparison:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2635:                # FIXME: figure out the flaky -1024 anti-leaks on windows. See #8044
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2763:                        from .dynamo_test_failures import FIXME_inductor_non_strict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2764:                        strict_default = filename not in FIXME_inductor_non_strict
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3128:            # FIXME: `x` is a sparse view of `v`. Currently rebase_history for
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4054:# FIXME: modernize these to be consistent with make_tensor
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4341:# FIXME: remove this by updating test suites using it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4350:# FIXME: remove this by updating test suites using it
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4404:# FIXME: improve load_tests() documentation here
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4434:# FIXME: document this and move it to test_serialization
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4516:# FIXME: delete this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4524:# FIXME: move to test_sparse or sparse utils
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:119:# FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1854:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2417:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:153:                    # FIXME: for now reductions with non-zero reduction identity and
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:454:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:530:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:643:            # FIXME: amax reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:652:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:653:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:682:            # FIXME: amax reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:691:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:692:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:792:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:801:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:873:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:917:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:992:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:1163:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:97:        # FIXME: Causes floating point exception on ROCm
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2243:        # FIXME add an override for JIT and revert 0. back to 0
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3023:    # FIXME: eager and ref impl throw different types of errors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4021:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4081:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4218:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8146:    # FIXME: Derivative wrt. weight not implemented
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12045:               # FIXME: geqrf can't forward with complex inputs that require grad
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14037:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14060:               # FIXME: both derivatives are implemented incorrectly
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14062:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14680:            # FIXME: intentionally misreports dtypes
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14682:            # FIXME: numpy reference diverges: Comparing (nan+nanj) and (-0+0j)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15015:                        # FIXME: incorrectly tries to pass a rhs scalar
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15055:                        # FIXME: incorrectly tries to pass a rhs scalar
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15342:                        # FIXME Complex values error with: Greatest absolute difference: nan at index
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15385:                        # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18994:            # FIXME: uint8 input returns uint8 instead of bool
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19006:            # FIXME: uint8 input returns uint8 instead of bool
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19019:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19034:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19067:            # FIXME: count_nonzero does not accept keepdim kwarg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19075:            # FIXME: dim=[] reduces all dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19084:        # FIXME: mean needs 'dim' parameter when using the 'out' overload.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19095:            # FIXME: mean does not support passing keepdim without passing dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19097:            # FIXME: mean reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19100:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19123:            # FIXME: prod reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19126:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19151:            # FIXME: cannot specify keepdim without dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19153:            # FIXME: dim=[] reduces all dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19156:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19178:            # FIXME: dim=[] reduces all dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19199:            # FIXME: cannot specify keepdim without dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19201:            # FIXME: dim=[] reduces all dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19204:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19226:            # FIXME: dim=[] reduces all dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19248:            # FIXME: prod does not support passing keepdim without passing dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19250:            # FIXME: prod reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19253:            # FIXME: prod does not support passing None to dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19260:            # FIXME: ValueError: The data in MaskedTensor a and Tensor b do not match
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19283:            # FIXME: sum does not support passing keepdim without passing dim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19285:            # FIXME: sum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19288:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19313:            # FIXME: nansum reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19316:            # FIXME: flaky test so skipped instead of xfailed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19643:            # FIXME: CUDA driver API confirmed a leak in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19665:            # FIXME: CUDA driver API confirmed a leak in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21188:            # FIXME output 0: meta disagrees with real impl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21306:            # FIXME output 0: meta disagrees with real impl
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21632:            # FIXME: enable dtype-based tolerances in test_ops.py:TestCommon._ref_test_helper
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21851:        # FIXME: doesn't support chalf
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21864:        # FIXME: doesn't support chalf
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21900:            # FIXME: AssertionError: RuntimeError not raised
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22180:            # FIXME: uint8 input returns uint8 instead of bool
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22191:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22203:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22214:            # FIXME: uint8 input returns uint8 instead of bool
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22224:            # FIXME: count_nonzero does not accept keepdim kwarg
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22239:            # FIXME: dim=[] reduces all dimensions
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22249:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22261:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22266:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22286:            # FIXME: doesn't test out behavior properly for this operator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22288:            # FIXME: mean reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22292:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22334:            # FIXME: doesn't test out behavior properly for this operator
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22336:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22341:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22352:            # FIXME: reduces all dimensions when dim=[]
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22357:            # FIXME: improve precision
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22417:            # FIXME: shouldn't check empty results
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22447:            # FIXME: should not compare results of empty_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22503:            # FIXME: should not compare results of empty_like
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:709:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:800:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:893:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:202:            # FIXME that's a crude approximation for promoting args
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2983:        # FIXME: Calling to_device(x, device) should work but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3662:    # FIXME: in some cases we sill need to explicitly pass in ordered_kwargs_for_cpp_kernel
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4956:        # FIXME: no need to do this after we switch to the torchgen-ed C shim
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1252:        # FIXME: passing `-fopenmp` adds libgomp.so to the generated shared library's dependencies.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1837:            # FIXME handle embedded optional types?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2628:        # FIXME: This is not exactly right for cases like below:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/onnxrt.py:15:    # FIXME(abock): update test/dynamo/test_backends.py to call is_onnxrt_backend_supported()
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1417:        # FIXME (tmanlaibaatar) this is utter hack to unblock HuggingFace export
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3355:            obj, obj.__name__, getfile(obj), obj.__code__  # type: ignore[union-attr] # FIXME Add MethodType.__code__ to typeshed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:920:      // FIXME We should always extract DataPtrs, in order to catch the case of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:116:  // FIXME: stride should be optional
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cuda/DistributionTemplates.h:106: * FIXME: Can we specialize elementwise_kernel and launch_kernel in Loops.cuh
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:259:      // FIXME: remove magic > 0 after we ensure no models were serialized with -1 defaults.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/ATen/ScalarOps.h:28:// FIXME: this should be (and was) Scalar::toTensor, but there is currently no
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:749:/// \todo FIXME: remove when \c constexpr becomes really \c constexpr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:154:    this->Size = this->Capacity = 0; // FIXME: Setting Capacity to 0 is suspect.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:768:  // FIXME: Consider assigning over existing elements, rather than clearing &
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1106:  // FIXME: don't do this if they're efficiently moveable.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1169:  // FIXME: this may not actually make any sense if we can efficiently move
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/device_utils.h:10:// FIXME: Currently, CPU and CUDA backend are mutually exclusive.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroupGloo.hpp:68:  // FIXME: This probably should be called WorkGloo since the work is executed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/detail/TensorDataContainer.h:31:// FIXME: There is no `operator<<` overload for `at::kBFloat16` type,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:125:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:130:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:185:                    # FIXME: CUDA Graph does not work well with CUPTI teardown.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/h2/connection.py:1808:            # FIXME: Should we split this into one event per active stream?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/util/response.py:99:    # FIXME: Can we do this somehow without accessing private httplib _method?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/response.py:782:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/response.py:787:                # FIXME: Is there a better way to differentiate between SSLErrors?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/response.py:1051:        # FIXME, this method's type doesn't say returning None is possible
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/urllib3/response.py:1219:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2031:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3201:    # FIXME: 'Distribution.insert_on' is too complex (13)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:326:        # FIXME: handle?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:327:        # FIXME: magic signatures?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/build_env.py:200:                # FIXME: Consider direct URL?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:480:            # FIXME: need a test for this elif block
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:371:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:259:            # FIXME: it would be nice to keep track of the source
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:631:            # FIXME: https://github.com/pypa/pip/issues/11943
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:466:            # FIXME: Remove this after figuring out CI job failures related to min, max, mean
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:67:    # FIXME: figure out a better way when we support sparse tensors in jit
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:98:    # FIXME: clone indices on construction.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:252:# FIXME: Ideally these functions should be methods on Type class, but we have a
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:901:# FIXME: Fails _cdfvec
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:1294:# FIXME: problems sampling.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:9003:    # FIXME: this is only a quick-and-dirty test of a quick-and-dirty bugfix.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:799:            # FIXME: implement this somewhen, for now go with builtin values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:800:            # FIXME: calc optimal lwork by calling ?hbevd(lwork=-1)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:805:            # FIXME: implement this somewhen, for now go with builtin values
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:903:    # FIXME: suppress?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:904:    # FIXME: how to catch the _fblas.error?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:942:    # prints '0-th dimension must be fixed to 3 but got 5', FIXME: suppress?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:740:        # FIXME Jitted JAX arrays do not have a device attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:325:        # FIXME https://github.com/jax-ml/jax/issues/27418
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/differentiate/tests/test_differentiate.py:585:        # FIXME https://github.com/scipy/scipy/pull/22320#discussion_r1914898175
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/_constraints.py:492:    # FIXME: when bugs in VectorFunction/LinearVectorFunction are worked out,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__dual_annealing.py:69:    # FIXME: there are some discontinuities in behaviour as a function of `qv`,
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/integrate/_ode.py:392:            # FIXME: this really should be raise an exception. Will that break
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/conftest.py:504:    # FIXME: populate the dict once
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/spatial/tests/test_kdtree.py:634:        # raises an exception for bug 870 (FIXME: Does it?)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/spatial/_kdtree.py:913:        result = np.empty((m,n),dtype=float)  # FIXME: figure out the best dtype
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/_delegators.py:21:         sig = "( FIXME )"
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:110:        # FIXME: for complex types, the computations are done in
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/scipy/signal/_signaltools.py:4339:    # FIXME: Can this function be replaced with an appropriate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1007:    #FIXME the 'e' dtype might work in future
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_mem_policy.py:12:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:6159:        # FIXME:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_interface.py:131:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:19:#FIXME: this will probably change when we require full C99 campatibility
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1129:        # FIXME cinf not tested.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1774:                        reason='failures on 32-bit Python, see FIXME below')
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1818:        # FIXME: NAN raises FP invalid exception:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1821:        # FIXME: skipped on MSVC:32-bit during switch to Meson, 10 cases fail
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:2794:            # FIXME: a not used
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1758:     * FIXME: This should check for a flag on the data-type that
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:236:        # FIXME: This seems like it will copy strings around
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/ma/core.py:2839:            # FIXME: should we set `_data._sharedmask = True`?
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/numpy/conftest.py:73:#FIXME when yield tests are gone.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/image_to_text.py:204:        # FIXME: We need to pop here due to a difference in how `generation.py` and `generation.tf_utils.py`
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:380:            # FIXME: ydshieh and/or Narsil
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/modeling_gguf_pytorch_utils.py:376:    # FIXME: Currently this implementation is only for flan-t5 architecture.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/protein.py:85:                    seq[i] = "X"  # FIXME: strings are immutable
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:472:        # FIXME:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:241:        # FIXME:
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics3/image_processing_idefics3.py:229:# FIXME Amy: make a more general crop function that isn't just centre crop
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/image_processing_smolvlm.py:226:# FIXME Amy: make a more general crop function that isn't just centre crop
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/idefics2/image_processing_idefics2.py:125:# FIXME Amy: merge this function with the one in image_transforms.py
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1653:        # FIXME h_boxes takes the last one computed, keep this in mind
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:426:        # FIXME max_tokens_to_generate is embedded into this processor's call.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:539:        # FIXME - We hard code "pt" here because the rest of the processing assumes torch tensors
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1958:        # FIXME h_boxes takes the last one computed, keep this in mind
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/joblib/logger.py:144:            # FIXME: Too much logic duplicated
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/boto3/exceptions.py:100:# FIXME: Backward compatibility
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:911:        "check_estimators_empty_data_messages": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:912:        "check_estimators_nan_inf": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:913:        "check_estimator_sparse_array": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:914:        "check_estimator_sparse_matrix": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:915:        "check_fit1d": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:916:        "check_fit2d_predict1d": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:917:        "check_complex_data": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:918:        "check_fit2d_1feature": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:925:        "check_estimators_overwrite_params": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:926:        "check_estimators_nan_inf": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:927:        "check_dont_overwrite_parameters": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:966:        "check_estimators_nan_inf": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:967:        "check_classifiers_one_label_sample_weights": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:968:        "check_fit2d_1feature": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:976:        "check_estimators_nan_inf": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:977:        "check_classifiers_one_label_sample_weights": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:978:        "check_fit2d_1feature": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1216:        "check_dict_unchanged": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1280:                    "check_n_features_in_after_fitting": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1281:                    "check_dataframe_column_names_consistency": "FIXME",
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1392:# FIXME: this test should be uncommented when the checks will be granular
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1397:    # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/tests/test_gpr.py:760:    # FIXME: before fitting, the estimator does not have information regarding
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_common.py:98:    # FIXME: we can introduce equal_nan=True in recent version of numpy.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:117:        eps = np.finfo(np.float32).eps  # FIXME: This is quite large!
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:517:                # FIXME: we could consider to support multiclass-multioutput if
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:175:            # FIXME: We temporarily bypass this test. This is due to the fact
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:691:    # FIXME: the following snippet does not yield the same results on 32 bits
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_common.py:252:# FIXME: we should move this test in `estimator_checks` once we are able
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_kde.py:127:    # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:623:        # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1164:        # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_selection/tests/test_from_model.py:483:    # FIXME: we cannot validate the upper bound of the attribute at transform
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:606:        # FIXME We compute all the distances, while we could have only computed
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:278:# FIXME; this test is broken with different random states, needs to be revisited
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/compose/_target.py:281:        # FIXME: a FunctionTransformer can return a 1D array even when validate
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:109:        # FIXME: the current Cython implementation is too slow for a large number of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:698:    # FIXME: the current Cython implementation is too slow for a large number of
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/tests/test_glm.py:376:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:330:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:392:        # FIXME: Same as in test_ridge_regression_unpenalized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:447:        # FIXME: Same as in test_ridge_regression_unpenalized.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1551:        # FIXME
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1558:        # FIXME: SAGA on sparse data fits the intercept inaccurately with the
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/cross_decomposition/tests/test_pls.py:78:    # FIXME: one would expect y_trans == pls.y_scores_ but this is not
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:2540:# FIXME: Replace this test with a full `check_estimator` once we have API only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/multiclass.py:1207:        # FIXME: there are more elaborate methods than generating the codebook
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_multiclass.py:903:# FIXME: we should move this test in `estimator_checks` once we are able
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:745:# FIXME: we should move this test in `estimator_checks` once we are able
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:65:    # FIXME Remove this test once the more general partial_fit tests are merged
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:308:    # FIXME: write a test to show this.
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:1718:# FIXME: Replace this test with a full `check_estimator` once we have API only
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:657:        # FIXME Jitted JAX arrays do not have a device attribute
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_funcs.py:715:    # FIXME https://github.com/data-apis/array-api-compat/pull/231
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1728:        # FIXME: np.float16 could be preserved if _inplace_csr_row_normalize_l2
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/tests/test_weighted.py:890:        # FIXME nx.goldberg_radzik(D, 1)
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:713:                # FIXME directed graphs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:809:            # FIXME directed graphs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:859:                    # FIXME directed graphs
./qdrant/extraction-legacy/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:378:    # FIXME: error_dps should not be necessary
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PixarImagePlugin.py:61:        # FIXME: to be continued...
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:178:                # FIXME: the fill decoder is not implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:216:                # FIXME: jpeg tables are tile dependent; the prefix
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:78:# FIXME: add support for pilfont2 format (see FontFile.py)
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:133:        self.info = []  # FIXME: should be a dictionary
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:225:        # FIXME: use service provider instead
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageQt.py:140:        # FIXME - is this really the best way to do this?
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:152:            # FIXME: this may read whole file if not a text file
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:249:        self._fp = self.fp  # FIXME: hack
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:102:            # FIXME: fix Fill2 to properly support matte for I+F images
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:129:            # FIXME: should add a font repository
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/TiffTags.py:209:    # FIXME add more tags here
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/MpoImagePlugin.py:128:        self._fp = self.fp  # FIXME: hack
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageDraw2.py:54:        # FIXME: add support for bitmap fonts
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PdfImagePlugin.py:57:    # FIXME: Should replace ASCIIHexDecode with RunLengthDecode
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/SpiderImagePlugin.py:161:        self._fp = self.fp  # FIXME: hack
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PngImagePlugin.py:445:            icc_profile = None  # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:962:        # FIXME What about tagdata?
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:229:    raise NotImplementedError(msg)  # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:260:    # FIXME: supports GIMP gradients only
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:544:        # FIXME: take "new" parameters / other image?
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:1796:                # FIXME: use self.size here?
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:1932:            # FIXME: _imaging returns a confusing error message for this case
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:2790:    # FIXME: the different transform methods need further explanation
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/MspImagePlugin.py:184:    header[12] = checksum  # FIXME: is this the right field?
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:341:            # FIXME: This is a hack to handle TIFF's JpegTables tag.
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:638:    # FIXME: make MAXBLOCK a configuration parameter
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/GifImagePlugin.py:120:        self._fp = self.fp  # FIXME: hack
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageOps.py:54:        # FIXME: apply to lookup table, not image data
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PSDraw.py:44:        # FIXME: incomplete
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/McIdasImagePlugin.py:55:            # FIXME: add memory map support
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PsdImagePlugin.py:40:    (7, 8): ("L", 1),  # FIXME: multilayer
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/XVThumbImagePlugin.py:17:# FIXME: make save work (this requires quantization support)
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PcdImagePlugin.py:49:        self._size = 768, 512  # FIXME: not correct for rotated images!
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageCms.py:1103:        # FIXME: I get different results for the same data w. different
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/PcxImagePlugin.py:96:            # FIXME: hey, this doesn't work with the incremental loader !!!
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:110:        self.info["flashpix"] = s  # FIXME: value will change
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:238:    # FIXME: The quantization tables can be used to estimate the
./core/py/pipeline/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:798:    # FIXME: issue a warning if the wrong form is used (post-1.1.7)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1290:    # FIXME: simplify(E(X)) seems to hang without extended_positive=True
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/deltafunctions.py:144:            #FIXME: the second term tells whether is DeltaDirac or Derivative
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:544:    # FIXME: If alpha, beta are not declared as finite the line below hangs
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:330:        # (?) FIXME this is only correct when b & c != null !
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1182:    # FIXME: The line below should be True rather than None
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1198:    # FIXME: Should the line below be True rather than None?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:2171:    # FIXME: This evaluates as:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:617:    # FIXME: could replace with random selection after test passes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:643:    # FIXME: could replace with random selection after test passes
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:925:    # FIXME: The test below fails because (-infx).is_extended_positive is True
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1617:            # FIXME: is_positive/is_negative is False doesn't take account of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:456:        # FIXME: Currently complex intervals are not supported.  A possible
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1226:        # FIXME: currently tan(pi/2) return zoo
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_delta_functions.py:37:    # FIXME: this is generally undefined @ x=0
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_bessel.py:514:    # FIXME: could have these return NaN; for now just fix infinite recursion
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1424:            # FIXME: This should probably be handled with something like:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:152:    # FIXME: This doesn't yet work:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:120:    contravariant and covariant Idx subclasses.  (FIXME: this is not yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:150:    # FIXME: symmetries from power needs to check special cases, else nothing
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:168:    FIXME: Add support for Numpy broadcasting
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:196:        # FIXME: search for symmetries
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:279:            # FIXME:  No support for Piecewise yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:295:            "FIXME: No specialized handling of type %s" % type(expr))
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:449:        # FIXME:  No support for Piecewise yet
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:469:        "FIXME: No specialized handling of type %s" % type(expr))
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:249:    "complex": DataType("double", "COMPLEX*16", "complex", "", "", "float") #FIXME:
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1530:        # FIXME: this is probably general enough for other high-level
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen.py:16:#FIXME: Fails due to circular import in with core
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:85:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:235:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:83:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:225:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:89:    # FIXME: how to pass inline to the RustCodePrinter?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:248:    # FIXME: how to pass inline to the RustCodePrinter?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:911:    # FIXME: The solution here should be O((x-2)**3) so is incorrect
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:929:    # FIXME: Solution should be O((x+2)**6)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:948:    # FIXME: checkodesol fails for this solution...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:956:    # FIXME: checkodesol fails for this solution...
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2480:    # FIXME: assert checksysodesol(eq3, sol3) == (True, [0, 0])
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2485:    # FIXME: assert checksysodesol(eq4, sol4) == (True, [0, 0])
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2516:    # FIXME: assert checksysodesol(eq1, sol1) == (True, [0, 0, 0])
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2524:    # FIXME: assert checksysodesol(eq2, sol2) == (True, [0, 0, 0])
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/recurr.py:564:            # FIXME: The call to rsolve_ratio below should suffice (rsolve_poly
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:937:    # FIXME: Find lcm() of all the divisors and divide with it, instead of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/paulialgebra.py:144:    # FIXME don't work for -I*Pauli(2)*Pauli(3)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/hep/gamma_matrices.py:315:    gctr = 4  # FIXME specific for d=4
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2221:    FIXME: This is a bottle-neck, can we do it faster?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2758:        # FIXME: If we arrive here, there are no ordered dummies. A method to
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/external/tests/test_codegen.py:184:            "FIXME: filename extension unknown for language: %s" % language)
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/maple.py:8:FIXME: This module is still under actively developed. Some functions may be not completed.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/julia.py:68:    # assignment (if False).  FIXME: this should be looked a more carefully
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:85:    # assignment (if False).  FIXME: this should be looked a more carefully
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:258:        # FIXME: how to do better, e.g., for octave_code(2*GoldenRatio)?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1375:        # FIXME: Refactor this code and matrix into some tabular environment.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1442:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1490:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:243:    # FIXME: is it worth worrying about this?  Its not wrong, just
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:358:    # FIXME?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:339:    # FIXME: sT fails because Cycle is not immutable and calling srepr(Cycle(1, 2))
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:184:    # FIXME: is it worth worrying about this?  Its not wrong, just
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:293:    # FIXME?
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:243:                            "FIXME: no support for contractions in factor yet")
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:255:                        # syntax is currently undefined.  FIXME: What would be
./core/py/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:261:                            raise ValueError("FIXME: lhs present in rhs,\
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:186:        # FIXME this is kind of a hack, but we will jump to the previous keyframe
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/autoaugment.py:103:# FIXME: Eliminate copy-pasted code for fill standardization and _augmentation_space() by moving stuff on a base class
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:74:            # FIXME: Is this needed? SqueezeNet should only be called from the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:75:            # FIXME: squeezenet1_x() functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:76:            # FIXME: This checking is not done for the other models
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:491:        # FIXME We don't know if we should expect this to happen
./core/py/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1552:            # FIXME: why are there type ignores here? We support two signatures for json_schema_extra callables...
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:363:    FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:1403:            # FIXME: I want to make these keywords but still parse attributes.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:223:    # FIXME: use inheritance
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/julia.py:195:            # FIXME: This escape pattern is not perfect.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:536:            # FIXME: aren't the offsets wrong?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:998:            # FIXME: Use ABC lexer in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:41:            # FIXME when e is present, no decimal point needed
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:172:            # FIXME when e is present, no decimal point needed
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/typst.py:135:            # FIXME: make this work
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/utils/distributed.py:114:        # FIXME: verify that ROCm transform nccl to rccl
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/loss/binary_cross_entropy.py:44:            # FIXME should off/on be different for smoothing w/ BCE? Other impl out there differ
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/imagenet_info.py:40:            # FIXME at some point pretrained_cfg should include dataset-tag,
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:141:        # FIXME WIP, not completed. Downstream support in model needed for non-contiguous valid patches
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:154:            # patch dropout mode, completely remove dropped patches (FIXME needs downstream support in model)
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:324:                # FIXME we could vectorize patch mode across batch, worth the effort?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/dataset_factory.py:218:        # FIXME support more advance split cfg for ImageFolder/Tar datasets in the future
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_loader.py:376:            # FIXME add crop args when sequence transforms support crop modes
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_image_in_tar.py:89:        cache_tarinfo = True if tar_bytes > 10*1024**3 else False  # FIXME magic number, 10GB
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:210:            # _logger.info(f'shuffle seed: {self.seed}, {seed}, epoch: {epoch}')  # FIXME temporary
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:434:        # _logger.info(f'start {i}, {self.worker_id}')  # FIXME temporary debug
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:441:        # _logger.info(f'end {i}, {self.worker_id}')  # FIXME temporary debug
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:22:    # FIXME improve the selection right now just tfds prefix or fallback path, will need options to
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:40:        # FIXME support split here or in reader?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:146:        self.input_key = input_key  # FIXME support tuples / lists of inputs and targets and full range of Feature
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:179:        # FIXME need to determine if reinit_each_iter is necessary. I'm don't completely trust behaviour
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:249:                num_replicas_in_sync=self.dist_num_replicas  # FIXME does this arg have any impact?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/data/transforms_factory.py:146:            # FIXME integration of RKR is a WIP
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/kron.py:106:        deterministic: Deterministic behaviour across save / load (resume). FIXME slow, needs work
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adamp.py:33:        # FIXME this is a problem for PyTorch XLA
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/lars.py:106:                    # FIXME nested where required since logical and/or not working in PT XLA
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:187:    #@_use_grad_for_differentiable  # FIXME internal context mgr, can't use
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:454:#@_disable_dynamo_if_unsupported(single_tensor_fn=_single_tensor_adopt)  # FIXME internal context mgr, can't use
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/_param_groups.py:89:        # FIXME interface needs more work
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:87:        # FIXME try to check if momentum dtype is appropriate for device? Torch API not great for this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:119:                    # FIXME this is a bit of a hack, optimizer.load_state_dict appears to upcast
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:298:                # FIXME not 100% sure if this remains capturable?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/mars.py:183:                # FIXME add multi-tensor (if usage warrants), make more standard
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:267:                # FIXME not 100% sure if this remains capturable?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/lamb.py:229:                    # FIXME nested where required since logical and/or not working in PT XLA
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/optim/sgdw.py:92:    # FIXME figure out how to make _use_grad_for_differentiable interchangeable with no_grad decorator
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/mlp.py:180:            hidden_features = hidden_features // 2  # FIXME base reduction on gate property?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pool2d_same.py:23:    # FIXME how to deal with count_include_pad vs not for external padding?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/attention2d.py:136:            # FIXME dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/squeeze_excite.py:98:        x_se = x.mean((1, 2), keepdims=True)  # FIXME avg dim [1:n-1], don't assume 2D NHWC
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:183:# FIXME to remove, keeping for comparison for now
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:596:#     FIXME WIP
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/drop.py:137:        self.fast = fast  # FIXME finish comparisons of fast vs not
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/lambda_layer.py:127:            # FIXME relative pos embedding path not fully verified
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:74:    # FIXME add support for unflattened spatial dim?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:206:        # FIXME support nD
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/attention_pool.py:83:            # FIXME interpolate
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:67:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:81:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:87:#group_std = group_std_tpu  # FIXME TPU temporary
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:28:    assert k_size is None, 'Different q & k sizes not currently supported'  # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:39:    #     # FIXME different q vs k sizes is a WIP, need to better offset the two grids?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:98:        src_size = (src_size, src_size)  # FIXME could support non-equal src if argument passed
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:481:        # FIXME change to not use one-hot/einsum?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:149:        # FIXME not clear if this stride behaviour is what the paper intended
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:189:        # FIXME figure out how to switch impl between this and conv2d if XLA being used.
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:146:    force_in_chs = int(options['fc']) if 'fc' in options else 0  # FIXME hack to deal with in_chs issue in TPU def
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:471:                    # FIXME s2d is a WIP
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_hub.py:132:    # FIXME I may change @ -> # and be parsed as fragment in a URI model name scheme
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:95:    aa_layer: Optional[str] = None  # FIXME support string factory for this
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:180:        # FIXME partial shortcut needed if first block handled as per original, not used for my current impl
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:298:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:310:        # FIXME this 1x1 expansion is pushed down into the cross and block paths in the darknet cfgs. Also,
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:377:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:444:                nn.AvgPool2d(2) if stride == 2 else nn.Identity(),   # FIXME dilation handling
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:525:    FIXME is there a more common 3x3 + 1x1 conv block to name this after?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:977:        # FIXME need to dilate self attn to have dilated network support, moop moop
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/res2net.py:62:            # FIXME this should probably have count_include_pad=False, but hurts original weights
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/hrnet.py:536:        assert output_stride == 32  # FIXME support dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:1428:    # FIXME experimental
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:2139:# FIXME experimental group cong / GroupNorm / EvoNorm experiments
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/fastvit.py:349:        # FIXME output of this act was not used in original impl, likely due to bug
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_helpers.py:24:    # FIXME replace with 3.9 stdlib fn when min at 3.9
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/ghostnet.py:657:        # FIXME init
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_manipulate.py:22:        # FIXME this a bit of a quick and dirty hack to skip classifier head params based on ordering
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv3.py:650:    FIXME untested, this is a preliminary impl of some FBNet-V3 variants.
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/regnet.py:1207:    # FIXME invalid weight <-> model match, mistake on their end
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/metaformer.py:552:                # FIXME not actually returning mlp hidden state right now as pre-logits.
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:313:        # FIXME MFSA and forward_intermediates overlap, they both take indices from specific features
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:336:        # FIXME see note above
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:375:                # FIXME fix grad checkpointing
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:563:            # FIXME fix grad checkpointing
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/dpn.py:173:        assert output_stride == 32  # FIXME look into dilation support
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/efficientvit_mit.py:1171:# FIXME will wait for v2 SAM models which are pending
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:93:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:147:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:236:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:344:        # FIXME dilation isn't right w/ extra ks > 1 convs
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:351:                dilation=dilation,  # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:379:                dilation=dilation,  # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:668:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_factory.py:26:        # FIXME may use fragment as revision, currently `@` in URI path
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_features.py:156:    FIXME This works well in eager Python but needs redesign for torchscript.
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_features.py:305:                    # FIXME this may need to be more generic / flexible for some nets
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_features.py:359:    FIXME this does not currently work with Torchscript, see FeatureHooks class
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/crossvit.py:73:        # FIXME look at relaxing size constraints
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/senet.py:11:FIXME I'm deprecating this model and moving them to ResNet as I don't want to maintain duplicate
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/vovnet.py:193:        assert output_stride == 32  # FIXME support dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/twins.py:431:        # FIXME slice block/pos_block if < max
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/twins.py:471:        # FIXME add block pruning
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:162:    # FIXME confirm we want 'channels last' in the patch channel layout, egg ph, ph, C instead of C, ph, hw
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:455:            # k = h << 16 | w  # FIXME can get jit compat with this
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:459:            # h, w = k >> 16, k & 0xFFFF  # FIXME can get jit compat with this
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:1225:        # FIXME unfinished / untested
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/davit.py:589:        # FIXME generalize this structure to ClassifierHead
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/davit.py:787:        # FIXME cleaner approach to missing head norm?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:1772:        # hf_hub_id='timm/vit_base_patch32_clip_224.openai_ft_in12k_in1k',  # FIXME weight exists, need to push
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2668:        # FIXME Google FlexiViT pretrained models have a strong preference for bilinear patch / embed
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2674:    # FIXME attn pool (currently only in siglip) params removed if pool disabled, is there a better soln?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer_sam.py:590:                    # FIXME only apply to final? Need experiments
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/coat.py:551:            parallel_blocks=[  # FIXME (partially?) overlap parallel w/ serial blocks??
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:863:        # FIXME slice block/pos_block if < max
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:905:        # FIXME add stage pruning
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_registry.py:217:        # FIXME should this be default behaviour? or default to include_tags=True?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/pit.py:365:        # FIXME need to update resize for PiT impl
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/mlp_mixer.py:300:        # FIXME drop_path (stochastic depth scaling rule or all the same?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/_prune.py:98:            # FIXME extra checks to ensure this is actually the FC classifier layer and not a diff Linear layer?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:566:            # FIXME handle dilation of avg pool
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:676:        # FIXME handle dilation?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/edgenext.py:350:            # FIXME support dilation / output_stride
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/densenet.py:357:                (r'^features\.transition(\d+)', MATCH_PREV_GROUP)  # FIXME combine with previous denselayer
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/dla.py:280:        assert output_stride == 32  # FIXME support dilation
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:116:        meta_hidden_dim: int = 384,  # FIXME what's the optimal value?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:137:            drop=(0.125, 0.)  # FIXME should there be stochasticity, appears to 'overfit' without?
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:374:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:402:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:759:        # FIXME more experiments needed
./core/py/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:897:    # FIXME WIP determining if there's a better weight init
./core/py/pipeline/.venv/lib/python3.12/site-packages/h11/_writers.py:54:    # XX FIXME: could at least make an effort to pull out the status message
./core/py/pipeline/.venv/lib/python3.12/site-packages/h11/_events.py:310:# XX FIXME: "A recipient MUST ignore (or consider as an error) any fields that
./core/py/pipeline/.venv/lib/python3.12/site-packages/h11/_readers.py:186:            # XX FIXME: we discard chunk extensions. Does anyone care?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/mixture_same_family.py:120:        # FIXME this may have the wrong shape when support contains batched
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/wishart.py:38:        >>> # xdoctest: +SKIP("FIXME: scale_tril must be at least two-dimensional")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/multinomial.py:35:        >>> # xdoctest: +SKIP("FIXME: found invalid values")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1455:                # FIXME: Unfortunately, for Windows, we are missing a worker
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:475:    """FIXME: Temporarily replace std:: invocations of math functions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:220:    # FIXME: Once 3.7 is the minimum version, type annotate `other` per PEP 563
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/cpp_jit.py:81:    # FIXME: Remove when back testing is no longer required.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:647:        # FIXME: the docs say that persistent_id should only return a string
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:790:        # FIXME: the docs say that persistent_id should only return a string
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:531:    # FIXME should probably check that lengths and offset aren't both set, but
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5464:        assert not (is_causal and attn_mask is None), "FIXME: is_causal not implemented for need_weights"
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1073:# FIXME (by @ssnl): Improve adaptive pooling docs: specify what the input and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:923:    # FIXME: copy.deepcopy() is not defined on nn.module
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/channelshuffle.py:20:        >>> # xdoctest: +IGNORE_WANT("FIXME: incorrect want")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/_functions.py:79:            # FIXME: https://github.com/pytorch/pytorch/issues/78656 describes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1606:    >>> # xdoctest: +SKIP("FIXME: Would call backwards a second time")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1742:        >>> # xdoctest: +SKIP("FIXME: error in doctest")
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/forward_ad.py:92:    # FIXME: We specify that __debug__ must be True because
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:153:    # FIXME: support multiple parameter groups
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:341:    # FIXME(@mrshenli): support multiple nn.Module instances
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:342:    # FIXME(@mrshenli): support multiple Optiimzer instances
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:343:    # FIXME(@mrshenli): need to broadcast model to sync parameters
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:405:    # FIXME: Using symbolic tracing to work around in DTensor expand mode.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:438:        # FIXME(@mrshenli): functionalization does not work for our use
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:167:        # FIXME: allow other sharding schemas
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:31:    # FIXME(@mrshenli): for sqrt, this is only mathematically correct for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:430:        # FIXME(@wanchaol, @mrshenli): the above seems to accidentally captured
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:626:                        # FIXME(@mrshenli): This is a temporary solution enable
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:239:    # FIXME gloo doesn't support _allgather_base
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:373:    # FIXME (kumpera) torch.load fails if we wrap with io.BufferedReader
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:342:        # FIXME the type of planner is wrong in load_state_dict
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:547:    # FIXME record_stream doesn't work with non-cuda tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:308:                # FIXME: there are a few things that fall under this like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:389:    # FIXME: this is wrong when dim=None and one of the dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:665:            # FIXME: this can be wrong for situations where we have
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset11.py:1362:    # FIXME(justinchuby): We need to handle what happens when we call b.op on a node return
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1249:        # FIXME(justinchuby): can index be an int and not a value?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1875:            # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1886:            # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1941:            # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1956:        # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2514:        # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2586:        # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3122:    # FIXME(justinchuby): Get rid of the try catch here to improve readability
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3126:        # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4273:        # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:7177:        # FIXME(justinchuby): report correct name for symbolic being executed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:285:                # FIXME(justinchuby): Avoid catching Exception.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset12.py:368:        # FIXME(justinchuby): cond is unused?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:128:        # FIXME: Avoid importing onnxscript into torch
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:86:        # FIXME(justinchuby): Add the return type back once we know how to handle mypy
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:41:    # FIXME: Avoid importing onnx into torch.onnx.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:138:    # FIXME: Avoid importing onnx into torch.onnx.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:50:        # FIXME: This is a hack to tracing through if-else Python blocks.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:185:        # FIXME: Bug in `dynamo.export`. Sometimes outputs returned in 'list' instead of 'tuple'.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:187:        # FIXME: Bug in `dynamo.export`. Sometimes single function return is wrapped in list.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2119:# FIXME: currently returns integers for boolean tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2151:# FIXME: currently returns integers for boolean tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2183:# FIXME: currently returns integers for boolean tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:658:            # FIXME: Implement reductions for dense dimensions for ops with non-zero reduction identities
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:705:        # FIXME: temporary workaround for issue with bfloat16/float16 remove when acctype is implemented for scatter_reduce
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:736:    # FIXME: when dense dimensions are implemented for CSR tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:527:        # FIXME and they have the same dtype, device, etc
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/testing/__init__.py:19:# from .testing import assert_allclose    # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:405:    # FIXME(Mario) Doesn't np.quantile accept a tuple?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:1683:            # FIXME: CUDA Graph does not work well with CUPTI teardown.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:942:        # FIXME (tmanlaibaatar)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:65:FIXME_inductor_non_strict = {
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5218:            # FIXME: Add testing for gloo/CUDA
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:239:        # FIXME dist.barrier deadlocks with multiple threads and NCCL: https://github.com/pytorch/pytorch/issues/95895
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:241:        # FIXME can't use the above all_reduce as it causes hangs on bionic and focal. It hangs:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py:28:        # FIXME Once we consolidate the error messages returned by the
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4667:    # FIXME Merge this test with the corresponding one in RpcTest.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4688:    # FIXME Merge this test with the corresponding one in RpcTest.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4712:    # FIXME Merge this test with the corresponding one in RpcTest.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4745:        # FIXME We wait until the remote completed creating the OwnerRRef
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4795:        # FIXME We wait until the remote completed creating the OwnerRRef
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2637:            # FIXME: remove after implementing reflection pad 3d
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3412:        self.FIXME_no_cuda_gradgrad_comparison = \
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3413:            kwargs.get('FIXME_no_cuda_gradgrad_comparison', False)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3547:            if self.check_gradgrad and not self.FIXME_no_cuda_gradgrad_comparison:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2635:                # FIXME: figure out the flaky -1024 anti-leaks on windows. See #8044
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2763:                        from .dynamo_test_failures import FIXME_inductor_non_strict
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2764:                        strict_default = filename not in FIXME_inductor_non_strict
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3128:            # FIXME: `x` is a sparse view of `v`. Currently rebase_history for
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4054:# FIXME: modernize these to be consistent with make_tensor
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4341:# FIXME: remove this by updating test suites using it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4350:# FIXME: remove this by updating test suites using it
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4404:# FIXME: improve load_tests() documentation here
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4434:# FIXME: document this and move it to test_serialization
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4516:# FIXME: delete this
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4524:# FIXME: move to test_sparse or sparse utils
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:119:# FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1854:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2417:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:153:                    # FIXME: for now reductions with non-zero reduction identity and
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:454:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:530:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:643:            # FIXME: amax reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:652:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:653:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:682:            # FIXME: amax reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:691:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:692:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:792:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:801:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:873:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:917:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:992:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:1163:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:97:        # FIXME: Causes floating point exception on ROCm
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2243:        # FIXME add an override for JIT and revert 0. back to 0
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3023:    # FIXME: eager and ref impl throw different types of errors
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4021:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4081:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4218:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8146:    # FIXME: Derivative wrt. weight not implemented
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12045:               # FIXME: geqrf can't forward with complex inputs that require grad
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14037:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14060:               # FIXME: both derivatives are implemented incorrectly
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14062:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14680:            # FIXME: intentionally misreports dtypes
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14682:            # FIXME: numpy reference diverges: Comparing (nan+nanj) and (-0+0j)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15015:                        # FIXME: incorrectly tries to pass a rhs scalar
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15055:                        # FIXME: incorrectly tries to pass a rhs scalar
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15342:                        # FIXME Complex values error with: Greatest absolute difference: nan at index
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15385:                        # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18994:            # FIXME: uint8 input returns uint8 instead of bool
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19006:            # FIXME: uint8 input returns uint8 instead of bool
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19019:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19034:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19067:            # FIXME: count_nonzero does not accept keepdim kwarg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19075:            # FIXME: dim=[] reduces all dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19084:        # FIXME: mean needs 'dim' parameter when using the 'out' overload.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19095:            # FIXME: mean does not support passing keepdim without passing dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19097:            # FIXME: mean reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19100:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19123:            # FIXME: prod reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19126:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19151:            # FIXME: cannot specify keepdim without dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19153:            # FIXME: dim=[] reduces all dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19156:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19178:            # FIXME: dim=[] reduces all dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19199:            # FIXME: cannot specify keepdim without dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19201:            # FIXME: dim=[] reduces all dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19204:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19226:            # FIXME: dim=[] reduces all dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19248:            # FIXME: prod does not support passing keepdim without passing dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19250:            # FIXME: prod reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19253:            # FIXME: prod does not support passing None to dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19260:            # FIXME: ValueError: The data in MaskedTensor a and Tensor b do not match
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19283:            # FIXME: sum does not support passing keepdim without passing dim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19285:            # FIXME: sum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19288:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19313:            # FIXME: nansum reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19316:            # FIXME: flaky test so skipped instead of xfailed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19643:            # FIXME: CUDA driver API confirmed a leak in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19665:            # FIXME: CUDA driver API confirmed a leak in
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21188:            # FIXME output 0: meta disagrees with real impl
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21306:            # FIXME output 0: meta disagrees with real impl
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21632:            # FIXME: enable dtype-based tolerances in test_ops.py:TestCommon._ref_test_helper
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21851:        # FIXME: doesn't support chalf
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21864:        # FIXME: doesn't support chalf
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21900:            # FIXME: AssertionError: RuntimeError not raised
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22180:            # FIXME: uint8 input returns uint8 instead of bool
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22191:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22203:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22214:            # FIXME: uint8 input returns uint8 instead of bool
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22224:            # FIXME: count_nonzero does not accept keepdim kwarg
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22239:            # FIXME: dim=[] reduces all dimensions
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22249:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22261:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22266:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22286:            # FIXME: doesn't test out behavior properly for this operator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22288:            # FIXME: mean reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22292:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22334:            # FIXME: doesn't test out behavior properly for this operator
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22336:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22341:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22352:            # FIXME: reduces all dimensions when dim=[]
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22357:            # FIXME: improve precision
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22417:            # FIXME: shouldn't check empty results
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22447:            # FIXME: should not compare results of empty_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22503:            # FIXME: should not compare results of empty_like
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:709:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:800:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:893:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:202:            # FIXME that's a crude approximation for promoting args
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2983:        # FIXME: Calling to_device(x, device) should work but
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3662:    # FIXME: in some cases we sill need to explicitly pass in ordered_kwargs_for_cpp_kernel
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4956:        # FIXME: no need to do this after we switch to the torchgen-ed C shim
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1252:        # FIXME: passing `-fopenmp` adds libgomp.so to the generated shared library's dependencies.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1837:            # FIXME handle embedded optional types?
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2628:        # FIXME: This is not exactly right for cases like below:
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/onnxrt.py:15:    # FIXME(abock): update test/dynamo/test_backends.py to call is_onnxrt_backend_supported()
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1417:        # FIXME (tmanlaibaatar) this is utter hack to unblock HuggingFace export
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3355:            obj, obj.__name__, getfile(obj), obj.__code__  # type: ignore[union-attr] # FIXME Add MethodType.__code__ to typeshed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:920:      // FIXME We should always extract DataPtrs, in order to catch the case of
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:116:  // FIXME: stride should be optional
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cuda/DistributionTemplates.h:106: * FIXME: Can we specialize elementwise_kernel and launch_kernel in Loops.cuh
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:259:      // FIXME: remove magic > 0 after we ensure no models were serialized with -1 defaults.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/ScalarOps.h:28:// FIXME: this should be (and was) Scalar::toTensor, but there is currently no
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:749:/// \todo FIXME: remove when \c constexpr becomes really \c constexpr
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:154:    this->Size = this->Capacity = 0; // FIXME: Setting Capacity to 0 is suspect.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:768:  // FIXME: Consider assigning over existing elements, rather than clearing &
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1106:  // FIXME: don't do this if they're efficiently moveable.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1169:  // FIXME: this may not actually make any sense if we can efficiently move
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/device_utils.h:10:// FIXME: Currently, CPU and CUDA backend are mutually exclusive.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroupGloo.hpp:68:  // FIXME: This probably should be called WorkGloo since the work is executed
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/detail/TensorDataContainer.h:31:// FIXME: There is no `operator<<` overload for `at::kBFloat16` type,
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:125:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:130:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:185:                    # FIXME: CUDA Graph does not work well with CUPTI teardown.
./core/py/pipeline/.venv/lib/python3.12/site-packages/h2/connection.py:1808:            # FIXME: Should we split this into one event per active stream?
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/util/response.py:99:    # FIXME: Can we do this somehow without accessing private httplib _method?
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:782:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:787:                # FIXME: Is there a better way to differentiate between SSLErrors?
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:1051:        # FIXME, this method's type doesn't say returning None is possible
./core/py/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:1219:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2031:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3201:    # FIXME: 'Distribution.insert_on' is too complex (13)
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:326:        # FIXME: handle?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:327:        # FIXME: magic signatures?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/build_env.py:200:                # FIXME: Consider direct URL?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:480:            # FIXME: need a test for this elif block
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:371:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:259:            # FIXME: it would be nice to keep track of the source
./core/py/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:631:            # FIXME: https://github.com/pypa/pip/issues/11943
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:466:            # FIXME: Remove this after figuring out CI job failures related to min, max, mean
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:67:    # FIXME: figure out a better way when we support sparse tensors in jit
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:98:    # FIXME: clone indices on construction.
./core/py/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:252:# FIXME: Ideally these functions should be methods on Type class, but we have a
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:901:# FIXME: Fails _cdfvec
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:1294:# FIXME: problems sampling.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:9003:    # FIXME: this is only a quick-and-dirty test of a quick-and-dirty bugfix.
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:799:            # FIXME: implement this somewhen, for now go with builtin values
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:800:            # FIXME: calc optimal lwork by calling ?hbevd(lwork=-1)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:805:            # FIXME: implement this somewhen, for now go with builtin values
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:903:    # FIXME: suppress?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:904:    # FIXME: how to catch the _fblas.error?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:942:    # prints '0-th dimension must be fixed to 3 but got 5', FIXME: suppress?
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:740:        # FIXME Jitted JAX arrays do not have a device attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:325:        # FIXME https://github.com/jax-ml/jax/issues/27418
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/differentiate/tests/test_differentiate.py:585:        # FIXME https://github.com/scipy/scipy/pull/22320#discussion_r1914898175
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_constraints.py:492:    # FIXME: when bugs in VectorFunction/LinearVectorFunction are worked out,
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__dual_annealing.py:69:    # FIXME: there are some discontinuities in behaviour as a function of `qv`,
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_ode.py:392:            # FIXME: this really should be raise an exception. Will that break
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/conftest.py:504:    # FIXME: populate the dict once
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/tests/test_kdtree.py:634:        # raises an exception for bug 870 (FIXME: Does it?)
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/_kdtree.py:913:        result = np.empty((m,n),dtype=float)  # FIXME: figure out the best dtype
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_delegators.py:21:         sig = "( FIXME )"
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:110:        # FIXME: for complex types, the computations are done in
./core/py/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_signaltools.py:4339:    # FIXME: Can this function be replaced with an appropriate
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1007:    #FIXME the 'e' dtype might work in future
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_mem_policy.py:12:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:6159:        # FIXME:
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_interface.py:131:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:19:#FIXME: this will probably change when we require full C99 campatibility
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1129:        # FIXME cinf not tested.
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1774:                        reason='failures on 32-bit Python, see FIXME below')
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1818:        # FIXME: NAN raises FP invalid exception:
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1821:        # FIXME: skipped on MSVC:32-bit during switch to Meson, 10 cases fail
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:2794:            # FIXME: a not used
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1758:     * FIXME: This should check for a flag on the data-type that
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:236:        # FIXME: This seems like it will copy strings around
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/core.py:2839:            # FIXME: should we set `_data._sharedmask = True`?
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./core/py/pipeline/.venv/lib/python3.12/site-packages/numpy/conftest.py:73:#FIXME when yield tests are gone.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/image_to_text.py:204:        # FIXME: We need to pop here due to a difference in how `generation.py` and `generation.tf_utils.py`
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:380:            # FIXME: ydshieh and/or Narsil
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_gguf_pytorch_utils.py:376:    # FIXME: Currently this implementation is only for flan-t5 architecture.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/protein.py:85:                    seq[i] = "X"  # FIXME: strings are immutable
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:472:        # FIXME:
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:241:        # FIXME:
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics3/image_processing_idefics3.py:229:# FIXME Amy: make a more general crop function that isn't just centre crop
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/image_processing_smolvlm.py:226:# FIXME Amy: make a more general crop function that isn't just centre crop
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/image_processing_idefics2.py:125:# FIXME Amy: merge this function with the one in image_transforms.py
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1653:        # FIXME h_boxes takes the last one computed, keep this in mind
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:426:        # FIXME max_tokens_to_generate is embedded into this processor's call.
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:539:        # FIXME - We hard code "pt" here because the rest of the processing assumes torch tensors
./core/py/pipeline/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1958:        # FIXME h_boxes takes the last one computed, keep this in mind
./core/py/pipeline/.venv/lib/python3.12/site-packages/joblib/logger.py:144:            # FIXME: Too much logic duplicated
./core/py/pipeline/.venv/lib/python3.12/site-packages/boto3/exceptions.py:100:# FIXME: Backward compatibility
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:911:        "check_estimators_empty_data_messages": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:912:        "check_estimators_nan_inf": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:913:        "check_estimator_sparse_array": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:914:        "check_estimator_sparse_matrix": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:915:        "check_fit1d": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:916:        "check_fit2d_predict1d": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:917:        "check_complex_data": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:918:        "check_fit2d_1feature": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:925:        "check_estimators_overwrite_params": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:926:        "check_estimators_nan_inf": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:927:        "check_dont_overwrite_parameters": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:966:        "check_estimators_nan_inf": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:967:        "check_classifiers_one_label_sample_weights": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:968:        "check_fit2d_1feature": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:976:        "check_estimators_nan_inf": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:977:        "check_classifiers_one_label_sample_weights": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:978:        "check_fit2d_1feature": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1216:        "check_dict_unchanged": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1280:                    "check_n_features_in_after_fitting": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1281:                    "check_dataframe_column_names_consistency": "FIXME",
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1392:# FIXME: this test should be uncommented when the checks will be granular
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1397:    # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/tests/test_gpr.py:760:    # FIXME: before fitting, the estimator does not have information regarding
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_common.py:98:    # FIXME: we can introduce equal_nan=True in recent version of numpy.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:117:        eps = np.finfo(np.float32).eps  # FIXME: This is quite large!
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:517:                # FIXME: we could consider to support multiclass-multioutput if
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:175:            # FIXME: We temporarily bypass this test. This is due to the fact
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:691:    # FIXME: the following snippet does not yield the same results on 32 bits
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_common.py:252:# FIXME: we should move this test in `estimator_checks` once we are able
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_kde.py:127:    # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:623:        # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1164:        # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/tests/test_from_model.py:483:    # FIXME: we cannot validate the upper bound of the attribute at transform
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:606:        # FIXME We compute all the distances, while we could have only computed
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:278:# FIXME; this test is broken with different random states, needs to be revisited
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/compose/_target.py:281:        # FIXME: a FunctionTransformer can return a 1D array even when validate
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:109:        # FIXME: the current Cython implementation is too slow for a large number of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:698:    # FIXME: the current Cython implementation is too slow for a large number of
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/tests/test_glm.py:376:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:330:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:392:        # FIXME: Same as in test_ridge_regression_unpenalized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:447:        # FIXME: Same as in test_ridge_regression_unpenalized.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1551:        # FIXME
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1558:        # FIXME: SAGA on sparse data fits the intercept inaccurately with the
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/cross_decomposition/tests/test_pls.py:78:    # FIXME: one would expect y_trans == pls.y_scores_ but this is not
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:2540:# FIXME: Replace this test with a full `check_estimator` once we have API only
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/multiclass.py:1207:        # FIXME: there are more elaborate methods than generating the codebook
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_multiclass.py:903:# FIXME: we should move this test in `estimator_checks` once we are able
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:745:# FIXME: we should move this test in `estimator_checks` once we are able
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:65:    # FIXME Remove this test once the more general partial_fit tests are merged
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:308:    # FIXME: write a test to show this.
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:1718:# FIXME: Replace this test with a full `check_estimator` once we have API only
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:657:        # FIXME Jitted JAX arrays do not have a device attribute
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_funcs.py:715:    # FIXME https://github.com/data-apis/array-api-compat/pull/231
./core/py/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1728:        # FIXME: np.float16 could be preserved if _inplace_csr_row_normalize_l2
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/tests/test_weighted.py:890:        # FIXME nx.goldberg_radzik(D, 1)
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:713:                # FIXME directed graphs
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:809:            # FIXME directed graphs
./core/py/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:859:                    # FIXME directed graphs
./core/py/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:378:    # FIXME: error_dps should not be necessary
./utilities/ts/node_modules/typescript/lib/typescriptServices.js:148691:            // FIXME: getter and setter use the same symbol. And it is rare to use only setter without getter, so in most cases the symbol always has getter flag.
./utilities/ts/node_modules/typescript/lib/typescript.js:148691:            // FIXME: getter and setter use the same symbol. And it is rare to use only setter without getter, so in most cases the symbol always has getter flag.
./utilities/ts/node_modules/typescript/lib/tsserver.js:148282:            // FIXME: getter and setter use the same symbol. And it is rare to use only setter without getter, so in most cases the symbol always has getter flag.
./utilities/ts/node_modules/typescript/lib/tsserverlibrary.js:148700:            // FIXME: getter and setter use the same symbol. And it is rare to use only setter without getter, so in most cases the symbol always has getter flag.
./.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1552:            # FIXME: why are there type ignores here? We support two signatures for json_schema_extra callables...
./.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:363:    FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.
./.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:1403:            # FIXME: I want to make these keywords but still parse attributes.
./.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:223:    # FIXME: use inheritance
./.venv/lib/python3.12/site-packages/pygments/lexers/julia.py:195:            # FIXME: This escape pattern is not perfect.
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:536:            # FIXME: aren't the offsets wrong?
./.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:998:            # FIXME: Use ABC lexer in the future
./.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:41:            # FIXME when e is present, no decimal point needed
./.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:172:            # FIXME when e is present, no decimal point needed
./.venv/lib/python3.12/site-packages/pygments/lexers/typst.py:135:            # FIXME: make this work
./.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./.venv/lib/python3.12/site-packages/h11/_writers.py:54:    # XX FIXME: could at least make an effort to pull out the status message
./.venv/lib/python3.12/site-packages/h11/_events.py:310:# XX FIXME: "A recipient MUST ignore (or consider as an error) any fields that
./.venv/lib/python3.12/site-packages/h11/_readers.py:186:            # XX FIXME: we discard chunk extensions. Does anyone care?
./.venv/lib/python3.12/site-packages/passlib/utils/compat/__init__.py:165:        # FIXME: there has to be a better way to do this
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:882:        # FIXME: this may not work for hashes with non-standard settings.
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:914:            # FIXME: this may overestimate size due to padding bits (e.g. bcrypt)
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:915:            # FIXME: this will be off by 1 for case-insensitive hashes.
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1501:        # FIXME: this may overestimate size due to padding bits
./.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1502:        # FIXME: this will be off by 1 for case-insensitive hashes.
./.venv/lib/python3.12/site-packages/passlib/context.py:1115:        # FIXME: if multiple hashes could match (e.g. lmhash vs nthash)
./.venv/lib/python3.12/site-packages/passlib/context.py:1215:    # FIXME: altering the configuration of this object isn't threadsafe,
./.venv/lib/python3.12/site-packages/passlib/context.py:1663:    # FIXME: this function suffered some bitrot in 1.6.1,
./.venv/lib/python3.12/site-packages/passlib/handlers/fshp.py:78:    # FIXME: should probably use different default rounds
./.venv/lib/python3.12/site-packages/passlib/handlers/windows.py:126:            # FIXME: just trusting ascii upper will work?
./.venv/lib/python3.12/site-packages/passlib/handlers/oracle.py:78:        # FIXME: not sure how oracle handles unicode.
./.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:241:            # FIXME: if salt was provided by user, this message won't be
./.venv/lib/python3.12/site-packages/passlib/handlers/mysql.py:67:        # FIXME: no idea if mysql has a policy about handling unicode passwords
./.venv/lib/python3.12/site-packages/passlib/handlers/mysql.py:117:        # FIXME: no idea if mysql has a policy about handling unicode passwords
./.venv/lib/python3.12/site-packages/passlib/handlers/phpass.py:118:        # FIXME: can't find definitive policy on how phpass handles non-ascii.
./.venv/lib/python3.12/site-packages/passlib/handlers/md5_crypt.py:263:    # FIXME: can't find definitive policy on how md5-crypt handles non-ascii.
./.venv/lib/python3.12/site-packages/passlib/handlers/des_crypt.py:349:        # FIXME: this technically might generate a rounds value 1 larger
./.venv/lib/python3.12/site-packages/passlib/crypto/des.py:583:# FIXME: more properly named _uint8_struct...
./.venv/lib/python3.12/site-packages/passlib/crypto/_md4.py:67:    # FIXME: make this follow hash object PEP better.
./.venv/lib/python3.12/site-packages/passlib/crypto/_md4.py:68:    # FIXME: this isn't threadsafe
./.venv/lib/python3.12/site-packages/passlib/apache.py:408:    # FIXME: htpasswd doc says passwords limited to 255 chars under Windows & MPE,
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:925:    # FIXME: fix UT framework - this hash is sensitive to password case, but verify() is not
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1646:        # FIXME: password unknown
./.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1652:        # FIXME: password unknown
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:114:    # FIXME: I've been lazy, should probably just add 'relaxed' kwd
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:399:            # FIXME: this ignores 'msg'
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:455:                # FIXME: should use a stdlib call to resolve this back
./.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1370:        # FIXME: this may be off for case-insensitive hashes, but that accounts
./.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:366:        # FIXME: this isn't failing even in broken case, need to figure out
./.venv/lib/python3.12/site-packages/passlib/tests/test_crypto_digest.py:221:    if not JYTHON: # FIXME: find out why not jython, or reenable this.
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1038:##    # FIXME: this generic wrapper doesn't handle custom settings
./.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1039:##    # FIXME: genconfig / genhash not supported.
./.venv/lib/python3.12/site-packages/passlib/ifc.py:139:        # FIXME:  need stub for classes that define .encrypt() instead ...
./.venv/lib/python3.12/site-packages/urllib3/util/response.py:99:    # FIXME: Can we do this somehow without accessing private httplib _method?
./.venv/lib/python3.12/site-packages/urllib3/response.py:782:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./.venv/lib/python3.12/site-packages/urllib3/response.py:787:                # FIXME: Is there a better way to differentiate between SSLErrors?
./.venv/lib/python3.12/site-packages/urllib3/response.py:1051:        # FIXME, this method's type doesn't say returning None is possible
./.venv/lib/python3.12/site-packages/urllib3/response.py:1219:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./.venv/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2031:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3201:    # FIXME: 'Distribution.insert_on' is too complex (13)
./.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:326:        # FIXME: handle?
./.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:327:        # FIXME: magic signatures?
./.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./.venv/lib/python3.12/site-packages/pip/_internal/build_env.py:200:                # FIXME: Consider direct URL?
./.venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./.venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:480:            # FIXME: need a test for this elif block
./.venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:371:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:259:            # FIXME: it would be nice to keep track of the source
./.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:631:            # FIXME: https://github.com/pypa/pip/issues/11943
./.venv/lib/python3.12/site-packages/paho/mqtt/client.py:1474:        # FIXME: doesn't account for weight
./.venv/lib/python3.12/site-packages/paho/mqtt/client.py:3359:                # FIXME - this doesn't deal with incorrectly large payloads
./.venv/lib/python3.12/site-packages/paho/mqtt/client.py:4218:        # FIXME: this should only be done if the message is known
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PixarImagePlugin.py:61:        # FIXME: to be continued...
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:178:                # FIXME: the fill decoder is not implemented
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:216:                # FIXME: jpeg tables are tile dependent; the prefix
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:78:# FIXME: add support for pilfont2 format (see FontFile.py)
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:133:        self.info = []  # FIXME: should be a dictionary
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:225:        # FIXME: use service provider instead
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageQt.py:140:        # FIXME - is this really the best way to do this?
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:152:            # FIXME: this may read whole file if not a text file
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:249:        self._fp = self.fp  # FIXME: hack
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:102:            # FIXME: fix Fill2 to properly support matte for I+F images
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:129:            # FIXME: should add a font repository
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/TiffTags.py:209:    # FIXME add more tags here
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/MpoImagePlugin.py:128:        self._fp = self.fp  # FIXME: hack
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageDraw2.py:54:        # FIXME: add support for bitmap fonts
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PdfImagePlugin.py:57:    # FIXME: Should replace ASCIIHexDecode with RunLengthDecode
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/SpiderImagePlugin.py:161:        self._fp = self.fp  # FIXME: hack
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PngImagePlugin.py:445:            icc_profile = None  # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:962:        # FIXME What about tagdata?
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:229:    raise NotImplementedError(msg)  # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:260:    # FIXME: supports GIMP gradients only
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:544:        # FIXME: take "new" parameters / other image?
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:1796:                # FIXME: use self.size here?
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:1932:            # FIXME: _imaging returns a confusing error message for this case
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/Image.py:2790:    # FIXME: the different transform methods need further explanation
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/MspImagePlugin.py:184:    header[12] = checksum  # FIXME: is this the right field?
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:341:            # FIXME: This is a hack to handle TIFF's JpegTables tag.
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:638:    # FIXME: make MAXBLOCK a configuration parameter
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/GifImagePlugin.py:120:        self._fp = self.fp  # FIXME: hack
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageOps.py:54:        # FIXME: apply to lookup table, not image data
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PSDraw.py:44:        # FIXME: incomplete
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/McIdasImagePlugin.py:55:            # FIXME: add memory map support
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PsdImagePlugin.py:40:    (7, 8): ("L", 1),  # FIXME: multilayer
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/XVThumbImagePlugin.py:17:# FIXME: make save work (this requires quantization support)
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PcdImagePlugin.py:49:        self._size = 768, 512  # FIXME: not correct for rotated images!
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/ImageCms.py:1103:        # FIXME: I get different results for the same data w. different
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/PcxImagePlugin.py:96:            # FIXME: hey, this doesn't work with the incremental loader !!!
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:110:        self.info["flashpix"] = s  # FIXME: value will change
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:238:    # FIXME: The quantization tables can be used to estimate the
./api/pipeline/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:798:    # FIXME: issue a warning if the wrong form is used (post-1.1.7)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1290:    # FIXME: simplify(E(X)) seems to hang without extended_positive=True
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/deltafunctions.py:144:            #FIXME: the second term tells whether is DeltaDirac or Derivative
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:544:    # FIXME: If alpha, beta are not declared as finite the line below hangs
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/facts.py:330:        # (?) FIXME this is only correct when b & c != null !
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1182:    # FIXME: The line below should be True rather than None
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1198:    # FIXME: Should the line below be True rather than None?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:2171:    # FIXME: This evaluates as:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:617:    # FIXME: could replace with random selection after test passes
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:643:    # FIXME: could replace with random selection after test passes
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:925:    # FIXME: The test below fails because (-infx).is_extended_positive is True
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1617:            # FIXME: is_positive/is_negative is False doesn't take account of
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:456:        # FIXME: Currently complex intervals are not supported.  A possible
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1226:        # FIXME: currently tan(pi/2) return zoo
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_delta_functions.py:37:    # FIXME: this is generally undefined @ x=0
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_bessel.py:514:    # FIXME: could have these return NaN; for now just fix infinite recursion
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1424:            # FIXME: This should probably be handled with something like:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:152:    # FIXME: This doesn't yet work:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:120:    contravariant and covariant Idx subclasses.  (FIXME: this is not yet
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:150:    # FIXME: symmetries from power needs to check special cases, else nothing
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:168:    FIXME: Add support for Numpy broadcasting
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:196:        # FIXME: search for symmetries
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:279:            # FIXME:  No support for Piecewise yet
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:295:            "FIXME: No specialized handling of type %s" % type(expr))
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:449:        # FIXME:  No support for Piecewise yet
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:469:        "FIXME: No specialized handling of type %s" % type(expr))
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:249:    "complex": DataType("double", "COMPLEX*16", "complex", "", "", "float") #FIXME:
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1530:        # FIXME: this is probably general enough for other high-level
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen.py:16:#FIXME: Fails due to circular import in with core
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:85:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:235:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:83:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:225:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:89:    # FIXME: how to pass inline to the RustCodePrinter?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:248:    # FIXME: how to pass inline to the RustCodePrinter?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:911:    # FIXME: The solution here should be O((x-2)**3) so is incorrect
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:929:    # FIXME: Solution should be O((x+2)**6)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:948:    # FIXME: checkodesol fails for this solution...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:956:    # FIXME: checkodesol fails for this solution...
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2480:    # FIXME: assert checksysodesol(eq3, sol3) == (True, [0, 0])
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2485:    # FIXME: assert checksysodesol(eq4, sol4) == (True, [0, 0])
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2516:    # FIXME: assert checksysodesol(eq1, sol1) == (True, [0, 0, 0])
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2524:    # FIXME: assert checksysodesol(eq2, sol2) == (True, [0, 0, 0])
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/recurr.py:564:            # FIXME: The call to rsolve_ratio below should suffice (rsolve_poly
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:937:    # FIXME: Find lcm() of all the divisors and divide with it, instead of
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/paulialgebra.py:144:    # FIXME don't work for -I*Pauli(2)*Pauli(3)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/hep/gamma_matrices.py:315:    gctr = 4  # FIXME specific for d=4
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2221:    FIXME: This is a bottle-neck, can we do it faster?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2758:        # FIXME: If we arrive here, there are no ordered dummies. A method to
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/external/tests/test_codegen.py:184:            "FIXME: filename extension unknown for language: %s" % language)
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/maple.py:8:FIXME: This module is still under actively developed. Some functions may be not completed.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/julia.py:68:    # assignment (if False).  FIXME: this should be looked a more carefully
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:85:    # assignment (if False).  FIXME: this should be looked a more carefully
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:258:        # FIXME: how to do better, e.g., for octave_code(2*GoldenRatio)?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1375:        # FIXME: Refactor this code and matrix into some tabular environment.
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1442:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1490:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:243:    # FIXME: is it worth worrying about this?  Its not wrong, just
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:358:    # FIXME?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:339:    # FIXME: sT fails because Cycle is not immutable and calling srepr(Cycle(1, 2))
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:184:    # FIXME: is it worth worrying about this?  Its not wrong, just
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:293:    # FIXME?
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:243:                            "FIXME: no support for contractions in factor yet")
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:255:                        # syntax is currently undefined.  FIXME: What would be
./api/pipeline/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:261:                            raise ValueError("FIXME: lhs present in rhs,\
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/io/video.py:186:        # FIXME this is kind of a hack, but we will jump to the previous keyframe
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/transforms/autoaugment.py:103:# FIXME: Eliminate copy-pasted code for fill standardization and _augmentation_space() by moving stuff on a base class
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:74:            # FIXME: Is this needed? SqueezeNet should only be called from the
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:75:            # FIXME: squeezenet1_x() functions
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:76:            # FIXME: This checking is not done for the other models
./api/pipeline/.venv/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:491:        # FIXME We don't know if we should expect this to happen
./api/pipeline/.venv/lib/python3.12/site-packages/pywt/_functions.py:89:    # FIXME: this function should really use scipy.integrate.quad
./api/pipeline/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1552:            # FIXME: why are there type ignores here? We support two signatures for json_schema_extra callables...
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:363:    FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:1403:            # FIXME: I want to make these keywords but still parse attributes.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:223:    # FIXME: use inheritance
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/julia.py:195:            # FIXME: This escape pattern is not perfect.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:536:            # FIXME: aren't the offsets wrong?
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:998:            # FIXME: Use ABC lexer in the future
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:41:            # FIXME when e is present, no decimal point needed
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:172:            # FIXME when e is present, no decimal point needed
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/lexers/typst.py:135:            # FIXME: make this work
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./api/pipeline/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/pipeline/.venv/lib/python3.12/site-packages/timm/utils/distributed.py:114:        # FIXME: verify that ROCm transform nccl to rccl
./api/pipeline/.venv/lib/python3.12/site-packages/timm/loss/binary_cross_entropy.py:44:            # FIXME should off/on be different for smoothing w/ BCE? Other impl out there differ
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/imagenet_info.py:40:            # FIXME at some point pretrained_cfg should include dataset-tag,
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:141:        # FIXME WIP, not completed. Downstream support in model needed for non-contiguous valid patches
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:154:            # patch dropout mode, completely remove dropped patches (FIXME needs downstream support in model)
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:324:                # FIXME we could vectorize patch mode across batch, worth the effort?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/dataset_factory.py:218:        # FIXME support more advance split cfg for ImageFolder/Tar datasets in the future
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/naflex_loader.py:376:            # FIXME add crop args when sequence transforms support crop modes
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_image_in_tar.py:89:        cache_tarinfo = True if tar_bytes > 10*1024**3 else False  # FIXME magic number, 10GB
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:210:            # _logger.info(f'shuffle seed: {self.seed}, {seed}, epoch: {epoch}')  # FIXME temporary
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:434:        # _logger.info(f'start {i}, {self.worker_id}')  # FIXME temporary debug
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:441:        # _logger.info(f'end {i}, {self.worker_id}')  # FIXME temporary debug
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:22:    # FIXME improve the selection right now just tfds prefix or fallback path, will need options to
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:40:        # FIXME support split here or in reader?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:146:        self.input_key = input_key  # FIXME support tuples / lists of inputs and targets and full range of Feature
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:179:        # FIXME need to determine if reinit_each_iter is necessary. I'm don't completely trust behaviour
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:249:                num_replicas_in_sync=self.dist_num_replicas  # FIXME does this arg have any impact?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/data/transforms_factory.py:146:            # FIXME integration of RKR is a WIP
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/kron.py:106:        deterministic: Deterministic behaviour across save / load (resume). FIXME slow, needs work
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adamp.py:33:        # FIXME this is a problem for PyTorch XLA
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/lars.py:106:                    # FIXME nested where required since logical and/or not working in PT XLA
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:187:    #@_use_grad_for_differentiable  # FIXME internal context mgr, can't use
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:454:#@_disable_dynamo_if_unsupported(single_tensor_fn=_single_tensor_adopt)  # FIXME internal context mgr, can't use
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/_param_groups.py:89:        # FIXME interface needs more work
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:87:        # FIXME try to check if momentum dtype is appropriate for device? Torch API not great for this.
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:119:                    # FIXME this is a bit of a hack, optimizer.load_state_dict appears to upcast
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:298:                # FIXME not 100% sure if this remains capturable?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/mars.py:183:                # FIXME add multi-tensor (if usage warrants), make more standard
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:267:                # FIXME not 100% sure if this remains capturable?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/lamb.py:229:                    # FIXME nested where required since logical and/or not working in PT XLA
./api/pipeline/.venv/lib/python3.12/site-packages/timm/optim/sgdw.py:92:    # FIXME figure out how to make _use_grad_for_differentiable interchangeable with no_grad decorator
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/mlp.py:180:            hidden_features = hidden_features // 2  # FIXME base reduction on gate property?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pool2d_same.py:23:    # FIXME how to deal with count_include_pad vs not for external padding?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/attention2d.py:136:            # FIXME dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/squeeze_excite.py:98:        x_se = x.mean((1, 2), keepdims=True)  # FIXME avg dim [1:n-1], don't assume 2D NHWC
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:183:# FIXME to remove, keeping for comparison for now
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:596:#     FIXME WIP
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/drop.py:137:        self.fast = fast  # FIXME finish comparisons of fast vs not
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/lambda_layer.py:127:            # FIXME relative pos embedding path not fully verified
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:74:    # FIXME add support for unflattened spatial dim?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:206:        # FIXME support nD
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/attention_pool.py:83:            # FIXME interpolate
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:67:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:81:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:87:#group_std = group_std_tpu  # FIXME TPU temporary
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:28:    assert k_size is None, 'Different q & k sizes not currently supported'  # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:39:    #     # FIXME different q vs k sizes is a WIP, need to better offset the two grids?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:98:        src_size = (src_size, src_size)  # FIXME could support non-equal src if argument passed
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:481:        # FIXME change to not use one-hot/einsum?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:149:        # FIXME not clear if this stride behaviour is what the paper intended
./api/pipeline/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:189:        # FIXME figure out how to switch impl between this and conv2d if XLA being used.
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:146:    force_in_chs = int(options['fc']) if 'fc' in options else 0  # FIXME hack to deal with in_chs issue in TPU def
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:471:                    # FIXME s2d is a WIP
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_hub.py:132:    # FIXME I may change @ -> # and be parsed as fragment in a URI model name scheme
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:95:    aa_layer: Optional[str] = None  # FIXME support string factory for this
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:180:        # FIXME partial shortcut needed if first block handled as per original, not used for my current impl
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:298:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:310:        # FIXME this 1x1 expansion is pushed down into the cross and block paths in the darknet cfgs. Also,
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:377:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:444:                nn.AvgPool2d(2) if stride == 2 else nn.Identity(),   # FIXME dilation handling
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:525:    FIXME is there a more common 3x3 + 1x1 conv block to name this after?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:977:        # FIXME need to dilate self attn to have dilated network support, moop moop
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/res2net.py:62:            # FIXME this should probably have count_include_pad=False, but hurts original weights
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/hrnet.py:536:        assert output_stride == 32  # FIXME support dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:1428:    # FIXME experimental
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:2139:# FIXME experimental group cong / GroupNorm / EvoNorm experiments
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/fastvit.py:349:        # FIXME output of this act was not used in original impl, likely due to bug
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_helpers.py:24:    # FIXME replace with 3.9 stdlib fn when min at 3.9
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/ghostnet.py:657:        # FIXME init
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_manipulate.py:22:        # FIXME this a bit of a quick and dirty hack to skip classifier head params based on ordering
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv3.py:650:    FIXME untested, this is a preliminary impl of some FBNet-V3 variants.
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/regnet.py:1207:    # FIXME invalid weight <-> model match, mistake on their end
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/metaformer.py:552:                # FIXME not actually returning mlp hidden state right now as pre-logits.
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:313:        # FIXME MFSA and forward_intermediates overlap, they both take indices from specific features
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:336:        # FIXME see note above
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:375:                # FIXME fix grad checkpointing
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:563:            # FIXME fix grad checkpointing
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/dpn.py:173:        assert output_stride == 32  # FIXME look into dilation support
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/efficientvit_mit.py:1171:# FIXME will wait for v2 SAM models which are pending
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:93:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:147:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:236:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:344:        # FIXME dilation isn't right w/ extra ks > 1 convs
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:351:                dilation=dilation,  # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:379:                dilation=dilation,  # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:668:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_factory.py:26:        # FIXME may use fragment as revision, currently `@` in URI path
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_features.py:156:    FIXME This works well in eager Python but needs redesign for torchscript.
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_features.py:305:                    # FIXME this may need to be more generic / flexible for some nets
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_features.py:359:    FIXME this does not currently work with Torchscript, see FeatureHooks class
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/crossvit.py:73:        # FIXME look at relaxing size constraints
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/senet.py:11:FIXME I'm deprecating this model and moving them to ResNet as I don't want to maintain duplicate
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/vovnet.py:193:        assert output_stride == 32  # FIXME support dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/twins.py:431:        # FIXME slice block/pos_block if < max
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/twins.py:471:        # FIXME add block pruning
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:162:    # FIXME confirm we want 'channels last' in the patch channel layout, egg ph, ph, C instead of C, ph, hw
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:455:            # k = h << 16 | w  # FIXME can get jit compat with this
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:459:            # h, w = k >> 16, k & 0xFFFF  # FIXME can get jit compat with this
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:1225:        # FIXME unfinished / untested
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/davit.py:589:        # FIXME generalize this structure to ClassifierHead
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/davit.py:787:        # FIXME cleaner approach to missing head norm?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:1772:        # hf_hub_id='timm/vit_base_patch32_clip_224.openai_ft_in12k_in1k',  # FIXME weight exists, need to push
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2668:        # FIXME Google FlexiViT pretrained models have a strong preference for bilinear patch / embed
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2674:    # FIXME attn pool (currently only in siglip) params removed if pool disabled, is there a better soln?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/vision_transformer_sam.py:590:                    # FIXME only apply to final? Need experiments
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/coat.py:551:            parallel_blocks=[  # FIXME (partially?) overlap parallel w/ serial blocks??
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:863:        # FIXME slice block/pos_block if < max
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:905:        # FIXME add stage pruning
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_registry.py:217:        # FIXME should this be default behaviour? or default to include_tags=True?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/pit.py:365:        # FIXME need to update resize for PiT impl
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/mlp_mixer.py:300:        # FIXME drop_path (stochastic depth scaling rule or all the same?)
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/_prune.py:98:            # FIXME extra checks to ensure this is actually the FC classifier layer and not a diff Linear layer?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:566:            # FIXME handle dilation of avg pool
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:676:        # FIXME handle dilation?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/edgenext.py:350:            # FIXME support dilation / output_stride
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/densenet.py:357:                (r'^features\.transition(\d+)', MATCH_PREV_GROUP)  # FIXME combine with previous denselayer
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/dla.py:280:        assert output_stride == 32  # FIXME support dilation
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:116:        meta_hidden_dim: int = 384,  # FIXME what's the optimal value?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:137:            drop=(0.125, 0.)  # FIXME should there be stochasticity, appears to 'overfit' without?
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:374:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:402:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:759:        # FIXME more experiments needed
./api/pipeline/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:897:    # FIXME WIP determining if there's a better weight init
./api/pipeline/.venv/lib/python3.12/site-packages/h11/_writers.py:54:    # XX FIXME: could at least make an effort to pull out the status message
./api/pipeline/.venv/lib/python3.12/site-packages/h11/_events.py:310:# XX FIXME: "A recipient MUST ignore (or consider as an error) any fields that
./api/pipeline/.venv/lib/python3.12/site-packages/h11/_readers.py:186:            # XX FIXME: we discard chunk extensions. Does anyone care?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/mixture_same_family.py:120:        # FIXME this may have the wrong shape when support contains batched
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/wishart.py:38:        >>> # xdoctest: +SKIP("FIXME: scale_tril must be at least two-dimensional")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributions/multinomial.py:35:        >>> # xdoctest: +SKIP("FIXME: found invalid values")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1455:                # FIXME: Unfortunately, for Windows, we are missing a worker
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:475:    """FIXME: Temporarily replace std:: invocations of math functions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:220:    # FIXME: Once 3.7 is the minimum version, type annotate `other` per PEP 563
./api/pipeline/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/cpp_jit.py:81:    # FIXME: Remove when back testing is no longer required.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:647:        # FIXME: the docs say that persistent_id should only return a string
./api/pipeline/.venv/lib/python3.12/site-packages/torch/serialization.py:790:        # FIXME: the docs say that persistent_id should only return a string
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:531:    # FIXME should probably check that lengths and offset aren't both set, but
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5464:        assert not (is_causal and attn_mask is None), "FIXME: is_causal not implemented for need_weights"
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1073:# FIXME (by @ssnl): Improve adaptive pooling docs: specify what the input and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:923:    # FIXME: copy.deepcopy() is not defined on nn.module
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/channelshuffle.py:20:        >>> # xdoctest: +IGNORE_WANT("FIXME: incorrect want")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/_functions.py:79:            # FIXME: https://github.com/pytorch/pytorch/issues/78656 describes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1606:    >>> # xdoctest: +SKIP("FIXME: Would call backwards a second time")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1742:        >>> # xdoctest: +SKIP("FIXME: error in doctest")
./api/pipeline/.venv/lib/python3.12/site-packages/torch/autograd/forward_ad.py:92:    # FIXME: We specify that __debug__ must be True because
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:153:    # FIXME: support multiple parameter groups
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:341:    # FIXME(@mrshenli): support multiple nn.Module instances
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:342:    # FIXME(@mrshenli): support multiple Optiimzer instances
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:343:    # FIXME(@mrshenli): need to broadcast model to sync parameters
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:405:    # FIXME: Using symbolic tracing to work around in DTensor expand mode.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:438:        # FIXME(@mrshenli): functionalization does not work for our use
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:167:        # FIXME: allow other sharding schemas
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:31:    # FIXME(@mrshenli): for sqrt, this is only mathematically correct for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:430:        # FIXME(@wanchaol, @mrshenli): the above seems to accidentally captured
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:626:                        # FIXME(@mrshenli): This is a temporary solution enable
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:239:    # FIXME gloo doesn't support _allgather_base
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:373:    # FIXME (kumpera) torch.load fails if we wrap with io.BufferedReader
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:342:        # FIXME the type of planner is wrong in load_state_dict
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:547:    # FIXME record_stream doesn't work with non-cuda tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:308:                # FIXME: there are a few things that fall under this like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:389:    # FIXME: this is wrong when dim=None and one of the dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:665:            # FIXME: this can be wrong for situations where we have
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset11.py:1362:    # FIXME(justinchuby): We need to handle what happens when we call b.op on a node return
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1249:        # FIXME(justinchuby): can index be an int and not a value?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1875:            # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1886:            # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1941:            # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1956:        # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2514:        # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2586:        # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3122:    # FIXME(justinchuby): Get rid of the try catch here to improve readability
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3126:        # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4273:        # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:7177:        # FIXME(justinchuby): report correct name for symbolic being executed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:285:                # FIXME(justinchuby): Avoid catching Exception.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset12.py:368:        # FIXME(justinchuby): cond is unused?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:128:        # FIXME: Avoid importing onnxscript into torch
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:86:        # FIXME(justinchuby): Add the return type back once we know how to handle mypy
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:41:    # FIXME: Avoid importing onnx into torch.onnx.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:138:    # FIXME: Avoid importing onnx into torch.onnx.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:50:        # FIXME: This is a hack to tracing through if-else Python blocks.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:185:        # FIXME: Bug in `dynamo.export`. Sometimes outputs returned in 'list' instead of 'tuple'.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:187:        # FIXME: Bug in `dynamo.export`. Sometimes single function return is wrapped in list.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2119:# FIXME: currently returns integers for boolean tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2151:# FIXME: currently returns integers for boolean tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2183:# FIXME: currently returns integers for boolean tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:658:            # FIXME: Implement reductions for dense dimensions for ops with non-zero reduction identities
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:705:        # FIXME: temporary workaround for issue with bfloat16/float16 remove when acctype is implemented for scatter_reduce
./api/pipeline/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:736:    # FIXME: when dense dimensions are implemented for CSR tensors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:527:        # FIXME and they have the same dtype, device, etc
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/testing/__init__.py:19:# from .testing import assert_allclose    # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:405:    # FIXME(Mario) Doesn't np.quantile accept a tuple?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/__init__.py:1683:            # FIXME: CUDA Graph does not work well with CUPTI teardown.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:942:        # FIXME (tmanlaibaatar)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:65:FIXME_inductor_non_strict = {
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5218:            # FIXME: Add testing for gloo/CUDA
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:239:        # FIXME dist.barrier deadlocks with multiple threads and NCCL: https://github.com/pytorch/pytorch/issues/95895
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:241:        # FIXME can't use the above all_reduce as it causes hangs on bionic and focal. It hangs:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py:28:        # FIXME Once we consolidate the error messages returned by the
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4667:    # FIXME Merge this test with the corresponding one in RpcTest.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4688:    # FIXME Merge this test with the corresponding one in RpcTest.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4712:    # FIXME Merge this test with the corresponding one in RpcTest.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4745:        # FIXME We wait until the remote completed creating the OwnerRRef
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4795:        # FIXME We wait until the remote completed creating the OwnerRRef
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2637:            # FIXME: remove after implementing reflection pad 3d
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3412:        self.FIXME_no_cuda_gradgrad_comparison = \
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3413:            kwargs.get('FIXME_no_cuda_gradgrad_comparison', False)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3547:            if self.check_gradgrad and not self.FIXME_no_cuda_gradgrad_comparison:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2635:                # FIXME: figure out the flaky -1024 anti-leaks on windows. See #8044
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2763:                        from .dynamo_test_failures import FIXME_inductor_non_strict
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2764:                        strict_default = filename not in FIXME_inductor_non_strict
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3128:            # FIXME: `x` is a sparse view of `v`. Currently rebase_history for
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4054:# FIXME: modernize these to be consistent with make_tensor
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4341:# FIXME: remove this by updating test suites using it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4350:# FIXME: remove this by updating test suites using it
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4404:# FIXME: improve load_tests() documentation here
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4434:# FIXME: document this and move it to test_serialization
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4516:# FIXME: delete this
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4524:# FIXME: move to test_sparse or sparse utils
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:119:# FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1854:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2417:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:153:                    # FIXME: for now reductions with non-zero reduction identity and
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:454:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:530:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:643:            # FIXME: amax reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:652:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:653:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:682:            # FIXME: amax reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:691:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:692:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:792:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:801:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:873:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:917:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:992:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:1163:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:97:        # FIXME: Causes floating point exception on ROCm
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2243:        # FIXME add an override for JIT and revert 0. back to 0
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3023:    # FIXME: eager and ref impl throw different types of errors
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4021:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4081:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4218:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8146:    # FIXME: Derivative wrt. weight not implemented
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12045:               # FIXME: geqrf can't forward with complex inputs that require grad
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14037:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14060:               # FIXME: both derivatives are implemented incorrectly
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14062:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14680:            # FIXME: intentionally misreports dtypes
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14682:            # FIXME: numpy reference diverges: Comparing (nan+nanj) and (-0+0j)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15015:                        # FIXME: incorrectly tries to pass a rhs scalar
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15055:                        # FIXME: incorrectly tries to pass a rhs scalar
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15342:                        # FIXME Complex values error with: Greatest absolute difference: nan at index
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15385:                        # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18994:            # FIXME: uint8 input returns uint8 instead of bool
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19006:            # FIXME: uint8 input returns uint8 instead of bool
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19019:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19034:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19067:            # FIXME: count_nonzero does not accept keepdim kwarg
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19075:            # FIXME: dim=[] reduces all dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19084:        # FIXME: mean needs 'dim' parameter when using the 'out' overload.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19095:            # FIXME: mean does not support passing keepdim without passing dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19097:            # FIXME: mean reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19100:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19123:            # FIXME: prod reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19126:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19151:            # FIXME: cannot specify keepdim without dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19153:            # FIXME: dim=[] reduces all dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19156:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19178:            # FIXME: dim=[] reduces all dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19199:            # FIXME: cannot specify keepdim without dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19201:            # FIXME: dim=[] reduces all dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19204:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19226:            # FIXME: dim=[] reduces all dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19248:            # FIXME: prod does not support passing keepdim without passing dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19250:            # FIXME: prod reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19253:            # FIXME: prod does not support passing None to dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19260:            # FIXME: ValueError: The data in MaskedTensor a and Tensor b do not match
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19283:            # FIXME: sum does not support passing keepdim without passing dim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19285:            # FIXME: sum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19288:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19313:            # FIXME: nansum reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19316:            # FIXME: flaky test so skipped instead of xfailed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19643:            # FIXME: CUDA driver API confirmed a leak in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19665:            # FIXME: CUDA driver API confirmed a leak in
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21188:            # FIXME output 0: meta disagrees with real impl
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21306:            # FIXME output 0: meta disagrees with real impl
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21632:            # FIXME: enable dtype-based tolerances in test_ops.py:TestCommon._ref_test_helper
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21851:        # FIXME: doesn't support chalf
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21864:        # FIXME: doesn't support chalf
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21900:            # FIXME: AssertionError: RuntimeError not raised
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22180:            # FIXME: uint8 input returns uint8 instead of bool
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22191:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22203:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22214:            # FIXME: uint8 input returns uint8 instead of bool
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22224:            # FIXME: count_nonzero does not accept keepdim kwarg
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22239:            # FIXME: dim=[] reduces all dimensions
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22249:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22261:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22266:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22286:            # FIXME: doesn't test out behavior properly for this operator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22288:            # FIXME: mean reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22292:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22334:            # FIXME: doesn't test out behavior properly for this operator
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22336:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22341:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22352:            # FIXME: reduces all dimensions when dim=[]
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22357:            # FIXME: improve precision
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22417:            # FIXME: shouldn't check empty results
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22447:            # FIXME: should not compare results of empty_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22503:            # FIXME: should not compare results of empty_like
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:709:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:800:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:893:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:202:            # FIXME that's a crude approximation for promoting args
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2983:        # FIXME: Calling to_device(x, device) should work but
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3662:    # FIXME: in some cases we sill need to explicitly pass in ordered_kwargs_for_cpp_kernel
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4956:        # FIXME: no need to do this after we switch to the torchgen-ed C shim
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1252:        # FIXME: passing `-fopenmp` adds libgomp.so to the generated shared library's dependencies.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1837:            # FIXME handle embedded optional types?
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2628:        # FIXME: This is not exactly right for cases like below:
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/onnxrt.py:15:    # FIXME(abock): update test/dynamo/test_backends.py to call is_onnxrt_backend_supported()
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1417:        # FIXME (tmanlaibaatar) this is utter hack to unblock HuggingFace export
./api/pipeline/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3355:            obj, obj.__name__, getfile(obj), obj.__code__  # type: ignore[union-attr] # FIXME Add MethodType.__code__ to typeshed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:920:      // FIXME We should always extract DataPtrs, in order to catch the case of
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:116:  // FIXME: stride should be optional
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cuda/DistributionTemplates.h:106: * FIXME: Can we specialize elementwise_kernel and launch_kernel in Loops.cuh
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:259:      // FIXME: remove magic > 0 after we ensure no models were serialized with -1 defaults.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/ATen/ScalarOps.h:28:// FIXME: this should be (and was) Scalar::toTensor, but there is currently no
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:749:/// \todo FIXME: remove when \c constexpr becomes really \c constexpr
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:154:    this->Size = this->Capacity = 0; // FIXME: Setting Capacity to 0 is suspect.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:768:  // FIXME: Consider assigning over existing elements, rather than clearing &
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1106:  // FIXME: don't do this if they're efficiently moveable.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1169:  // FIXME: this may not actually make any sense if we can efficiently move
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/device_utils.h:10:// FIXME: Currently, CPU and CUDA backend are mutually exclusive.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroupGloo.hpp:68:  // FIXME: This probably should be called WorkGloo since the work is executed
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/detail/TensorDataContainer.h:31:// FIXME: There is no `operator<<` overload for `at::kBFloat16` type,
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:125:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:130:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./api/pipeline/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:185:                    # FIXME: CUDA Graph does not work well with CUPTI teardown.
./api/pipeline/.venv/lib/python3.12/site-packages/h2/connection.py:1808:            # FIXME: Should we split this into one event per active stream?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/compat/__init__.py:165:        # FIXME: there has to be a better way to do this
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:882:        # FIXME: this may not work for hashes with non-standard settings.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:914:            # FIXME: this may overestimate size due to padding bits (e.g. bcrypt)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:915:            # FIXME: this will be off by 1 for case-insensitive hashes.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1501:        # FIXME: this may overestimate size due to padding bits
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1502:        # FIXME: this will be off by 1 for case-insensitive hashes.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:1115:        # FIXME: if multiple hashes could match (e.g. lmhash vs nthash)
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:1215:    # FIXME: altering the configuration of this object isn't threadsafe,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/context.py:1663:    # FIXME: this function suffered some bitrot in 1.6.1,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/fshp.py:78:    # FIXME: should probably use different default rounds
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/windows.py:126:            # FIXME: just trusting ascii upper will work?
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/oracle.py:78:        # FIXME: not sure how oracle handles unicode.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:241:            # FIXME: if salt was provided by user, this message won't be
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/mysql.py:67:        # FIXME: no idea if mysql has a policy about handling unicode passwords
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/mysql.py:117:        # FIXME: no idea if mysql has a policy about handling unicode passwords
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/phpass.py:118:        # FIXME: can't find definitive policy on how phpass handles non-ascii.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/md5_crypt.py:263:    # FIXME: can't find definitive policy on how md5-crypt handles non-ascii.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/handlers/des_crypt.py:349:        # FIXME: this technically might generate a rounds value 1 larger
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/des.py:583:# FIXME: more properly named _uint8_struct...
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/_md4.py:67:    # FIXME: make this follow hash object PEP better.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/crypto/_md4.py:68:    # FIXME: this isn't threadsafe
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/apache.py:408:    # FIXME: htpasswd doc says passwords limited to 255 chars under Windows & MPE,
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:925:    # FIXME: fix UT framework - this hash is sensitive to password case, but verify() is not
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1646:        # FIXME: password unknown
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1652:        # FIXME: password unknown
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:114:    # FIXME: I've been lazy, should probably just add 'relaxed' kwd
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:399:            # FIXME: this ignores 'msg'
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:455:                # FIXME: should use a stdlib call to resolve this back
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1370:        # FIXME: this may be off for case-insensitive hashes, but that accounts
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:366:        # FIXME: this isn't failing even in broken case, need to figure out
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/tests/test_crypto_digest.py:221:    if not JYTHON: # FIXME: find out why not jython, or reenable this.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1038:##    # FIXME: this generic wrapper doesn't handle custom settings
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1039:##    # FIXME: genconfig / genhash not supported.
./api/pipeline/.venv/lib/python3.12/site-packages/passlib/ifc.py:139:        # FIXME:  need stub for classes that define .encrypt() instead ...
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/util/response.py:99:    # FIXME: Can we do this somehow without accessing private httplib _method?
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:782:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:787:                # FIXME: Is there a better way to differentiate between SSLErrors?
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:1051:        # FIXME, this method's type doesn't say returning None is possible
./api/pipeline/.venv/lib/python3.12/site-packages/urllib3/response.py:1219:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2031:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3201:    # FIXME: 'Distribution.insert_on' is too complex (13)
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:326:        # FIXME: handle?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:327:        # FIXME: magic signatures?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/build_env.py:200:                # FIXME: Consider direct URL?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:480:            # FIXME: need a test for this elif block
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:371:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:259:            # FIXME: it would be nice to keep track of the source
./api/pipeline/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:631:            # FIXME: https://github.com/pypa/pip/issues/11943
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:466:            # FIXME: Remove this after figuring out CI job failures related to min, max, mean
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:67:    # FIXME: figure out a better way when we support sparse tensors in jit
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:98:    # FIXME: clone indices on construction.
./api/pipeline/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:252:# FIXME: Ideally these functions should be methods on Type class, but we have a
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:901:# FIXME: Fails _cdfvec
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:1294:# FIXME: problems sampling.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:9003:    # FIXME: this is only a quick-and-dirty test of a quick-and-dirty bugfix.
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:799:            # FIXME: implement this somewhen, for now go with builtin values
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:800:            # FIXME: calc optimal lwork by calling ?hbevd(lwork=-1)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:805:            # FIXME: implement this somewhen, for now go with builtin values
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:903:    # FIXME: suppress?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:904:    # FIXME: how to catch the _fblas.error?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:942:    # prints '0-th dimension must be fixed to 3 but got 5', FIXME: suppress?
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:740:        # FIXME Jitted JAX arrays do not have a device attribute
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:325:        # FIXME https://github.com/jax-ml/jax/issues/27418
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/differentiate/tests/test_differentiate.py:585:        # FIXME https://github.com/scipy/scipy/pull/22320#discussion_r1914898175
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/_constraints.py:492:    # FIXME: when bugs in VectorFunction/LinearVectorFunction are worked out,
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__dual_annealing.py:69:    # FIXME: there are some discontinuities in behaviour as a function of `qv`,
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/integrate/_ode.py:392:            # FIXME: this really should be raise an exception. Will that break
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/conftest.py:504:    # FIXME: populate the dict once
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/tests/test_kdtree.py:634:        # raises an exception for bug 870 (FIXME: Does it?)
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/spatial/_kdtree.py:913:        result = np.empty((m,n),dtype=float)  # FIXME: figure out the best dtype
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_delegators.py:21:         sig = "( FIXME )"
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:110:        # FIXME: for complex types, the computations are done in
./api/pipeline/.venv/lib/python3.12/site-packages/scipy/signal/_signaltools.py:4339:    # FIXME: Can this function be replaced with an appropriate
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1007:    #FIXME the 'e' dtype might work in future
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_mem_policy.py:12:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:6159:        # FIXME:
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_interface.py:131:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:19:#FIXME: this will probably change when we require full C99 campatibility
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1129:        # FIXME cinf not tested.
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1774:                        reason='failures on 32-bit Python, see FIXME below')
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1818:        # FIXME: NAN raises FP invalid exception:
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1821:        # FIXME: skipped on MSVC:32-bit during switch to Meson, 10 cases fail
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:2794:            # FIXME: a not used
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1758:     * FIXME: This should check for a flag on the data-type that
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:236:        # FIXME: This seems like it will copy strings around
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/core.py:2839:            # FIXME: should we set `_data._sharedmask = True`?
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./api/pipeline/.venv/lib/python3.12/site-packages/numpy/conftest.py:73:#FIXME when yield tests are gone.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/image_to_text.py:204:        # FIXME: We need to pop here due to a difference in how `generation.py` and `generation.tf_utils.py`
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:380:            # FIXME: ydshieh and/or Narsil
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/modeling_gguf_pytorch_utils.py:376:    # FIXME: Currently this implementation is only for flan-t5 architecture.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/protein.py:85:                    seq[i] = "X"  # FIXME: strings are immutable
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:472:        # FIXME:
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:241:        # FIXME:
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics3/image_processing_idefics3.py:229:# FIXME Amy: make a more general crop function that isn't just centre crop
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/image_processing_smolvlm.py:226:# FIXME Amy: make a more general crop function that isn't just centre crop
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/idefics2/image_processing_idefics2.py:125:# FIXME Amy: merge this function with the one in image_transforms.py
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1653:        # FIXME h_boxes takes the last one computed, keep this in mind
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:426:        # FIXME max_tokens_to_generate is embedded into this processor's call.
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:539:        # FIXME - We hard code "pt" here because the rest of the processing assumes torch tensors
./api/pipeline/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1958:        # FIXME h_boxes takes the last one computed, keep this in mind
./api/pipeline/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:1474:        # FIXME: doesn't account for weight
./api/pipeline/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:3359:                # FIXME - this doesn't deal with incorrectly large payloads
./api/pipeline/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:4218:        # FIXME: this should only be done if the message is known
./api/pipeline/.venv/lib/python3.12/site-packages/joblib/logger.py:144:            # FIXME: Too much logic duplicated
./api/pipeline/.venv/lib/python3.12/site-packages/boto3/exceptions.py:100:# FIXME: Backward compatibility
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:911:        "check_estimators_empty_data_messages": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:912:        "check_estimators_nan_inf": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:913:        "check_estimator_sparse_array": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:914:        "check_estimator_sparse_matrix": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:915:        "check_fit1d": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:916:        "check_fit2d_predict1d": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:917:        "check_complex_data": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:918:        "check_fit2d_1feature": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:925:        "check_estimators_overwrite_params": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:926:        "check_estimators_nan_inf": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:927:        "check_dont_overwrite_parameters": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:966:        "check_estimators_nan_inf": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:967:        "check_classifiers_one_label_sample_weights": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:968:        "check_fit2d_1feature": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:976:        "check_estimators_nan_inf": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:977:        "check_classifiers_one_label_sample_weights": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:978:        "check_fit2d_1feature": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1216:        "check_dict_unchanged": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1280:                    "check_n_features_in_after_fitting": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1281:                    "check_dataframe_column_names_consistency": "FIXME",
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1392:# FIXME: this test should be uncommented when the checks will be granular
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1397:    # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/tests/test_gpr.py:760:    # FIXME: before fitting, the estimator does not have information regarding
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_common.py:98:    # FIXME: we can introduce equal_nan=True in recent version of numpy.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:117:        eps = np.finfo(np.float32).eps  # FIXME: This is quite large!
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:517:                # FIXME: we could consider to support multiclass-multioutput if
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:175:            # FIXME: We temporarily bypass this test. This is due to the fact
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:691:    # FIXME: the following snippet does not yield the same results on 32 bits
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_common.py:252:# FIXME: we should move this test in `estimator_checks` once we are able
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_kde.py:127:    # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:623:        # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1164:        # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_selection/tests/test_from_model.py:483:    # FIXME: we cannot validate the upper bound of the attribute at transform
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:606:        # FIXME We compute all the distances, while we could have only computed
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:278:# FIXME; this test is broken with different random states, needs to be revisited
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/compose/_target.py:281:        # FIXME: a FunctionTransformer can return a 1D array even when validate
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:109:        # FIXME: the current Cython implementation is too slow for a large number of
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:698:    # FIXME: the current Cython implementation is too slow for a large number of
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/tests/test_glm.py:376:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:330:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:392:        # FIXME: Same as in test_ridge_regression_unpenalized.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:447:        # FIXME: Same as in test_ridge_regression_unpenalized.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1551:        # FIXME
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1558:        # FIXME: SAGA on sparse data fits the intercept inaccurately with the
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/cross_decomposition/tests/test_pls.py:78:    # FIXME: one would expect y_trans == pls.y_scores_ but this is not
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:2540:# FIXME: Replace this test with a full `check_estimator` once we have API only
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/multiclass.py:1207:        # FIXME: there are more elaborate methods than generating the codebook
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_multiclass.py:903:# FIXME: we should move this test in `estimator_checks` once we are able
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:745:# FIXME: we should move this test in `estimator_checks` once we are able
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:65:    # FIXME Remove this test once the more general partial_fit tests are merged
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:308:    # FIXME: write a test to show this.
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:1718:# FIXME: Replace this test with a full `check_estimator` once we have API only
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:657:        # FIXME Jitted JAX arrays do not have a device attribute
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_funcs.py:715:    # FIXME https://github.com/data-apis/array-api-compat/pull/231
./api/pipeline/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1728:        # FIXME: np.float16 could be preserved if _inplace_csr_row_normalize_l2
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/tests/test_weighted.py:890:        # FIXME nx.goldberg_radzik(D, 1)
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:713:                # FIXME directed graphs
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:809:            # FIXME directed graphs
./api/pipeline/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:859:                    # FIXME directed graphs
./api/pipeline/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:378:    # FIXME: error_dps should not be necessary
./api/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1552:            # FIXME: why are there type ignores here? We support two signatures for json_schema_extra callables...
./api/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:363:    FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.
./api/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:1403:            # FIXME: I want to make these keywords but still parse attributes.
./api/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:223:    # FIXME: use inheritance
./api/.venv/lib/python3.12/site-packages/pygments/lexers/julia.py:195:            # FIXME: This escape pattern is not perfect.
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:536:            # FIXME: aren't the offsets wrong?
./api/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:998:            # FIXME: Use ABC lexer in the future
./api/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:41:            # FIXME when e is present, no decimal point needed
./api/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:172:            # FIXME when e is present, no decimal point needed
./api/.venv/lib/python3.12/site-packages/pygments/lexers/typst.py:135:            # FIXME: make this work
./api/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./api/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/.venv/lib/python3.12/site-packages/h11/_writers.py:54:    # XX FIXME: could at least make an effort to pull out the status message
./api/.venv/lib/python3.12/site-packages/h11/_events.py:310:# XX FIXME: "A recipient MUST ignore (or consider as an error) any fields that
./api/.venv/lib/python3.12/site-packages/h11/_readers.py:186:            # XX FIXME: we discard chunk extensions. Does anyone care?
./api/.venv/lib/python3.12/site-packages/passlib/utils/compat/__init__.py:165:        # FIXME: there has to be a better way to do this
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:882:        # FIXME: this may not work for hashes with non-standard settings.
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:914:            # FIXME: this may overestimate size due to padding bits (e.g. bcrypt)
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:915:            # FIXME: this will be off by 1 for case-insensitive hashes.
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1501:        # FIXME: this may overestimate size due to padding bits
./api/.venv/lib/python3.12/site-packages/passlib/utils/handlers.py:1502:        # FIXME: this will be off by 1 for case-insensitive hashes.
./api/.venv/lib/python3.12/site-packages/passlib/context.py:1115:        # FIXME: if multiple hashes could match (e.g. lmhash vs nthash)
./api/.venv/lib/python3.12/site-packages/passlib/context.py:1215:    # FIXME: altering the configuration of this object isn't threadsafe,
./api/.venv/lib/python3.12/site-packages/passlib/context.py:1663:    # FIXME: this function suffered some bitrot in 1.6.1,
./api/.venv/lib/python3.12/site-packages/passlib/handlers/fshp.py:78:    # FIXME: should probably use different default rounds
./api/.venv/lib/python3.12/site-packages/passlib/handlers/windows.py:126:            # FIXME: just trusting ascii upper will work?
./api/.venv/lib/python3.12/site-packages/passlib/handlers/oracle.py:78:        # FIXME: not sure how oracle handles unicode.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/bcrypt.py:241:            # FIXME: if salt was provided by user, this message won't be
./api/.venv/lib/python3.12/site-packages/passlib/handlers/mysql.py:67:        # FIXME: no idea if mysql has a policy about handling unicode passwords
./api/.venv/lib/python3.12/site-packages/passlib/handlers/mysql.py:117:        # FIXME: no idea if mysql has a policy about handling unicode passwords
./api/.venv/lib/python3.12/site-packages/passlib/handlers/phpass.py:118:        # FIXME: can't find definitive policy on how phpass handles non-ascii.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/md5_crypt.py:263:    # FIXME: can't find definitive policy on how md5-crypt handles non-ascii.
./api/.venv/lib/python3.12/site-packages/passlib/handlers/des_crypt.py:349:        # FIXME: this technically might generate a rounds value 1 larger
./api/.venv/lib/python3.12/site-packages/passlib/crypto/des.py:583:# FIXME: more properly named _uint8_struct...
./api/.venv/lib/python3.12/site-packages/passlib/crypto/_md4.py:67:    # FIXME: make this follow hash object PEP better.
./api/.venv/lib/python3.12/site-packages/passlib/crypto/_md4.py:68:    # FIXME: this isn't threadsafe
./api/.venv/lib/python3.12/site-packages/passlib/apache.py:408:    # FIXME: htpasswd doc says passwords limited to 255 chars under Windows & MPE,
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:925:    # FIXME: fix UT framework - this hash is sensitive to password case, but verify() is not
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1646:        # FIXME: password unknown
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_handlers.py:1652:        # FIXME: password unknown
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:114:    # FIXME: I've been lazy, should probably just add 'relaxed' kwd
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:399:            # FIXME: this ignores 'msg'
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:455:                # FIXME: should use a stdlib call to resolve this back
./api/.venv/lib/python3.12/site-packages/passlib/tests/utils.py:1370:        # FIXME: this may be off for case-insensitive hashes, but that accounts
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_context.py:366:        # FIXME: this isn't failing even in broken case, need to figure out
./api/.venv/lib/python3.12/site-packages/passlib/tests/test_crypto_digest.py:221:    if not JYTHON: # FIXME: find out why not jython, or reenable this.
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1038:##    # FIXME: this generic wrapper doesn't handle custom settings
./api/.venv/lib/python3.12/site-packages/passlib/ext/django/utils.py:1039:##    # FIXME: genconfig / genhash not supported.
./api/.venv/lib/python3.12/site-packages/passlib/ifc.py:139:        # FIXME:  need stub for classes that define .encrypt() instead ...
./api/.venv/lib/python3.12/site-packages/urllib3/util/response.py:99:    # FIXME: Can we do this somehow without accessing private httplib _method?
./api/.venv/lib/python3.12/site-packages/urllib3/response.py:782:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./api/.venv/lib/python3.12/site-packages/urllib3/response.py:787:                # FIXME: Is there a better way to differentiate between SSLErrors?
./api/.venv/lib/python3.12/site-packages/urllib3/response.py:1051:        # FIXME, this method's type doesn't say returning None is possible
./api/.venv/lib/python3.12/site-packages/urllib3/response.py:1219:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./api/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2031:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./api/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3201:    # FIXME: 'Distribution.insert_on' is too complex (13)
./api/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:326:        # FIXME: handle?
./api/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:327:        # FIXME: magic signatures?
./api/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./api/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./api/.venv/lib/python3.12/site-packages/pip/_internal/build_env.py:200:                # FIXME: Consider direct URL?
./api/.venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:480:            # FIXME: need a test for this elif block
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:371:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./api/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:259:            # FIXME: it would be nice to keep track of the source
./api/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:631:            # FIXME: https://github.com/pypa/pip/issues/11943
./api/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:1474:        # FIXME: doesn't account for weight
./api/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:3359:                # FIXME - this doesn't deal with incorrectly large payloads
./api/.venv/lib/python3.12/site-packages/paho/mqtt/client.py:4218:        # FIXME: this should only be done if the message is known
./api/search/.venv/lib/python3.12/site-packages/PIL/PixarImagePlugin.py:61:        # FIXME: to be continued...
./api/search/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:178:                # FIXME: the fill decoder is not implemented
./api/search/.venv/lib/python3.12/site-packages/PIL/FpxImagePlugin.py:216:                # FIXME: jpeg tables are tile dependent; the prefix
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:78:# FIXME: add support for pilfont2 format (see FontFile.py)
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:133:        self.info = []  # FIXME: should be a dictionary
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:225:        # FIXME: use service provider instead
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageQt.py:140:        # FIXME - is this really the best way to do this?
./api/search/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:152:            # FIXME: this may read whole file if not a text file
./api/search/.venv/lib/python3.12/site-packages/PIL/ImImagePlugin.py:249:        self._fp = self.fp  # FIXME: hack
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:102:            # FIXME: fix Fill2 to properly support matte for I+F images
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageDraw.py:129:            # FIXME: should add a font repository
./api/search/.venv/lib/python3.12/site-packages/PIL/TiffTags.py:209:    # FIXME add more tags here
./api/search/.venv/lib/python3.12/site-packages/PIL/MpoImagePlugin.py:121:        self._fp = self.fp  # FIXME: hack
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageDraw2.py:54:        # FIXME: add support for bitmap fonts
./api/search/.venv/lib/python3.12/site-packages/PIL/PdfImagePlugin.py:57:    # FIXME: Should replace ASCIIHexDecode with RunLengthDecode
./api/search/.venv/lib/python3.12/site-packages/PIL/SpiderImagePlugin.py:161:        self._fp = self.fp  # FIXME: hack
./api/search/.venv/lib/python3.12/site-packages/PIL/PngImagePlugin.py:444:            icc_profile = None  # FIXME
./api/search/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:962:        # FIXME What about tagdata?
./api/search/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:229:    raise NotImplementedError(msg)  # FIXME
./api/search/.venv/lib/python3.12/site-packages/PIL/ImagePalette.py:260:    # FIXME: supports GIMP gradients only
./api/search/.venv/lib/python3.12/site-packages/PIL/Image.py:544:        # FIXME: take "new" parameters / other image?
./api/search/.venv/lib/python3.12/site-packages/PIL/Image.py:1791:                # FIXME: use self.size here?
./api/search/.venv/lib/python3.12/site-packages/PIL/Image.py:1927:            # FIXME: _imaging returns a confusing error message for this case
./api/search/.venv/lib/python3.12/site-packages/PIL/Image.py:2781:    # FIXME: the different transform methods need further explanation
./api/search/.venv/lib/python3.12/site-packages/PIL/MspImagePlugin.py:184:    header[12] = checksum  # FIXME: is this the right field?
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:340:            # FIXME: This is a hack to handle TIFF's JpegTables tag.
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:637:    # FIXME: make MAXBLOCK a configuration parameter
./api/search/.venv/lib/python3.12/site-packages/PIL/GifImagePlugin.py:120:        self._fp = self.fp  # FIXME: hack
./api/search/.venv/lib/python3.12/site-packages/PIL/XpmImagePlugin.py:85:                        # FIXME: handle colour names (see ImagePalette.py)
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageOps.py:54:        # FIXME: apply to lookup table, not image data
./api/search/.venv/lib/python3.12/site-packages/PIL/PSDraw.py:44:        # FIXME: incomplete
./api/search/.venv/lib/python3.12/site-packages/PIL/McIdasImagePlugin.py:53:            # FIXME: add memory map support
./api/search/.venv/lib/python3.12/site-packages/PIL/McIdasImagePlugin.py:57:            # FIXME: add memory map support
./api/search/.venv/lib/python3.12/site-packages/PIL/PsdImagePlugin.py:40:    (7, 8): ("L", 1),  # FIXME: multilayer
./api/search/.venv/lib/python3.12/site-packages/PIL/XVThumbImagePlugin.py:17:# FIXME: make save work (this requires quantization support)
./api/search/.venv/lib/python3.12/site-packages/PIL/PcdImagePlugin.py:49:        self._size = 768, 512  # FIXME: not correct for rotated images!
./api/search/.venv/lib/python3.12/site-packages/PIL/ImageCms.py:1105:        # FIXME: I get different results for the same data w. different
./api/search/.venv/lib/python3.12/site-packages/PIL/PcxImagePlugin.py:94:            # FIXME: hey, this doesn't work with the incremental loader !!!
./api/search/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:110:        self.info["flashpix"] = s  # FIXME: value will change
./api/search/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:238:    # FIXME: The quantization tables can be used to estimate the
./api/search/.venv/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:800:    # FIXME: issue a warning if the wrong form is used (post-1.1.7)
./api/search/.venv/lib/python3.12/site-packages/sympy/stats/tests/test_continuous_rv.py:1290:    # FIXME: simplify(E(X)) seems to hang without extended_positive=True
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/deltafunctions.py:144:            #FIXME: the second term tells whether is DeltaDirac or Derivative
./api/search/.venv/lib/python3.12/site-packages/sympy/integrals/tests/test_meijerint.py:544:    # FIXME: If alpha, beta are not declared as finite the line below hangs
./api/search/.venv/lib/python3.12/site-packages/sympy/core/facts.py:330:        # (?) FIXME this is only correct when b & c != null !
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1182:    # FIXME: The line below should be True rather than None
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:1198:    # FIXME: Should the line below be True rather than None?
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_arit.py:2171:    # FIXME: This evaluates as:
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:617:    # FIXME: could replace with random selection after test passes
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:643:    # FIXME: could replace with random selection after test passes
./api/search/.venv/lib/python3.12/site-packages/sympy/core/tests/test_relational.py:925:    # FIXME: The test below fails because (-infx).is_extended_positive is True
./api/search/.venv/lib/python3.12/site-packages/sympy/core/mul.py:1617:            # FIXME: is_positive/is_negative is False doesn't take account of
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/piecewise.py:456:        # FIXME: Currently complex intervals are not supported.  A possible
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/elementary/trigonometric.py:1226:        # FIXME: currently tan(pi/2) return zoo
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_delta_functions.py:37:    # FIXME: this is generally undefined @ x=0
./api/search/.venv/lib/python3.12/site-packages/sympy/functions/special/tests/test_bessel.py:514:    # FIXME: could have these return NaN; for now just fix infinite recursion
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/fancysets.py:1424:            # FIXME: This should probably be handled with something like:
./api/search/.venv/lib/python3.12/site-packages/sympy/sets/tests/test_fancysets.py:152:    # FIXME: This doesn't yet work:
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:120:    contravariant and covariant Idx subclasses.  (FIXME: this is not yet
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:150:    # FIXME: symmetries from power needs to check special cases, else nothing
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:168:    FIXME: Add support for Numpy broadcasting
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:196:        # FIXME: search for symmetries
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:279:            # FIXME:  No support for Piecewise yet
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:295:            "FIXME: No specialized handling of type %s" % type(expr))
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:449:        # FIXME:  No support for Piecewise yet
./api/search/.venv/lib/python3.12/site-packages/sympy/tensor/index_methods.py:469:        "FIXME: No specialized handling of type %s" % type(expr))
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:249:    "complex": DataType("double", "COMPLEX*16", "complex", "", "", "float") #FIXME:
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/codegen.py:1530:        # FIXME: this is probably general enough for other high-level
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen.py:16:#FIXME: Fails due to circular import in with core
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:85:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_julia.py:235:    # FIXME: how to pass inline=False to the JuliaCodePrinter?
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:83:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_octave.py:225:    # FIXME: how to pass inline=False to the OctaveCodePrinter?
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:89:    # FIXME: how to pass inline to the RustCodePrinter?
./api/search/.venv/lib/python3.12/site-packages/sympy/utilities/tests/test_codegen_rust.py:248:    # FIXME: how to pass inline to the RustCodePrinter?
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:911:    # FIXME: The solution here should be O((x-2)**3) so is incorrect
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:929:    # FIXME: Solution should be O((x+2)**6)
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:948:    # FIXME: checkodesol fails for this solution...
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_ode.py:956:    # FIXME: checkodesol fails for this solution...
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2480:    # FIXME: assert checksysodesol(eq3, sol3) == (True, [0, 0])
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2485:    # FIXME: assert checksysodesol(eq4, sol4) == (True, [0, 0])
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2516:    # FIXME: assert checksysodesol(eq1, sol1) == (True, [0, 0, 0])
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/ode/tests/test_systems.py:2524:    # FIXME: assert checksysodesol(eq2, sol2) == (True, [0, 0, 0])
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/recurr.py:564:            # FIXME: The call to rsolve_ratio below should suffice (rsolve_poly
./api/search/.venv/lib/python3.12/site-packages/sympy/solvers/pde.py:937:    # FIXME: Find lcm() of all the divisors and divide with it, instead of
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/paulialgebra.py:144:    # FIXME don't work for -I*Pauli(2)*Pauli(3)
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/hep/gamma_matrices.py:315:    gctr = 4  # FIXME specific for d=4
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2221:    FIXME: This is a bottle-neck, can we do it faster?
./api/search/.venv/lib/python3.12/site-packages/sympy/physics/secondquant.py:2758:        # FIXME: If we arrive here, there are no ordered dummies. A method to
./api/search/.venv/lib/python3.12/site-packages/sympy/external/tests/test_codegen.py:184:            "FIXME: filename extension unknown for language: %s" % language)
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/maple.py:8:FIXME: This module is still under actively developed. Some functions may be not completed.
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/julia.py:68:    # assignment (if False).  FIXME: this should be looked a more carefully
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:85:    # assignment (if False).  FIXME: this should be looked a more carefully
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/octave.py:258:        # FIXME: how to do better, e.g., for octave_code(2*GoldenRatio)?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1375:        # FIXME: Refactor this code and matrix into some tabular environment.
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1442:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/pretty/pretty.py:1490:        # FIXME refactor Matrix, Piecewise, and this into a tabular environment
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:243:    # FIXME: is it worth worrying about this?  Its not wrong, just
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_octave.py:358:    # FIXME?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_repr.py:339:    # FIXME: sT fails because Cycle is not immutable and calling srepr(Cycle(1, 2))
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:184:    # FIXME: is it worth worrying about this?  Its not wrong, just
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/tests/test_julia.py:293:    # FIXME?
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:243:                            "FIXME: no support for contractions in factor yet")
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:255:                        # syntax is currently undefined.  FIXME: What would be
./api/search/.venv/lib/python3.12/site-packages/sympy/printing/codeprinter.py:261:                            raise ValueError("FIXME: lhs present in rhs,\
./api/search/.venv/lib/python3.12/site-packages/torchvision/io/video.py:186:        # FIXME this is kind of a hack, but we will jump to the previous keyframe
./api/search/.venv/lib/python3.12/site-packages/torchvision/transforms/autoaugment.py:103:# FIXME: Eliminate copy-pasted code for fill standardization and _augmentation_space() by moving stuff on a base class
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:74:            # FIXME: Is this needed? SqueezeNet should only be called from the
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:75:            # FIXME: squeezenet1_x() functions
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/squeezenet.py:76:            # FIXME: This checking is not done for the other models
./api/search/.venv/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:491:        # FIXME We don't know if we should expect this to happen
./api/search/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1552:            # FIXME: why are there type ignores here? We support two signatures for json_schema_extra callables...
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/haskell.py:363:    FIXME: A Cryptol2 lexer based on the lexemes defined in the Haskell 98 Report.
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/openscad.py:81:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/objective.py:452:            (r':param: [a-zA-Z_]\w*|:returns?:|(FIXME|MARK|TODO):',
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/templates.py:1403:            # FIXME: I want to make these keywords but still parse attributes.
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/sql.py:223:    # FIXME: use inheritance
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/julia.py:195:            # FIXME: This escape pattern is not perfect.
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:536:            # FIXME: aren't the offsets wrong?
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/markup.py:998:            # FIXME: Use ABC lexer in the future
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:41:            # FIXME when e is present, no decimal point needed
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/graphics.py:172:            # FIXME when e is present, no decimal point needed
./api/search/.venv/lib/python3.12/site-packages/pygments/lexers/typst.py:135:            # FIXME: make this work
./api/search/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/search/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./api/search/.venv/lib/python3.12/site-packages/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/search/.venv/lib/python3.12/site-packages/timm/utils/distributed.py:114:        # FIXME: verify that ROCm transform nccl to rccl
./api/search/.venv/lib/python3.12/site-packages/timm/loss/binary_cross_entropy.py:44:            # FIXME should off/on be different for smoothing w/ BCE? Other impl out there differ
./api/search/.venv/lib/python3.12/site-packages/timm/data/imagenet_info.py:40:            # FIXME at some point pretrained_cfg should include dataset-tag,
./api/search/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:141:        # FIXME WIP, not completed. Downstream support in model needed for non-contiguous valid patches
./api/search/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:154:            # patch dropout mode, completely remove dropped patches (FIXME needs downstream support in model)
./api/search/.venv/lib/python3.12/site-packages/timm/data/naflex_random_erasing.py:324:                # FIXME we could vectorize patch mode across batch, worth the effort?
./api/search/.venv/lib/python3.12/site-packages/timm/data/dataset_factory.py:218:        # FIXME support more advance split cfg for ImageFolder/Tar datasets in the future
./api/search/.venv/lib/python3.12/site-packages/timm/data/naflex_loader.py:376:            # FIXME add crop args when sequence transforms support crop modes
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_image_in_tar.py:89:        cache_tarinfo = True if tar_bytes > 10*1024**3 else False  # FIXME magic number, 10GB
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:210:            # _logger.info(f'shuffle seed: {self.seed}, {seed}, epoch: {epoch}')  # FIXME temporary
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:434:        # _logger.info(f'start {i}, {self.worker_id}')  # FIXME temporary debug
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_wds.py:441:        # _logger.info(f'end {i}, {self.worker_id}')  # FIXME temporary debug
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:22:    # FIXME improve the selection right now just tfds prefix or fallback path, will need options to
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_factory.py:40:        # FIXME support split here or in reader?
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:146:        self.input_key = input_key  # FIXME support tuples / lists of inputs and targets and full range of Feature
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:179:        # FIXME need to determine if reinit_each_iter is necessary. I'm don't completely trust behaviour
./api/search/.venv/lib/python3.12/site-packages/timm/data/readers/reader_tfds.py:249:                num_replicas_in_sync=self.dist_num_replicas  # FIXME does this arg have any impact?
./api/search/.venv/lib/python3.12/site-packages/timm/data/transforms_factory.py:146:            # FIXME integration of RKR is a WIP
./api/search/.venv/lib/python3.12/site-packages/timm/optim/kron.py:106:        deterministic: Deterministic behaviour across save / load (resume). FIXME slow, needs work
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adamp.py:33:        # FIXME this is a problem for PyTorch XLA
./api/search/.venv/lib/python3.12/site-packages/timm/optim/lars.py:106:                    # FIXME nested where required since logical and/or not working in PT XLA
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:187:    #@_use_grad_for_differentiable  # FIXME internal context mgr, can't use
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adopt.py:454:#@_disable_dynamo_if_unsupported(single_tensor_fn=_single_tensor_adopt)  # FIXME internal context mgr, can't use
./api/search/.venv/lib/python3.12/site-packages/timm/optim/_param_groups.py:87:        # FIXME interface needs more work
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:87:        # FIXME try to check if momentum dtype is appropriate for device? Torch API not great for this.
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:119:                    # FIXME this is a bit of a hack, optimizer.load_state_dict appears to upcast
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adafactor_bv.py:337:    # FIXME TODO
./api/search/.venv/lib/python3.12/site-packages/timm/optim/adamw.py:298:                # FIXME not 100% sure if this remains capturable?
./api/search/.venv/lib/python3.12/site-packages/timm/optim/mars.py:183:                # FIXME add multi-tensor (if usage warrants), make more standard
./api/search/.venv/lib/python3.12/site-packages/timm/optim/nadamw.py:267:                # FIXME not 100% sure if this remains capturable?
./api/search/.venv/lib/python3.12/site-packages/timm/optim/lamb.py:229:                    # FIXME nested where required since logical and/or not working in PT XLA
./api/search/.venv/lib/python3.12/site-packages/timm/optim/sgdw.py:92:    # FIXME figure out how to make _use_grad_for_differentiable interchangeable with no_grad decorator
./api/search/.venv/lib/python3.12/site-packages/timm/layers/mlp.py:180:            hidden_features = hidden_features // 2  # FIXME base reduction on gate property?
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pool2d_same.py:16:    # FIXME how to deal with count_include_pad vs not for external padding?
./api/search/.venv/lib/python3.12/site-packages/timm/layers/attention2d.py:136:            # FIXME dilation
./api/search/.venv/lib/python3.12/site-packages/timm/layers/squeeze_excite.py:98:        x_se = x.mean((1, 2), keepdims=True)  # FIXME avg dim [1:n-1], don't assume 2D NHWC
./api/search/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:183:# FIXME to remove, keeping for comparison for now
./api/search/.venv/lib/python3.12/site-packages/timm/layers/patch_embed.py:596:#     FIXME WIP
./api/search/.venv/lib/python3.12/site-packages/timm/layers/drop.py:137:        self.fast = fast  # FIXME finish comparisons of fast vs not
./api/search/.venv/lib/python3.12/site-packages/timm/layers/lambda_layer.py:127:            # FIXME relative pos embedding path not fully verified
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:73:    # FIXME add support for unflattened spatial dim?
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_sincos.py:194:        # FIXME support nD
./api/search/.venv/lib/python3.12/site-packages/timm/layers/attention_pool.py:83:            # FIXME interpolate
./api/search/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:67:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./api/search/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:81:        x = x.reshape(B, groups, -1)  # FIXME simpler shape causing TPU / XLA issues
./api/search/.venv/lib/python3.12/site-packages/timm/layers/evo_norm.py:87:#group_std = group_std_tpu  # FIXME TPU temporary
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:28:    assert k_size is None, 'Different q & k sizes not currently supported'  # FIXME
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:39:    #     # FIXME different q vs k sizes is a WIP, need to better offset the two grids?
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:98:        src_size = (src_size, src_size)  # FIXME could support non-equal src if argument passed
./api/search/.venv/lib/python3.12/site-packages/timm/layers/pos_embed_rel.py:481:        # FIXME change to not use one-hot/einsum?
./api/search/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:149:        # FIXME not clear if this stride behaviour is what the paper intended
./api/search/.venv/lib/python3.12/site-packages/timm/layers/halo_attn.py:189:        # FIXME figure out how to switch impl between this and conv2d if XLA being used.
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:146:    force_in_chs = int(options['fc']) if 'fc' in options else 0  # FIXME hack to deal with in_chs issue in TPU def
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_builder.py:471:                    # FIXME s2d is a WIP
./api/search/.venv/lib/python3.12/site-packages/timm/models/_hub.py:132:    # FIXME I may change @ -> # and be parsed as fragment in a URI model name scheme
./api/search/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:95:    aa_layer: Optional[str] = None  # FIXME support string factory for this
./api/search/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:180:        # FIXME partial shortcut needed if first block handled as per original, not used for my current impl
./api/search/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:298:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./api/search/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:310:        # FIXME this 1x1 expansion is pushed down into the cross and block paths in the darknet cfgs. Also,
./api/search/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:377:                    nn.AvgPool2d(2) if stride == 2 else nn.Identity(),  # FIXME dilation handling
./api/search/.venv/lib/python3.12/site-packages/timm/models/cspnet.py:444:                nn.AvgPool2d(2) if stride == 2 else nn.Identity(),   # FIXME dilation handling
./api/search/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:525:    FIXME is there a more common 3x3 + 1x1 conv block to name this after?
./api/search/.venv/lib/python3.12/site-packages/timm/models/byobnet.py:977:        # FIXME need to dilate self attn to have dilated network support, moop moop
./api/search/.venv/lib/python3.12/site-packages/timm/models/res2net.py:62:            # FIXME this should probably have count_include_pad=False, but hurts original weights
./api/search/.venv/lib/python3.12/site-packages/timm/models/hrnet.py:536:        assert output_stride == 32  # FIXME support dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:1428:    # FIXME experimental
./api/search/.venv/lib/python3.12/site-packages/timm/models/efficientnet.py:2139:# FIXME experimental group cong / GroupNorm / EvoNorm experiments
./api/search/.venv/lib/python3.12/site-packages/timm/models/fastvit.py:349:        # FIXME output of this act was not used in original impl, likely due to bug
./api/search/.venv/lib/python3.12/site-packages/timm/models/_helpers.py:24:    # FIXME replace with 3.9 stdlib fn when min at 3.9
./api/search/.venv/lib/python3.12/site-packages/timm/models/ghostnet.py:657:        # FIXME init
./api/search/.venv/lib/python3.12/site-packages/timm/models/_manipulate.py:22:        # FIXME this a bit of a quick and dirty hack to skip classifier head params based on ordering
./api/search/.venv/lib/python3.12/site-packages/timm/models/mobilenetv3.py:650:    FIXME untested, this is a preliminary impl of some FBNet-V3 variants.
./api/search/.venv/lib/python3.12/site-packages/timm/models/regnet.py:1207:    # FIXME invalid weight <-> model match, mistake on their end
./api/search/.venv/lib/python3.12/site-packages/timm/models/metaformer.py:552:                # FIXME not actually returning mlp hidden state right now as pre-logits.
./api/search/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:297:        # FIXME MFSA and forward_intermediates overlap, they both take indices from specific features
./api/search/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:320:        # FIXME see note above
./api/search/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:359:                # FIXME fix grad checkpointing
./api/search/.venv/lib/python3.12/site-packages/timm/models/mobilenetv5.py:545:            # FIXME fix grad checkpointing
./api/search/.venv/lib/python3.12/site-packages/timm/models/dpn.py:173:        assert output_stride == 32  # FIXME look into dilation support
./api/search/.venv/lib/python3.12/site-packages/timm/models/efficientvit_mit.py:1171:# FIXME will wait for v2 SAM models which are pending
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:93:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:147:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:236:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:344:        # FIXME dilation isn't right w/ extra ks > 1 convs
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:351:                dilation=dilation,  # FIXME
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:379:                dilation=dilation,  # FIXME
./api/search/.venv/lib/python3.12/site-packages/timm/models/_efficientnet_blocks.py:668:        use_aa = aa_layer is not None and stride > 1  # FIXME handle dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/_factory.py:26:        # FIXME may use fragment as revision, currently `@` in URI path
./api/search/.venv/lib/python3.12/site-packages/timm/models/_features.py:156:    FIXME This works well in eager Python but needs redesign for torchscript.
./api/search/.venv/lib/python3.12/site-packages/timm/models/_features.py:305:                    # FIXME this may need to be more generic / flexible for some nets
./api/search/.venv/lib/python3.12/site-packages/timm/models/_features.py:359:    FIXME this does not currently work with Torchscript, see FeatureHooks class
./api/search/.venv/lib/python3.12/site-packages/timm/models/crossvit.py:73:        # FIXME look at relaxing size constraints
./api/search/.venv/lib/python3.12/site-packages/timm/models/senet.py:11:FIXME I'm deprecating this model and moving them to ResNet as I don't want to maintain duplicate
./api/search/.venv/lib/python3.12/site-packages/timm/models/vovnet.py:193:        assert output_stride == 32  # FIXME support dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/twins.py:431:        # FIXME slice block/pos_block if < max
./api/search/.venv/lib/python3.12/site-packages/timm/models/twins.py:471:        # FIXME add block pruning
./api/search/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:162:    # FIXME confirm we want 'channels last' in the patch channel layout, egg ph, ph, C instead of C, ph, hw
./api/search/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:455:            # k = h << 16 | w  # FIXME can get jit compat with this
./api/search/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:459:            # h, w = k >> 16, k & 0xFFFF  # FIXME can get jit compat with this
./api/search/.venv/lib/python3.12/site-packages/timm/models/naflexvit.py:1225:        # FIXME unfinished / untested
./api/search/.venv/lib/python3.12/site-packages/timm/models/davit.py:589:        # FIXME generalize this structure to ClassifierHead
./api/search/.venv/lib/python3.12/site-packages/timm/models/davit.py:787:        # FIXME cleaner approach to missing head norm?
./api/search/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:1772:        # hf_hub_id='timm/vit_base_patch32_clip_224.openai_ft_in12k_in1k',  # FIXME weight exists, need to push
./api/search/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2668:        # FIXME Google FlexiViT pretrained models have a strong preference for bilinear patch / embed
./api/search/.venv/lib/python3.12/site-packages/timm/models/vision_transformer.py:2674:    # FIXME attn pool (currently only in siglip) params removed if pool disabled, is there a better soln?
./api/search/.venv/lib/python3.12/site-packages/timm/models/vision_transformer_sam.py:590:                    # FIXME only apply to final? Need experiments
./api/search/.venv/lib/python3.12/site-packages/timm/models/coat.py:551:            parallel_blocks=[  # FIXME (partially?) overlap parallel w/ serial blocks??
./api/search/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:863:        # FIXME slice block/pos_block if < max
./api/search/.venv/lib/python3.12/site-packages/timm/models/mvitv2.py:905:        # FIXME add stage pruning
./api/search/.venv/lib/python3.12/site-packages/timm/models/_registry.py:217:        # FIXME should this be default behaviour? or default to include_tags=True?
./api/search/.venv/lib/python3.12/site-packages/timm/models/pit.py:365:        # FIXME need to update resize for PiT impl
./api/search/.venv/lib/python3.12/site-packages/timm/models/mlp_mixer.py:300:        # FIXME drop_path (stochastic depth scaling rule or all the same?)
./api/search/.venv/lib/python3.12/site-packages/timm/models/_prune.py:98:            # FIXME extra checks to ensure this is actually the FC classifier layer and not a diff Linear layer?
./api/search/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:566:            # FIXME handle dilation of avg pool
./api/search/.venv/lib/python3.12/site-packages/timm/models/maxxvit.py:676:        # FIXME handle dilation?
./api/search/.venv/lib/python3.12/site-packages/timm/models/edgenext.py:350:            # FIXME support dilation / output_stride
./api/search/.venv/lib/python3.12/site-packages/timm/models/densenet.py:357:                (r'^features\.transition(\d+)', MATCH_PREV_GROUP)  # FIXME combine with previous denselayer
./api/search/.venv/lib/python3.12/site-packages/timm/models/dla.py:280:        assert output_stride == 32  # FIXME support dilation
./api/search/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:116:        meta_hidden_dim: int = 384,  # FIXME what's the optimal value?
./api/search/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:137:            drop=(0.125, 0.)  # FIXME should there be stochasticity, appears to 'overfit' without?
./api/search/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:374:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./api/search/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:402:            # FIXME PyTorch XLA needs cat impl, roll not lowered
./api/search/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:759:        # FIXME more experiments needed
./api/search/.venv/lib/python3.12/site-packages/timm/models/swin_transformer_v2_cr.py:897:    # FIXME WIP determining if there's a better weight init
./api/search/.venv/lib/python3.12/site-packages/h11/_writers.py:54:    # XX FIXME: could at least make an effort to pull out the status message
./api/search/.venv/lib/python3.12/site-packages/h11/_events.py:310:# XX FIXME: "A recipient MUST ignore (or consider as an error) any fields that
./api/search/.venv/lib/python3.12/site-packages/h11/_readers.py:186:            # XX FIXME: we discard chunk extensions. Does anyone care?
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/mixture_same_family.py:120:        # FIXME this may have the wrong shape when support contains batched
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/wishart.py:38:        >>> # xdoctest: +SKIP("FIXME: scale_tril must be at least two-dimensional")
./api/search/.venv/lib/python3.12/site-packages/torch/distributions/multinomial.py:35:        >>> # xdoctest: +SKIP("FIXME: found invalid values")
./api/search/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1455:                # FIXME: Unfortunately, for Windows, we are missing a worker
./api/search/.venv/lib/python3.12/site-packages/torch/utils/hipify/hipify_python.py:475:    """FIXME: Temporarily replace std:: invocations of math functions
./api/search/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py:220:    # FIXME: Once 3.7 is the minimum version, type annotate `other` per PEP 563
./api/search/.venv/lib/python3.12/site-packages/torch/utils/benchmark/utils/cpp_jit.py:81:    # FIXME: Remove when back testing is no longer required.
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:647:        # FIXME: the docs say that persistent_id should only return a string
./api/search/.venv/lib/python3.12/site-packages/torch/serialization.py:790:        # FIXME: the docs say that persistent_id should only return a string
./api/search/.venv/lib/python3.12/site-packages/torch/_meta_registrations.py:531:    # FIXME should probably check that lengths and offset aren't both set, but
./api/search/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5464:        assert not (is_causal and attn_mask is None), "FIXME: is_causal not implemented for need_weights"
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1073:# FIXME (by @ssnl): Improve adaptive pooling docs: specify what the input and
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:923:    # FIXME: copy.deepcopy() is not defined on nn.module
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/channelshuffle.py:20:        >>> # xdoctest: +IGNORE_WANT("FIXME: incorrect want")
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/_functions.py:79:            # FIXME: https://github.com/pytorch/pytorch/issues/78656 describes
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1606:    >>> # xdoctest: +SKIP("FIXME: Would call backwards a second time")
./api/search/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1742:        >>> # xdoctest: +SKIP("FIXME: error in doctest")
./api/search/.venv/lib/python3.12/site-packages/torch/autograd/forward_ad.py:92:    # FIXME: We specify that __debug__ must be True because
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:153:    # FIXME: support multiple parameter groups
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:341:    # FIXME(@mrshenli): support multiple nn.Module instances
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:342:    # FIXME(@mrshenli): support multiple Optiimzer instances
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:343:    # FIXME(@mrshenli): need to broadcast model to sync parameters
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:405:    # FIXME: Using symbolic tracing to work around in DTensor expand mode.
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/api.py:438:        # FIXME(@mrshenli): functionalization does not work for our use
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/parallel_mode.py:167:        # FIXME: allow other sharding schemas
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/experimental_ops.py:31:    # FIXME(@mrshenli): for sqrt, this is only mathematically correct for
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:430:        # FIXME(@wanchaol, @mrshenli): the above seems to accidentally captured
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_spmd/distribute.py:626:                        # FIXME(@mrshenli): This is a temporary solution enable
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_functional_collectives_impl.py:239:    # FIXME gloo doesn't support _allgather_base
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/utils.py:373:    # FIXME (kumpera) torch.load fails if we wrap with io.BufferedReader
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/checkpoint/optimizer.py:342:        # FIXME the type of planner is wrong in load_state_dict
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/fsdp/_common_utils.py:547:    # FIXME record_stream doesn't work with non-cuda tensors
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/elastic/rendezvous/etcd_rendezvous.py:308:                # FIXME: there are a few things that fall under this like
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:389:    # FIXME: this is wrong when dim=None and one of the dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/distributed/_tensor/ops/view_ops.py:665:            # FIXME: this can be wrong for situations where we have
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset11.py:1362:    # FIXME(justinchuby): We need to handle what happens when we call b.op on a node return
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1249:        # FIXME(justinchuby): can index be an int and not a value?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1875:            # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1886:            # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1941:            # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:1956:        # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2514:        # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2586:        # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3122:    # FIXME(justinchuby): Get rid of the try catch here to improve readability
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:3126:        # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:4273:        # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:7177:        # FIXME(justinchuby): report correct name for symbolic being executed
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_helper.py:285:                # FIXME(justinchuby): Avoid catching Exception.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/symbolic_opset12.py:368:        # FIXME(justinchuby): cond is unused?
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/exporter.py:128:        # FIXME: Avoid importing onnxscript into torch
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/jit_utils.py:86:        # FIXME(justinchuby): Add the return type back once we know how to handle mypy
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:41:    # FIXME: Avoid importing onnx into torch.onnx.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/serialization.py:138:    # FIXME: Avoid importing onnx into torch.onnx.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/fx/fx_symbolic_graph_extractor.py:50:        # FIXME: This is a hack to tracing through if-else Python blocks.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:185:        # FIXME: Bug in `dynamo.export`. Sometimes outputs returned in 'list' instead of 'tuple'.
./api/search/.venv/lib/python3.12/site-packages/torch/onnx/_internal/io_adapter.py:187:        # FIXME: Bug in `dynamo.export`. Sometimes single function return is wrapped in list.
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2119:# FIXME: currently returns integers for boolean tensors
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2151:# FIXME: currently returns integers for boolean tensors
./api/search/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py:2183:# FIXME: currently returns integers for boolean tensors
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:658:            # FIXME: Implement reductions for dense dimensions for ops with non-zero reduction identities
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:705:        # FIXME: temporary workaround for issue with bfloat16/float16 remove when acctype is implemented for scatter_reduce
./api/search/.venv/lib/python3.12/site-packages/torch/masked/_ops.py:736:    # FIXME: when dense dimensions are implemented for CSR tensors
./api/search/.venv/lib/python3.12/site-packages/torch/_numpy/_ndarray.py:527:        # FIXME and they have the same dtype, device, etc
./api/search/.venv/lib/python3.12/site-packages/torch/_numpy/testing/__init__.py:19:# from .testing import assert_allclose    # FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/_numpy/_reductions_impl.py:405:    # FIXME(Mario) Doesn't np.quantile accept a tuple?
./api/search/.venv/lib/python3.12/site-packages/torch/__init__.py:1683:            # FIXME: CUDA Graph does not work well with CUPTI teardown.
./api/search/.venv/lib/python3.12/site-packages/torch/fx/experimental/proxy_tensor.py:942:        # FIXME (tmanlaibaatar)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/dynamo_test_failures.py:65:FIXME_inductor_non_strict = {
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/distributed_test.py:5218:            # FIXME: Add testing for gloo/CUDA
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:239:        # FIXME dist.barrier deadlocks with multiple threads and NCCL: https://github.com/pytorch/pytorch/issues/95895
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/_tensor/common_dtensor.py:241:        # FIXME can't use the above all_reduce as it causes hangs on bionic and focal. It hangs:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py:28:        # FIXME Once we consolidate the error messages returned by the
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4667:    # FIXME Merge this test with the corresponding one in RpcTest.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4688:    # FIXME Merge this test with the corresponding one in RpcTest.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4712:    # FIXME Merge this test with the corresponding one in RpcTest.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4745:        # FIXME We wait until the remote completed creating the OwnerRRef
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/distributed/rpc/rpc_test.py:4795:        # FIXME We wait until the remote completed creating the OwnerRRef
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:2637:            # FIXME: remove after implementing reflection pad 3d
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3412:        self.FIXME_no_cuda_gradgrad_comparison = \
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3413:            kwargs.get('FIXME_no_cuda_gradgrad_comparison', False)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_nn.py:3547:            if self.check_gradgrad and not self.FIXME_no_cuda_gradgrad_comparison:
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2635:                # FIXME: figure out the flaky -1024 anti-leaks on windows. See #8044
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2763:                        from .dynamo_test_failures import FIXME_inductor_non_strict
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:2764:                        strict_default = filename not in FIXME_inductor_non_strict
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:3128:            # FIXME: `x` is a sparse view of `v`. Currently rebase_history for
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4054:# FIXME: modernize these to be consistent with make_tensor
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4341:# FIXME: remove this by updating test suites using it
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4350:# FIXME: remove this by updating test suites using it
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4404:# FIXME: improve load_tests() documentation here
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4434:# FIXME: document this and move it to test_serialization
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4516:# FIXME: delete this
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_utils.py:4524:# FIXME: move to test_sparse or sparse utils
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/core.py:119:# FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:1854:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:2417:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:153:                    # FIXME: for now reductions with non-zero reduction identity and
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:454:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:530:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:643:            # FIXME: amax reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:652:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:653:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:682:            # FIXME: amax reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:691:            # FIXME: "cuda_scatter_gather_base_kernel_func" not implemented for ... (used for sparse_coo inputs)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:692:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:792:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:801:            # FIXME: "_segment_reduce_lengths_cpu/cuda" not implemented for ... (used for sparse_csr inputs)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:873:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:917:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:992:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/_masked.py:1163:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/special.py:244:    # TODO: FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/opinfo/definitions/fft.py:97:        # FIXME: Causes floating point exception on ROCm
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2243:        # FIXME add an override for JIT and revert 0. back to 0
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:2644:    # TODO: FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:3023:    # FIXME: eager and ref impl throw different types of errors
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4021:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4081:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:4218:    # FIXME: https://github.com/pytorch/pytorch/issues/85656
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:8146:    # FIXME: Derivative wrt. weight not implemented
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12045:               # FIXME: geqrf can't forward with complex inputs that require grad
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12317:                        # TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12678:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12689:            # TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12705:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12719:            # TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12766:                        # TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:12780:                        # TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14037:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14060:               # FIXME: both derivatives are implemented incorrectly
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14062:               # FIXME: AssertionError: False is not true : Tensors failed to compare as equal!
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14680:            # FIXME: intentionally misreports dtypes
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:14682:            # FIXME: numpy reference diverges: Comparing (nan+nanj) and (-0+0j)
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15011:                    # TODO: FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15015:                        # FIXME: incorrectly tries to pass a rhs scalar
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15019:    # TODO: FIXME, ideally by implemented grad for both inputs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15055:                        # FIXME: incorrectly tries to pass a rhs scalar
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15059:    # TODO: FIXME, ideally by implementing grad for both inputs
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15342:                        # FIXME Complex values error with: Greatest absolute difference: nan at index
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15385:                        # FIXME
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:15828:                        # TODO: FIXME tolerance is too high
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18123:               # TODO: FIXME: complex inputs requiring grad error in forward
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:18994:            # FIXME: uint8 input returns uint8 instead of bool
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19006:            # FIXME: uint8 input returns uint8 instead of bool
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19019:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19034:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19067:            # FIXME: count_nonzero does not accept keepdim kwarg
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19075:            # FIXME: dim=[] reduces all dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19084:        # FIXME: mean needs 'dim' parameter when using the 'out' overload.
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19095:            # FIXME: mean does not support passing keepdim without passing dim
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19097:            # FIXME: mean reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19100:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19123:            # FIXME: prod reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19126:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19151:            # FIXME: cannot specify keepdim without dim
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19153:            # FIXME: dim=[] reduces all dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19156:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19178:            # FIXME: dim=[] reduces all dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19199:            # FIXME: cannot specify keepdim without dim
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19201:            # FIXME: dim=[] reduces all dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19204:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19226:            # FIXME: dim=[] reduces all dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19248:            # FIXME: prod does not support passing keepdim without passing dim
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19250:            # FIXME: prod reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19253:            # FIXME: prod does not support passing None to dim
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19260:            # FIXME: ValueError: The data in MaskedTensor a and Tensor b do not match
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19283:            # FIXME: sum does not support passing keepdim without passing dim
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19285:            # FIXME: sum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19288:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19313:            # FIXME: nansum reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19316:            # FIXME: flaky test so skipped instead of xfailed
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19643:            # FIXME: CUDA driver API confirmed a leak in
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:19665:            # FIXME: CUDA driver API confirmed a leak in
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21188:            # FIXME output 0: meta disagrees with real impl
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21306:            # FIXME output 0: meta disagrees with real impl
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21632:            # FIXME: enable dtype-based tolerances in test_ops.py:TestCommon._ref_test_helper
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21851:        # FIXME: doesn't support chalf
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21864:        # FIXME: doesn't support chalf
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:21900:            # FIXME: AssertionError: RuntimeError not raised
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22180:            # FIXME: uint8 input returns uint8 instead of bool
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22191:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22203:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22214:            # FIXME: uint8 input returns uint8 instead of bool
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22224:            # FIXME: count_nonzero does not accept keepdim kwarg
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22239:            # FIXME: dim=[] reduces all dimensions
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22249:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22261:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22266:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22286:            # FIXME: doesn't test out behavior properly for this operator
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22288:            # FIXME: mean reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22292:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22334:            # FIXME: doesn't test out behavior properly for this operator
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22336:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22341:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22352:            # FIXME: reduces all dimensions when dim=[]
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22357:            # FIXME: improve precision
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22417:            # FIXME: shouldn't check empty results
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22447:            # FIXME: should not compare results of empty_like
./api/search/.venv/lib/python3.12/site-packages/torch/testing/_internal/common_methods_invocations.py:22503:            # FIXME: should not compare results of empty_like
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:709:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:800:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./api/search/.venv/lib/python3.12/site-packages/torch/ao/nn/quantized/modules/conv.py:893:        >>> # xdoctest: +SKIP("FIXME: output_size is not a parameter)
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:202:            # FIXME that's a crude approximation for promoting args
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:2983:        # FIXME: Calling to_device(x, device) should work but
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:3662:    # FIXME: in some cases we sill need to explicitly pass in ordered_kwargs_for_cpp_kernel
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/ir.py:4956:        # FIXME: no need to do this after we switch to the torchgen-ed C shim
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codecache.py:1252:        # FIXME: passing `-fopenmp` adds libgomp.so to the generated shared library's dependencies.
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/cpp_wrapper_cpu.py:1837:            # FIXME handle embedded optional types?
./api/search/.venv/lib/python3.12/site-packages/torch/_inductor/codegen/triton.py:2628:        # FIXME: This is not exactly right for cases like below:
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/backends/onnxrt.py:15:    # FIXME(abock): update test/dynamo/test_backends.py to call is_onnxrt_backend_supported()
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1417:        # FIXME (tmanlaibaatar) this is utter hack to unblock HuggingFace export
./api/search/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3355:            obj, obj.__name__, getfile(obj), obj.__code__  # type: ignore[union-attr] # FIXME Add MethodType.__code__ to typeshed
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/core/ivalue_inl.h:920:      // FIXME We should always extract DataPtrs, in order to catch the case of
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/Resize.h:116:  // FIXME: stride should be optional
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/cuda/DistributionTemplates.h:106: * FIXME: Can we specialize elementwise_kernel and launch_kernel in Loops.cuh
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/native/UpSample.h:259:      // FIXME: remove magic > 0 after we ensure no models were serialized with -1 defaults.
./api/search/.venv/lib/python3.12/site-packages/torch/include/ATen/ScalarOps.h:28:// FIXME: this should be (and was) Scalar::toTensor, but there is currently no
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/llvmMathExtras.h:749:/// \todo FIXME: remove when \c constexpr becomes really \c constexpr
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:154:    this->Size = this->Capacity = 0; // FIXME: Setting Capacity to 0 is suspect.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:768:  // FIXME: Consider assigning over existing elements, rather than clearing &
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1106:  // FIXME: don't do this if they're efficiently moveable.
./api/search/.venv/lib/python3.12/site-packages/torch/include/c10/util/SmallVector.h:1169:  // FIXME: this may not actually make any sense if we can efficiently move
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/inductor/aoti_runtime/device_utils.h:10:// FIXME: Currently, CPU and CUDA backend are mutually exclusive.
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/distributed/c10d/ProcessGroupGloo.hpp:68:  // FIXME: This probably should be called WorkGloo since the work is executed
./api/search/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include/torch/detail/TensorDataContainer.h:31:// FIXME: There is no `operator<<` overload for `at::kBFloat16` type,
./api/search/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:125:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./api/search/.venv/lib/python3.12/site-packages/torch/include/tensorpipe/common/buffer.h:130:    // FIXME: Once we go C++17, use std::launder on the returned pointer.
./api/search/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:185:                    # FIXME: CUDA Graph does not work well with CUPTI teardown.
./api/search/.venv/lib/python3.12/site-packages/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./api/search/.venv/lib/python3.12/site-packages/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./api/search/.venv/lib/python3.12/site-packages/h2/connection.py:1808:            # FIXME: Should we split this into one event per active stream?
./api/search/.venv/lib/python3.12/site-packages/urllib3/util/response.py:99:    # FIXME: Can we do this somehow without accessing private httplib _method?
./api/search/.venv/lib/python3.12/site-packages/urllib3/response.py:782:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./api/search/.venv/lib/python3.12/site-packages/urllib3/response.py:787:                # FIXME: Is there a better way to differentiate between SSLErrors?
./api/search/.venv/lib/python3.12/site-packages/urllib3/response.py:1051:        # FIXME, this method's type doesn't say returning None is possible
./api/search/.venv/lib/python3.12/site-packages/urllib3/response.py:1219:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:72:       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:75:       Now recognizes ``FIXME`` by default.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py:81:                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/metadata.py:443:            # FIXME this rejects UNKNOWN, is that right?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/distlib/database.py:933:                # FIXME handle the case where zipfile is not available
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/util/response.py:103:    # FIXME: Can we do this somehow without accessing private httplib _method?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py:371:        # FIXME rethrow compatible exceptions should we ever use this
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:441:                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:446:                # FIXME: Is there a better way to differentiate between SSLErrors?
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py:798:        # FIXME: Rewrite this method and make it a class with a better structured logic.
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:2031:    # FIXME: 'ZipProvider._extract_resource' is too complex (12)
./api/search/.venv/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py:3201:    # FIXME: 'Distribution.insert_on' is too complex (13)
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:326:        # FIXME: handle?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/utils/unpacking.py:327:        # FIXME: magic signatures?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:15:# FIXME doesn't account for venv linked to global site-packages
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/locations/base.py:59:        # FIXME: keep src in cwd for now (it is not a temporary folder)
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/build_env.py:200:                # FIXME: Consider direct URL?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/vcs/subversion.py:59:                # FIXME: should we warn?
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/req_uninstall.py:480:            # FIXME: need a test for this elif block
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/req_install.py:371:        # FIXME: Is there a better place to create the build_dir? (hg and bzr
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/req/req_file.py:259:            # FIXME: it would be nice to keep track of the source
./api/search/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py:631:            # FIXME: https://github.com/pypa/pip/issues/11943
./api/search/.venv/lib/python3.12/site-packages/torchgen/native_function_generation.py:466:            # FIXME: Remove this after figuring out CI job failures related to min, max, mean
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_trace_type.py:67:    # FIXME: figure out a better way when we support sparse tensors in jit
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:98:    # FIXME: clone indices on construction.
./api/search/.venv/lib/python3.12/site-packages/torchgen/packaged/autograd/gen_inplace_or_view_type.py:252:# FIXME: Ideally these functions should be methods on Type class, but we have a
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:901:# FIXME: Fails _cdfvec
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/_discrete_distns.py:1294:# FIXME: problems sampling.
./api/search/.venv/lib/python3.12/site-packages/scipy/stats/tests/test_distributions.py:9003:    # FIXME: this is only a quick-and-dirty test of a quick-and-dirty bugfix.
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:799:            # FIXME: implement this somewhen, for now go with builtin values
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:800:            # FIXME: calc optimal lwork by calling ?hbevd(lwork=-1)
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/_decomp.py:805:            # FIXME: implement this somewhen, for now go with builtin values
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:903:    # FIXME: suppress?
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:904:    # FIXME: how to catch the _fblas.error?
./api/search/.venv/lib/python3.12/site-packages/scipy/linalg/tests/test_blas.py:942:    # prints '0-th dimension must be fixed to 3 but got 5', FIXME: suppress?
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/common/_helpers.py:740:        # FIXME Jitted JAX arrays do not have a device attribute
./api/search/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_extra/_lib/_utils/_helpers.py:325:        # FIXME https://github.com/jax-ml/jax/issues/27418
./api/search/.venv/lib/python3.12/site-packages/scipy/differentiate/tests/test_differentiate.py:585:        # FIXME https://github.com/scipy/scipy/pull/22320#discussion_r1914898175
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/_constraints.py:492:    # FIXME: when bugs in VectorFunction/LinearVectorFunction are worked out,
./api/search/.venv/lib/python3.12/site-packages/scipy/optimize/tests/test__dual_annealing.py:69:    # FIXME: there are some discontinuities in behaviour as a function of `qv`,
./api/search/.venv/lib/python3.12/site-packages/scipy/integrate/_ode.py:392:            # FIXME: this really should be raise an exception. Will that break
./api/search/.venv/lib/python3.12/site-packages/scipy/conftest.py:504:    # FIXME: populate the dict once
./api/search/.venv/lib/python3.12/site-packages/scipy/spatial/tests/test_kdtree.py:634:        # raises an exception for bug 870 (FIXME: Does it?)
./api/search/.venv/lib/python3.12/site-packages/scipy/spatial/_kdtree.py:913:        result = np.empty((m,n),dtype=float)  # FIXME: figure out the best dtype
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/_delegators.py:21:         sig = "( FIXME )"
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/tests/test_bsplines.py:110:        # FIXME: for complex types, the computations are done in
./api/search/.venv/lib/python3.12/site-packages/scipy/signal/_signaltools.py:4339:    # FIXME: Can this function be replaced with an appropriate
./api/search/.venv/lib/python3.12/site-packages/numpy/linalg/tests/test_linalg.py:1007:    #FIXME the 'e' dtype might work in future
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_mem_policy.py:12:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_multiarray.py:6159:        # FIXME:
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_array_interface.py:131:# FIXME: numpy.testing.extbuild uses `numpy.distutils`, so this won't work on
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath_complex.py:19:#FIXME: this will probably change when we require full C99 campatibility
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1129:        # FIXME cinf not tested.
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1774:                        reason='failures on 32-bit Python, see FIXME below')
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1818:        # FIXME: NAN raises FP invalid exception:
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:1821:        # FIXME: skipped on MSVC:32-bit during switch to Meson, 10 cases fail
./api/search/.venv/lib/python3.12/site-packages/numpy/core/tests/test_umath.py:2794:            # FIXME: a not used
./api/search/.venv/lib/python3.12/site-packages/numpy/core/include/numpy/ndarraytypes.h:1758:     * FIXME: This should check for a flag on the data-type that
./api/search/.venv/lib/python3.12/site-packages/numpy/lib/npyio.py:236:        # FIXME: This seems like it will copy strings around
./api/search/.venv/lib/python3.12/site-packages/numpy/ma/core.py:2839:            # FIXME: should we set `_data._sharedmask = True`?
./api/search/.venv/lib/python3.12/site-packages/numpy/ma/tests/test_old_ma.py:654:        #TODO FIXME: Find out what the following raises a warning in r8247
./api/search/.venv/lib/python3.12/site-packages/numpy/conftest.py:73:#FIXME when yield tests are gone.
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/image_to_text.py:204:        # FIXME: We need to pop here due to a difference in how `generation.py` and `generation.tf_utils.py`
./api/search/.venv/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:380:            # FIXME: ydshieh and/or Narsil
./api/search/.venv/lib/python3.12/site-packages/transformers/modeling_gguf_pytorch_utils.py:376:    # FIXME: Currently this implementation is only for flan-t5 architecture.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/esm/openfold_utils/protein.py:85:                    seq[i] = "X"  # FIXME: strings are immutable
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bamba/modeling_bamba.py:472:        # FIXME:
./api/search/.venv/lib/python3.12/site-packages/transformers/models/bamba/modular_bamba.py:241:        # FIXME:
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics3/image_processing_idefics3.py:229:# FIXME Amy: make a more general crop function that isn't just centre crop
./api/search/.venv/lib/python3.12/site-packages/transformers/models/smolvlm/image_processing_smolvlm.py:226:# FIXME Amy: make a more general crop function that isn't just centre crop
./api/search/.venv/lib/python3.12/site-packages/transformers/models/idefics2/image_processing_idefics2.py:125:# FIXME Amy: merge this function with the one in image_transforms.py
./api/search/.venv/lib/python3.12/site-packages/transformers/models/detr/modeling_detr.py:1653:        # FIXME h_boxes takes the last one computed, keep this in mind
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:426:        # FIXME max_tokens_to_generate is embedded into this processor's call.
./api/search/.venv/lib/python3.12/site-packages/transformers/models/fuyu/processing_fuyu.py:539:        # FIXME - We hard code "pt" here because the rest of the processing assumes torch tensors
./api/search/.venv/lib/python3.12/site-packages/transformers/models/conditional_detr/modeling_conditional_detr.py:1958:        # FIXME h_boxes takes the last one computed, keep this in mind
./api/search/.venv/lib/python3.12/site-packages/joblib/logger.py:144:            # FIXME: Too much logic duplicated
./api/search/.venv/lib/python3.12/site-packages/boto3/exceptions.py:100:# FIXME: Backward compatibility
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:911:        "check_estimators_empty_data_messages": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:912:        "check_estimators_nan_inf": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:913:        "check_estimator_sparse_array": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:914:        "check_estimator_sparse_matrix": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:915:        "check_fit1d": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:916:        "check_fit2d_predict1d": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:917:        "check_complex_data": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:918:        "check_fit2d_1feature": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:925:        "check_estimators_overwrite_params": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:926:        "check_estimators_nan_inf": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:927:        "check_dont_overwrite_parameters": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:966:        "check_estimators_nan_inf": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:967:        "check_classifiers_one_label_sample_weights": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:968:        "check_fit2d_1feature": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:976:        "check_estimators_nan_inf": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:977:        "check_classifiers_one_label_sample_weights": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:978:        "check_fit2d_1feature": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1216:        "check_dict_unchanged": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1280:                    "check_n_features_in_after_fitting": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/_test_common/instance_generator.py:1281:                    "check_dataframe_column_names_consistency": "FIXME",
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1392:# FIXME: this test should be uncommented when the checks will be granular
./api/search/.venv/lib/python3.12/site-packages/sklearn/utils/tests/test_estimator_checks.py:1397:    # FIXME
./api/search/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/tests/test_gpr.py:760:    # FIXME: before fitting, the estimator does not have information regarding
./api/search/.venv/lib/python3.12/site-packages/sklearn/preprocessing/tests/test_common.py:98:    # FIXME: we can introduce equal_nan=True in recent version of numpy.
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:117:        eps = np.finfo(np.float32).eps  # FIXME: This is quite large!
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:517:                # FIXME: we could consider to support multiclass-multioutput if
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:175:            # FIXME: We temporarily bypass this test. This is due to the fact
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_gradient_boosting.py:691:    # FIXME: the following snippet does not yield the same results on 32 bits
./api/search/.venv/lib/python3.12/site-packages/sklearn/ensemble/tests/test_common.py:252:# FIXME: we should move this test in `estimator_checks` once we are able
./api/search/.venv/lib/python3.12/site-packages/sklearn/neighbors/tests/test_kde.py:127:    # FIXME
./api/search/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:623:        # FIXME
./api/search/.venv/lib/python3.12/site-packages/sklearn/multioutput.py:1164:        # FIXME
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_selection/tests/test_from_model.py:483:    # FIXME: we cannot validate the upper bound of the attribute at transform
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/_agglomerative.py:606:        # FIXME We compute all the distances, while we could have only computed
./api/search/.venv/lib/python3.12/site-packages/sklearn/cluster/tests/test_affinity_propagation.py:278:# FIXME; this test is broken with different random states, needs to be revisited
./api/search/.venv/lib/python3.12/site-packages/sklearn/compose/_target.py:281:        # FIXME: a FunctionTransformer can return a 1D array even when validate
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:109:        # FIXME: the current Cython implementation is too slow for a large number of
./api/search/.venv/lib/python3.12/site-packages/sklearn/metrics/tests/test_pairwise_distances_reduction.py:698:    # FIXME: the current Cython implementation is too slow for a large number of
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/_glm/tests/test_glm.py:376:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:330:    # FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:392:        # FIXME: Same as in test_ridge_regression_unpenalized.
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_ridge.py:447:        # FIXME: Same as in test_ridge_regression_unpenalized.
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1551:        # FIXME
./api/search/.venv/lib/python3.12/site-packages/sklearn/linear_model/tests/test_logistic.py:1558:        # FIXME: SAGA on sparse data fits the intercept inaccurately with the
./api/search/.venv/lib/python3.12/site-packages/sklearn/cross_decomposition/tests/test_pls.py:78:    # FIXME: one would expect y_trans == pls.y_scores_ but this is not
./api/search/.venv/lib/python3.12/site-packages/sklearn/model_selection/tests/test_search.py:2540:# FIXME: Replace this test with a full `check_estimator` once we have API only
./api/search/.venv/lib/python3.12/site-packages/sklearn/multiclass.py:1207:        # FIXME: there are more elaborate methods than generating the codebook
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_multiclass.py:903:# FIXME: we should move this test in `estimator_checks` once we are able
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_multioutput.py:745:# FIXME: we should move this test in `estimator_checks` once we are able
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:65:    # FIXME Remove this test once the more general partial_fit tests are merged
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_naive_bayes.py:308:    # FIXME: write a test to show this.
./api/search/.venv/lib/python3.12/site-packages/sklearn/tests/test_pipeline.py:1718:# FIXME: Replace this test with a full `check_estimator` once we have API only
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_compat/common/_helpers.py:657:        # FIXME Jitted JAX arrays do not have a device attribute
./api/search/.venv/lib/python3.12/site-packages/sklearn/externals/array_api_extra/_lib/_funcs.py:715:    # FIXME https://github.com/data-apis/array-api-compat/pull/231
./api/search/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1728:        # FIXME: np.float16 could be preserved if _inplace_csr_row_normalize_l2
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/shortest_paths/tests/test_weighted.py:890:        # FIXME nx.goldberg_radzik(D, 1)
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:713:                # FIXME directed graphs
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:809:            # FIXME directed graphs
./api/search/.venv/lib/python3.12/site-packages/networkx/algorithms/isomorphism/ismags.py:859:                    # FIXME directed graphs
./api/search/.venv/lib/python3.12/site-packages/mpmath/tests/test_interval.py:378:    # FIXME: error_dps should not be necessary
```

**Recommended Thresholds:**
- TODO: <20 items (informational debt)
- FIXME: <5 items (critical debt requiring attention)

---

## Summary and Recommendations

### Quality Metrics Overview

| Metric | Status | Score/Count | Threshold | Action Required |
|--------|--------|-------------|-----------|-----------------|
| Ruff Linting | See above | See above | 0 issues | Fix linting issues |
| Black Formatting | See above | See above | 0 files | Run `black .` |
| MyPy Type Checking | See above | See above | 0 errors | Add type hints |
| Clang-Tidy (C++) | See above | See above | 0 errors, <10 warnings | Fix C++ issues |
| TODO Count | See above | See above | <20 items | Review and resolve |
| FIXME Count | See above | See above | <5 items | **Priority: Fix immediately** |
| Test Coverage | See above | See above | >80% | Write more tests |

### Recommended Actions

1. **High Priority:**
   - Fix all FIXME items immediately
   - Resolve any failing tests
   - Address critical linting errors

2. **Medium Priority:**
   - Improve test coverage to >80%
   - Fix type checking errors
   - Resolve C++ linting warnings

3. **Low Priority:**
   - Clean up TODO items
   - Improve code formatting consistency
   - Enhance documentation

### Quality Gates

For production deployment, ensure:
- [ ] All tests pass
- [ ] Test coverage >80%
- [ ] No FIXME items remain
- [ ] No critical linting errors
- [ ] Type checking passes
- [ ] Code is properly formatted

### Next Steps

1. Run individual tools to fix specific issues:
   ```bash
   # Fix Python formatting
   black .
   
   # Fix Python imports and basic issues
   ruff check --fix .
   
   # Run tests
   pytest --cov=.
   
   # Type check
   mypy .
   ```

2. Set up pre-commit hooks to maintain quality
3. Configure CI/CD pipeline with these quality checks
4. Regular quality reviews and technical debt cleanup

---

**Report Generated:** $(date)  
**Total Runtime:** $(date -d@$(($(date +%s) - START_TIME)) -u +%H:%M:%S)
