# ────────── LOCAL PATHS ──────────
# Absolute or relative; all will be created if missing.
VP_INPUT_DIR=videos_raw # for local testing only.
VP_OUTPUT_DIR=.output
VP_TMP_DIR=.output/tmp
VP_FRAMES_DIR=.output/tmp/frames
VP_LOGS_DIR=.output/logs
VP_REPORTS_DIR=.output/reports

# ────────── PERFORMANCE KNOBS ──────────
VP_MAX_WORKERS=4          # ffmpeg crop threads
VP_BATCH_SIZE=8           # CLIP micro-batch size
VP_SAMPLE_FPS=0.1         # fallback uniform sampling when scene split too sparse

# ────────── OPTIONAL STEPS ──────────
VP_ENABLE_CROP=1          # 1=run border-crop, 0=skip
VP_ENABLE_DEDUP=1         # 1=run dHash dedup, 0=skip

# ────────── CROPPING PARAMS ──────────
VP_CROP_PROBES=3
VP_CROP_CLIP_SECS=2
VP_CROP_SAFE_MARGIN=4
VP_CROP_HWACCEL=cuda
VP_CROP_CROPDETECT=24:16:0
VP_CROP_ENCODER=h264_nvenc
VP_CROP_PRESET=p5
VP_CROP_TUNE=hq
VP_CROP_CQ=23

# ────────── OPENCV & FFMPEG ──────────
VP_SCENE_THRESH=0.12      # ffmpeg scene change threshold
VP_MIN_FRAMES=12          # guarantee at least this many frames per video
VP_TOLERANCE=5            # border detection tolerance
VP_EDGE_THRESH=10
VP_DHASH_SIZE=8           # dHash resolution

# ────────── MODEL SELECTION ──────────
CLIP_MODEL=jina_ai/jina-clip-v2
FORCE_CPU=0                   # 1=force CPU even if CUDA available, 0=use GPU if available

# ────────── QDRANT (VECTOR DB) ──────────
QDRANT_URL=https://QDRANT-ENDPOINT:6333
QDRANT_KEY=QDRANT_API_KEY
QDRANT_COLLECTION=watched_frames
QDRANT_DIM=512

# ────────── AWS & S3 BUCKETS ──────────
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
S3_VIDEOS_BUCKET=oriane-contents
S3_FRAMES_BUCKET=oriane-frames
S3_APP_BUCKET=oriane-app

# ────────── AURORA POSTGRESQL ──────────
DB_HOST=
DB_PORT=5432
DB_NAME=
DB_USER=
DB_PASSWORD=

# ────────── LOCAL / DEV FLAGS ──────────
# Set LOCAL_MODE=1  ➜ skip all DB writes
# Set SKIP_UPLOAD=1 ➜ skip frame PNG uploads to S3
# Leave unset (or 0) for full production behaviour
LOCAL_MODE=0
SKIP_UPLOAD=0
